{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be564ffe-7c6a-4983-a927-c53f79fe530b",
   "metadata": {},
   "source": [
    "> ### EEE4423: Deep Learning Lab\n",
    "\n",
    "# Final Project: Long-tail Visual Recognition for Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a79cfd0-d8f1-4f72-a4c8-13cea70ff275",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T13:15:24.008695Z",
     "iopub.status.busy": "2022-06-18T13:15:24.008249Z",
     "iopub.status.idle": "2022-06-18T13:15:25.953242Z",
     "shell.execute_reply": "2022-06-18T13:15:25.951795Z",
     "shell.execute_reply.started": "2022-06-18T13:15:24.008646Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/jovyan_venv/.venv/torch1.9.0-py3.8-cuda11.1/lib/python3.8/site-packages (22.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc95aaf9-45c8-4742-95ed-b20a8a1172a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T13:15:25.956945Z",
     "iopub.status.busy": "2022-06-18T13:15:25.956366Z",
     "iopub.status.idle": "2022-06-18T13:15:27.747677Z",
     "shell.execute_reply": "2022-06-18T13:15:27.746135Z",
     "shell.execute_reply.started": "2022-06-18T13:15:25.956870Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /home/jovyan_venv/.venv/torch1.9.0-py3.8-cuda11.1/lib/python3.8/site-packages (2.10.1)\n",
      "Requirement already satisfied: alembic in /home/jovyan_venv/.venv/torch1.9.0-py3.8-cuda11.1/lib/python3.8/site-packages (from optuna) (1.8.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /home/jovyan_venv/.venv/torch1.9.0-py3.8-cuda11.1/lib/python3.8/site-packages (from optuna) (1.4.37)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optuna) (1.22.2)\n",
      "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.8.0)\n",
      "Requirement already satisfied: cliff in /home/jovyan_venv/.venv/torch1.9.0-py3.8-cuda11.1/lib/python3.8/site-packages (from optuna) (3.10.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: colorlog in /home/jovyan_venv/.venv/torch1.9.0-py3.8-cuda11.1/lib/python3.8/site-packages (from optuna) (6.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: tqdm in /home/jovyan_venv/.venv/torch1.9.0-py3.8-cuda11.1/lib/python3.8/site-packages (from optuna) (4.62.3)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /home/jovyan_venv/.venv/torch1.9.0-py3.8-cuda11.1/lib/python3.8/site-packages (from optuna) (0.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->optuna) (3.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/jovyan_venv/.venv/torch1.9.0-py3.8-cuda11.1/lib/python3.8/site-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
      "Requirement already satisfied: importlib-metadata in /home/jovyan_venv/.venv/torch1.9.0-py3.8-cuda11.1/lib/python3.8/site-packages (from alembic->optuna) (4.10.1)\n",
      "Requirement already satisfied: Mako in /home/jovyan_venv/.venv/torch1.9.0-py3.8-cuda11.1/lib/python3.8/site-packages (from alembic->optuna) (1.2.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic->optuna) (5.4.0)\n",
      "Requirement already satisfied: autopage>=0.4.0 in /home/jovyan_venv/.venv/torch1.9.0-py3.8-cuda11.1/lib/python3.8/site-packages (from cliff->optuna) (0.5.1)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /home/jovyan_venv/.venv/torch1.9.0-py3.8-cuda11.1/lib/python3.8/site-packages (from cliff->optuna) (5.9.0)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /home/jovyan_venv/.venv/torch1.9.0-py3.8-cuda11.1/lib/python3.8/site-packages (from cliff->optuna) (3.5.0)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /home/jovyan_venv/.venv/torch1.9.0-py3.8-cuda11.1/lib/python3.8/site-packages (from cliff->optuna) (3.3.0)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /home/jovyan_venv/.venv/torch1.9.0-py3.8-cuda11.1/lib/python3.8/site-packages (from cliff->optuna) (2.4.1)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /home/jovyan_venv/.venv/torch1.9.0-py3.8-cuda11.1/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->alembic->optuna) (3.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c02ddadf-1c1d-4697-bc9e-1dd4855e2fbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-23T05:42:54.102357Z",
     "iopub.status.busy": "2022-06-23T05:42:54.101862Z",
     "iopub.status.idle": "2022-06-23T05:42:56.919090Z",
     "shell.execute_reply": "2022-06-23T05:42:56.917981Z",
     "shell.execute_reply.started": "2022-06-23T05:42:54.102287Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import optuna\n",
    "import joblib\n",
    "\n",
    "\n",
    "from misc.project.utils import resnet18, IMBALANCECIFAR10_V, IMBALANCECIFAR100_V, compute_accuracy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48bbdadb-65e7-46e6-934d-98a6f29f875d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T13:15:27.792050Z",
     "iopub.status.busy": "2022-06-18T13:15:27.791187Z",
     "iopub.status.idle": "2022-06-18T13:15:27.797589Z",
     "shell.execute_reply": "2022-06-18T13:15:27.796681Z",
     "shell.execute_reply.started": "2022-06-18T13:15:27.792014Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET = 'CIFAR10' #['CIFAR10', 'CIFAR100']\n",
    "IMB_TYPE = 'exp' #['exp', 'step']\n",
    "IMB_FACTOR = 0.01 #[0.1, 0.01]\n",
    "SAVE_DIR = 'logs/exp-0.1' \n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "os.makedirs(osp.join(SAVE_DIR), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54550ce4-ff87-418a-af80-71f13e30cb88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T13:15:27.798952Z",
     "iopub.status.busy": "2022-06-18T13:15:27.798708Z",
     "iopub.status.idle": "2022-06-18T13:15:27.806393Z",
     "shell.execute_reply": "2022-06-18T13:15:27.805690Z",
     "shell.execute_reply.started": "2022-06-18T13:15:27.798924Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# num_cls = 10, 100 (CIFAR10, CIFAR100)\n",
    "# val_num_each_cls = 1000, 100 (CIFAR10, CIFAR100)\n",
    "\n",
    "def for_split_set(num_cls, val_num_each_cls, samples_of_each_cls):\n",
    "    val_idx_list = []\n",
    "    for i in range(num_cls):\n",
    "        for j in range(val_num_each_cls):\n",
    "            index = np.random.randint(i*0, (i+1)*samples_of_each_cls) # 0~4999의 숫자를 랜덤으로 하나 뽑는다.\n",
    "            while index in val_idx_list: # index가 이미 리스트에 있다면 다시 뽑는다.\n",
    "                index = np.random.randint(i*0, (i+1)*samples_of_each_cls) # 0~4999의 숫자를 랜덤으로 하나 뽑는다.\n",
    "            val_idx_list.append(index)\n",
    "\n",
    "    train_idx = np.arange(50000)\n",
    "    train_idx_list = list(np.delete(train_idx, val_idx_list))\n",
    "\n",
    "    for i in val_idx_list:\n",
    "        if i in train_idx_list:\n",
    "            print(\"중복이 있습니다!\")\n",
    "    \n",
    "    return val_idx_list, train_idx_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c1c03c5-6c7f-44eb-a2af-ef8fb447c7f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T13:15:27.808092Z",
     "iopub.status.busy": "2022-06-18T13:15:27.807466Z",
     "iopub.status.idle": "2022-06-18T13:15:27.812980Z",
     "shell.execute_reply": "2022-06-18T13:15:27.812275Z",
     "shell.execute_reply.started": "2022-06-18T13:15:27.808064Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89cd2ed6-fb5c-4218-a236-17e9f6116b82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T13:15:43.559125Z",
     "iopub.status.busy": "2022-06-18T13:15:43.558637Z",
     "iopub.status.idle": "2022-06-18T13:15:43.570271Z",
     "shell.execute_reply": "2022-06-18T13:15:43.569169Z",
     "shell.execute_reply.started": "2022-06-18T13:15:43.559084Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_loaders():\n",
    "    # inbalance 된거니까 쓰면됨\n",
    "    if DATASET == 'CIFAR10':\n",
    "        val_idx, train_idx = for_split_set(10, 1000, 5000)\n",
    "        train_dataset = IMBALANCECIFAR10_V(root='../dataset/project', imb_type=IMB_TYPE, imb_factor=IMB_FACTOR, sub_idx=val_idx, train=True, download=True, transform=transform_train)\n",
    "        val_dataset = IMBALANCECIFAR10_V(root='../dataset/project', imb_factor=1, train=True, download=True, sub_idx=train_idx, transform=transform_test)\n",
    "    elif DATASET == 'CIFAR100':\n",
    "        val_idx, train_idx = for_split_set(100, 100, 500)\n",
    "        train_dataset = IMBALANCECIFAR100_V(root='../dataset/project', imb_type=IMB_TYPE, imb_factor=IMB_FACTOR, sub_idx=val_idx, train=True, download=True, transform=transform_train)\n",
    "        val_dataset = IMBALANCECIFAR100_V(root='../dataset/project', imb_factor=1, train=True, download=True, sub_idx=train_idx, transform=transform_test)\n",
    "\n",
    "    cls_num_list = train_dataset.get_cls_num_list()\n",
    "    print('cls num list(train_dataset):')\n",
    "    print(cls_num_list)\n",
    "\n",
    "    cls_num_list = val_dataset.get_cls_num_list()\n",
    "    print('cls num list(val_dataset):')\n",
    "    print(cls_num_list)\n",
    "    num_classes = len(cls_num_list)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "        num_workers=4, drop_last=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=100, shuffle=False,\n",
    "        num_workers=4, )\n",
    "\n",
    "    return train_loader, val_loader, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ecbc751-1e5a-4fc2-8858-b93552215c54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T13:15:58.542313Z",
     "iopub.status.busy": "2022-06-18T13:15:58.541687Z",
     "iopub.status.idle": "2022-06-18T13:15:58.548878Z",
     "shell.execute_reply": "2022-06-18T13:15:58.548031Z",
     "shell.execute_reply.started": "2022-06-18T13:15:58.542271Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.backbone = resnet18()\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = F.adaptive_max_pool2d(x, 1)\n",
    "        x = x.view(batch_size, -1)\n",
    "        pred = self.classifier(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c1307c2-cf1f-4715-b5f5-ffb01905deb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T13:16:00.006730Z",
     "iopub.status.busy": "2022-06-18T13:16:00.006292Z",
     "iopub.status.idle": "2022-06-18T13:16:00.015811Z",
     "shell.execute_reply": "2022-06-18T13:16:00.015016Z",
     "shell.execute_reply.started": "2022-06-18T13:16:00.006692Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(EPOCHS, model, train_loader, criterion, optimizer, scheduler):\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        loss_history = []\n",
    "        model.train()\n",
    "        for batch_index, data in enumerate(train_loader):\n",
    "            image, target = data\n",
    "            image, target = image.cuda(), target.cuda()\n",
    "\n",
    "            pred = model(image)\n",
    "            loss = criterion(pred, target)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_history.append(loss.item())\n",
    "\n",
    "        topk_acc, head_acc, tail_acc = compute_accuracy(train_loader, model)\n",
    "        loss_mean = np.mean(loss_history)\n",
    "        scheduler.step()\n",
    "\n",
    "        print('Epoch: [{:03d}] \\t Loss {:.4f} \\t Acc {:.2f} \\t AccHead {:.2f} \\t AccTail {:.2f}'.format(epoch+1, loss_mean, topk_acc[0], head_acc[0], tail_acc[0]))\n",
    "\n",
    "    torch.save({\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch},\n",
    "        osp.join(SAVE_DIR, 'ep{:03d}.pth'.format(EPOCHS))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cd43044-7d8d-4526-9903-21b9f5fa6adc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T13:16:05.007895Z",
     "iopub.status.busy": "2022-06-18T13:16:05.007438Z",
     "iopub.status.idle": "2022-06-18T13:16:05.013943Z",
     "shell.execute_reply": "2022-06-18T13:16:05.013098Z",
     "shell.execute_reply.started": "2022-06-18T13:16:05.007856Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    topk_acc, head_acc, tail_acc = compute_accuracy(test_loader, model)\n",
    "    # head : training sample개수가 많은 집함, tail : training samplg이 적은 아이들 -> head의 성능저하를 최소화하고 tail의 성능을 올리는 것이 목표\n",
    "    print('Acc {:.2f} \\t AccHead {:.2f} \\t AccTail {:.2f}'.format(topk_acc[0], head_acc[0], tail_acc[0]))\n",
    "\n",
    "    accuracy = topk_acc[0]\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8202390-44b0-4ce5-9ba1-d5422174e3ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T13:16:07.025586Z",
     "iopub.status.busy": "2022-06-18T13:16:07.025148Z",
     "iopub.status.idle": "2022-06-18T13:16:46.508163Z",
     "shell.execute_reply": "2022-06-18T13:16:46.507195Z",
     "shell.execute_reply.started": "2022-06-18T13:16:07.025537Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cls num list(train_dataset):\n",
      "[4000, 2397, 1437, 861, 516, 309, 185, 111, 66, 40]\n",
      "cls num list(val_dataset):\n",
      "[1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]\n"
     ]
    }
   ],
   "source": [
    "LR = 0.1 # 이거 줄이면 시간 너무오래걸림.\n",
    "MOMENTUM = 0.9\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "torch.manual_seed(0)\n",
    "train_loader, test_loader, num_classes = get_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1463ec0d-4aaa-406c-8b8d-c4324afbe266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T13:16:46.523774Z",
     "iopub.status.busy": "2022-06-18T13:16:46.523658Z",
     "iopub.status.idle": "2022-06-18T13:16:46.529175Z",
     "shell.execute_reply": "2022-06-18T13:16:46.528558Z",
     "shell.execute_reply.started": "2022-06-18T13:16:46.523761Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(trial):\n",
    "    cfg = {\n",
    "        'n_epoch': trial.suggest_categorical('n_epoch', [90, 200]), # 실제 실험에서는 90, 200으로 진행\n",
    "        'weight_decay': trial.suggest_loguniform('weight_decay', 1e-5, 1e-1),\n",
    "    }\n",
    "\n",
    "    model = ResNet18(num_classes)\n",
    "    model = model.cuda()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=cfg['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=150, gamma=0.1)\n",
    "\n",
    "    train(cfg['n_epoch'], model, train_loader, criterion, optimizer, scheduler)\n",
    "    test_accuracy = test(model, test_loader)\n",
    "    \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7e0eeaf-81b5-44fc-9f9e-6cee5ed3c345",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T13:16:46.530183Z",
     "iopub.status.busy": "2022-06-18T13:16:46.530066Z",
     "iopub.status.idle": "2022-06-18T16:24:10.567901Z",
     "shell.execute_reply": "2022-06-18T16:24:10.566449Z",
     "shell.execute_reply.started": "2022-06-18T13:16:46.530170Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 13:16:46,536]\u001b[0m A new study created in memory with name: no-name-bbff8b3f-633e-4342-8f76-8d59717dbb55\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [001] \t Loss 2.0838 \t Acc 40.32 \t AccHead 43.43 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.4879 \t Acc 44.88 \t AccHead 48.33 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.3941 \t Acc 40.31 \t AccHead 43.42 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.3534 \t Acc 28.84 \t AccHead 31.07 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.3696 \t Acc 45.68 \t AccHead 49.19 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.3838 \t Acc 45.91 \t AccHead 49.46 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 1.3730 \t Acc 44.14 \t AccHead 47.56 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 1.4172 \t Acc 40.30 \t AccHead 43.42 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 1.3867 \t Acc 25.14 \t AccHead 27.08 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 1.3918 \t Acc 35.01 \t AccHead 37.70 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 1.3805 \t Acc 51.57 \t AccHead 55.55 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 1.3811 \t Acc 42.21 \t AccHead 45.47 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 1.3710 \t Acc 44.46 \t AccHead 47.88 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 1.3725 \t Acc 40.28 \t AccHead 43.40 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 1.3761 \t Acc 40.41 \t AccHead 43.53 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 1.3863 \t Acc 40.84 \t AccHead 43.98 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 1.3684 \t Acc 44.55 \t AccHead 47.97 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 1.4006 \t Acc 40.68 \t AccHead 43.80 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 1.4518 \t Acc 40.54 \t AccHead 43.67 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 1.4221 \t Acc 48.20 \t AccHead 51.92 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 1.3932 \t Acc 40.30 \t AccHead 43.42 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 1.3867 \t Acc 41.12 \t AccHead 44.28 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 1.3891 \t Acc 42.58 \t AccHead 45.88 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 1.4357 \t Acc 48.52 \t AccHead 52.27 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 1.3729 \t Acc 40.27 \t AccHead 43.38 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 1.3688 \t Acc 27.02 \t AccHead 29.11 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 1.3945 \t Acc 38.69 \t AccHead 41.67 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 1.3752 \t Acc 29.96 \t AccHead 32.28 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 1.3937 \t Acc 42.02 \t AccHead 45.25 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 1.3941 \t Acc 44.60 \t AccHead 48.04 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 1.3877 \t Acc 50.77 \t AccHead 54.67 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 1.3802 \t Acc 46.45 \t AccHead 50.03 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 1.3691 \t Acc 40.39 \t AccHead 43.50 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 1.3978 \t Acc 44.77 \t AccHead 48.23 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 1.3832 \t Acc 44.30 \t AccHead 47.73 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 1.4887 \t Acc 41.19 \t AccHead 44.38 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 1.5062 \t Acc 40.37 \t AccHead 43.47 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 1.4972 \t Acc 40.30 \t AccHead 43.41 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 1.5258 \t Acc 45.01 \t AccHead 48.49 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 1.5160 \t Acc 24.77 \t AccHead 26.69 \t AccTail 0.00\n",
      "Epoch: [041] \t Loss 1.5269 \t Acc 24.15 \t AccHead 26.01 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 1.5135 \t Acc 24.14 \t AccHead 26.00 \t AccTail 0.00\n",
      "Epoch: [043] \t Loss 1.5237 \t Acc 40.20 \t AccHead 43.29 \t AccTail 0.00\n",
      "Epoch: [044] \t Loss 1.5141 \t Acc 45.51 \t AccHead 49.03 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 1.5736 \t Acc 40.27 \t AccHead 43.38 \t AccTail 0.00\n",
      "Epoch: [046] \t Loss 1.5655 \t Acc 43.05 \t AccHead 46.37 \t AccTail 0.00\n",
      "Epoch: [047] \t Loss 1.5263 \t Acc 30.39 \t AccHead 32.74 \t AccTail 0.00\n",
      "Epoch: [048] \t Loss 1.5170 \t Acc 41.47 \t AccHead 44.69 \t AccTail 0.00\n",
      "Epoch: [049] \t Loss 1.5241 \t Acc 44.36 \t AccHead 47.79 \t AccTail 0.00\n",
      "Epoch: [050] \t Loss 1.5724 \t Acc 40.28 \t AccHead 43.38 \t AccTail 0.00\n",
      "Epoch: [051] \t Loss 1.6679 \t Acc 40.28 \t AccHead 43.38 \t AccTail 0.00\n",
      "Epoch: [052] \t Loss 1.6702 \t Acc 40.30 \t AccHead 43.43 \t AccTail 0.00\n",
      "Epoch: [053] \t Loss 1.6671 \t Acc 40.33 \t AccHead 43.46 \t AccTail 0.00\n",
      "Epoch: [054] \t Loss 1.6643 \t Acc 40.25 \t AccHead 43.36 \t AccTail 0.00\n",
      "Epoch: [055] \t Loss 1.6680 \t Acc 40.34 \t AccHead 43.46 \t AccTail 0.00\n",
      "Epoch: [056] \t Loss 1.6638 \t Acc 40.25 \t AccHead 43.37 \t AccTail 0.00\n",
      "Epoch: [057] \t Loss 1.6645 \t Acc 40.28 \t AccHead 43.38 \t AccTail 0.00\n",
      "Epoch: [058] \t Loss 1.6640 \t Acc 40.33 \t AccHead 43.44 \t AccTail 0.00\n",
      "Epoch: [059] \t Loss 1.6633 \t Acc 40.29 \t AccHead 43.42 \t AccTail 0.00\n",
      "Epoch: [060] \t Loss 1.6650 \t Acc 40.31 \t AccHead 43.43 \t AccTail 0.00\n",
      "Epoch: [061] \t Loss 1.6658 \t Acc 40.28 \t AccHead 43.38 \t AccTail 0.00\n",
      "Epoch: [062] \t Loss 1.6642 \t Acc 40.35 \t AccHead 43.46 \t AccTail 0.00\n",
      "Epoch: [063] \t Loss 1.6654 \t Acc 40.36 \t AccHead 43.48 \t AccTail 0.00\n",
      "Epoch: [064] \t Loss 1.6685 \t Acc 40.21 \t AccHead 43.33 \t AccTail 0.00\n",
      "Epoch: [065] \t Loss 1.6667 \t Acc 40.32 \t AccHead 43.41 \t AccTail 0.00\n",
      "Epoch: [066] \t Loss 1.6673 \t Acc 40.33 \t AccHead 43.43 \t AccTail 0.00\n",
      "Epoch: [067] \t Loss 1.6661 \t Acc 40.35 \t AccHead 43.45 \t AccTail 0.00\n",
      "Epoch: [068] \t Loss 1.6630 \t Acc 40.26 \t AccHead 43.36 \t AccTail 0.00\n",
      "Epoch: [069] \t Loss 1.6679 \t Acc 40.34 \t AccHead 43.45 \t AccTail 0.00\n",
      "Epoch: [070] \t Loss 1.6632 \t Acc 40.27 \t AccHead 43.39 \t AccTail 0.00\n",
      "Epoch: [071] \t Loss 1.6660 \t Acc 40.31 \t AccHead 43.41 \t AccTail 0.00\n",
      "Epoch: [072] \t Loss 1.6655 \t Acc 40.34 \t AccHead 43.47 \t AccTail 0.00\n",
      "Epoch: [073] \t Loss 1.6658 \t Acc 40.32 \t AccHead 43.43 \t AccTail 0.00\n",
      "Epoch: [074] \t Loss 1.6710 \t Acc 40.30 \t AccHead 43.41 \t AccTail 0.00\n",
      "Epoch: [075] \t Loss 1.6644 \t Acc 40.28 \t AccHead 43.39 \t AccTail 0.00\n",
      "Epoch: [076] \t Loss 1.6645 \t Acc 40.23 \t AccHead 43.34 \t AccTail 0.00\n",
      "Epoch: [077] \t Loss 1.6766 \t Acc 40.29 \t AccHead 43.39 \t AccTail 0.00\n",
      "Epoch: [078] \t Loss 1.6685 \t Acc 40.29 \t AccHead 43.39 \t AccTail 0.00\n",
      "Epoch: [079] \t Loss 1.6629 \t Acc 40.29 \t AccHead 43.41 \t AccTail 0.00\n",
      "Epoch: [080] \t Loss 1.6734 \t Acc 40.36 \t AccHead 43.48 \t AccTail 0.00\n",
      "Epoch: [081] \t Loss 1.6698 \t Acc 40.26 \t AccHead 43.38 \t AccTail 0.00\n",
      "Epoch: [082] \t Loss 1.6628 \t Acc 40.30 \t AccHead 43.40 \t AccTail 0.00\n",
      "Epoch: [083] \t Loss 1.6663 \t Acc 40.36 \t AccHead 43.49 \t AccTail 0.00\n",
      "Epoch: [084] \t Loss 1.6623 \t Acc 40.33 \t AccHead 43.44 \t AccTail 0.00\n",
      "Epoch: [085] \t Loss 1.6645 \t Acc 40.28 \t AccHead 43.40 \t AccTail 0.00\n",
      "Epoch: [086] \t Loss 1.6665 \t Acc 40.32 \t AccHead 43.43 \t AccTail 0.00\n",
      "Epoch: [087] \t Loss 1.6657 \t Acc 40.35 \t AccHead 43.45 \t AccTail 0.00\n",
      "Epoch: [088] \t Loss 1.6702 \t Acc 40.34 \t AccHead 43.45 \t AccTail 0.00\n",
      "Epoch: [089] \t Loss 1.6658 \t Acc 40.31 \t AccHead 43.43 \t AccTail 0.00\n",
      "Epoch: [090] \t Loss 1.6655 \t Acc 40.29 \t AccHead 43.40 \t AccTail 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 13:27:50,089]\u001b[0m Trial 0 finished with value: 10.10815715789795 and parameters: {'n_epoch': 90, 'weight_decay': 0.04693209296935963}. Best is trial 0 with value: 10.10815715789795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 10.11 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [001] \t Loss 2.3162 \t Acc 40.89 \t AccHead 44.05 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.3788 \t Acc 47.56 \t AccHead 51.22 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.2392 \t Acc 51.57 \t AccHead 55.56 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.1589 \t Acc 58.62 \t AccHead 63.13 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.1515 \t Acc 46.46 \t AccHead 50.04 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.1281 \t Acc 51.29 \t AccHead 55.26 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 1.0885 \t Acc 62.37 \t AccHead 67.17 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 1.1053 \t Acc 59.49 \t AccHead 64.08 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 1.0837 \t Acc 56.45 \t AccHead 60.78 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 1.0820 \t Acc 60.83 \t AccHead 65.50 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 1.0657 \t Acc 59.78 \t AccHead 64.38 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 1.0781 \t Acc 61.07 \t AccHead 65.77 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 1.0741 \t Acc 57.78 \t AccHead 62.26 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 1.0690 \t Acc 57.40 \t AccHead 61.80 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 1.0769 \t Acc 54.25 \t AccHead 58.44 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 1.0670 \t Acc 60.69 \t AccHead 65.37 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 1.0702 \t Acc 51.81 \t AccHead 55.83 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 1.0636 \t Acc 63.32 \t AccHead 68.20 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 1.0644 \t Acc 48.76 \t AccHead 52.54 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 1.0678 \t Acc 52.54 \t AccHead 56.61 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 1.0550 \t Acc 48.64 \t AccHead 52.21 \t AccTail 2.67\n",
      "Epoch: [022] \t Loss 1.0524 \t Acc 59.78 \t AccHead 64.41 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 1.0589 \t Acc 45.90 \t AccHead 49.42 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 1.0683 \t Acc 48.35 \t AccHead 52.07 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 1.0885 \t Acc 60.47 \t AccHead 65.12 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 1.0663 \t Acc 57.79 \t AccHead 62.27 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 1.0922 \t Acc 61.73 \t AccHead 66.48 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 1.0725 \t Acc 60.58 \t AccHead 65.26 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 1.0761 \t Acc 61.35 \t AccHead 66.07 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 1.0818 \t Acc 62.97 \t AccHead 67.83 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 1.0657 \t Acc 60.01 \t AccHead 64.64 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 1.0632 \t Acc 57.44 \t AccHead 61.86 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 1.0650 \t Acc 64.08 \t AccHead 69.04 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 1.0661 \t Acc 55.27 \t AccHead 59.53 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 1.0793 \t Acc 63.10 \t AccHead 67.94 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 1.0601 \t Acc 59.52 \t AccHead 64.10 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 1.0762 \t Acc 61.06 \t AccHead 65.77 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 1.0704 \t Acc 63.20 \t AccHead 68.08 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 1.0726 \t Acc 59.07 \t AccHead 63.62 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 1.0814 \t Acc 59.83 \t AccHead 64.45 \t AccTail 0.00\n",
      "Epoch: [041] \t Loss 1.0605 \t Acc 61.23 \t AccHead 65.96 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 1.0749 \t Acc 53.25 \t AccHead 57.37 \t AccTail 0.00\n",
      "Epoch: [043] \t Loss 1.0693 \t Acc 53.59 \t AccHead 57.73 \t AccTail 0.00\n",
      "Epoch: [044] \t Loss 1.0865 \t Acc 58.84 \t AccHead 63.38 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 1.0672 \t Acc 59.78 \t AccHead 64.39 \t AccTail 0.00\n",
      "Epoch: [046] \t Loss 1.0621 \t Acc 57.07 \t AccHead 61.48 \t AccTail 0.00\n",
      "Epoch: [047] \t Loss 1.0829 \t Acc 59.88 \t AccHead 64.52 \t AccTail 0.00\n",
      "Epoch: [048] \t Loss 1.0878 \t Acc 51.55 \t AccHead 55.54 \t AccTail 0.00\n",
      "Epoch: [049] \t Loss 1.0843 \t Acc 52.38 \t AccHead 56.44 \t AccTail 0.00\n",
      "Epoch: [050] \t Loss 1.0689 \t Acc 61.77 \t AccHead 66.54 \t AccTail 0.00\n",
      "Epoch: [051] \t Loss 1.0661 \t Acc 51.47 \t AccHead 55.44 \t AccTail 0.00\n",
      "Epoch: [052] \t Loss 1.1067 \t Acc 59.20 \t AccHead 63.78 \t AccTail 0.00\n",
      "Epoch: [053] \t Loss 1.0930 \t Acc 57.35 \t AccHead 61.78 \t AccTail 0.00\n",
      "Epoch: [054] \t Loss 1.0706 \t Acc 61.00 \t AccHead 65.73 \t AccTail 0.00\n",
      "Epoch: [055] \t Loss 1.0827 \t Acc 59.51 \t AccHead 64.09 \t AccTail 0.00\n",
      "Epoch: [056] \t Loss 1.0885 \t Acc 61.41 \t AccHead 66.15 \t AccTail 0.00\n",
      "Epoch: [057] \t Loss 1.0596 \t Acc 54.33 \t AccHead 58.54 \t AccTail 0.00\n",
      "Epoch: [058] \t Loss 1.0990 \t Acc 60.89 \t AccHead 65.57 \t AccTail 0.00\n",
      "Epoch: [059] \t Loss 1.0819 \t Acc 65.03 \t AccHead 70.05 \t AccTail 0.00\n",
      "Epoch: [060] \t Loss 1.0701 \t Acc 62.67 \t AccHead 67.54 \t AccTail 0.00\n",
      "Epoch: [061] \t Loss 1.0827 \t Acc 61.94 \t AccHead 66.73 \t AccTail 0.00\n",
      "Epoch: [062] \t Loss 1.0852 \t Acc 57.62 \t AccHead 62.07 \t AccTail 0.00\n",
      "Epoch: [063] \t Loss 1.0673 \t Acc 45.88 \t AccHead 48.95 \t AccTail 6.09\n",
      "Epoch: [064] \t Loss 1.0669 \t Acc 57.54 \t AccHead 61.99 \t AccTail 0.00\n",
      "Epoch: [065] \t Loss 1.0897 \t Acc 57.67 \t AccHead 62.13 \t AccTail 0.00\n",
      "Epoch: [066] \t Loss 1.0848 \t Acc 63.46 \t AccHead 68.35 \t AccTail 0.00\n",
      "Epoch: [067] \t Loss 1.0768 \t Acc 61.63 \t AccHead 66.40 \t AccTail 0.00\n",
      "Epoch: [068] \t Loss 1.0785 \t Acc 55.59 \t AccHead 59.90 \t AccTail 0.00\n",
      "Epoch: [069] \t Loss 1.0925 \t Acc 57.12 \t AccHead 61.54 \t AccTail 0.00\n",
      "Epoch: [070] \t Loss 1.0756 \t Acc 54.87 \t AccHead 59.12 \t AccTail 0.00\n",
      "Epoch: [071] \t Loss 1.0722 \t Acc 39.57 \t AccHead 42.62 \t AccTail 0.00\n",
      "Epoch: [072] \t Loss 1.0611 \t Acc 62.87 \t AccHead 67.71 \t AccTail 0.00\n",
      "Epoch: [073] \t Loss 1.0695 \t Acc 35.32 \t AccHead 38.05 \t AccTail 0.00\n",
      "Epoch: [074] \t Loss 1.1015 \t Acc 62.38 \t AccHead 67.18 \t AccTail 0.00\n",
      "Epoch: [075] \t Loss 1.0997 \t Acc 56.89 \t AccHead 61.29 \t AccTail 0.00\n",
      "Epoch: [076] \t Loss 1.0797 \t Acc 61.96 \t AccHead 66.77 \t AccTail 0.00\n",
      "Epoch: [077] \t Loss 1.0717 \t Acc 60.23 \t AccHead 64.87 \t AccTail 0.00\n",
      "Epoch: [078] \t Loss 1.0753 \t Acc 47.53 \t AccHead 51.20 \t AccTail 0.00\n",
      "Epoch: [079] \t Loss 1.0751 \t Acc 59.84 \t AccHead 64.42 \t AccTail 0.00\n",
      "Epoch: [080] \t Loss 1.0863 \t Acc 60.16 \t AccHead 64.80 \t AccTail 0.00\n",
      "Epoch: [081] \t Loss 1.0830 \t Acc 47.95 \t AccHead 51.64 \t AccTail 0.00\n",
      "Epoch: [082] \t Loss 1.0834 \t Acc 55.07 \t AccHead 59.33 \t AccTail 0.00\n",
      "Epoch: [083] \t Loss 1.0729 \t Acc 51.96 \t AccHead 55.63 \t AccTail 4.26\n",
      "Epoch: [084] \t Loss 1.0742 \t Acc 55.60 \t AccHead 59.88 \t AccTail 0.00\n",
      "Epoch: [085] \t Loss 1.0710 \t Acc 61.97 \t AccHead 66.76 \t AccTail 0.00\n",
      "Epoch: [086] \t Loss 1.0779 \t Acc 53.86 \t AccHead 57.99 \t AccTail 0.00\n",
      "Epoch: [087] \t Loss 1.1028 \t Acc 49.39 \t AccHead 53.21 \t AccTail 0.00\n",
      "Epoch: [088] \t Loss 1.0865 \t Acc 53.16 \t AccHead 57.27 \t AccTail 0.00\n",
      "Epoch: [089] \t Loss 1.1245 \t Acc 49.33 \t AccHead 53.14 \t AccTail 0.00\n",
      "Epoch: [090] \t Loss 1.0827 \t Acc 60.02 \t AccHead 64.68 \t AccTail 0.00\n",
      "Epoch: [091] \t Loss 1.1007 \t Acc 52.50 \t AccHead 56.52 \t AccTail 0.00\n",
      "Epoch: [092] \t Loss 1.0846 \t Acc 60.39 \t AccHead 65.03 \t AccTail 0.00\n",
      "Epoch: [093] \t Loss 1.0924 \t Acc 55.61 \t AccHead 59.89 \t AccTail 0.00\n",
      "Epoch: [094] \t Loss 1.0994 \t Acc 60.63 \t AccHead 65.32 \t AccTail 0.00\n",
      "Epoch: [095] \t Loss 1.0940 \t Acc 54.07 \t AccHead 58.27 \t AccTail 0.00\n",
      "Epoch: [096] \t Loss 1.0820 \t Acc 58.73 \t AccHead 62.52 \t AccTail 9.50\n",
      "Epoch: [097] \t Loss 1.0884 \t Acc 48.60 \t AccHead 52.34 \t AccTail 0.00\n",
      "Epoch: [098] \t Loss 1.0952 \t Acc 59.30 \t AccHead 63.87 \t AccTail 0.00\n",
      "Epoch: [099] \t Loss 1.1062 \t Acc 54.38 \t AccHead 58.57 \t AccTail 0.00\n",
      "Epoch: [100] \t Loss 1.0965 \t Acc 48.58 \t AccHead 52.35 \t AccTail 0.00\n",
      "Epoch: [101] \t Loss 1.1051 \t Acc 55.38 \t AccHead 59.66 \t AccTail 0.00\n",
      "Epoch: [102] \t Loss 1.1112 \t Acc 56.46 \t AccHead 60.83 \t AccTail 0.00\n",
      "Epoch: [103] \t Loss 1.1217 \t Acc 57.85 \t AccHead 62.34 \t AccTail 0.00\n",
      "Epoch: [104] \t Loss 1.0953 \t Acc 52.18 \t AccHead 56.21 \t AccTail 0.00\n",
      "Epoch: [105] \t Loss 1.1141 \t Acc 55.62 \t AccHead 59.93 \t AccTail 0.00\n",
      "Epoch: [106] \t Loss 1.0856 \t Acc 56.01 \t AccHead 60.33 \t AccTail 0.00\n",
      "Epoch: [107] \t Loss 1.1227 \t Acc 56.69 \t AccHead 61.04 \t AccTail 0.00\n",
      "Epoch: [108] \t Loss 1.1204 \t Acc 39.91 \t AccHead 42.99 \t AccTail 0.00\n",
      "Epoch: [109] \t Loss 1.1380 \t Acc 45.27 \t AccHead 48.75 \t AccTail 0.00\n",
      "Epoch: [110] \t Loss 1.1135 \t Acc 61.39 \t AccHead 66.15 \t AccTail 0.00\n",
      "Epoch: [111] \t Loss 1.1009 \t Acc 58.81 \t AccHead 63.34 \t AccTail 0.00\n",
      "Epoch: [112] \t Loss 1.0901 \t Acc 62.13 \t AccHead 66.95 \t AccTail 0.00\n",
      "Epoch: [113] \t Loss 1.1177 \t Acc 60.35 \t AccHead 65.01 \t AccTail 0.00\n",
      "Epoch: [114] \t Loss 1.1077 \t Acc 58.00 \t AccHead 62.47 \t AccTail 0.00\n",
      "Epoch: [115] \t Loss 1.1156 \t Acc 61.56 \t AccHead 66.33 \t AccTail 0.00\n",
      "Epoch: [116] \t Loss 1.0934 \t Acc 41.45 \t AccHead 44.64 \t AccTail 0.00\n",
      "Epoch: [117] \t Loss 1.1161 \t Acc 52.77 \t AccHead 56.86 \t AccTail 0.00\n",
      "Epoch: [118] \t Loss 1.1098 \t Acc 50.38 \t AccHead 54.27 \t AccTail 0.00\n",
      "Epoch: [119] \t Loss 1.1135 \t Acc 60.56 \t AccHead 65.23 \t AccTail 0.00\n",
      "Epoch: [120] \t Loss 1.1110 \t Acc 54.09 \t AccHead 58.28 \t AccTail 0.00\n",
      "Epoch: [121] \t Loss 1.0878 \t Acc 51.23 \t AccHead 55.20 \t AccTail 0.00\n",
      "Epoch: [122] \t Loss 1.1186 \t Acc 60.33 \t AccHead 64.98 \t AccTail 0.00\n",
      "Epoch: [123] \t Loss 1.1010 \t Acc 58.44 \t AccHead 62.94 \t AccTail 0.00\n",
      "Epoch: [124] \t Loss 1.0977 \t Acc 30.75 \t AccHead 33.13 \t AccTail 0.00\n",
      "Epoch: [125] \t Loss 1.1403 \t Acc 56.62 \t AccHead 61.00 \t AccTail 0.00\n",
      "Epoch: [126] \t Loss 1.1001 \t Acc 61.36 \t AccHead 66.07 \t AccTail 0.00\n",
      "Epoch: [127] \t Loss 1.1099 \t Acc 54.60 \t AccHead 58.80 \t AccTail 0.00\n",
      "Epoch: [128] \t Loss 1.1092 \t Acc 50.15 \t AccHead 54.02 \t AccTail 0.00\n",
      "Epoch: [129] \t Loss 1.0955 \t Acc 59.68 \t AccHead 64.28 \t AccTail 0.00\n",
      "Epoch: [130] \t Loss 1.1213 \t Acc 42.27 \t AccHead 45.54 \t AccTail 0.00\n",
      "Epoch: [131] \t Loss 1.1145 \t Acc 57.77 \t AccHead 62.22 \t AccTail 0.00\n",
      "Epoch: [132] \t Loss 1.1350 \t Acc 56.27 \t AccHead 60.63 \t AccTail 0.00\n",
      "Epoch: [133] \t Loss 1.1302 \t Acc 58.60 \t AccHead 63.09 \t AccTail 0.00\n",
      "Epoch: [134] \t Loss 1.1032 \t Acc 38.68 \t AccHead 41.67 \t AccTail 0.00\n",
      "Epoch: [135] \t Loss 1.1140 \t Acc 52.84 \t AccHead 56.92 \t AccTail 0.00\n",
      "Epoch: [136] \t Loss 1.1560 \t Acc 53.30 \t AccHead 57.42 \t AccTail 0.00\n",
      "Epoch: [137] \t Loss 1.1045 \t Acc 56.63 \t AccHead 61.01 \t AccTail 0.00\n",
      "Epoch: [138] \t Loss 1.1254 \t Acc 58.67 \t AccHead 63.22 \t AccTail 0.00\n",
      "Epoch: [139] \t Loss 1.1087 \t Acc 54.29 \t AccHead 58.49 \t AccTail 0.00\n",
      "Epoch: [140] \t Loss 1.1183 \t Acc 18.31 \t AccHead 19.72 \t AccTail 0.00\n",
      "Epoch: [141] \t Loss 1.1227 \t Acc 62.42 \t AccHead 67.21 \t AccTail 0.00\n",
      "Epoch: [142] \t Loss 1.0952 \t Acc 57.45 \t AccHead 61.91 \t AccTail 0.00\n",
      "Epoch: [143] \t Loss 1.1100 \t Acc 58.76 \t AccHead 63.32 \t AccTail 0.00\n",
      "Epoch: [144] \t Loss 1.1302 \t Acc 51.24 \t AccHead 55.22 \t AccTail 0.00\n",
      "Epoch: [145] \t Loss 1.1283 \t Acc 57.31 \t AccHead 61.73 \t AccTail 0.00\n",
      "Epoch: [146] \t Loss 1.1414 \t Acc 56.72 \t AccHead 61.09 \t AccTail 0.00\n",
      "Epoch: [147] \t Loss 1.1150 \t Acc 62.24 \t AccHead 67.01 \t AccTail 0.00\n",
      "Epoch: [148] \t Loss 1.1240 \t Acc 56.52 \t AccHead 60.77 \t AccTail 1.69\n",
      "Epoch: [149] \t Loss 1.1261 \t Acc 50.09 \t AccHead 53.97 \t AccTail 0.00\n",
      "Epoch: [150] \t Loss 1.1399 \t Acc 59.27 \t AccHead 63.84 \t AccTail 0.00\n",
      "Epoch: [151] \t Loss 1.0191 \t Acc 67.81 \t AccHead 73.05 \t AccTail 0.00\n",
      "Epoch: [152] \t Loss 0.9590 \t Acc 67.97 \t AccHead 73.22 \t AccTail 0.00\n",
      "Epoch: [153] \t Loss 0.9400 \t Acc 68.58 \t AccHead 73.88 \t AccTail 0.00\n",
      "Epoch: [154] \t Loss 0.9327 \t Acc 68.36 \t AccHead 73.62 \t AccTail 0.00\n",
      "Epoch: [155] \t Loss 0.9315 \t Acc 68.78 \t AccHead 74.08 \t AccTail 0.00\n",
      "Epoch: [156] \t Loss 0.9190 \t Acc 68.85 \t AccHead 74.15 \t AccTail 0.00\n",
      "Epoch: [157] \t Loss 0.9142 \t Acc 69.45 \t AccHead 74.79 \t AccTail 0.00\n",
      "Epoch: [158] \t Loss 0.9184 \t Acc 69.31 \t AccHead 74.61 \t AccTail 0.00\n",
      "Epoch: [159] \t Loss 0.9043 \t Acc 68.71 \t AccHead 74.01 \t AccTail 0.00\n",
      "Epoch: [160] \t Loss 0.9150 \t Acc 69.56 \t AccHead 74.92 \t AccTail 0.00\n",
      "Epoch: [161] \t Loss 0.8975 \t Acc 69.46 \t AccHead 74.81 \t AccTail 0.00\n",
      "Epoch: [162] \t Loss 0.9015 \t Acc 66.21 \t AccHead 71.31 \t AccTail 0.00\n",
      "Epoch: [163] \t Loss 0.9093 \t Acc 68.88 \t AccHead 74.17 \t AccTail 0.00\n",
      "Epoch: [164] \t Loss 0.8953 \t Acc 69.64 \t AccHead 75.03 \t AccTail 0.00\n",
      "Epoch: [165] \t Loss 0.8962 \t Acc 69.36 \t AccHead 74.69 \t AccTail 0.00\n",
      "Epoch: [166] \t Loss 0.8899 \t Acc 68.82 \t AccHead 74.11 \t AccTail 0.00\n",
      "Epoch: [167] \t Loss 0.9124 \t Acc 64.76 \t AccHead 69.75 \t AccTail 0.00\n",
      "Epoch: [168] \t Loss 0.8856 \t Acc 68.80 \t AccHead 74.14 \t AccTail 0.00\n",
      "Epoch: [169] \t Loss 0.8831 \t Acc 70.04 \t AccHead 75.39 \t AccTail 0.00\n",
      "Epoch: [170] \t Loss 0.8832 \t Acc 68.36 \t AccHead 73.50 \t AccTail 1.70\n",
      "Epoch: [171] \t Loss 0.8905 \t Acc 69.59 \t AccHead 74.94 \t AccTail 0.14\n",
      "Epoch: [172] \t Loss 0.8893 \t Acc 69.64 \t AccHead 74.97 \t AccTail 0.71\n",
      "Epoch: [173] \t Loss 0.8747 \t Acc 68.71 \t AccHead 73.26 \t AccTail 10.01\n",
      "Epoch: [174] \t Loss 0.8827 \t Acc 64.10 \t AccHead 69.06 \t AccTail 0.14\n",
      "Epoch: [175] \t Loss 0.8712 \t Acc 71.50 \t AccHead 76.98 \t AccTail 0.42\n",
      "Epoch: [176] \t Loss 0.8829 \t Acc 68.75 \t AccHead 73.90 \t AccTail 2.12\n",
      "Epoch: [177] \t Loss 0.8764 \t Acc 68.16 \t AccHead 72.93 \t AccTail 6.51\n",
      "Epoch: [178] \t Loss 0.8699 \t Acc 70.52 \t AccHead 75.88 \t AccTail 1.13\n",
      "Epoch: [179] \t Loss 0.8607 \t Acc 70.48 \t AccHead 75.81 \t AccTail 1.42\n",
      "Epoch: [180] \t Loss 0.8658 \t Acc 70.11 \t AccHead 75.51 \t AccTail 0.28\n",
      "Epoch: [181] \t Loss 0.8576 \t Acc 67.84 \t AccHead 72.88 \t AccTail 2.82\n",
      "Epoch: [182] \t Loss 0.8746 \t Acc 68.16 \t AccHead 73.11 \t AccTail 3.84\n",
      "Epoch: [183] \t Loss 0.8662 \t Acc 71.85 \t AccHead 77.24 \t AccTail 2.53\n",
      "Epoch: [184] \t Loss 0.8703 \t Acc 69.04 \t AccHead 74.34 \t AccTail 0.42\n",
      "Epoch: [185] \t Loss 0.8510 \t Acc 68.23 \t AccHead 73.39 \t AccTail 1.28\n",
      "Epoch: [186] \t Loss 0.8576 \t Acc 69.89 \t AccHead 75.14 \t AccTail 1.84\n",
      "Epoch: [187] \t Loss 0.8598 \t Acc 67.97 \t AccHead 72.40 \t AccTail 10.61\n",
      "Epoch: [188] \t Loss 0.8601 \t Acc 68.52 \t AccHead 73.49 \t AccTail 4.11\n",
      "Epoch: [189] \t Loss 0.8564 \t Acc 69.86 \t AccHead 75.11 \t AccTail 1.56\n",
      "Epoch: [190] \t Loss 0.8611 \t Acc 67.97 \t AccHead 72.95 \t AccTail 3.40\n",
      "Epoch: [191] \t Loss 0.8478 \t Acc 71.59 \t AccHead 76.96 \t AccTail 2.39\n",
      "Epoch: [192] \t Loss 0.8589 \t Acc 69.07 \t AccHead 74.06 \t AccTail 4.26\n",
      "Epoch: [193] \t Loss 0.8581 \t Acc 69.50 \t AccHead 73.87 \t AccTail 13.01\n",
      "Epoch: [194] \t Loss 0.8547 \t Acc 67.88 \t AccHead 71.95 \t AccTail 15.16\n",
      "Epoch: [195] \t Loss 0.8413 \t Acc 71.41 \t AccHead 76.15 \t AccTail 10.30\n",
      "Epoch: [196] \t Loss 0.8527 \t Acc 68.91 \t AccHead 74.08 \t AccTail 1.70\n",
      "Epoch: [197] \t Loss 0.8621 \t Acc 70.10 \t AccHead 74.63 \t AccTail 11.33\n",
      "Epoch: [198] \t Loss 0.8509 \t Acc 72.60 \t AccHead 77.37 \t AccTail 10.38\n",
      "Epoch: [199] \t Loss 0.8476 \t Acc 72.65 \t AccHead 77.60 \t AccTail 8.24\n",
      "Epoch: [200] \t Loss 0.8470 \t Acc 61.47 \t AccHead 65.99 \t AccTail 2.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 13:52:37,913]\u001b[0m Trial 1 finished with value: 23.885574340820312 and parameters: {'n_epoch': 200, 'weight_decay': 0.009352899646879149}. Best is trial 1 with value: 23.885574340820312.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 23.89 \t AccHead 46.32 \t AccTail 0.96\n",
      "Epoch: [001] \t Loss 2.8181 \t Acc 41.14 \t AccHead 44.33 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.7653 \t Acc 51.70 \t AccHead 55.71 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.3872 \t Acc 52.28 \t AccHead 56.32 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.2716 \t Acc 59.58 \t AccHead 64.18 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.3935 \t Acc 58.33 \t AccHead 62.84 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.1630 \t Acc 61.01 \t AccHead 65.72 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 1.0955 \t Acc 64.30 \t AccHead 69.17 \t AccTail 1.13\n",
      "Epoch: [008] \t Loss 1.0631 \t Acc 59.75 \t AccHead 64.36 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 1.0214 \t Acc 66.49 \t AccHead 71.63 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 0.9880 \t Acc 67.98 \t AccHead 73.24 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 0.9758 \t Acc 68.35 \t AccHead 73.61 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 0.9698 \t Acc 66.29 \t AccHead 71.41 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 0.9641 \t Acc 67.46 \t AccHead 72.25 \t AccTail 5.25\n",
      "Epoch: [014] \t Loss 0.9137 \t Acc 69.59 \t AccHead 74.88 \t AccTail 0.99\n",
      "Epoch: [015] \t Loss 0.8876 \t Acc 69.94 \t AccHead 75.21 \t AccTail 1.84\n",
      "Epoch: [016] \t Loss 0.8689 \t Acc 71.48 \t AccHead 76.87 \t AccTail 1.56\n",
      "Epoch: [017] \t Loss 0.8493 \t Acc 72.24 \t AccHead 77.73 \t AccTail 1.13\n",
      "Epoch: [018] \t Loss 0.8219 \t Acc 73.37 \t AccHead 78.96 \t AccTail 0.85\n",
      "Epoch: [019] \t Loss 0.8156 \t Acc 72.25 \t AccHead 77.18 \t AccTail 8.62\n",
      "Epoch: [020] \t Loss 0.8131 \t Acc 72.45 \t AccHead 77.25 \t AccTail 10.33\n",
      "Epoch: [021] \t Loss 0.7804 \t Acc 74.84 \t AccHead 79.84 \t AccTail 10.04\n",
      "Epoch: [022] \t Loss 0.7705 \t Acc 73.92 \t AccHead 79.29 \t AccTail 4.26\n",
      "Epoch: [023] \t Loss 0.7539 \t Acc 76.27 \t AccHead 81.59 \t AccTail 7.10\n",
      "Epoch: [024] \t Loss 0.7361 \t Acc 76.86 \t AccHead 82.11 \t AccTail 8.65\n",
      "Epoch: [025] \t Loss 0.7110 \t Acc 76.30 \t AccHead 81.04 \t AccTail 14.99\n",
      "Epoch: [026] \t Loss 0.6994 \t Acc 76.02 \t AccHead 79.51 \t AccTail 30.93\n",
      "Epoch: [027] \t Loss 0.7047 \t Acc 77.55 \t AccHead 81.42 \t AccTail 27.34\n",
      "Epoch: [028] \t Loss 0.6699 \t Acc 78.05 \t AccHead 82.55 \t AccTail 19.72\n",
      "Epoch: [029] \t Loss 0.6484 \t Acc 78.25 \t AccHead 82.50 \t AccTail 22.90\n",
      "Epoch: [030] \t Loss 0.6400 \t Acc 78.25 \t AccHead 82.09 \t AccTail 28.37\n",
      "Epoch: [031] \t Loss 0.6246 \t Acc 79.79 \t AccHead 84.10 \t AccTail 23.94\n",
      "Epoch: [032] \t Loss 0.6186 \t Acc 76.85 \t AccHead 81.08 \t AccTail 22.25\n",
      "Epoch: [033] \t Loss 0.6054 \t Acc 78.71 \t AccHead 82.84 \t AccTail 25.32\n",
      "Epoch: [034] \t Loss 0.6052 \t Acc 79.87 \t AccHead 84.09 \t AccTail 25.49\n",
      "Epoch: [035] \t Loss 0.5862 \t Acc 79.17 \t AccHead 82.90 \t AccTail 30.68\n",
      "Epoch: [036] \t Loss 0.5761 \t Acc 81.18 \t AccHead 85.52 \t AccTail 24.54\n",
      "Epoch: [037] \t Loss 0.5593 \t Acc 81.91 \t AccHead 85.89 \t AccTail 30.51\n",
      "Epoch: [038] \t Loss 0.5561 \t Acc 81.59 \t AccHead 84.26 \t AccTail 47.03\n",
      "Epoch: [039] \t Loss 0.5318 \t Acc 82.73 \t AccHead 85.84 \t AccTail 42.41\n",
      "Epoch: [040] \t Loss 0.5414 \t Acc 81.33 \t AccHead 84.98 \t AccTail 33.95\n",
      "Epoch: [041] \t Loss 0.5237 \t Acc 82.82 \t AccHead 86.10 \t AccTail 40.37\n",
      "Epoch: [042] \t Loss 0.5116 \t Acc 81.90 \t AccHead 84.74 \t AccTail 44.96\n",
      "Epoch: [043] \t Loss 0.5131 \t Acc 83.95 \t AccHead 87.04 \t AccTail 43.99\n",
      "Epoch: [044] \t Loss 0.4956 \t Acc 84.26 \t AccHead 87.89 \t AccTail 36.98\n",
      "Epoch: [045] \t Loss 0.4830 \t Acc 83.61 \t AccHead 86.91 \t AccTail 40.93\n",
      "Epoch: [046] \t Loss 0.4804 \t Acc 83.73 \t AccHead 88.11 \t AccTail 26.60\n",
      "Epoch: [047] \t Loss 0.4598 \t Acc 84.98 \t AccHead 87.31 \t AccTail 54.75\n",
      "Epoch: [048] \t Loss 0.4484 \t Acc 84.07 \t AccHead 86.87 \t AccTail 47.95\n",
      "Epoch: [049] \t Loss 0.4472 \t Acc 86.26 \t AccHead 88.88 \t AccTail 52.33\n",
      "Epoch: [050] \t Loss 0.4400 \t Acc 84.74 \t AccHead 88.42 \t AccTail 37.02\n",
      "Epoch: [051] \t Loss 0.4333 \t Acc 85.88 \t AccHead 88.58 \t AccTail 50.78\n",
      "Epoch: [052] \t Loss 0.4289 \t Acc 87.29 \t AccHead 89.42 \t AccTail 59.75\n",
      "Epoch: [053] \t Loss 0.4230 \t Acc 86.08 \t AccHead 88.17 \t AccTail 58.89\n",
      "Epoch: [054] \t Loss 0.4207 \t Acc 85.80 \t AccHead 88.67 \t AccTail 48.51\n",
      "Epoch: [055] \t Loss 0.4119 \t Acc 85.48 \t AccHead 88.48 \t AccTail 46.68\n",
      "Epoch: [056] \t Loss 0.3912 \t Acc 87.92 \t AccHead 89.85 \t AccTail 62.96\n",
      "Epoch: [057] \t Loss 0.3871 \t Acc 86.41 \t AccHead 88.12 \t AccTail 64.31\n",
      "Epoch: [058] \t Loss 0.3831 \t Acc 86.19 \t AccHead 88.24 \t AccTail 59.43\n",
      "Epoch: [059] \t Loss 0.3621 \t Acc 88.41 \t AccHead 91.22 \t AccTail 52.12\n",
      "Epoch: [060] \t Loss 0.3663 \t Acc 87.04 \t AccHead 89.14 \t AccTail 59.86\n",
      "Epoch: [061] \t Loss 0.3548 \t Acc 89.22 \t AccHead 91.02 \t AccTail 65.96\n",
      "Epoch: [062] \t Loss 0.3365 \t Acc 89.53 \t AccHead 91.78 \t AccTail 60.40\n",
      "Epoch: [063] \t Loss 0.3370 \t Acc 89.12 \t AccHead 90.93 \t AccTail 65.82\n",
      "Epoch: [064] \t Loss 0.3325 \t Acc 88.80 \t AccHead 91.16 \t AccTail 58.16\n",
      "Epoch: [065] \t Loss 0.3203 \t Acc 89.75 \t AccHead 90.95 \t AccTail 74.33\n",
      "Epoch: [066] \t Loss 0.3103 \t Acc 90.35 \t AccHead 92.27 \t AccTail 65.34\n",
      "Epoch: [067] \t Loss 0.3159 \t Acc 90.25 \t AccHead 91.43 \t AccTail 75.04\n",
      "Epoch: [068] \t Loss 0.3070 \t Acc 90.76 \t AccHead 92.85 \t AccTail 63.49\n",
      "Epoch: [069] \t Loss 0.2986 \t Acc 90.51 \t AccHead 92.56 \t AccTail 64.12\n",
      "Epoch: [070] \t Loss 0.2902 \t Acc 89.34 \t AccHead 91.30 \t AccTail 64.03\n",
      "Epoch: [071] \t Loss 0.3066 \t Acc 89.19 \t AccHead 92.06 \t AccTail 52.06\n",
      "Epoch: [072] \t Loss 0.2760 \t Acc 90.87 \t AccHead 92.02 \t AccTail 75.89\n",
      "Epoch: [073] \t Loss 0.2862 \t Acc 90.78 \t AccHead 92.49 \t AccTail 68.56\n",
      "Epoch: [074] \t Loss 0.2804 \t Acc 91.12 \t AccHead 91.97 \t AccTail 80.17\n",
      "Epoch: [075] \t Loss 0.2633 \t Acc 91.03 \t AccHead 93.20 \t AccTail 63.10\n",
      "Epoch: [076] \t Loss 0.2620 \t Acc 91.21 \t AccHead 92.90 \t AccTail 69.27\n",
      "Epoch: [077] \t Loss 0.2443 \t Acc 91.90 \t AccHead 93.13 \t AccTail 75.96\n",
      "Epoch: [078] \t Loss 0.2398 \t Acc 92.06 \t AccHead 94.10 \t AccTail 65.58\n",
      "Epoch: [079] \t Loss 0.2411 \t Acc 92.64 \t AccHead 94.35 \t AccTail 70.50\n",
      "Epoch: [080] \t Loss 0.2464 \t Acc 92.49 \t AccHead 93.38 \t AccTail 81.07\n",
      "Epoch: [081] \t Loss 0.2452 \t Acc 91.46 \t AccHead 92.82 \t AccTail 73.87\n",
      "Epoch: [082] \t Loss 0.2389 \t Acc 91.90 \t AccHead 93.47 \t AccTail 71.55\n",
      "Epoch: [083] \t Loss 0.2250 \t Acc 93.28 \t AccHead 94.42 \t AccTail 78.40\n",
      "Epoch: [084] \t Loss 0.2250 \t Acc 92.32 \t AccHead 93.65 \t AccTail 75.00\n",
      "Epoch: [085] \t Loss 0.2110 \t Acc 91.98 \t AccHead 92.95 \t AccTail 79.49\n",
      "Epoch: [086] \t Loss 0.2123 \t Acc 93.45 \t AccHead 94.34 \t AccTail 81.87\n",
      "Epoch: [087] \t Loss 0.1988 \t Acc 93.13 \t AccHead 94.38 \t AccTail 76.94\n",
      "Epoch: [088] \t Loss 0.2030 \t Acc 94.71 \t AccHead 95.41 \t AccTail 85.73\n",
      "Epoch: [089] \t Loss 0.2022 \t Acc 93.61 \t AccHead 95.15 \t AccTail 73.58\n",
      "Epoch: [090] \t Loss 0.1950 \t Acc 93.70 \t AccHead 95.12 \t AccTail 75.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 14:03:40,386]\u001b[0m Trial 2 finished with value: 50.338623046875 and parameters: {'n_epoch': 90, 'weight_decay': 1.2327520262024438e-05}. Best is trial 2 with value: 50.338623046875.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 50.34 \t AccHead 73.58 \t AccTail 26.59\n",
      "Epoch: [001] \t Loss 2.3914 \t Acc 46.89 \t AccHead 50.52 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.4792 \t Acc 54.45 \t AccHead 58.64 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.2696 \t Acc 55.88 \t AccHead 60.20 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.1676 \t Acc 59.62 \t AccHead 64.23 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.0888 \t Acc 63.15 \t AccHead 68.06 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.0355 \t Acc 62.75 \t AccHead 67.61 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 0.9999 \t Acc 66.43 \t AccHead 71.54 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 0.9873 \t Acc 66.43 \t AccHead 71.56 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 0.9556 \t Acc 68.39 \t AccHead 73.66 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 0.9309 \t Acc 67.32 \t AccHead 72.50 \t AccTail 0.28\n",
      "Epoch: [011] \t Loss 0.9082 \t Acc 68.51 \t AccHead 73.79 \t AccTail 0.14\n",
      "Epoch: [012] \t Loss 0.9066 \t Acc 70.68 \t AccHead 76.08 \t AccTail 0.57\n",
      "Epoch: [013] \t Loss 0.8886 \t Acc 69.91 \t AccHead 75.30 \t AccTail 0.28\n",
      "Epoch: [014] \t Loss 0.8881 \t Acc 68.66 \t AccHead 73.72 \t AccTail 2.98\n",
      "Epoch: [015] \t Loss 0.8748 \t Acc 57.09 \t AccHead 60.98 \t AccTail 6.79\n",
      "Epoch: [016] \t Loss 0.8563 \t Acc 69.59 \t AccHead 74.11 \t AccTail 11.17\n",
      "Epoch: [017] \t Loss 0.8417 \t Acc 72.38 \t AccHead 77.53 \t AccTail 5.40\n",
      "Epoch: [018] \t Loss 0.8450 \t Acc 71.96 \t AccHead 77.02 \t AccTail 5.97\n",
      "Epoch: [019] \t Loss 0.8401 \t Acc 72.17 \t AccHead 76.33 \t AccTail 18.39\n",
      "Epoch: [020] \t Loss 0.8247 \t Acc 63.60 \t AccHead 68.01 \t AccTail 6.37\n",
      "Epoch: [021] \t Loss 0.8273 \t Acc 67.33 \t AccHead 71.82 \t AccTail 9.08\n",
      "Epoch: [022] \t Loss 0.8169 \t Acc 70.72 \t AccHead 76.08 \t AccTail 0.85\n",
      "Epoch: [023] \t Loss 0.7930 \t Acc 67.95 \t AccHead 72.69 \t AccTail 6.52\n",
      "Epoch: [024] \t Loss 0.8021 \t Acc 71.23 \t AccHead 75.02 \t AccTail 22.07\n",
      "Epoch: [025] \t Loss 0.7833 \t Acc 64.40 \t AccHead 68.53 \t AccTail 11.02\n",
      "Epoch: [026] \t Loss 0.7881 \t Acc 64.41 \t AccHead 69.28 \t AccTail 1.13\n",
      "Epoch: [027] \t Loss 0.7948 \t Acc 72.82 \t AccHead 77.14 \t AccTail 16.50\n",
      "Epoch: [028] \t Loss 0.7807 \t Acc 73.50 \t AccHead 78.71 \t AccTail 5.95\n",
      "Epoch: [029] \t Loss 0.7647 \t Acc 73.83 \t AccHead 78.81 \t AccTail 8.84\n",
      "Epoch: [030] \t Loss 0.7662 \t Acc 73.46 \t AccHead 77.86 \t AccTail 16.43\n",
      "Epoch: [031] \t Loss 0.7785 \t Acc 72.69 \t AccHead 76.64 \t AccTail 21.31\n",
      "Epoch: [032] \t Loss 0.7537 \t Acc 73.27 \t AccHead 78.29 \t AccTail 7.82\n",
      "Epoch: [033] \t Loss 0.7677 \t Acc 68.75 \t AccHead 73.89 \t AccTail 2.26\n",
      "Epoch: [034] \t Loss 0.7581 \t Acc 72.22 \t AccHead 76.47 \t AccTail 17.46\n",
      "Epoch: [035] \t Loss 0.7643 \t Acc 73.21 \t AccHead 77.23 \t AccTail 21.55\n",
      "Epoch: [036] \t Loss 0.7544 \t Acc 72.63 \t AccHead 77.61 \t AccTail 8.19\n",
      "Epoch: [037] \t Loss 0.7536 \t Acc 73.00 \t AccHead 77.63 \t AccTail 13.15\n",
      "Epoch: [038] \t Loss 0.7591 \t Acc 73.08 \t AccHead 77.35 \t AccTail 17.94\n",
      "Epoch: [039] \t Loss 0.7451 \t Acc 74.52 \t AccHead 78.92 \t AccTail 17.33\n",
      "Epoch: [040] \t Loss 0.7509 \t Acc 58.75 \t AccHead 63.00 \t AccTail 3.41\n",
      "Epoch: [041] \t Loss 0.7382 \t Acc 66.96 \t AccHead 71.70 \t AccTail 5.00\n",
      "Epoch: [042] \t Loss 0.7447 \t Acc 71.49 \t AccHead 73.81 \t AccTail 41.34\n",
      "Epoch: [043] \t Loss 0.7329 \t Acc 75.70 \t AccHead 79.15 \t AccTail 30.92\n",
      "Epoch: [044] \t Loss 0.7397 \t Acc 69.39 \t AccHead 73.85 \t AccTail 11.72\n",
      "Epoch: [045] \t Loss 0.7456 \t Acc 72.94 \t AccHead 75.41 \t AccTail 40.93\n",
      "Epoch: [046] \t Loss 0.7340 \t Acc 65.54 \t AccHead 69.60 \t AccTail 12.91\n",
      "Epoch: [047] \t Loss 0.7501 \t Acc 64.91 \t AccHead 68.72 \t AccTail 15.58\n",
      "Epoch: [048] \t Loss 0.7637 \t Acc 67.97 \t AccHead 72.55 \t AccTail 8.38\n",
      "Epoch: [049] \t Loss 0.7459 \t Acc 74.18 \t AccHead 79.26 \t AccTail 8.36\n",
      "Epoch: [050] \t Loss 0.7386 \t Acc 73.63 \t AccHead 77.80 \t AccTail 19.77\n",
      "Epoch: [051] \t Loss 0.7418 \t Acc 66.20 \t AccHead 71.25 \t AccTail 0.85\n",
      "Epoch: [052] \t Loss 0.7189 \t Acc 73.40 \t AccHead 77.82 \t AccTail 16.03\n",
      "Epoch: [053] \t Loss 0.7485 \t Acc 67.44 \t AccHead 70.67 \t AccTail 25.60\n",
      "Epoch: [054] \t Loss 0.7481 \t Acc 72.51 \t AccHead 77.02 \t AccTail 14.04\n",
      "Epoch: [055] \t Loss 0.7323 \t Acc 70.34 \t AccHead 75.45 \t AccTail 4.38\n",
      "Epoch: [056] \t Loss 0.7334 \t Acc 68.46 \t AccHead 72.11 \t AccTail 21.10\n",
      "Epoch: [057] \t Loss 0.7457 \t Acc 76.42 \t AccHead 80.70 \t AccTail 21.27\n",
      "Epoch: [058] \t Loss 0.7208 \t Acc 69.21 \t AccHead 73.35 \t AccTail 15.77\n",
      "Epoch: [059] \t Loss 0.7184 \t Acc 73.15 \t AccHead 76.89 \t AccTail 24.68\n",
      "Epoch: [060] \t Loss 0.7136 \t Acc 65.47 \t AccHead 69.68 \t AccTail 11.03\n",
      "Epoch: [061] \t Loss 0.7254 \t Acc 70.11 \t AccHead 75.24 \t AccTail 3.95\n",
      "Epoch: [062] \t Loss 0.7237 \t Acc 76.13 \t AccHead 80.34 \t AccTail 21.23\n",
      "Epoch: [063] \t Loss 0.7415 \t Acc 72.35 \t AccHead 77.65 \t AccTail 3.55\n",
      "Epoch: [064] \t Loss 0.7204 \t Acc 75.30 \t AccHead 79.50 \t AccTail 20.74\n",
      "Epoch: [065] \t Loss 0.7356 \t Acc 70.04 \t AccHead 73.25 \t AccTail 28.63\n",
      "Epoch: [066] \t Loss 0.7223 \t Acc 72.39 \t AccHead 76.17 \t AccTail 23.59\n",
      "Epoch: [067] \t Loss 0.7367 \t Acc 76.62 \t AccHead 81.41 \t AccTail 14.81\n",
      "Epoch: [068] \t Loss 0.7381 \t Acc 69.74 \t AccHead 73.84 \t AccTail 16.81\n",
      "Epoch: [069] \t Loss 0.7233 \t Acc 73.99 \t AccHead 79.23 \t AccTail 6.21\n",
      "Epoch: [070] \t Loss 0.7330 \t Acc 68.62 \t AccHead 72.58 \t AccTail 17.28\n",
      "Epoch: [071] \t Loss 0.7238 \t Acc 71.69 \t AccHead 76.69 \t AccTail 7.19\n",
      "Epoch: [072] \t Loss 0.7380 \t Acc 75.10 \t AccHead 79.49 \t AccTail 18.36\n",
      "Epoch: [073] \t Loss 0.7173 \t Acc 70.30 \t AccHead 73.60 \t AccTail 27.62\n",
      "Epoch: [074] \t Loss 0.7102 \t Acc 72.46 \t AccHead 76.42 \t AccTail 21.33\n",
      "Epoch: [075] \t Loss 0.7222 \t Acc 60.11 \t AccHead 63.06 \t AccTail 21.92\n",
      "Epoch: [076] \t Loss 0.7242 \t Acc 75.89 \t AccHead 80.26 \t AccTail 19.38\n",
      "Epoch: [077] \t Loss 0.7423 \t Acc 74.49 \t AccHead 78.75 \t AccTail 19.49\n",
      "Epoch: [078] \t Loss 0.7211 \t Acc 76.66 \t AccHead 81.90 \t AccTail 8.65\n",
      "Epoch: [079] \t Loss 0.7177 \t Acc 72.61 \t AccHead 76.24 \t AccTail 25.50\n",
      "Epoch: [080] \t Loss 0.7278 \t Acc 70.68 \t AccHead 75.43 \t AccTail 9.32\n",
      "Epoch: [081] \t Loss 0.7288 \t Acc 68.30 \t AccHead 72.30 \t AccTail 16.57\n",
      "Epoch: [082] \t Loss 0.7248 \t Acc 66.82 \t AccHead 70.77 \t AccTail 15.60\n",
      "Epoch: [083] \t Loss 0.7280 \t Acc 70.54 \t AccHead 73.70 \t AccTail 29.72\n",
      "Epoch: [084] \t Loss 0.7211 \t Acc 71.14 \t AccHead 74.33 \t AccTail 29.69\n",
      "Epoch: [085] \t Loss 0.7363 \t Acc 71.68 \t AccHead 74.96 \t AccTail 29.12\n",
      "Epoch: [086] \t Loss 0.7134 \t Acc 70.45 \t AccHead 73.39 \t AccTail 32.68\n",
      "Epoch: [087] \t Loss 0.7111 \t Acc 73.33 \t AccHead 77.55 \t AccTail 18.79\n",
      "Epoch: [088] \t Loss 0.7280 \t Acc 64.55 \t AccHead 68.79 \t AccTail 9.26\n",
      "Epoch: [089] \t Loss 0.7173 \t Acc 72.26 \t AccHead 76.34 \t AccTail 19.09\n",
      "Epoch: [090] \t Loss 0.7107 \t Acc 69.66 \t AccHead 74.28 \t AccTail 9.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 14:14:44,466]\u001b[0m Trial 3 finished with value: 31.567773818969727 and parameters: {'n_epoch': 90, 'weight_decay': 0.002394531093789722}. Best is trial 2 with value: 50.338623046875.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 31.57 \t AccHead 55.60 \t AccTail 7.01\n",
      "Epoch: [001] \t Loss 2.1437 \t Acc 40.31 \t AccHead 43.44 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.4080 \t Acc 35.68 \t AccHead 38.42 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.4040 \t Acc 40.19 \t AccHead 43.29 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.3819 \t Acc 28.98 \t AccHead 31.21 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.4024 \t Acc 28.97 \t AccHead 31.21 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.4303 \t Acc 16.06 \t AccHead 17.29 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 1.4128 \t Acc 50.57 \t AccHead 54.46 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 1.4109 \t Acc 47.09 \t AccHead 50.74 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 1.4063 \t Acc 46.16 \t AccHead 49.74 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 1.4720 \t Acc 39.87 \t AccHead 42.96 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 1.5230 \t Acc 40.13 \t AccHead 43.22 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 1.5353 \t Acc 40.36 \t AccHead 43.47 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 1.5250 \t Acc 40.33 \t AccHead 43.43 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 1.5266 \t Acc 40.54 \t AccHead 43.68 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 1.5243 \t Acc 25.24 \t AccHead 27.19 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 1.5439 \t Acc 40.40 \t AccHead 43.51 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 1.5459 \t Acc 40.79 \t AccHead 43.92 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 1.5285 \t Acc 24.11 \t AccHead 25.98 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 1.5913 \t Acc 25.11 \t AccHead 27.05 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 1.6101 \t Acc 40.32 \t AccHead 43.45 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 1.6663 \t Acc 40.25 \t AccHead 43.36 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 1.5641 \t Acc 40.05 \t AccHead 43.12 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 1.5466 \t Acc 43.62 \t AccHead 47.00 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 1.5505 \t Acc 40.35 \t AccHead 43.48 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 1.5429 \t Acc 40.36 \t AccHead 43.49 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 1.5373 \t Acc 41.13 \t AccHead 44.32 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 1.5423 \t Acc 40.71 \t AccHead 43.83 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 1.5375 \t Acc 24.86 \t AccHead 26.79 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 1.5473 \t Acc 40.35 \t AccHead 43.47 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 1.5585 \t Acc 40.33 \t AccHead 43.45 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 1.6215 \t Acc 40.32 \t AccHead 43.42 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 1.5758 \t Acc 24.29 \t AccHead 26.16 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 1.6188 \t Acc 40.30 \t AccHead 43.41 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 1.5658 \t Acc 40.34 \t AccHead 43.45 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 1.5454 \t Acc 46.16 \t AccHead 49.72 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 1.5594 \t Acc 40.33 \t AccHead 43.46 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 1.5352 \t Acc 40.26 \t AccHead 43.38 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 1.5349 \t Acc 40.35 \t AccHead 43.46 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 1.5856 \t Acc 40.28 \t AccHead 43.39 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 1.5940 \t Acc 40.35 \t AccHead 43.46 \t AccTail 0.00\n",
      "Epoch: [041] \t Loss 1.5774 \t Acc 40.34 \t AccHead 43.43 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 1.6142 \t Acc 40.27 \t AccHead 43.38 \t AccTail 0.00\n",
      "Epoch: [043] \t Loss 1.5584 \t Acc 20.69 \t AccHead 22.29 \t AccTail 0.00\n",
      "Epoch: [044] \t Loss 1.6814 \t Acc 40.27 \t AccHead 43.37 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 1.6752 \t Acc 40.34 \t AccHead 43.45 \t AccTail 0.00\n",
      "Epoch: [046] \t Loss 1.6778 \t Acc 40.28 \t AccHead 43.39 \t AccTail 0.00\n",
      "Epoch: [047] \t Loss 1.6725 \t Acc 40.37 \t AccHead 43.49 \t AccTail 0.00\n",
      "Epoch: [048] \t Loss 1.6764 \t Acc 40.28 \t AccHead 43.40 \t AccTail 0.00\n",
      "Epoch: [049] \t Loss 1.6741 \t Acc 40.28 \t AccHead 43.39 \t AccTail 0.00\n",
      "Epoch: [050] \t Loss 1.6774 \t Acc 40.28 \t AccHead 43.39 \t AccTail 0.00\n",
      "Epoch: [051] \t Loss 1.6721 \t Acc 40.32 \t AccHead 43.44 \t AccTail 0.00\n",
      "Epoch: [052] \t Loss 1.6730 \t Acc 40.27 \t AccHead 43.38 \t AccTail 0.00\n",
      "Epoch: [053] \t Loss 1.6777 \t Acc 40.31 \t AccHead 43.42 \t AccTail 0.00\n",
      "Epoch: [054] \t Loss 1.6747 \t Acc 40.43 \t AccHead 43.54 \t AccTail 0.00\n",
      "Epoch: [055] \t Loss 1.6718 \t Acc 40.35 \t AccHead 43.47 \t AccTail 0.00\n",
      "Epoch: [056] \t Loss 1.6751 \t Acc 40.36 \t AccHead 43.50 \t AccTail 0.00\n",
      "Epoch: [057] \t Loss 1.6759 \t Acc 40.31 \t AccHead 43.43 \t AccTail 0.00\n",
      "Epoch: [058] \t Loss 1.6728 \t Acc 40.28 \t AccHead 43.38 \t AccTail 0.00\n",
      "Epoch: [059] \t Loss 1.6713 \t Acc 40.35 \t AccHead 43.45 \t AccTail 0.00\n",
      "Epoch: [060] \t Loss 1.6743 \t Acc 40.26 \t AccHead 43.37 \t AccTail 0.00\n",
      "Epoch: [061] \t Loss 1.6734 \t Acc 40.32 \t AccHead 43.43 \t AccTail 0.00\n",
      "Epoch: [062] \t Loss 1.6746 \t Acc 40.33 \t AccHead 43.46 \t AccTail 0.00\n",
      "Epoch: [063] \t Loss 1.6740 \t Acc 40.36 \t AccHead 43.48 \t AccTail 0.00\n",
      "Epoch: [064] \t Loss 1.6731 \t Acc 40.35 \t AccHead 43.48 \t AccTail 0.00\n",
      "Epoch: [065] \t Loss 1.6755 \t Acc 40.26 \t AccHead 43.38 \t AccTail 0.00\n",
      "Epoch: [066] \t Loss 1.6709 \t Acc 40.31 \t AccHead 43.42 \t AccTail 0.00\n",
      "Epoch: [067] \t Loss 1.6702 \t Acc 40.25 \t AccHead 43.35 \t AccTail 0.00\n",
      "Epoch: [068] \t Loss 1.6795 \t Acc 40.27 \t AccHead 43.38 \t AccTail 0.00\n",
      "Epoch: [069] \t Loss 1.6751 \t Acc 40.37 \t AccHead 43.48 \t AccTail 0.00\n",
      "Epoch: [070] \t Loss 1.6757 \t Acc 40.33 \t AccHead 43.46 \t AccTail 0.00\n",
      "Epoch: [071] \t Loss 1.6810 \t Acc 40.29 \t AccHead 43.41 \t AccTail 0.00\n",
      "Epoch: [072] \t Loss 1.6767 \t Acc 40.26 \t AccHead 43.38 \t AccTail 0.00\n",
      "Epoch: [073] \t Loss 1.6724 \t Acc 40.41 \t AccHead 43.53 \t AccTail 0.00\n",
      "Epoch: [074] \t Loss 1.6784 \t Acc 40.30 \t AccHead 43.41 \t AccTail 0.00\n",
      "Epoch: [075] \t Loss 1.6770 \t Acc 40.34 \t AccHead 43.46 \t AccTail 0.00\n",
      "Epoch: [076] \t Loss 1.6742 \t Acc 40.31 \t AccHead 43.43 \t AccTail 0.00\n",
      "Epoch: [077] \t Loss 1.6747 \t Acc 40.35 \t AccHead 43.46 \t AccTail 0.00\n",
      "Epoch: [078] \t Loss 1.6794 \t Acc 40.33 \t AccHead 43.45 \t AccTail 0.00\n",
      "Epoch: [079] \t Loss 1.6708 \t Acc 40.31 \t AccHead 43.43 \t AccTail 0.00\n",
      "Epoch: [080] \t Loss 1.6742 \t Acc 40.37 \t AccHead 43.50 \t AccTail 0.00\n",
      "Epoch: [081] \t Loss 1.6715 \t Acc 40.32 \t AccHead 43.42 \t AccTail 0.00\n",
      "Epoch: [082] \t Loss 1.6773 \t Acc 40.27 \t AccHead 43.38 \t AccTail 0.00\n",
      "Epoch: [083] \t Loss 1.6775 \t Acc 40.30 \t AccHead 43.40 \t AccTail 0.00\n",
      "Epoch: [084] \t Loss 1.6765 \t Acc 40.33 \t AccHead 43.45 \t AccTail 0.00\n",
      "Epoch: [085] \t Loss 1.6735 \t Acc 40.33 \t AccHead 43.43 \t AccTail 0.00\n",
      "Epoch: [086] \t Loss 1.6724 \t Acc 40.33 \t AccHead 43.45 \t AccTail 0.00\n",
      "Epoch: [087] \t Loss 1.6730 \t Acc 40.29 \t AccHead 43.40 \t AccTail 0.00\n",
      "Epoch: [088] \t Loss 1.6742 \t Acc 40.29 \t AccHead 43.40 \t AccTail 0.00\n",
      "Epoch: [089] \t Loss 1.6753 \t Acc 40.32 \t AccHead 43.45 \t AccTail 0.00\n",
      "Epoch: [090] \t Loss 1.6739 \t Acc 40.34 \t AccHead 43.45 \t AccTail 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 14:25:55,489]\u001b[0m Trial 4 finished with value: 10.10815715789795 and parameters: {'n_epoch': 90, 'weight_decay': 0.0689012572886808}. Best is trial 2 with value: 50.338623046875.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 10.11 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [001] \t Loss 2.7899 \t Acc 52.19 \t AccHead 56.21 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.5211 \t Acc 54.44 \t AccHead 58.66 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.3185 \t Acc 57.44 \t AccHead 61.89 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.1678 \t Acc 63.94 \t AccHead 68.87 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.2151 \t Acc 60.42 \t AccHead 65.10 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.1341 \t Acc 62.73 \t AccHead 67.58 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 1.0664 \t Acc 65.22 \t AccHead 70.27 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 1.0076 \t Acc 64.31 \t AccHead 69.30 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 0.9710 \t Acc 66.91 \t AccHead 71.59 \t AccTail 5.98\n",
      "Epoch: [010] \t Loss 0.9637 \t Acc 67.42 \t AccHead 72.64 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 1.0077 \t Acc 60.24 \t AccHead 64.89 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 1.0162 \t Acc 66.47 \t AccHead 71.62 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 0.9448 \t Acc 70.07 \t AccHead 75.31 \t AccTail 2.12\n",
      "Epoch: [014] \t Loss 0.8808 \t Acc 71.28 \t AccHead 76.20 \t AccTail 7.24\n",
      "Epoch: [015] \t Loss 0.8674 \t Acc 68.73 \t AccHead 73.79 \t AccTail 2.98\n",
      "Epoch: [016] \t Loss 0.8400 \t Acc 70.87 \t AccHead 76.18 \t AccTail 2.26\n",
      "Epoch: [017] \t Loss 0.8099 \t Acc 72.98 \t AccHead 77.96 \t AccTail 8.37\n",
      "Epoch: [018] \t Loss 0.8035 \t Acc 72.25 \t AccHead 76.83 \t AccTail 13.01\n",
      "Epoch: [019] \t Loss 0.7730 \t Acc 73.60 \t AccHead 78.63 \t AccTail 8.49\n",
      "Epoch: [020] \t Loss 0.7690 \t Acc 75.18 \t AccHead 79.84 \t AccTail 14.75\n",
      "Epoch: [021] \t Loss 0.7361 \t Acc 75.30 \t AccHead 80.38 \t AccTail 9.86\n",
      "Epoch: [022] \t Loss 0.7230 \t Acc 75.82 \t AccHead 79.27 \t AccTail 31.26\n",
      "Epoch: [023] \t Loss 0.7045 \t Acc 77.14 \t AccHead 81.27 \t AccTail 23.84\n",
      "Epoch: [024] \t Loss 0.7013 \t Acc 77.63 \t AccHead 82.30 \t AccTail 17.46\n",
      "Epoch: [025] \t Loss 0.6864 \t Acc 78.61 \t AccHead 82.58 \t AccTail 27.20\n",
      "Epoch: [026] \t Loss 0.6526 \t Acc 75.14 \t AccHead 79.21 \t AccTail 22.38\n",
      "Epoch: [027] \t Loss 0.6718 \t Acc 76.40 \t AccHead 80.00 \t AccTail 29.90\n",
      "Epoch: [028] \t Loss 0.6327 \t Acc 76.69 \t AccHead 80.70 \t AccTail 24.50\n",
      "Epoch: [029] \t Loss 0.6357 \t Acc 79.21 \t AccHead 83.36 \t AccTail 25.18\n",
      "Epoch: [030] \t Loss 0.6199 \t Acc 79.99 \t AccHead 84.21 \t AccTail 24.96\n",
      "Epoch: [031] \t Loss 0.6049 \t Acc 79.92 \t AccHead 82.81 \t AccTail 42.41\n",
      "Epoch: [032] \t Loss 0.6090 \t Acc 79.65 \t AccHead 82.57 \t AccTail 41.78\n",
      "Epoch: [033] \t Loss 0.5999 \t Acc 78.72 \t AccHead 82.67 \t AccTail 27.62\n",
      "Epoch: [034] \t Loss 0.5882 \t Acc 80.79 \t AccHead 84.41 \t AccTail 33.71\n",
      "Epoch: [035] \t Loss 0.5876 \t Acc 80.77 \t AccHead 84.25 \t AccTail 35.69\n",
      "Epoch: [036] \t Loss 0.5735 \t Acc 80.50 \t AccHead 83.95 \t AccTail 36.06\n",
      "Epoch: [037] \t Loss 0.5600 \t Acc 81.14 \t AccHead 84.42 \t AccTail 38.58\n",
      "Epoch: [038] \t Loss 0.5629 \t Acc 80.36 \t AccHead 84.50 \t AccTail 26.52\n",
      "Epoch: [039] \t Loss 0.5547 \t Acc 81.91 \t AccHead 84.05 \t AccTail 54.17\n",
      "Epoch: [040] \t Loss 0.5398 \t Acc 81.25 \t AccHead 85.63 \t AccTail 24.61\n",
      "Epoch: [041] \t Loss 0.5334 \t Acc 79.35 \t AccHead 82.86 \t AccTail 33.85\n",
      "Epoch: [042] \t Loss 0.5289 \t Acc 76.02 \t AccHead 78.82 \t AccTail 39.92\n",
      "Epoch: [043] \t Loss 0.5113 \t Acc 81.84 \t AccHead 85.38 \t AccTail 35.98\n",
      "Epoch: [044] \t Loss 0.5173 \t Acc 81.15 \t AccHead 85.44 \t AccTail 25.50\n",
      "Epoch: [045] \t Loss 0.5265 \t Acc 82.08 \t AccHead 85.88 \t AccTail 32.67\n",
      "Epoch: [046] \t Loss 0.5130 \t Acc 83.26 \t AccHead 85.90 \t AccTail 49.15\n",
      "Epoch: [047] \t Loss 0.5076 \t Acc 83.47 \t AccHead 87.67 \t AccTail 28.88\n",
      "Epoch: [048] \t Loss 0.4800 \t Acc 83.07 \t AccHead 86.65 \t AccTail 36.63\n",
      "Epoch: [049] \t Loss 0.4945 \t Acc 84.33 \t AccHead 87.40 \t AccTail 44.70\n",
      "Epoch: [050] \t Loss 0.4857 \t Acc 84.12 \t AccHead 86.20 \t AccTail 57.22\n",
      "Epoch: [051] \t Loss 0.4973 \t Acc 84.09 \t AccHead 86.56 \t AccTail 52.12\n",
      "Epoch: [052] \t Loss 0.4814 \t Acc 83.11 \t AccHead 86.14 \t AccTail 43.77\n",
      "Epoch: [053] \t Loss 0.4754 \t Acc 82.54 \t AccHead 85.66 \t AccTail 42.07\n",
      "Epoch: [054] \t Loss 0.4796 \t Acc 84.43 \t AccHead 87.46 \t AccTail 45.12\n",
      "Epoch: [055] \t Loss 0.4618 \t Acc 83.99 \t AccHead 87.33 \t AccTail 40.54\n",
      "Epoch: [056] \t Loss 0.4773 \t Acc 83.08 \t AccHead 86.08 \t AccTail 44.29\n",
      "Epoch: [057] \t Loss 0.4772 \t Acc 84.11 \t AccHead 86.55 \t AccTail 52.61\n",
      "Epoch: [058] \t Loss 0.4654 \t Acc 81.04 \t AccHead 83.31 \t AccTail 51.63\n",
      "Epoch: [059] \t Loss 0.4445 \t Acc 82.32 \t AccHead 85.25 \t AccTail 44.33\n",
      "Epoch: [060] \t Loss 0.4538 \t Acc 83.79 \t AccHead 86.38 \t AccTail 50.07\n",
      "Epoch: [061] \t Loss 0.4371 \t Acc 83.42 \t AccHead 85.08 \t AccTail 62.11\n",
      "Epoch: [062] \t Loss 0.4354 \t Acc 83.63 \t AccHead 87.77 \t AccTail 29.67\n",
      "Epoch: [063] \t Loss 0.4335 \t Acc 86.72 \t AccHead 89.33 \t AccTail 52.90\n",
      "Epoch: [064] \t Loss 0.4371 \t Acc 84.28 \t AccHead 87.26 \t AccTail 45.75\n",
      "Epoch: [065] \t Loss 0.4476 \t Acc 83.43 \t AccHead 85.28 \t AccTail 59.60\n",
      "Epoch: [066] \t Loss 0.4140 \t Acc 83.19 \t AccHead 85.87 \t AccTail 48.44\n",
      "Epoch: [067] \t Loss 0.4351 \t Acc 83.65 \t AccHead 85.46 \t AccTail 60.23\n",
      "Epoch: [068] \t Loss 0.4137 \t Acc 84.84 \t AccHead 87.44 \t AccTail 51.34\n",
      "Epoch: [069] \t Loss 0.4202 \t Acc 85.70 \t AccHead 88.28 \t AccTail 52.27\n",
      "Epoch: [070] \t Loss 0.3934 \t Acc 86.68 \t AccHead 89.31 \t AccTail 52.62\n",
      "Epoch: [071] \t Loss 0.3992 \t Acc 83.67 \t AccHead 85.47 \t AccTail 60.40\n",
      "Epoch: [072] \t Loss 0.3983 \t Acc 87.68 \t AccHead 90.03 \t AccTail 57.12\n",
      "Epoch: [073] \t Loss 0.4043 \t Acc 85.81 \t AccHead 88.39 \t AccTail 52.54\n",
      "Epoch: [074] \t Loss 0.4115 \t Acc 87.53 \t AccHead 90.21 \t AccTail 52.90\n",
      "Epoch: [075] \t Loss 0.3974 \t Acc 85.37 \t AccHead 87.48 \t AccTail 58.07\n",
      "Epoch: [076] \t Loss 0.3985 \t Acc 87.59 \t AccHead 90.36 \t AccTail 51.49\n",
      "Epoch: [077] \t Loss 0.3893 \t Acc 87.32 \t AccHead 89.28 \t AccTail 61.90\n",
      "Epoch: [078] \t Loss 0.3779 \t Acc 86.57 \t AccHead 88.49 \t AccTail 61.78\n",
      "Epoch: [079] \t Loss 0.3856 \t Acc 85.25 \t AccHead 87.79 \t AccTail 52.27\n",
      "Epoch: [080] \t Loss 0.3925 \t Acc 86.66 \t AccHead 87.78 \t AccTail 72.18\n",
      "Epoch: [081] \t Loss 0.3772 \t Acc 85.10 \t AccHead 86.39 \t AccTail 68.32\n",
      "Epoch: [082] \t Loss 0.3747 \t Acc 84.56 \t AccHead 87.74 \t AccTail 43.42\n",
      "Epoch: [083] \t Loss 0.3956 \t Acc 85.17 \t AccHead 86.50 \t AccTail 67.85\n",
      "Epoch: [084] \t Loss 0.3679 \t Acc 87.66 \t AccHead 90.07 \t AccTail 56.14\n",
      "Epoch: [085] \t Loss 0.3733 \t Acc 88.36 \t AccHead 90.30 \t AccTail 63.33\n",
      "Epoch: [086] \t Loss 0.3797 \t Acc 85.70 \t AccHead 87.49 \t AccTail 62.45\n",
      "Epoch: [087] \t Loss 0.3734 \t Acc 86.42 \t AccHead 89.55 \t AccTail 45.97\n",
      "Epoch: [088] \t Loss 0.3489 \t Acc 87.62 \t AccHead 90.65 \t AccTail 48.37\n",
      "Epoch: [089] \t Loss 0.3703 \t Acc 86.20 \t AccHead 88.39 \t AccTail 57.79\n",
      "Epoch: [090] \t Loss 0.3711 \t Acc 86.88 \t AccHead 89.52 \t AccTail 52.69\n",
      "Epoch: [091] \t Loss 0.3481 \t Acc 85.33 \t AccHead 88.27 \t AccTail 47.17\n",
      "Epoch: [092] \t Loss 0.3642 \t Acc 87.95 \t AccHead 89.57 \t AccTail 66.90\n",
      "Epoch: [093] \t Loss 0.3672 \t Acc 87.44 \t AccHead 89.28 \t AccTail 63.49\n",
      "Epoch: [094] \t Loss 0.3528 \t Acc 88.27 \t AccHead 91.00 \t AccTail 52.97\n",
      "Epoch: [095] \t Loss 0.3509 \t Acc 87.02 \t AccHead 90.26 \t AccTail 45.28\n",
      "Epoch: [096] \t Loss 0.3471 \t Acc 89.42 \t AccHead 91.91 \t AccTail 57.20\n",
      "Epoch: [097] \t Loss 0.3476 \t Acc 89.02 \t AccHead 91.10 \t AccTail 62.20\n",
      "Epoch: [098] \t Loss 0.3576 \t Acc 87.49 \t AccHead 88.36 \t AccTail 76.14\n",
      "Epoch: [099] \t Loss 0.3339 \t Acc 88.32 \t AccHead 91.19 \t AccTail 51.27\n",
      "Epoch: [100] \t Loss 0.3403 \t Acc 88.25 \t AccHead 89.64 \t AccTail 70.13\n",
      "Epoch: [101] \t Loss 0.3391 \t Acc 87.80 \t AccHead 89.64 \t AccTail 63.97\n",
      "Epoch: [102] \t Loss 0.3508 \t Acc 87.11 \t AccHead 88.77 \t AccTail 65.72\n",
      "Epoch: [103] \t Loss 0.3393 \t Acc 87.43 \t AccHead 89.86 \t AccTail 56.07\n",
      "Epoch: [104] \t Loss 0.3442 \t Acc 86.93 \t AccHead 88.31 \t AccTail 69.07\n",
      "Epoch: [105] \t Loss 0.3330 \t Acc 88.45 \t AccHead 89.58 \t AccTail 73.86\n",
      "Epoch: [106] \t Loss 0.3430 \t Acc 89.76 \t AccHead 91.31 \t AccTail 69.73\n",
      "Epoch: [107] \t Loss 0.3364 \t Acc 85.78 \t AccHead 89.33 \t AccTail 40.00\n",
      "Epoch: [108] \t Loss 0.3312 \t Acc 88.38 \t AccHead 90.86 \t AccTail 56.29\n",
      "Epoch: [109] \t Loss 0.3281 \t Acc 86.59 \t AccHead 88.09 \t AccTail 67.14\n",
      "Epoch: [110] \t Loss 0.3441 \t Acc 86.02 \t AccHead 88.79 \t AccTail 49.93\n",
      "Epoch: [111] \t Loss 0.3275 \t Acc 88.39 \t AccHead 90.32 \t AccTail 63.51\n",
      "Epoch: [112] \t Loss 0.3325 \t Acc 89.76 \t AccHead 91.36 \t AccTail 69.08\n",
      "Epoch: [113] \t Loss 0.3290 \t Acc 88.24 \t AccHead 89.84 \t AccTail 67.51\n",
      "Epoch: [114] \t Loss 0.3263 \t Acc 87.61 \t AccHead 89.52 \t AccTail 62.89\n",
      "Epoch: [115] \t Loss 0.3121 \t Acc 85.91 \t AccHead 86.90 \t AccTail 73.02\n",
      "Epoch: [116] \t Loss 0.3241 \t Acc 89.67 \t AccHead 92.23 \t AccTail 56.52\n",
      "Epoch: [117] \t Loss 0.3259 \t Acc 87.60 \t AccHead 89.37 \t AccTail 64.69\n",
      "Epoch: [118] \t Loss 0.3279 \t Acc 86.53 \t AccHead 89.20 \t AccTail 52.05\n",
      "Epoch: [119] \t Loss 0.3187 \t Acc 87.81 \t AccHead 90.62 \t AccTail 51.49\n",
      "Epoch: [120] \t Loss 0.3129 \t Acc 89.37 \t AccHead 90.97 \t AccTail 68.69\n",
      "Epoch: [121] \t Loss 0.3183 \t Acc 86.84 \t AccHead 89.05 \t AccTail 58.27\n",
      "Epoch: [122] \t Loss 0.3271 \t Acc 83.49 \t AccHead 85.21 \t AccTail 61.41\n",
      "Epoch: [123] \t Loss 0.3400 \t Acc 89.58 \t AccHead 91.92 \t AccTail 59.21\n",
      "Epoch: [124] \t Loss 0.3109 \t Acc 89.67 \t AccHead 92.19 \t AccTail 57.12\n",
      "Epoch: [125] \t Loss 0.3228 \t Acc 83.61 \t AccHead 85.62 \t AccTail 57.59\n",
      "Epoch: [126] \t Loss 0.3161 \t Acc 88.65 \t AccHead 90.36 \t AccTail 66.38\n",
      "Epoch: [127] \t Loss 0.3029 \t Acc 90.12 \t AccHead 91.19 \t AccTail 76.20\n",
      "Epoch: [128] \t Loss 0.3070 \t Acc 90.20 \t AccHead 91.33 \t AccTail 75.46\n",
      "Epoch: [129] \t Loss 0.3247 \t Acc 88.11 \t AccHead 89.82 \t AccTail 65.91\n",
      "Epoch: [130] \t Loss 0.3095 \t Acc 91.33 \t AccHead 93.22 \t AccTail 66.81\n",
      "Epoch: [131] \t Loss 0.3058 \t Acc 89.39 \t AccHead 91.66 \t AccTail 59.92\n",
      "Epoch: [132] \t Loss 0.3065 \t Acc 89.52 \t AccHead 91.06 \t AccTail 69.55\n",
      "Epoch: [133] \t Loss 0.3153 \t Acc 89.05 \t AccHead 90.02 \t AccTail 76.49\n",
      "Epoch: [134] \t Loss 0.3147 \t Acc 88.21 \t AccHead 90.32 \t AccTail 60.93\n",
      "Epoch: [135] \t Loss 0.3137 \t Acc 86.75 \t AccHead 89.13 \t AccTail 55.89\n",
      "Epoch: [136] \t Loss 0.3197 \t Acc 85.89 \t AccHead 86.57 \t AccTail 77.12\n",
      "Epoch: [137] \t Loss 0.3064 \t Acc 90.51 \t AccHead 92.06 \t AccTail 70.52\n",
      "Epoch: [138] \t Loss 0.3067 \t Acc 87.46 \t AccHead 88.50 \t AccTail 73.97\n",
      "Epoch: [139] \t Loss 0.2983 \t Acc 88.77 \t AccHead 89.54 \t AccTail 78.75\n",
      "Epoch: [140] \t Loss 0.3005 \t Acc 87.33 \t AccHead 89.33 \t AccTail 61.28\n",
      "Epoch: [141] \t Loss 0.3145 \t Acc 89.77 \t AccHead 90.82 \t AccTail 76.24\n",
      "Epoch: [142] \t Loss 0.3050 \t Acc 87.31 \t AccHead 89.52 \t AccTail 58.82\n",
      "Epoch: [143] \t Loss 0.2907 \t Acc 88.58 \t AccHead 90.18 \t AccTail 67.84\n",
      "Epoch: [144] \t Loss 0.3107 \t Acc 89.01 \t AccHead 91.10 \t AccTail 61.90\n",
      "Epoch: [145] \t Loss 0.2959 \t Acc 89.85 \t AccHead 90.68 \t AccTail 79.24\n",
      "Epoch: [146] \t Loss 0.2906 \t Acc 89.00 \t AccHead 90.64 \t AccTail 67.76\n",
      "Epoch: [147] \t Loss 0.2867 \t Acc 88.94 \t AccHead 90.57 \t AccTail 67.80\n",
      "Epoch: [148] \t Loss 0.2868 \t Acc 88.43 \t AccHead 90.49 \t AccTail 61.65\n",
      "Epoch: [149] \t Loss 0.3012 \t Acc 88.09 \t AccHead 89.43 \t AccTail 70.68\n",
      "Epoch: [150] \t Loss 0.3064 \t Acc 89.08 \t AccHead 90.36 \t AccTail 72.40\n",
      "Epoch: [151] \t Loss 0.1956 \t Acc 95.65 \t AccHead 96.60 \t AccTail 83.38\n",
      "Epoch: [152] \t Loss 0.1457 \t Acc 96.48 \t AccHead 97.10 \t AccTail 88.35\n",
      "Epoch: [153] \t Loss 0.1154 \t Acc 97.17 \t AccHead 97.51 \t AccTail 92.79\n",
      "Epoch: [154] \t Loss 0.1065 \t Acc 97.24 \t AccHead 97.79 \t AccTail 90.11\n",
      "Epoch: [155] \t Loss 0.0905 \t Acc 97.36 \t AccHead 97.87 \t AccTail 90.79\n",
      "Epoch: [156] \t Loss 0.0892 \t Acc 97.95 \t AccHead 98.36 \t AccTail 92.66\n",
      "Epoch: [157] \t Loss 0.0831 \t Acc 98.33 \t AccHead 98.66 \t AccTail 94.00\n",
      "Epoch: [158] \t Loss 0.0737 \t Acc 98.45 \t AccHead 98.67 \t AccTail 95.62\n",
      "Epoch: [159] \t Loss 0.0675 \t Acc 98.29 \t AccHead 98.60 \t AccTail 94.18\n",
      "Epoch: [160] \t Loss 0.0638 \t Acc 98.68 \t AccHead 98.97 \t AccTail 94.91\n",
      "Epoch: [161] \t Loss 0.0673 \t Acc 98.31 \t AccHead 98.58 \t AccTail 94.77\n",
      "Epoch: [162] \t Loss 0.0567 \t Acc 98.62 \t AccHead 98.94 \t AccTail 94.48\n",
      "Epoch: [163] \t Loss 0.0519 \t Acc 98.60 \t AccHead 98.71 \t AccTail 97.18\n",
      "Epoch: [164] \t Loss 0.0577 \t Acc 98.94 \t AccHead 99.17 \t AccTail 96.05\n",
      "Epoch: [165] \t Loss 0.0516 \t Acc 98.77 \t AccHead 98.87 \t AccTail 97.45\n",
      "Epoch: [166] \t Loss 0.0468 \t Acc 98.91 \t AccHead 99.23 \t AccTail 94.77\n",
      "Epoch: [167] \t Loss 0.0441 \t Acc 99.00 \t AccHead 99.23 \t AccTail 95.89\n",
      "Epoch: [168] \t Loss 0.0488 \t Acc 98.81 \t AccHead 98.99 \t AccTail 96.44\n",
      "Epoch: [169] \t Loss 0.0438 \t Acc 99.16 \t AccHead 99.30 \t AccTail 97.31\n",
      "Epoch: [170] \t Loss 0.0403 \t Acc 99.23 \t AccHead 99.32 \t AccTail 98.01\n",
      "Epoch: [171] \t Loss 0.0384 \t Acc 99.34 \t AccHead 99.48 \t AccTail 97.59\n",
      "Epoch: [172] \t Loss 0.0380 \t Acc 99.20 \t AccHead 99.31 \t AccTail 97.73\n",
      "Epoch: [173] \t Loss 0.0372 \t Acc 99.23 \t AccHead 99.39 \t AccTail 97.18\n",
      "Epoch: [174] \t Loss 0.0343 \t Acc 99.33 \t AccHead 99.46 \t AccTail 97.59\n",
      "Epoch: [175] \t Loss 0.0308 \t Acc 99.35 \t AccHead 99.41 \t AccTail 98.58\n",
      "Epoch: [176] \t Loss 0.0293 \t Acc 99.16 \t AccHead 99.40 \t AccTail 96.02\n",
      "Epoch: [177] \t Loss 0.0313 \t Acc 99.29 \t AccHead 99.31 \t AccTail 99.01\n",
      "Epoch: [178] \t Loss 0.0324 \t Acc 99.35 \t AccHead 99.45 \t AccTail 98.02\n",
      "Epoch: [179] \t Loss 0.0314 \t Acc 99.30 \t AccHead 99.34 \t AccTail 98.72\n",
      "Epoch: [180] \t Loss 0.0317 \t Acc 99.43 \t AccHead 99.57 \t AccTail 97.59\n",
      "Epoch: [181] \t Loss 0.0272 \t Acc 99.43 \t AccHead 99.55 \t AccTail 97.88\n",
      "Epoch: [182] \t Loss 0.0245 \t Acc 99.58 \t AccHead 99.65 \t AccTail 98.72\n",
      "Epoch: [183] \t Loss 0.0269 \t Acc 99.44 \t AccHead 99.55 \t AccTail 98.01\n",
      "Epoch: [184] \t Loss 0.0257 \t Acc 99.56 \t AccHead 99.60 \t AccTail 99.14\n",
      "Epoch: [185] \t Loss 0.0245 \t Acc 99.66 \t AccHead 99.74 \t AccTail 98.58\n",
      "Epoch: [186] \t Loss 0.0228 \t Acc 99.43 \t AccHead 99.49 \t AccTail 98.73\n",
      "Epoch: [187] \t Loss 0.0222 \t Acc 99.44 \t AccHead 99.58 \t AccTail 97.57\n",
      "Epoch: [188] \t Loss 0.0257 \t Acc 99.44 \t AccHead 99.55 \t AccTail 98.02\n",
      "Epoch: [189] \t Loss 0.0233 \t Acc 99.53 \t AccHead 99.58 \t AccTail 98.87\n",
      "Epoch: [190] \t Loss 0.0219 \t Acc 99.52 \t AccHead 99.52 \t AccTail 99.58\n",
      "Epoch: [191] \t Loss 0.0211 \t Acc 99.61 \t AccHead 99.63 \t AccTail 99.44\n",
      "Epoch: [192] \t Loss 0.0240 \t Acc 99.55 \t AccHead 99.57 \t AccTail 99.29\n",
      "Epoch: [193] \t Loss 0.0206 \t Acc 99.69 \t AccHead 99.69 \t AccTail 99.57\n",
      "Epoch: [194] \t Loss 0.0200 \t Acc 99.60 \t AccHead 99.64 \t AccTail 99.15\n",
      "Epoch: [195] \t Loss 0.0217 \t Acc 99.61 \t AccHead 99.64 \t AccTail 99.29\n",
      "Epoch: [196] \t Loss 0.0172 \t Acc 99.77 \t AccHead 99.84 \t AccTail 98.86\n",
      "Epoch: [197] \t Loss 0.0182 \t Acc 99.59 \t AccHead 99.65 \t AccTail 98.86\n",
      "Epoch: [198] \t Loss 0.0190 \t Acc 99.56 \t AccHead 99.56 \t AccTail 99.58\n",
      "Epoch: [199] \t Loss 0.0222 \t Acc 99.57 \t AccHead 99.65 \t AccTail 98.59\n",
      "Epoch: [200] \t Loss 0.0178 \t Acc 99.64 \t AccHead 99.66 \t AccTail 99.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 14:50:44,196]\u001b[0m Trial 5 finished with value: 56.24178695678711 and parameters: {'n_epoch': 200, 'weight_decay': 0.0004882461261877769}. Best is trial 5 with value: 56.24178695678711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 56.24 \t AccHead 77.82 \t AccTail 34.19\n",
      "Epoch: [001] \t Loss 2.3880 \t Acc 52.90 \t AccHead 56.96 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.4476 \t Acc 57.39 \t AccHead 61.82 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.3024 \t Acc 59.56 \t AccHead 64.15 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.2054 \t Acc 63.60 \t AccHead 68.50 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.1199 \t Acc 63.33 \t AccHead 68.20 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.0435 \t Acc 66.19 \t AccHead 71.14 \t AccTail 1.43\n",
      "Epoch: [007] \t Loss 1.0498 \t Acc 65.66 \t AccHead 70.71 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 0.9968 \t Acc 66.06 \t AccHead 71.01 \t AccTail 1.98\n",
      "Epoch: [009] \t Loss 0.9519 \t Acc 67.75 \t AccHead 72.72 \t AccTail 3.53\n",
      "Epoch: [010] \t Loss 0.9334 \t Acc 69.30 \t AccHead 74.61 \t AccTail 0.57\n",
      "Epoch: [011] \t Loss 0.9072 \t Acc 71.38 \t AccHead 76.72 \t AccTail 1.99\n",
      "Epoch: [012] \t Loss 0.8863 \t Acc 69.28 \t AccHead 74.16 \t AccTail 5.96\n",
      "Epoch: [013] \t Loss 0.8615 \t Acc 70.11 \t AccHead 75.50 \t AccTail 0.28\n",
      "Epoch: [014] \t Loss 0.8469 \t Acc 72.66 \t AccHead 77.97 \t AccTail 3.69\n",
      "Epoch: [015] \t Loss 0.8276 \t Acc 72.87 \t AccHead 77.70 \t AccTail 10.33\n",
      "Epoch: [016] \t Loss 0.7992 \t Acc 69.76 \t AccHead 74.50 \t AccTail 8.36\n",
      "Epoch: [017] \t Loss 0.7859 \t Acc 74.89 \t AccHead 79.89 \t AccTail 9.93\n",
      "Epoch: [018] \t Loss 0.7715 \t Acc 72.40 \t AccHead 76.95 \t AccTail 13.58\n",
      "Epoch: [019] \t Loss 0.7471 \t Acc 74.96 \t AccHead 80.19 \t AccTail 7.34\n",
      "Epoch: [020] \t Loss 0.7344 \t Acc 72.61 \t AccHead 76.62 \t AccTail 20.65\n",
      "Epoch: [021] \t Loss 0.7249 \t Acc 76.21 \t AccHead 80.84 \t AccTail 16.03\n",
      "Epoch: [022] \t Loss 0.7098 \t Acc 71.57 \t AccHead 75.30 \t AccTail 23.45\n",
      "Epoch: [023] \t Loss 0.7055 \t Acc 76.90 \t AccHead 81.34 \t AccTail 19.61\n",
      "Epoch: [024] \t Loss 0.6917 \t Acc 75.30 \t AccHead 79.03 \t AccTail 27.16\n",
      "Epoch: [025] \t Loss 0.6618 \t Acc 76.36 \t AccHead 80.59 \t AccTail 21.64\n",
      "Epoch: [026] \t Loss 0.6770 \t Acc 77.13 \t AccHead 81.06 \t AccTail 26.10\n",
      "Epoch: [027] \t Loss 0.6514 \t Acc 77.55 \t AccHead 81.74 \t AccTail 23.12\n",
      "Epoch: [028] \t Loss 0.6428 \t Acc 74.35 \t AccHead 78.27 \t AccTail 23.73\n",
      "Epoch: [029] \t Loss 0.6457 \t Acc 78.18 \t AccHead 82.78 \t AccTail 18.64\n",
      "Epoch: [030] \t Loss 0.6445 \t Acc 77.82 \t AccHead 81.65 \t AccTail 28.29\n",
      "Epoch: [031] \t Loss 0.6201 \t Acc 80.06 \t AccHead 83.50 \t AccTail 35.68\n",
      "Epoch: [032] \t Loss 0.6004 \t Acc 79.76 \t AccHead 83.47 \t AccTail 31.53\n",
      "Epoch: [033] \t Loss 0.6016 \t Acc 80.19 \t AccHead 83.60 \t AccTail 35.75\n",
      "Epoch: [034] \t Loss 0.5716 \t Acc 78.74 \t AccHead 81.82 \t AccTail 38.87\n",
      "Epoch: [035] \t Loss 0.5915 \t Acc 79.89 \t AccHead 82.97 \t AccTail 40.11\n",
      "Epoch: [036] \t Loss 0.5857 \t Acc 75.31 \t AccHead 77.59 \t AccTail 45.98\n",
      "Epoch: [037] \t Loss 0.5737 \t Acc 81.11 \t AccHead 83.50 \t AccTail 50.14\n",
      "Epoch: [038] \t Loss 0.5633 \t Acc 80.06 \t AccHead 83.13 \t AccTail 40.11\n",
      "Epoch: [039] \t Loss 0.5668 \t Acc 79.54 \t AccHead 83.07 \t AccTail 33.80\n",
      "Epoch: [040] \t Loss 0.5591 \t Acc 81.79 \t AccHead 85.01 \t AccTail 40.03\n",
      "Epoch: [041] \t Loss 0.5463 \t Acc 81.69 \t AccHead 85.01 \t AccTail 38.61\n",
      "Epoch: [042] \t Loss 0.5492 \t Acc 78.21 \t AccHead 81.78 \t AccTail 31.77\n",
      "Epoch: [043] \t Loss 0.5363 \t Acc 82.10 \t AccHead 85.66 \t AccTail 36.07\n",
      "Epoch: [044] \t Loss 0.5414 \t Acc 80.18 \t AccHead 83.57 \t AccTail 36.13\n",
      "Epoch: [045] \t Loss 0.5276 \t Acc 79.94 \t AccHead 83.78 \t AccTail 30.01\n",
      "Epoch: [046] \t Loss 0.5275 \t Acc 80.70 \t AccHead 83.96 \t AccTail 38.65\n",
      "Epoch: [047] \t Loss 0.5189 \t Acc 82.73 \t AccHead 86.19 \t AccTail 37.99\n",
      "Epoch: [048] \t Loss 0.5126 \t Acc 82.74 \t AccHead 85.74 \t AccTail 43.99\n",
      "Epoch: [049] \t Loss 0.5169 \t Acc 81.76 \t AccHead 86.02 \t AccTail 26.59\n",
      "Epoch: [050] \t Loss 0.5050 \t Acc 82.24 \t AccHead 85.43 \t AccTail 41.10\n",
      "Epoch: [051] \t Loss 0.4970 \t Acc 80.75 \t AccHead 83.26 \t AccTail 48.31\n",
      "Epoch: [052] \t Loss 0.5095 \t Acc 83.62 \t AccHead 86.76 \t AccTail 42.98\n",
      "Epoch: [053] \t Loss 0.5034 \t Acc 83.97 \t AccHead 87.27 \t AccTail 41.30\n",
      "Epoch: [054] \t Loss 0.4963 \t Acc 83.99 \t AccHead 87.28 \t AccTail 41.28\n",
      "Epoch: [055] \t Loss 0.4766 \t Acc 78.49 \t AccHead 80.43 \t AccTail 53.27\n",
      "Epoch: [056] \t Loss 0.5033 \t Acc 81.31 \t AccHead 84.10 \t AccTail 45.18\n",
      "Epoch: [057] \t Loss 0.4821 \t Acc 79.53 \t AccHead 82.92 \t AccTail 35.64\n",
      "Epoch: [058] \t Loss 0.4875 \t Acc 81.81 \t AccHead 83.38 \t AccTail 61.36\n",
      "Epoch: [059] \t Loss 0.4781 \t Acc 81.05 \t AccHead 84.91 \t AccTail 30.73\n",
      "Epoch: [060] \t Loss 0.4584 \t Acc 84.14 \t AccHead 87.70 \t AccTail 38.22\n",
      "Epoch: [061] \t Loss 0.4736 \t Acc 76.05 \t AccHead 78.51 \t AccTail 43.95\n",
      "Epoch: [062] \t Loss 0.4745 \t Acc 83.03 \t AccHead 85.20 \t AccTail 55.07\n",
      "Epoch: [063] \t Loss 0.4702 \t Acc 82.92 \t AccHead 85.82 \t AccTail 45.40\n",
      "Epoch: [064] \t Loss 0.4740 \t Acc 83.53 \t AccHead 86.58 \t AccTail 43.89\n",
      "Epoch: [065] \t Loss 0.4548 \t Acc 75.73 \t AccHead 79.96 \t AccTail 20.54\n",
      "Epoch: [066] \t Loss 0.4663 \t Acc 81.92 \t AccHead 84.55 \t AccTail 47.80\n",
      "Epoch: [067] \t Loss 0.4559 \t Acc 83.87 \t AccHead 86.75 \t AccTail 46.69\n",
      "Epoch: [068] \t Loss 0.4576 \t Acc 83.23 \t AccHead 86.08 \t AccTail 45.93\n",
      "Epoch: [069] \t Loss 0.4565 \t Acc 85.93 \t AccHead 88.89 \t AccTail 47.44\n",
      "Epoch: [070] \t Loss 0.4586 \t Acc 85.43 \t AccHead 88.67 \t AccTail 43.40\n",
      "Epoch: [071] \t Loss 0.4406 \t Acc 84.76 \t AccHead 87.66 \t AccTail 47.09\n",
      "Epoch: [072] \t Loss 0.4565 \t Acc 79.21 \t AccHead 81.05 \t AccTail 55.51\n",
      "Epoch: [073] \t Loss 0.4435 \t Acc 84.38 \t AccHead 85.85 \t AccTail 65.35\n",
      "Epoch: [074] \t Loss 0.4341 \t Acc 84.79 \t AccHead 88.03 \t AccTail 42.70\n",
      "Epoch: [075] \t Loss 0.4460 \t Acc 84.48 \t AccHead 86.89 \t AccTail 52.99\n",
      "Epoch: [076] \t Loss 0.4292 \t Acc 84.31 \t AccHead 86.83 \t AccTail 51.84\n",
      "Epoch: [077] \t Loss 0.4484 \t Acc 84.00 \t AccHead 86.12 \t AccTail 56.70\n",
      "Epoch: [078] \t Loss 0.4405 \t Acc 84.10 \t AccHead 86.38 \t AccTail 54.79\n",
      "Epoch: [079] \t Loss 0.4308 \t Acc 79.69 \t AccHead 83.34 \t AccTail 32.58\n",
      "Epoch: [080] \t Loss 0.4362 \t Acc 85.79 \t AccHead 88.27 \t AccTail 53.74\n",
      "Epoch: [081] \t Loss 0.4269 \t Acc 84.40 \t AccHead 86.26 \t AccTail 60.20\n",
      "Epoch: [082] \t Loss 0.4235 \t Acc 82.55 \t AccHead 84.20 \t AccTail 61.16\n",
      "Epoch: [083] \t Loss 0.4312 \t Acc 86.98 \t AccHead 89.90 \t AccTail 49.22\n",
      "Epoch: [084] \t Loss 0.4191 \t Acc 84.50 \t AccHead 87.94 \t AccTail 39.86\n",
      "Epoch: [085] \t Loss 0.4282 \t Acc 86.47 \t AccHead 88.82 \t AccTail 55.95\n",
      "Epoch: [086] \t Loss 0.4038 \t Acc 84.20 \t AccHead 88.08 \t AccTail 33.99\n",
      "Epoch: [087] \t Loss 0.4153 \t Acc 84.98 \t AccHead 87.05 \t AccTail 58.27\n",
      "Epoch: [088] \t Loss 0.4089 \t Acc 85.95 \t AccHead 87.75 \t AccTail 62.66\n",
      "Epoch: [089] \t Loss 0.4043 \t Acc 86.21 \t AccHead 88.34 \t AccTail 58.70\n",
      "Epoch: [090] \t Loss 0.4111 \t Acc 84.51 \t AccHead 87.08 \t AccTail 51.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 15:01:50,328]\u001b[0m Trial 6 finished with value: 49.76245880126953 and parameters: {'n_epoch': 90, 'weight_decay': 0.0006718561699566825}. Best is trial 5 with value: 56.24178695678711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 49.76 \t AccHead 73.00 \t AccTail 26.02\n",
      "Epoch: [001] \t Loss 3.0474 \t Acc 39.70 \t AccHead 42.77 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.5963 \t Acc 49.03 \t AccHead 52.80 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.4376 \t Acc 49.48 \t AccHead 53.31 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.2606 \t Acc 59.29 \t AccHead 63.88 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.2452 \t Acc 62.66 \t AccHead 67.50 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.1546 \t Acc 60.48 \t AccHead 65.16 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 1.2429 \t Acc 60.79 \t AccHead 65.45 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 1.1162 \t Acc 63.78 \t AccHead 68.71 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 1.0854 \t Acc 64.30 \t AccHead 69.23 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 1.0633 \t Acc 65.77 \t AccHead 70.84 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 1.0375 \t Acc 66.28 \t AccHead 71.41 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 1.0124 \t Acc 66.31 \t AccHead 71.42 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 0.9871 \t Acc 66.91 \t AccHead 72.05 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 0.9611 \t Acc 65.81 \t AccHead 70.68 \t AccTail 2.82\n",
      "Epoch: [015] \t Loss 0.9460 \t Acc 67.54 \t AccHead 72.74 \t AccTail 0.14\n",
      "Epoch: [016] \t Loss 0.9363 \t Acc 68.71 \t AccHead 74.00 \t AccTail 0.42\n",
      "Epoch: [017] \t Loss 0.9234 \t Acc 69.89 \t AccHead 75.25 \t AccTail 0.71\n",
      "Epoch: [018] \t Loss 0.9187 \t Acc 68.31 \t AccHead 73.20 \t AccTail 4.83\n",
      "Epoch: [019] \t Loss 0.8969 \t Acc 69.74 \t AccHead 74.92 \t AccTail 2.82\n",
      "Epoch: [020] \t Loss 0.8802 \t Acc 69.13 \t AccHead 74.45 \t AccTail 0.42\n",
      "Epoch: [021] \t Loss 0.8706 \t Acc 70.83 \t AccHead 75.94 \t AccTail 4.94\n",
      "Epoch: [022] \t Loss 0.8412 \t Acc 72.44 \t AccHead 77.10 \t AccTail 11.57\n",
      "Epoch: [023] \t Loss 0.8337 \t Acc 71.88 \t AccHead 77.29 \t AccTail 1.42\n",
      "Epoch: [024] \t Loss 0.8058 \t Acc 72.59 \t AccHead 77.76 \t AccTail 5.13\n",
      "Epoch: [025] \t Loss 0.8092 \t Acc 72.53 \t AccHead 77.59 \t AccTail 7.20\n",
      "Epoch: [026] \t Loss 0.7876 \t Acc 70.05 \t AccHead 74.74 \t AccTail 9.34\n",
      "Epoch: [027] \t Loss 0.8099 \t Acc 72.90 \t AccHead 77.09 \t AccTail 18.47\n",
      "Epoch: [028] \t Loss 0.7639 \t Acc 74.30 \t AccHead 79.60 \t AccTail 5.92\n",
      "Epoch: [029] \t Loss 0.7515 \t Acc 75.59 \t AccHead 80.59 \t AccTail 10.40\n",
      "Epoch: [030] \t Loss 0.7405 \t Acc 73.82 \t AccHead 79.22 \t AccTail 3.82\n",
      "Epoch: [031] \t Loss 0.7286 \t Acc 76.30 \t AccHead 81.42 \t AccTail 9.92\n",
      "Epoch: [032] \t Loss 0.7006 \t Acc 77.27 \t AccHead 81.90 \t AccTail 17.51\n",
      "Epoch: [033] \t Loss 0.6969 \t Acc 76.60 \t AccHead 81.15 \t AccTail 17.71\n",
      "Epoch: [034] \t Loss 0.6744 \t Acc 75.15 \t AccHead 79.71 \t AccTail 16.03\n",
      "Epoch: [035] \t Loss 0.6694 \t Acc 78.65 \t AccHead 82.45 \t AccTail 29.16\n",
      "Epoch: [036] \t Loss 0.6543 \t Acc 79.47 \t AccHead 83.64 \t AccTail 25.00\n",
      "Epoch: [037] \t Loss 0.6266 \t Acc 78.92 \t AccHead 83.74 \t AccTail 16.31\n",
      "Epoch: [038] \t Loss 0.6366 \t Acc 76.47 \t AccHead 80.16 \t AccTail 28.71\n",
      "Epoch: [039] \t Loss 0.6246 \t Acc 81.13 \t AccHead 85.00 \t AccTail 31.07\n",
      "Epoch: [040] \t Loss 0.6106 \t Acc 77.44 \t AccHead 80.88 \t AccTail 32.81\n",
      "Epoch: [041] \t Loss 0.6088 \t Acc 80.57 \t AccHead 84.07 \t AccTail 35.31\n",
      "Epoch: [042] \t Loss 0.5779 \t Acc 80.16 \t AccHead 83.96 \t AccTail 30.63\n",
      "Epoch: [043] \t Loss 0.5704 \t Acc 81.88 \t AccHead 85.42 \t AccTail 35.89\n",
      "Epoch: [044] \t Loss 0.5578 \t Acc 80.22 \t AccHead 83.81 \t AccTail 33.66\n",
      "Epoch: [045] \t Loss 0.5436 \t Acc 80.96 \t AccHead 84.65 \t AccTail 33.19\n",
      "Epoch: [046] \t Loss 0.5499 \t Acc 82.31 \t AccHead 86.11 \t AccTail 33.19\n",
      "Epoch: [047] \t Loss 0.5276 \t Acc 81.67 \t AccHead 85.03 \t AccTail 38.10\n",
      "Epoch: [048] \t Loss 0.5093 \t Acc 82.40 \t AccHead 85.47 \t AccTail 42.39\n",
      "Epoch: [049] \t Loss 0.5129 \t Acc 83.26 \t AccHead 87.12 \t AccTail 33.19\n",
      "Epoch: [050] \t Loss 0.4950 \t Acc 81.82 \t AccHead 84.56 \t AccTail 46.32\n",
      "Epoch: [051] \t Loss 0.4978 \t Acc 83.07 \t AccHead 85.51 \t AccTail 51.55\n",
      "Epoch: [052] \t Loss 0.4762 \t Acc 83.15 \t AccHead 86.25 \t AccTail 42.76\n",
      "Epoch: [053] \t Loss 0.4648 \t Acc 84.24 \t AccHead 87.23 \t AccTail 45.45\n",
      "Epoch: [054] \t Loss 0.4599 \t Acc 84.53 \t AccHead 87.41 \t AccTail 47.02\n",
      "Epoch: [055] \t Loss 0.4452 \t Acc 85.62 \t AccHead 89.07 \t AccTail 41.02\n",
      "Epoch: [056] \t Loss 0.4442 \t Acc 86.60 \t AccHead 89.34 \t AccTail 51.20\n",
      "Epoch: [057] \t Loss 0.4380 \t Acc 84.18 \t AccHead 86.71 \t AccTail 51.62\n",
      "Epoch: [058] \t Loss 0.4239 \t Acc 85.46 \t AccHead 87.72 \t AccTail 56.23\n",
      "Epoch: [059] \t Loss 0.4335 \t Acc 87.40 \t AccHead 89.60 \t AccTail 58.92\n",
      "Epoch: [060] \t Loss 0.4061 \t Acc 87.20 \t AccHead 89.63 \t AccTail 55.67\n",
      "Epoch: [061] \t Loss 0.3932 \t Acc 86.40 \t AccHead 89.06 \t AccTail 51.91\n",
      "Epoch: [062] \t Loss 0.4012 \t Acc 86.45 \t AccHead 89.61 \t AccTail 45.30\n",
      "Epoch: [063] \t Loss 0.3858 \t Acc 88.19 \t AccHead 90.91 \t AccTail 52.91\n",
      "Epoch: [064] \t Loss 0.3662 \t Acc 88.60 \t AccHead 91.57 \t AccTail 50.14\n",
      "Epoch: [065] \t Loss 0.3695 \t Acc 88.72 \t AccHead 90.99 \t AccTail 59.21\n",
      "Epoch: [066] \t Loss 0.3662 \t Acc 88.09 \t AccHead 90.02 \t AccTail 63.19\n",
      "Epoch: [067] \t Loss 0.3536 \t Acc 88.92 \t AccHead 91.46 \t AccTail 56.07\n",
      "Epoch: [068] \t Loss 0.3499 \t Acc 88.63 \t AccHead 90.76 \t AccTail 61.07\n",
      "Epoch: [069] \t Loss 0.3414 \t Acc 88.77 \t AccHead 90.58 \t AccTail 65.40\n",
      "Epoch: [070] \t Loss 0.3311 \t Acc 89.49 \t AccHead 91.50 \t AccTail 63.51\n",
      "Epoch: [071] \t Loss 0.3166 \t Acc 88.71 \t AccHead 90.53 \t AccTail 65.06\n",
      "Epoch: [072] \t Loss 0.3297 \t Acc 89.13 \t AccHead 90.37 \t AccTail 73.13\n",
      "Epoch: [073] \t Loss 0.3233 \t Acc 89.41 \t AccHead 91.19 \t AccTail 66.43\n",
      "Epoch: [074] \t Loss 0.3065 \t Acc 90.74 \t AccHead 92.28 \t AccTail 70.68\n",
      "Epoch: [075] \t Loss 0.3023 \t Acc 90.87 \t AccHead 92.19 \t AccTail 73.80\n",
      "Epoch: [076] \t Loss 0.3086 \t Acc 89.47 \t AccHead 91.51 \t AccTail 63.14\n",
      "Epoch: [077] \t Loss 0.2842 \t Acc 90.99 \t AccHead 92.69 \t AccTail 68.98\n",
      "Epoch: [078] \t Loss 0.2813 \t Acc 91.44 \t AccHead 93.31 \t AccTail 67.09\n",
      "Epoch: [079] \t Loss 0.2820 \t Acc 90.09 \t AccHead 91.06 \t AccTail 77.48\n",
      "Epoch: [080] \t Loss 0.2772 \t Acc 90.88 \t AccHead 92.87 \t AccTail 65.21\n",
      "Epoch: [081] \t Loss 0.2710 \t Acc 91.28 \t AccHead 92.84 \t AccTail 71.10\n",
      "Epoch: [082] \t Loss 0.2730 \t Acc 91.27 \t AccHead 92.97 \t AccTail 69.13\n",
      "Epoch: [083] \t Loss 0.2641 \t Acc 91.21 \t AccHead 92.68 \t AccTail 72.20\n",
      "Epoch: [084] \t Loss 0.2553 \t Acc 89.58 \t AccHead 91.39 \t AccTail 66.20\n",
      "Epoch: [085] \t Loss 0.2466 \t Acc 91.38 \t AccHead 92.58 \t AccTail 75.68\n",
      "Epoch: [086] \t Loss 0.2477 \t Acc 90.44 \t AccHead 91.88 \t AccTail 71.81\n",
      "Epoch: [087] \t Loss 0.2396 \t Acc 91.27 \t AccHead 92.57 \t AccTail 74.54\n",
      "Epoch: [088] \t Loss 0.2588 \t Acc 92.68 \t AccHead 93.99 \t AccTail 75.88\n",
      "Epoch: [089] \t Loss 0.2241 \t Acc 92.04 \t AccHead 93.64 \t AccTail 71.16\n",
      "Epoch: [090] \t Loss 0.2393 \t Acc 91.82 \t AccHead 92.69 \t AccTail 80.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 15:13:00,173]\u001b[0m Trial 7 finished with value: 52.198524475097656 and parameters: {'n_epoch': 90, 'weight_decay': 4.201741854557997e-05}. Best is trial 5 with value: 56.24178695678711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 52.20 \t AccHead 71.82 \t AccTail 32.15\n",
      "Epoch: [001] \t Loss 2.4917 \t Acc 41.34 \t AccHead 44.53 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.5071 \t Acc 48.28 \t AccHead 51.99 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.2761 \t Acc 58.43 \t AccHead 62.94 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.1908 \t Acc 58.36 \t AccHead 62.84 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.1239 \t Acc 58.45 \t AccHead 62.98 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.0745 \t Acc 62.82 \t AccHead 67.69 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 1.0506 \t Acc 63.65 \t AccHead 68.57 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 1.0070 \t Acc 65.71 \t AccHead 70.80 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 1.0110 \t Acc 56.24 \t AccHead 60.58 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 0.9647 \t Acc 64.45 \t AccHead 69.41 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 0.9611 \t Acc 68.58 \t AccHead 73.89 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 0.9518 \t Acc 66.74 \t AccHead 71.88 \t AccTail 0.28\n",
      "Epoch: [013] \t Loss 0.9325 \t Acc 60.23 \t AccHead 64.89 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 0.9291 \t Acc 66.52 \t AccHead 71.66 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 0.9072 \t Acc 67.42 \t AccHead 71.53 \t AccTail 13.94\n",
      "Epoch: [016] \t Loss 0.9066 \t Acc 63.38 \t AccHead 68.27 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 0.9008 \t Acc 63.89 \t AccHead 68.65 \t AccTail 2.26\n",
      "Epoch: [018] \t Loss 0.8760 \t Acc 65.00 \t AccHead 69.84 \t AccTail 2.40\n",
      "Epoch: [019] \t Loss 0.8959 \t Acc 64.54 \t AccHead 69.52 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 0.8701 \t Acc 66.09 \t AccHead 70.74 \t AccTail 5.81\n",
      "Epoch: [021] \t Loss 0.8650 \t Acc 66.60 \t AccHead 71.74 \t AccTail 0.28\n",
      "Epoch: [022] \t Loss 0.8731 \t Acc 70.50 \t AccHead 75.84 \t AccTail 1.27\n",
      "Epoch: [023] \t Loss 0.8706 \t Acc 68.47 \t AccHead 73.73 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 0.8786 \t Acc 66.92 \t AccHead 72.07 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 0.8606 \t Acc 68.52 \t AccHead 73.82 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 0.8471 \t Acc 69.56 \t AccHead 74.93 \t AccTail 0.14\n",
      "Epoch: [027] \t Loss 0.8518 \t Acc 65.12 \t AccHead 70.14 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 0.8623 \t Acc 69.74 \t AccHead 75.10 \t AccTail 0.14\n",
      "Epoch: [029] \t Loss 0.8362 \t Acc 69.81 \t AccHead 74.55 \t AccTail 8.36\n",
      "Epoch: [030] \t Loss 0.8414 \t Acc 71.52 \t AccHead 76.87 \t AccTail 2.54\n",
      "Epoch: [031] \t Loss 0.8282 \t Acc 63.32 \t AccHead 68.22 \t AccTail 0.14\n",
      "Epoch: [032] \t Loss 0.8448 \t Acc 67.45 \t AccHead 72.40 \t AccTail 3.39\n",
      "Epoch: [033] \t Loss 0.8434 \t Acc 65.96 \t AccHead 69.05 \t AccTail 25.82\n",
      "Epoch: [034] \t Loss 0.8409 \t Acc 72.79 \t AccHead 77.54 \t AccTail 11.19\n",
      "Epoch: [035] \t Loss 0.8274 \t Acc 70.21 \t AccHead 75.10 \t AccTail 6.68\n",
      "Epoch: [036] \t Loss 0.8366 \t Acc 68.75 \t AccHead 72.28 \t AccTail 23.06\n",
      "Epoch: [037] \t Loss 0.8325 \t Acc 73.40 \t AccHead 77.31 \t AccTail 22.88\n",
      "Epoch: [038] \t Loss 0.8145 \t Acc 72.34 \t AccHead 77.05 \t AccTail 11.08\n",
      "Epoch: [039] \t Loss 0.8234 \t Acc 69.44 \t AccHead 74.69 \t AccTail 1.28\n",
      "Epoch: [040] \t Loss 0.8219 \t Acc 72.00 \t AccHead 77.07 \t AccTail 6.62\n",
      "Epoch: [041] \t Loss 0.8168 \t Acc 70.67 \t AccHead 75.40 \t AccTail 9.46\n",
      "Epoch: [042] \t Loss 0.8303 \t Acc 61.36 \t AccHead 65.06 \t AccTail 13.68\n",
      "Epoch: [043] \t Loss 0.8415 \t Acc 73.86 \t AccHead 79.47 \t AccTail 1.13\n",
      "Epoch: [044] \t Loss 0.8151 \t Acc 68.66 \t AccHead 73.44 \t AccTail 6.53\n",
      "Epoch: [045] \t Loss 0.8222 \t Acc 69.80 \t AccHead 73.24 \t AccTail 25.11\n",
      "Epoch: [046] \t Loss 0.8246 \t Acc 73.63 \t AccHead 78.18 \t AccTail 14.37\n",
      "Epoch: [047] \t Loss 0.8189 \t Acc 72.90 \t AccHead 77.33 \t AccTail 15.77\n",
      "Epoch: [048] \t Loss 0.8175 \t Acc 72.91 \t AccHead 77.54 \t AccTail 12.89\n",
      "Epoch: [049] \t Loss 0.8110 \t Acc 72.67 \t AccHead 77.97 \t AccTail 3.83\n",
      "Epoch: [050] \t Loss 0.7916 \t Acc 64.75 \t AccHead 67.74 \t AccTail 25.85\n",
      "Epoch: [051] \t Loss 0.7933 \t Acc 67.30 \t AccHead 70.93 \t AccTail 19.94\n",
      "Epoch: [052] \t Loss 0.8120 \t Acc 68.62 \t AccHead 73.03 \t AccTail 11.11\n",
      "Epoch: [053] \t Loss 0.7950 \t Acc 71.15 \t AccHead 74.76 \t AccTail 24.58\n",
      "Epoch: [054] \t Loss 0.8240 \t Acc 71.07 \t AccHead 76.10 \t AccTail 6.07\n",
      "Epoch: [055] \t Loss 0.8022 \t Acc 70.76 \t AccHead 74.91 \t AccTail 16.88\n",
      "Epoch: [056] \t Loss 0.8152 \t Acc 69.86 \t AccHead 74.30 \t AccTail 12.31\n",
      "Epoch: [057] \t Loss 0.7887 \t Acc 71.81 \t AccHead 76.10 \t AccTail 16.17\n",
      "Epoch: [058] \t Loss 0.8248 \t Acc 69.11 \t AccHead 74.27 \t AccTail 1.99\n",
      "Epoch: [059] \t Loss 0.8034 \t Acc 61.80 \t AccHead 66.39 \t AccTail 1.99\n",
      "Epoch: [060] \t Loss 0.7996 \t Acc 71.92 \t AccHead 76.75 \t AccTail 9.21\n",
      "Epoch: [061] \t Loss 0.8217 \t Acc 70.71 \t AccHead 75.44 \t AccTail 9.10\n",
      "Epoch: [062] \t Loss 0.7945 \t Acc 66.72 \t AccHead 70.01 \t AccTail 23.97\n",
      "Epoch: [063] \t Loss 0.8176 \t Acc 71.41 \t AccHead 76.40 \t AccTail 6.66\n",
      "Epoch: [064] \t Loss 0.8156 \t Acc 63.16 \t AccHead 67.91 \t AccTail 1.70\n",
      "Epoch: [065] \t Loss 0.8037 \t Acc 70.56 \t AccHead 75.08 \t AccTail 11.77\n",
      "Epoch: [066] \t Loss 0.7862 \t Acc 68.50 \t AccHead 72.17 \t AccTail 20.82\n",
      "Epoch: [067] \t Loss 0.8217 \t Acc 63.03 \t AccHead 67.30 \t AccTail 7.77\n",
      "Epoch: [068] \t Loss 0.8148 \t Acc 70.44 \t AccHead 74.21 \t AccTail 21.56\n",
      "Epoch: [069] \t Loss 0.7796 \t Acc 68.85 \t AccHead 73.36 \t AccTail 10.48\n",
      "Epoch: [070] \t Loss 0.8017 \t Acc 66.51 \t AccHead 70.44 \t AccTail 15.56\n",
      "Epoch: [071] \t Loss 0.8037 \t Acc 63.52 \t AccHead 66.80 \t AccTail 21.10\n",
      "Epoch: [072] \t Loss 0.7889 \t Acc 71.08 \t AccHead 75.81 \t AccTail 10.03\n",
      "Epoch: [073] \t Loss 0.7963 \t Acc 69.42 \t AccHead 73.93 \t AccTail 11.03\n",
      "Epoch: [074] \t Loss 0.7889 \t Acc 71.24 \t AccHead 75.43 \t AccTail 17.09\n",
      "Epoch: [075] \t Loss 0.8025 \t Acc 72.35 \t AccHead 77.35 \t AccTail 7.52\n",
      "Epoch: [076] \t Loss 0.7878 \t Acc 72.66 \t AccHead 76.42 \t AccTail 23.94\n",
      "Epoch: [077] \t Loss 0.8152 \t Acc 68.22 \t AccHead 72.80 \t AccTail 8.92\n",
      "Epoch: [078] \t Loss 0.8033 \t Acc 68.69 \t AccHead 72.53 \t AccTail 19.18\n",
      "Epoch: [079] \t Loss 0.8022 \t Acc 65.21 \t AccHead 67.53 \t AccTail 35.17\n",
      "Epoch: [080] \t Loss 0.8029 \t Acc 69.92 \t AccHead 74.51 \t AccTail 10.47\n",
      "Epoch: [081] \t Loss 0.7799 \t Acc 69.42 \t AccHead 74.17 \t AccTail 8.05\n",
      "Epoch: [082] \t Loss 0.7893 \t Acc 73.38 \t AccHead 77.72 \t AccTail 17.11\n",
      "Epoch: [083] \t Loss 0.7934 \t Acc 71.39 \t AccHead 75.28 \t AccTail 21.05\n",
      "Epoch: [084] \t Loss 0.7969 \t Acc 69.02 \t AccHead 73.20 \t AccTail 14.65\n",
      "Epoch: [085] \t Loss 0.7869 \t Acc 74.33 \t AccHead 78.99 \t AccTail 14.12\n",
      "Epoch: [086] \t Loss 0.7940 \t Acc 71.14 \t AccHead 74.63 \t AccTail 25.92\n",
      "Epoch: [087] \t Loss 0.8003 \t Acc 66.45 \t AccHead 69.61 \t AccTail 25.39\n",
      "Epoch: [088] \t Loss 0.8137 \t Acc 62.92 \t AccHead 65.68 \t AccTail 27.26\n",
      "Epoch: [089] \t Loss 0.8058 \t Acc 70.53 \t AccHead 75.50 \t AccTail 5.82\n",
      "Epoch: [090] \t Loss 0.8110 \t Acc 66.70 \t AccHead 71.76 \t AccTail 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 15:24:05,088]\u001b[0m Trial 8 finished with value: 30.071767807006836 and parameters: {'n_epoch': 90, 'weight_decay': 0.003177707639070479}. Best is trial 5 with value: 56.24178695678711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 30.07 \t AccHead 57.20 \t AccTail 2.35\n",
      "Epoch: [001] \t Loss 2.2186 \t Acc 51.01 \t AccHead 54.97 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.3458 \t Acc 58.72 \t AccHead 63.24 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.2232 \t Acc 57.63 \t AccHead 62.08 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.2756 \t Acc 57.28 \t AccHead 61.70 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.1681 \t Acc 61.10 \t AccHead 65.82 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.0776 \t Acc 61.14 \t AccHead 65.87 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 1.0332 \t Acc 65.71 \t AccHead 70.78 \t AccTail 0.28\n",
      "Epoch: [008] \t Loss 0.9861 \t Acc 64.73 \t AccHead 69.73 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 0.9637 \t Acc 68.28 \t AccHead 73.56 \t AccTail 0.14\n",
      "Epoch: [010] \t Loss 0.9482 \t Acc 67.25 \t AccHead 72.43 \t AccTail 0.28\n",
      "Epoch: [011] \t Loss 0.9083 \t Acc 68.94 \t AccHead 73.37 \t AccTail 11.85\n",
      "Epoch: [012] \t Loss 0.8759 \t Acc 68.90 \t AccHead 74.10 \t AccTail 1.28\n",
      "Epoch: [013] \t Loss 0.8635 \t Acc 70.67 \t AccHead 75.40 \t AccTail 9.48\n",
      "Epoch: [014] \t Loss 0.8573 \t Acc 67.44 \t AccHead 72.55 \t AccTail 1.69\n",
      "Epoch: [015] \t Loss 0.8405 \t Acc 69.31 \t AccHead 74.57 \t AccTail 0.85\n",
      "Epoch: [016] \t Loss 0.8112 \t Acc 69.64 \t AccHead 74.62 \t AccTail 5.23\n",
      "Epoch: [017] \t Loss 0.8004 \t Acc 71.13 \t AccHead 76.53 \t AccTail 1.27\n",
      "Epoch: [018] \t Loss 0.8015 \t Acc 71.05 \t AccHead 75.92 \t AccTail 7.94\n",
      "Epoch: [019] \t Loss 0.7920 \t Acc 70.86 \t AccHead 75.76 \t AccTail 7.10\n",
      "Epoch: [020] \t Loss 0.7792 \t Acc 64.14 \t AccHead 67.58 \t AccTail 19.66\n",
      "Epoch: [021] \t Loss 0.7712 \t Acc 73.68 \t AccHead 77.81 \t AccTail 19.71\n",
      "Epoch: [022] \t Loss 0.7594 \t Acc 74.08 \t AccHead 79.49 \t AccTail 4.37\n",
      "Epoch: [023] \t Loss 0.7482 \t Acc 72.55 \t AccHead 77.10 \t AccTail 13.14\n",
      "Epoch: [024] \t Loss 0.7503 \t Acc 74.08 \t AccHead 78.59 \t AccTail 15.34\n",
      "Epoch: [025] \t Loss 0.7426 \t Acc 73.04 \t AccHead 77.74 \t AccTail 12.06\n",
      "Epoch: [026] \t Loss 0.7384 \t Acc 76.50 \t AccHead 80.40 \t AccTail 25.85\n",
      "Epoch: [027] \t Loss 0.7337 \t Acc 74.36 \t AccHead 78.87 \t AccTail 15.98\n",
      "Epoch: [028] \t Loss 0.7221 \t Acc 73.83 \t AccHead 77.28 \t AccTail 28.98\n",
      "Epoch: [029] \t Loss 0.7264 \t Acc 75.73 \t AccHead 80.77 \t AccTail 10.48\n",
      "Epoch: [030] \t Loss 0.7149 \t Acc 70.63 \t AccHead 74.10 \t AccTail 25.71\n",
      "Epoch: [031] \t Loss 0.7145 \t Acc 69.26 \t AccHead 73.58 \t AccTail 13.42\n",
      "Epoch: [032] \t Loss 0.7011 \t Acc 70.99 \t AccHead 73.82 \t AccTail 34.56\n",
      "Epoch: [033] \t Loss 0.7003 \t Acc 75.51 \t AccHead 80.03 \t AccTail 17.18\n",
      "Epoch: [034] \t Loss 0.6832 \t Acc 75.02 \t AccHead 79.81 \t AccTail 13.26\n",
      "Epoch: [035] \t Loss 0.6737 \t Acc 74.99 \t AccHead 79.57 \t AccTail 15.48\n",
      "Epoch: [036] \t Loss 0.6823 \t Acc 78.94 \t AccHead 83.71 \t AccTail 17.11\n",
      "Epoch: [037] \t Loss 0.6908 \t Acc 72.68 \t AccHead 77.26 \t AccTail 13.54\n",
      "Epoch: [038] \t Loss 0.6864 \t Acc 73.78 \t AccHead 78.30 \t AccTail 15.06\n",
      "Epoch: [039] \t Loss 0.6787 \t Acc 72.79 \t AccHead 77.43 \t AccTail 12.85\n",
      "Epoch: [040] \t Loss 0.6973 \t Acc 76.66 \t AccHead 81.40 \t AccTail 15.51\n",
      "Epoch: [041] \t Loss 0.6734 \t Acc 76.81 \t AccHead 80.52 \t AccTail 28.61\n",
      "Epoch: [042] \t Loss 0.6765 \t Acc 70.93 \t AccHead 74.90 \t AccTail 19.52\n",
      "Epoch: [043] \t Loss 0.6786 \t Acc 76.72 \t AccHead 79.95 \t AccTail 35.12\n",
      "Epoch: [044] \t Loss 0.6700 \t Acc 77.10 \t AccHead 81.06 \t AccTail 25.67\n",
      "Epoch: [045] \t Loss 0.6649 \t Acc 74.91 \t AccHead 78.31 \t AccTail 30.78\n",
      "Epoch: [046] \t Loss 0.6782 \t Acc 74.30 \t AccHead 77.48 \t AccTail 33.29\n",
      "Epoch: [047] \t Loss 0.6653 \t Acc 76.54 \t AccHead 79.91 \t AccTail 32.86\n",
      "Epoch: [048] \t Loss 0.6558 \t Acc 74.77 \t AccHead 78.54 \t AccTail 25.88\n",
      "Epoch: [049] \t Loss 0.6508 \t Acc 72.91 \t AccHead 75.95 \t AccTail 33.57\n",
      "Epoch: [050] \t Loss 0.6600 \t Acc 73.36 \t AccHead 77.53 \t AccTail 18.95\n",
      "Epoch: [051] \t Loss 0.6533 \t Acc 76.48 \t AccHead 81.28 \t AccTail 14.31\n",
      "Epoch: [052] \t Loss 0.6516 \t Acc 73.79 \t AccHead 78.63 \t AccTail 10.68\n",
      "Epoch: [053] \t Loss 0.6383 \t Acc 77.85 \t AccHead 80.04 \t AccTail 49.43\n",
      "Epoch: [054] \t Loss 0.6477 \t Acc 77.60 \t AccHead 81.78 \t AccTail 23.37\n",
      "Epoch: [055] \t Loss 0.6494 \t Acc 72.29 \t AccHead 75.18 \t AccTail 34.94\n",
      "Epoch: [056] \t Loss 0.6394 \t Acc 76.25 \t AccHead 80.06 \t AccTail 26.81\n",
      "Epoch: [057] \t Loss 0.6445 \t Acc 76.60 \t AccHead 81.66 \t AccTail 11.30\n",
      "Epoch: [058] \t Loss 0.6293 \t Acc 78.10 \t AccHead 82.57 \t AccTail 20.25\n",
      "Epoch: [059] \t Loss 0.6417 \t Acc 71.41 \t AccHead 75.05 \t AccTail 23.93\n",
      "Epoch: [060] \t Loss 0.6510 \t Acc 75.87 \t AccHead 80.77 \t AccTail 12.45\n",
      "Epoch: [061] \t Loss 0.6499 \t Acc 75.15 \t AccHead 77.84 \t AccTail 40.37\n",
      "Epoch: [062] \t Loss 0.6347 \t Acc 76.42 \t AccHead 79.43 \t AccTail 37.27\n",
      "Epoch: [063] \t Loss 0.6585 \t Acc 75.26 \t AccHead 79.01 \t AccTail 26.73\n",
      "Epoch: [064] \t Loss 0.6346 \t Acc 74.90 \t AccHead 79.08 \t AccTail 20.57\n",
      "Epoch: [065] \t Loss 0.6387 \t Acc 75.87 \t AccHead 79.81 \t AccTail 25.00\n",
      "Epoch: [066] \t Loss 0.6356 \t Acc 74.69 \t AccHead 78.08 \t AccTail 30.74\n",
      "Epoch: [067] \t Loss 0.6430 \t Acc 77.21 \t AccHead 81.69 \t AccTail 19.35\n",
      "Epoch: [068] \t Loss 0.6363 \t Acc 77.61 \t AccHead 81.49 \t AccTail 27.23\n",
      "Epoch: [069] \t Loss 0.6495 \t Acc 71.44 \t AccHead 75.33 \t AccTail 21.19\n",
      "Epoch: [070] \t Loss 0.6229 \t Acc 70.65 \t AccHead 74.25 \t AccTail 23.83\n",
      "Epoch: [071] \t Loss 0.6392 \t Acc 76.53 \t AccHead 79.36 \t AccTail 39.86\n",
      "Epoch: [072] \t Loss 0.6397 \t Acc 76.33 \t AccHead 79.15 \t AccTail 39.80\n",
      "Epoch: [073] \t Loss 0.6216 \t Acc 73.12 \t AccHead 76.71 \t AccTail 26.52\n",
      "Epoch: [074] \t Loss 0.6149 \t Acc 77.50 \t AccHead 82.69 \t AccTail 9.94\n",
      "Epoch: [075] \t Loss 0.6432 \t Acc 74.04 \t AccHead 77.25 \t AccTail 32.44\n",
      "Epoch: [076] \t Loss 0.6141 \t Acc 78.64 \t AccHead 81.83 \t AccTail 37.39\n",
      "Epoch: [077] \t Loss 0.6288 \t Acc 78.56 \t AccHead 83.86 \t AccTail 10.41\n",
      "Epoch: [078] \t Loss 0.6259 \t Acc 75.19 \t AccHead 78.93 \t AccTail 26.77\n",
      "Epoch: [079] \t Loss 0.6151 \t Acc 75.60 \t AccHead 79.81 \t AccTail 21.19\n",
      "Epoch: [080] \t Loss 0.6219 \t Acc 79.65 \t AccHead 84.02 \t AccTail 23.06\n",
      "Epoch: [081] \t Loss 0.6314 \t Acc 77.77 \t AccHead 81.85 \t AccTail 25.00\n",
      "Epoch: [082] \t Loss 0.6241 \t Acc 80.32 \t AccHead 85.03 \t AccTail 19.03\n",
      "Epoch: [083] \t Loss 0.6255 \t Acc 77.91 \t AccHead 81.64 \t AccTail 29.70\n",
      "Epoch: [084] \t Loss 0.6330 \t Acc 76.62 \t AccHead 81.39 \t AccTail 14.97\n",
      "Epoch: [085] \t Loss 0.6136 \t Acc 78.74 \t AccHead 82.36 \t AccTail 32.06\n",
      "Epoch: [086] \t Loss 0.6293 \t Acc 75.77 \t AccHead 78.64 \t AccTail 38.61\n",
      "Epoch: [087] \t Loss 0.6355 \t Acc 77.37 \t AccHead 81.72 \t AccTail 21.30\n",
      "Epoch: [088] \t Loss 0.6039 \t Acc 78.46 \t AccHead 83.34 \t AccTail 15.06\n",
      "Epoch: [089] \t Loss 0.6206 \t Acc 80.51 \t AccHead 84.24 \t AccTail 31.96\n",
      "Epoch: [090] \t Loss 0.6262 \t Acc 75.36 \t AccHead 79.16 \t AccTail 26.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 15:35:22,564]\u001b[0m Trial 9 finished with value: 39.21965026855469 and parameters: {'n_epoch': 90, 'weight_decay': 0.0016234028607792713}. Best is trial 5 with value: 56.24178695678711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 39.22 \t AccHead 61.22 \t AccTail 16.74\n",
      "Epoch: [001] \t Loss 2.8888 \t Acc 52.34 \t AccHead 56.39 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.5106 \t Acc 56.97 \t AccHead 61.37 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.5204 \t Acc 57.24 \t AccHead 61.67 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.3587 \t Acc 56.27 \t AccHead 60.64 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.2567 \t Acc 60.45 \t AccHead 65.11 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.1763 \t Acc 61.37 \t AccHead 66.14 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 1.1914 \t Acc 60.84 \t AccHead 65.51 \t AccTail 0.14\n",
      "Epoch: [008] \t Loss 1.1374 \t Acc 65.12 \t AccHead 70.14 \t AccTail 0.14\n",
      "Epoch: [009] \t Loss 1.0425 \t Acc 66.97 \t AccHead 72.10 \t AccTail 0.43\n",
      "Epoch: [010] \t Loss 1.0192 \t Acc 66.63 \t AccHead 71.75 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 1.0040 \t Acc 67.93 \t AccHead 72.58 \t AccTail 7.52\n",
      "Epoch: [012] \t Loss 0.9674 \t Acc 66.56 \t AccHead 71.38 \t AccTail 4.11\n",
      "Epoch: [013] \t Loss 0.9675 \t Acc 64.52 \t AccHead 69.50 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 0.9409 \t Acc 69.70 \t AccHead 74.50 \t AccTail 7.64\n",
      "Epoch: [015] \t Loss 0.9041 \t Acc 70.56 \t AccHead 75.99 \t AccTail 0.28\n",
      "Epoch: [016] \t Loss 0.8925 \t Acc 71.16 \t AccHead 76.02 \t AccTail 8.47\n",
      "Epoch: [017] \t Loss 0.8561 \t Acc 72.17 \t AccHead 76.63 \t AccTail 14.55\n",
      "Epoch: [018] \t Loss 0.8340 \t Acc 70.77 \t AccHead 74.95 \t AccTail 16.45\n",
      "Epoch: [019] \t Loss 0.8104 \t Acc 73.11 \t AccHead 78.23 \t AccTail 6.67\n",
      "Epoch: [020] \t Loss 0.7797 \t Acc 74.71 \t AccHead 79.46 \t AccTail 12.80\n",
      "Epoch: [021] \t Loss 0.7825 \t Acc 74.41 \t AccHead 78.60 \t AccTail 20.42\n",
      "Epoch: [022] \t Loss 0.7460 \t Acc 74.49 \t AccHead 78.52 \t AccTail 22.68\n",
      "Epoch: [023] \t Loss 0.7370 \t Acc 74.91 \t AccHead 79.98 \t AccTail 9.34\n",
      "Epoch: [024] \t Loss 0.7129 \t Acc 76.52 \t AccHead 81.79 \t AccTail 8.35\n",
      "Epoch: [025] \t Loss 0.6990 \t Acc 77.18 \t AccHead 81.34 \t AccTail 23.34\n",
      "Epoch: [026] \t Loss 0.6864 \t Acc 78.14 \t AccHead 82.19 \t AccTail 25.43\n",
      "Epoch: [027] \t Loss 0.6598 \t Acc 77.57 \t AccHead 81.95 \t AccTail 20.60\n",
      "Epoch: [028] \t Loss 0.6559 \t Acc 77.87 \t AccHead 82.06 \t AccTail 23.84\n",
      "Epoch: [029] \t Loss 0.6331 \t Acc 75.29 \t AccHead 79.17 \t AccTail 25.18\n",
      "Epoch: [030] \t Loss 0.6186 \t Acc 77.08 \t AccHead 80.84 \t AccTail 28.53\n",
      "Epoch: [031] \t Loss 0.6176 \t Acc 79.42 \t AccHead 82.97 \t AccTail 33.52\n",
      "Epoch: [032] \t Loss 0.6201 \t Acc 79.64 \t AccHead 83.17 \t AccTail 33.57\n",
      "Epoch: [033] \t Loss 0.5938 \t Acc 80.98 \t AccHead 86.02 \t AccTail 15.36\n",
      "Epoch: [034] \t Loss 0.5790 \t Acc 81.53 \t AccHead 84.97 \t AccTail 36.88\n",
      "Epoch: [035] \t Loss 0.5731 \t Acc 78.61 \t AccHead 82.09 \t AccTail 33.48\n",
      "Epoch: [036] \t Loss 0.5752 \t Acc 81.25 \t AccHead 85.53 \t AccTail 26.09\n",
      "Epoch: [037] \t Loss 0.5530 \t Acc 80.98 \t AccHead 84.85 \t AccTail 30.93\n",
      "Epoch: [038] \t Loss 0.5415 \t Acc 80.67 \t AccHead 83.33 \t AccTail 46.33\n",
      "Epoch: [039] \t Loss 0.5404 \t Acc 82.07 \t AccHead 84.59 \t AccTail 49.50\n",
      "Epoch: [040] \t Loss 0.5397 \t Acc 82.74 \t AccHead 86.53 \t AccTail 33.05\n",
      "Epoch: [041] \t Loss 0.5174 \t Acc 82.62 \t AccHead 86.40 \t AccTail 33.76\n",
      "Epoch: [042] \t Loss 0.5176 \t Acc 82.70 \t AccHead 86.11 \t AccTail 38.53\n",
      "Epoch: [043] \t Loss 0.4875 \t Acc 83.39 \t AccHead 87.00 \t AccTail 36.72\n",
      "Epoch: [044] \t Loss 0.4940 \t Acc 81.94 \t AccHead 85.12 \t AccTail 40.90\n",
      "Epoch: [045] \t Loss 0.4893 \t Acc 84.89 \t AccHead 87.58 \t AccTail 50.07\n",
      "Epoch: [046] \t Loss 0.4785 \t Acc 83.83 \t AccHead 87.55 \t AccTail 35.46\n",
      "Epoch: [047] \t Loss 0.4839 \t Acc 84.83 \t AccHead 87.23 \t AccTail 53.75\n",
      "Epoch: [048] \t Loss 0.4641 \t Acc 86.06 \t AccHead 89.11 \t AccTail 46.69\n",
      "Epoch: [049] \t Loss 0.4643 \t Acc 85.54 \t AccHead 89.07 \t AccTail 39.80\n",
      "Epoch: [050] \t Loss 0.4437 \t Acc 82.04 \t AccHead 85.07 \t AccTail 42.94\n",
      "Epoch: [051] \t Loss 0.4570 \t Acc 83.61 \t AccHead 86.78 \t AccTail 42.47\n",
      "Epoch: [052] \t Loss 0.4504 \t Acc 83.92 \t AccHead 86.50 \t AccTail 50.21\n",
      "Epoch: [053] \t Loss 0.4338 \t Acc 84.95 \t AccHead 87.90 \t AccTail 46.67\n",
      "Epoch: [054] \t Loss 0.4272 \t Acc 85.72 \t AccHead 87.93 \t AccTail 57.20\n",
      "Epoch: [055] \t Loss 0.4345 \t Acc 85.35 \t AccHead 88.13 \t AccTail 49.36\n",
      "Epoch: [056] \t Loss 0.4254 \t Acc 86.41 \t AccHead 88.36 \t AccTail 61.19\n",
      "Epoch: [057] \t Loss 0.4165 \t Acc 85.17 \t AccHead 88.75 \t AccTail 38.67\n",
      "Epoch: [058] \t Loss 0.4097 \t Acc 87.04 \t AccHead 90.38 \t AccTail 43.85\n",
      "Epoch: [059] \t Loss 0.4071 \t Acc 87.95 \t AccHead 90.62 \t AccTail 53.39\n",
      "Epoch: [060] \t Loss 0.3862 \t Acc 86.66 \t AccHead 89.23 \t AccTail 53.26\n",
      "Epoch: [061] \t Loss 0.3944 \t Acc 86.84 \t AccHead 88.49 \t AccTail 65.39\n",
      "Epoch: [062] \t Loss 0.4059 \t Acc 85.94 \t AccHead 88.16 \t AccTail 57.14\n",
      "Epoch: [063] \t Loss 0.3785 \t Acc 86.64 \t AccHead 89.83 \t AccTail 45.25\n",
      "Epoch: [064] \t Loss 0.3884 \t Acc 85.16 \t AccHead 88.55 \t AccTail 40.88\n",
      "Epoch: [065] \t Loss 0.3606 \t Acc 86.18 \t AccHead 89.42 \t AccTail 44.51\n",
      "Epoch: [066] \t Loss 0.3884 \t Acc 86.23 \t AccHead 89.07 \t AccTail 49.36\n",
      "Epoch: [067] \t Loss 0.3689 \t Acc 87.10 \t AccHead 89.00 \t AccTail 62.50\n",
      "Epoch: [068] \t Loss 0.3672 \t Acc 87.88 \t AccHead 89.65 \t AccTail 64.97\n",
      "Epoch: [069] \t Loss 0.3601 \t Acc 90.45 \t AccHead 92.21 \t AccTail 67.75\n",
      "Epoch: [070] \t Loss 0.3593 \t Acc 88.06 \t AccHead 89.68 \t AccTail 67.00\n",
      "Epoch: [071] \t Loss 0.3426 \t Acc 89.21 \t AccHead 91.41 \t AccTail 60.76\n",
      "Epoch: [072] \t Loss 0.3441 \t Acc 86.23 \t AccHead 89.29 \t AccTail 46.83\n",
      "Epoch: [073] \t Loss 0.3515 \t Acc 86.37 \t AccHead 88.60 \t AccTail 57.69\n",
      "Epoch: [074] \t Loss 0.3375 \t Acc 89.08 \t AccHead 91.52 \t AccTail 57.69\n",
      "Epoch: [075] \t Loss 0.3373 \t Acc 87.44 \t AccHead 88.83 \t AccTail 69.53\n",
      "Epoch: [076] \t Loss 0.3426 \t Acc 89.63 \t AccHead 91.51 \t AccTail 65.40\n",
      "Epoch: [077] \t Loss 0.3279 \t Acc 86.90 \t AccHead 89.07 \t AccTail 58.84\n",
      "Epoch: [078] \t Loss 0.3086 \t Acc 88.91 \t AccHead 89.84 \t AccTail 76.87\n",
      "Epoch: [079] \t Loss 0.3213 \t Acc 90.17 \t AccHead 92.50 \t AccTail 59.86\n",
      "Epoch: [080] \t Loss 0.3124 \t Acc 89.41 \t AccHead 91.65 \t AccTail 60.40\n",
      "Epoch: [081] \t Loss 0.3122 \t Acc 86.69 \t AccHead 88.59 \t AccTail 62.17\n",
      "Epoch: [082] \t Loss 0.3011 \t Acc 89.32 \t AccHead 91.12 \t AccTail 65.96\n",
      "Epoch: [083] \t Loss 0.3181 \t Acc 89.85 \t AccHead 91.70 \t AccTail 65.91\n",
      "Epoch: [084] \t Loss 0.3007 \t Acc 90.06 \t AccHead 91.13 \t AccTail 76.13\n",
      "Epoch: [085] \t Loss 0.2963 \t Acc 89.43 \t AccHead 91.08 \t AccTail 68.12\n",
      "Epoch: [086] \t Loss 0.3003 \t Acc 89.21 \t AccHead 90.74 \t AccTail 69.53\n",
      "Epoch: [087] \t Loss 0.3033 \t Acc 89.30 \t AccHead 90.82 \t AccTail 69.63\n",
      "Epoch: [088] \t Loss 0.2833 \t Acc 89.90 \t AccHead 91.65 \t AccTail 67.09\n",
      "Epoch: [089] \t Loss 0.2969 \t Acc 90.50 \t AccHead 92.66 \t AccTail 62.45\n",
      "Epoch: [090] \t Loss 0.2859 \t Acc 89.69 \t AccHead 91.63 \t AccTail 64.64\n",
      "Epoch: [091] \t Loss 0.2847 \t Acc 88.12 \t AccHead 89.74 \t AccTail 67.23\n",
      "Epoch: [092] \t Loss 0.2894 \t Acc 89.51 \t AccHead 91.78 \t AccTail 60.17\n",
      "Epoch: [093] \t Loss 0.2897 \t Acc 88.98 \t AccHead 91.08 \t AccTail 61.70\n",
      "Epoch: [094] \t Loss 0.2834 \t Acc 88.93 \t AccHead 89.90 \t AccTail 76.35\n",
      "Epoch: [095] \t Loss 0.2698 \t Acc 90.94 \t AccHead 93.08 \t AccTail 63.22\n",
      "Epoch: [096] \t Loss 0.2754 \t Acc 91.08 \t AccHead 92.72 \t AccTail 69.79\n",
      "Epoch: [097] \t Loss 0.2647 \t Acc 91.28 \t AccHead 92.43 \t AccTail 76.45\n",
      "Epoch: [098] \t Loss 0.2710 \t Acc 90.66 \t AccHead 92.60 \t AccTail 65.29\n",
      "Epoch: [099] \t Loss 0.2712 \t Acc 90.59 \t AccHead 91.91 \t AccTail 73.50\n",
      "Epoch: [100] \t Loss 0.2490 \t Acc 91.27 \t AccHead 93.40 \t AccTail 63.84\n",
      "Epoch: [101] \t Loss 0.2471 \t Acc 91.21 \t AccHead 93.35 \t AccTail 63.61\n",
      "Epoch: [102] \t Loss 0.2540 \t Acc 92.31 \t AccHead 93.79 \t AccTail 73.01\n",
      "Epoch: [103] \t Loss 0.2556 \t Acc 90.19 \t AccHead 91.86 \t AccTail 68.69\n",
      "Epoch: [104] \t Loss 0.2396 \t Acc 90.41 \t AccHead 92.25 \t AccTail 66.67\n",
      "Epoch: [105] \t Loss 0.2526 \t Acc 90.18 \t AccHead 91.86 \t AccTail 68.50\n",
      "Epoch: [106] \t Loss 0.2579 \t Acc 92.90 \t AccHead 93.87 \t AccTail 80.34\n",
      "Epoch: [107] \t Loss 0.2458 \t Acc 89.82 \t AccHead 91.38 \t AccTail 69.47\n",
      "Epoch: [108] \t Loss 0.2636 \t Acc 91.34 \t AccHead 92.93 \t AccTail 70.68\n",
      "Epoch: [109] \t Loss 0.2309 \t Acc 91.38 \t AccHead 92.83 \t AccTail 72.52\n",
      "Epoch: [110] \t Loss 0.2588 \t Acc 91.18 \t AccHead 91.69 \t AccTail 84.64\n",
      "Epoch: [111] \t Loss 0.2496 \t Acc 90.88 \t AccHead 92.13 \t AccTail 74.57\n",
      "Epoch: [112] \t Loss 0.2492 \t Acc 92.51 \t AccHead 93.67 \t AccTail 77.54\n",
      "Epoch: [113] \t Loss 0.2352 \t Acc 91.71 \t AccHead 93.21 \t AccTail 72.24\n",
      "Epoch: [114] \t Loss 0.2295 \t Acc 90.98 \t AccHead 91.22 \t AccTail 87.91\n",
      "Epoch: [115] \t Loss 0.2371 \t Acc 93.33 \t AccHead 94.04 \t AccTail 84.16\n",
      "Epoch: [116] \t Loss 0.2207 \t Acc 91.76 \t AccHead 92.63 \t AccTail 80.51\n",
      "Epoch: [117] \t Loss 0.2299 \t Acc 91.64 \t AccHead 93.02 \t AccTail 73.80\n",
      "Epoch: [118] \t Loss 0.2350 \t Acc 90.59 \t AccHead 92.80 \t AccTail 61.82\n",
      "Epoch: [119] \t Loss 0.2288 \t Acc 91.16 \t AccHead 92.75 \t AccTail 70.58\n",
      "Epoch: [120] \t Loss 0.2354 \t Acc 89.41 \t AccHead 91.04 \t AccTail 68.36\n",
      "Epoch: [121] \t Loss 0.2240 \t Acc 91.55 \t AccHead 92.68 \t AccTail 76.91\n",
      "Epoch: [122] \t Loss 0.2243 \t Acc 92.10 \t AccHead 92.99 \t AccTail 80.54\n",
      "Epoch: [123] \t Loss 0.2228 \t Acc 92.42 \t AccHead 94.24 \t AccTail 68.75\n",
      "Epoch: [124] \t Loss 0.2198 \t Acc 91.09 \t AccHead 92.84 \t AccTail 68.46\n",
      "Epoch: [125] \t Loss 0.2305 \t Acc 92.27 \t AccHead 93.68 \t AccTail 74.01\n",
      "Epoch: [126] \t Loss 0.2144 \t Acc 90.61 \t AccHead 91.84 \t AccTail 74.75\n",
      "Epoch: [127] \t Loss 0.2215 \t Acc 92.83 \t AccHead 93.26 \t AccTail 87.27\n",
      "Epoch: [128] \t Loss 0.2091 \t Acc 91.94 \t AccHead 93.13 \t AccTail 76.60\n",
      "Epoch: [129] \t Loss 0.1944 \t Acc 92.50 \t AccHead 93.41 \t AccTail 80.74\n",
      "Epoch: [130] \t Loss 0.2260 \t Acc 92.72 \t AccHead 93.56 \t AccTail 81.75\n",
      "Epoch: [131] \t Loss 0.2328 \t Acc 92.48 \t AccHead 93.56 \t AccTail 78.56\n",
      "Epoch: [132] \t Loss 0.2144 \t Acc 91.15 \t AccHead 92.91 \t AccTail 68.37\n",
      "Epoch: [133] \t Loss 0.2027 \t Acc 92.45 \t AccHead 93.18 \t AccTail 82.91\n",
      "Epoch: [134] \t Loss 0.2116 \t Acc 93.66 \t AccHead 94.10 \t AccTail 87.96\n",
      "Epoch: [135] \t Loss 0.2152 \t Acc 92.33 \t AccHead 93.29 \t AccTail 79.86\n",
      "Epoch: [136] \t Loss 0.1971 \t Acc 93.02 \t AccHead 93.86 \t AccTail 82.23\n",
      "Epoch: [137] \t Loss 0.2231 \t Acc 90.21 \t AccHead 90.60 \t AccTail 85.13\n",
      "Epoch: [138] \t Loss 0.2029 \t Acc 88.95 \t AccHead 89.69 \t AccTail 79.38\n",
      "Epoch: [139] \t Loss 0.2129 \t Acc 93.49 \t AccHead 93.76 \t AccTail 89.91\n",
      "Epoch: [140] \t Loss 0.2060 \t Acc 93.13 \t AccHead 93.68 \t AccTail 86.00\n",
      "Epoch: [141] \t Loss 0.2170 \t Acc 93.76 \t AccHead 94.79 \t AccTail 80.43\n",
      "Epoch: [142] \t Loss 0.2027 \t Acc 92.99 \t AccHead 94.35 \t AccTail 75.39\n",
      "Epoch: [143] \t Loss 0.2012 \t Acc 93.70 \t AccHead 94.86 \t AccTail 78.67\n",
      "Epoch: [144] \t Loss 0.2014 \t Acc 93.60 \t AccHead 94.49 \t AccTail 81.96\n",
      "Epoch: [145] \t Loss 0.2018 \t Acc 92.14 \t AccHead 93.07 \t AccTail 80.06\n",
      "Epoch: [146] \t Loss 0.1946 \t Acc 92.59 \t AccHead 94.04 \t AccTail 73.75\n",
      "Epoch: [147] \t Loss 0.2098 \t Acc 92.64 \t AccHead 94.31 \t AccTail 71.10\n",
      "Epoch: [148] \t Loss 0.2077 \t Acc 93.71 \t AccHead 94.78 \t AccTail 79.89\n",
      "Epoch: [149] \t Loss 0.2037 \t Acc 93.66 \t AccHead 94.07 \t AccTail 88.37\n",
      "Epoch: [150] \t Loss 0.1875 \t Acc 92.37 \t AccHead 92.93 \t AccTail 85.17\n",
      "Epoch: [151] \t Loss 0.1352 \t Acc 97.46 \t AccHead 97.92 \t AccTail 91.53\n",
      "Epoch: [152] \t Loss 0.0800 \t Acc 98.04 \t AccHead 98.37 \t AccTail 93.79\n",
      "Epoch: [153] \t Loss 0.0732 \t Acc 98.20 \t AccHead 98.37 \t AccTail 96.05\n",
      "Epoch: [154] \t Loss 0.0620 \t Acc 98.56 \t AccHead 98.72 \t AccTail 96.47\n",
      "Epoch: [155] \t Loss 0.0512 \t Acc 98.74 \t AccHead 98.90 \t AccTail 96.73\n",
      "Epoch: [156] \t Loss 0.0542 \t Acc 98.99 \t AccHead 99.13 \t AccTail 97.16\n",
      "Epoch: [157] \t Loss 0.0457 \t Acc 98.99 \t AccHead 99.24 \t AccTail 95.74\n",
      "Epoch: [158] \t Loss 0.0417 \t Acc 99.15 \t AccHead 99.18 \t AccTail 98.73\n",
      "Epoch: [159] \t Loss 0.0401 \t Acc 99.07 \t AccHead 99.27 \t AccTail 96.46\n",
      "Epoch: [160] \t Loss 0.0390 \t Acc 99.34 \t AccHead 99.45 \t AccTail 97.88\n",
      "Epoch: [161] \t Loss 0.0374 \t Acc 99.24 \t AccHead 99.41 \t AccTail 97.02\n",
      "Epoch: [162] \t Loss 0.0345 \t Acc 99.28 \t AccHead 99.44 \t AccTail 97.17\n",
      "Epoch: [163] \t Loss 0.0333 \t Acc 99.29 \t AccHead 99.33 \t AccTail 98.73\n",
      "Epoch: [164] \t Loss 0.0289 \t Acc 99.43 \t AccHead 99.53 \t AccTail 98.17\n",
      "Epoch: [165] \t Loss 0.0278 \t Acc 99.29 \t AccHead 99.41 \t AccTail 97.74\n",
      "Epoch: [166] \t Loss 0.0286 \t Acc 99.41 \t AccHead 99.52 \t AccTail 98.03\n",
      "Epoch: [167] \t Loss 0.0238 \t Acc 99.48 \t AccHead 99.65 \t AccTail 97.32\n",
      "Epoch: [168] \t Loss 0.0246 \t Acc 99.43 \t AccHead 99.50 \t AccTail 98.59\n",
      "Epoch: [169] \t Loss 0.0237 \t Acc 99.61 \t AccHead 99.65 \t AccTail 99.15\n",
      "Epoch: [170] \t Loss 0.0240 \t Acc 99.63 \t AccHead 99.66 \t AccTail 99.29\n",
      "Epoch: [171] \t Loss 0.0231 \t Acc 99.50 \t AccHead 99.56 \t AccTail 98.72\n",
      "Epoch: [172] \t Loss 0.0205 \t Acc 99.48 \t AccHead 99.57 \t AccTail 98.30\n",
      "Epoch: [173] \t Loss 0.0223 \t Acc 99.61 \t AccHead 99.67 \t AccTail 98.87\n",
      "Epoch: [174] \t Loss 0.0218 \t Acc 99.72 \t AccHead 99.76 \t AccTail 99.15\n",
      "Epoch: [175] \t Loss 0.0196 \t Acc 99.68 \t AccHead 99.72 \t AccTail 99.15\n",
      "Epoch: [176] \t Loss 0.0180 \t Acc 99.68 \t AccHead 99.79 \t AccTail 98.15\n",
      "Epoch: [177] \t Loss 0.0199 \t Acc 99.64 \t AccHead 99.70 \t AccTail 98.87\n",
      "Epoch: [178] \t Loss 0.0183 \t Acc 99.64 \t AccHead 99.68 \t AccTail 99.15\n",
      "Epoch: [179] \t Loss 0.0176 \t Acc 99.64 \t AccHead 99.70 \t AccTail 98.87\n",
      "Epoch: [180] \t Loss 0.0170 \t Acc 99.59 \t AccHead 99.68 \t AccTail 98.44\n",
      "Epoch: [181] \t Loss 0.0168 \t Acc 99.74 \t AccHead 99.77 \t AccTail 99.29\n",
      "Epoch: [182] \t Loss 0.0194 \t Acc 99.66 \t AccHead 99.72 \t AccTail 98.87\n",
      "Epoch: [183] \t Loss 0.0156 \t Acc 99.71 \t AccHead 99.75 \t AccTail 99.15\n",
      "Epoch: [184] \t Loss 0.0162 \t Acc 99.69 \t AccHead 99.68 \t AccTail 99.72\n",
      "Epoch: [185] \t Loss 0.0169 \t Acc 99.82 \t AccHead 99.85 \t AccTail 99.43\n",
      "Epoch: [186] \t Loss 0.0185 \t Acc 99.72 \t AccHead 99.74 \t AccTail 99.43\n",
      "Epoch: [187] \t Loss 0.0171 \t Acc 99.68 \t AccHead 99.72 \t AccTail 99.15\n",
      "Epoch: [188] \t Loss 0.0144 \t Acc 99.80 \t AccHead 99.83 \t AccTail 99.44\n",
      "Epoch: [189] \t Loss 0.0133 \t Acc 99.74 \t AccHead 99.77 \t AccTail 99.29\n",
      "Epoch: [190] \t Loss 0.0138 \t Acc 99.82 \t AccHead 99.86 \t AccTail 99.29\n",
      "Epoch: [191] \t Loss 0.0150 \t Acc 99.78 \t AccHead 99.78 \t AccTail 99.72\n",
      "Epoch: [192] \t Loss 0.0136 \t Acc 99.81 \t AccHead 99.85 \t AccTail 99.29\n",
      "Epoch: [193] \t Loss 0.0128 \t Acc 99.75 \t AccHead 99.76 \t AccTail 99.58\n",
      "Epoch: [194] \t Loss 0.0110 \t Acc 99.87 \t AccHead 99.89 \t AccTail 99.57\n",
      "Epoch: [195] \t Loss 0.0106 \t Acc 99.82 \t AccHead 99.83 \t AccTail 99.72\n",
      "Epoch: [196] \t Loss 0.0122 \t Acc 99.82 \t AccHead 99.86 \t AccTail 99.29\n",
      "Epoch: [197] \t Loss 0.0110 \t Acc 99.79 \t AccHead 99.79 \t AccTail 99.72\n",
      "Epoch: [198] \t Loss 0.0129 \t Acc 99.81 \t AccHead 99.81 \t AccTail 99.72\n",
      "Epoch: [199] \t Loss 0.0103 \t Acc 99.83 \t AccHead 99.85 \t AccTail 99.57\n",
      "Epoch: [200] \t Loss 0.0126 \t Acc 99.83 \t AccHead 99.86 \t AccTail 99.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 15:59:54,050]\u001b[0m Trial 10 finished with value: 56.11037826538086 and parameters: {'n_epoch': 200, 'weight_decay': 0.00024735153950860374}. Best is trial 5 with value: 56.24178695678711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 56.11 \t AccHead 78.78 \t AccTail 32.95\n",
      "Epoch: [001] \t Loss 3.0338 \t Acc 46.02 \t AccHead 49.58 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.7933 \t Acc 53.47 \t AccHead 57.60 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.3907 \t Acc 57.62 \t AccHead 62.08 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.3077 \t Acc 58.85 \t AccHead 63.40 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.2263 \t Acc 62.50 \t AccHead 67.34 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.1493 \t Acc 62.51 \t AccHead 67.33 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 1.0939 \t Acc 63.30 \t AccHead 68.01 \t AccTail 2.13\n",
      "Epoch: [008] \t Loss 1.1495 \t Acc 62.20 \t AccHead 66.99 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 1.0518 \t Acc 65.79 \t AccHead 70.13 \t AccTail 9.62\n",
      "Epoch: [010] \t Loss 0.9921 \t Acc 67.81 \t AccHead 73.01 \t AccTail 0.14\n",
      "Epoch: [011] \t Loss 0.9608 \t Acc 66.23 \t AccHead 71.31 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 0.9523 \t Acc 67.16 \t AccHead 72.27 \t AccTail 1.13\n",
      "Epoch: [013] \t Loss 0.9205 \t Acc 69.09 \t AccHead 74.26 \t AccTail 2.40\n",
      "Epoch: [014] \t Loss 0.8870 \t Acc 70.46 \t AccHead 75.79 \t AccTail 1.97\n",
      "Epoch: [015] \t Loss 0.8790 \t Acc 71.33 \t AccHead 76.15 \t AccTail 9.04\n",
      "Epoch: [016] \t Loss 0.8459 \t Acc 70.81 \t AccHead 75.91 \t AccTail 4.94\n",
      "Epoch: [017] \t Loss 0.8308 \t Acc 73.44 \t AccHead 77.83 \t AccTail 16.67\n",
      "Epoch: [018] \t Loss 0.7975 \t Acc 74.31 \t AccHead 79.57 \t AccTail 5.97\n",
      "Epoch: [019] \t Loss 0.7877 \t Acc 73.19 \t AccHead 78.25 \t AccTail 7.78\n",
      "Epoch: [020] \t Loss 0.7775 \t Acc 73.92 \t AccHead 78.69 \t AccTail 12.31\n",
      "Epoch: [021] \t Loss 0.7685 \t Acc 73.73 \t AccHead 78.71 \t AccTail 9.34\n",
      "Epoch: [022] \t Loss 0.7362 \t Acc 75.66 \t AccHead 80.54 \t AccTail 12.69\n",
      "Epoch: [023] \t Loss 0.7210 \t Acc 76.96 \t AccHead 81.72 \t AccTail 15.40\n",
      "Epoch: [024] \t Loss 0.7110 \t Acc 76.89 \t AccHead 80.78 \t AccTail 26.66\n",
      "Epoch: [025] \t Loss 0.6981 \t Acc 77.39 \t AccHead 81.68 \t AccTail 21.81\n",
      "Epoch: [026] \t Loss 0.6844 \t Acc 77.08 \t AccHead 80.96 \t AccTail 26.67\n",
      "Epoch: [027] \t Loss 0.6673 \t Acc 79.38 \t AccHead 83.70 \t AccTail 23.40\n",
      "Epoch: [028] \t Loss 0.6522 \t Acc 78.15 \t AccHead 82.83 \t AccTail 17.42\n",
      "Epoch: [029] \t Loss 0.6577 \t Acc 76.31 \t AccHead 80.59 \t AccTail 20.60\n",
      "Epoch: [030] \t Loss 0.6195 \t Acc 78.29 \t AccHead 81.79 \t AccTail 32.86\n",
      "Epoch: [031] \t Loss 0.6132 \t Acc 78.45 \t AccHead 82.52 \t AccTail 25.64\n",
      "Epoch: [032] \t Loss 0.6056 \t Acc 80.46 \t AccHead 85.09 \t AccTail 20.51\n",
      "Epoch: [033] \t Loss 0.5802 \t Acc 80.77 \t AccHead 83.38 \t AccTail 47.18\n",
      "Epoch: [034] \t Loss 0.5904 \t Acc 81.56 \t AccHead 84.58 \t AccTail 42.57\n",
      "Epoch: [035] \t Loss 0.5608 \t Acc 82.23 \t AccHead 85.67 \t AccTail 37.77\n",
      "Epoch: [036] \t Loss 0.5658 \t Acc 80.54 \t AccHead 83.07 \t AccTail 47.89\n",
      "Epoch: [037] \t Loss 0.5522 \t Acc 83.19 \t AccHead 86.41 \t AccTail 41.44\n",
      "Epoch: [038] \t Loss 0.5294 \t Acc 82.61 \t AccHead 86.04 \t AccTail 38.28\n",
      "Epoch: [039] \t Loss 0.5320 \t Acc 81.91 \t AccHead 86.01 \t AccTail 28.65\n",
      "Epoch: [040] \t Loss 0.5248 \t Acc 81.26 \t AccHead 84.32 \t AccTail 41.64\n",
      "Epoch: [041] \t Loss 0.5099 \t Acc 82.24 \t AccHead 85.40 \t AccTail 41.36\n",
      "Epoch: [042] \t Loss 0.4976 \t Acc 81.40 \t AccHead 84.22 \t AccTail 44.98\n",
      "Epoch: [043] \t Loss 0.5066 \t Acc 82.38 \t AccHead 85.40 \t AccTail 43.20\n",
      "Epoch: [044] \t Loss 0.4920 \t Acc 83.75 \t AccHead 87.12 \t AccTail 40.03\n",
      "Epoch: [045] \t Loss 0.4751 \t Acc 82.52 \t AccHead 84.83 \t AccTail 52.48\n",
      "Epoch: [046] \t Loss 0.4782 \t Acc 84.49 \t AccHead 87.59 \t AccTail 44.10\n",
      "Epoch: [047] \t Loss 0.4661 \t Acc 81.92 \t AccHead 84.67 \t AccTail 46.40\n",
      "Epoch: [048] \t Loss 0.4477 \t Acc 84.48 \t AccHead 86.94 \t AccTail 52.68\n",
      "Epoch: [049] \t Loss 0.4588 \t Acc 82.11 \t AccHead 84.92 \t AccTail 45.83\n",
      "Epoch: [050] \t Loss 0.4342 \t Acc 86.19 \t AccHead 88.82 \t AccTail 51.99\n",
      "Epoch: [051] \t Loss 0.4354 \t Acc 86.44 \t AccHead 89.76 \t AccTail 43.24\n",
      "Epoch: [052] \t Loss 0.4225 \t Acc 84.15 \t AccHead 85.89 \t AccTail 61.48\n",
      "Epoch: [053] \t Loss 0.4423 \t Acc 83.81 \t AccHead 85.34 \t AccTail 63.92\n",
      "Epoch: [054] \t Loss 0.4081 \t Acc 84.35 \t AccHead 87.04 \t AccTail 49.65\n",
      "Epoch: [055] \t Loss 0.4330 \t Acc 85.83 \t AccHead 88.25 \t AccTail 54.46\n",
      "Epoch: [056] \t Loss 0.4194 \t Acc 85.61 \t AccHead 88.89 \t AccTail 42.88\n",
      "Epoch: [057] \t Loss 0.3912 \t Acc 87.48 \t AccHead 90.36 \t AccTail 50.28\n",
      "Epoch: [058] \t Loss 0.3954 \t Acc 86.58 \t AccHead 88.70 \t AccTail 58.95\n",
      "Epoch: [059] \t Loss 0.3918 \t Acc 85.39 \t AccHead 87.90 \t AccTail 52.83\n",
      "Epoch: [060] \t Loss 0.3869 \t Acc 85.97 \t AccHead 88.16 \t AccTail 57.51\n",
      "Epoch: [061] \t Loss 0.3840 \t Acc 83.49 \t AccHead 85.08 \t AccTail 63.01\n",
      "Epoch: [062] \t Loss 0.3800 \t Acc 87.64 \t AccHead 89.36 \t AccTail 65.35\n",
      "Epoch: [063] \t Loss 0.3593 \t Acc 85.27 \t AccHead 87.92 \t AccTail 50.92\n",
      "Epoch: [064] \t Loss 0.3648 \t Acc 86.93 \t AccHead 88.64 \t AccTail 64.82\n",
      "Epoch: [065] \t Loss 0.3576 \t Acc 88.08 \t AccHead 90.78 \t AccTail 52.98\n",
      "Epoch: [066] \t Loss 0.3572 \t Acc 86.79 \t AccHead 89.85 \t AccTail 47.24\n",
      "Epoch: [067] \t Loss 0.3680 \t Acc 88.11 \t AccHead 90.31 \t AccTail 59.63\n",
      "Epoch: [068] \t Loss 0.3644 \t Acc 89.03 \t AccHead 91.16 \t AccTail 61.53\n",
      "Epoch: [069] \t Loss 0.3536 \t Acc 88.10 \t AccHead 88.70 \t AccTail 80.31\n",
      "Epoch: [070] \t Loss 0.3283 \t Acc 88.28 \t AccHead 90.17 \t AccTail 63.79\n",
      "Epoch: [071] \t Loss 0.3281 \t Acc 90.56 \t AccHead 92.27 \t AccTail 68.32\n",
      "Epoch: [072] \t Loss 0.3207 \t Acc 89.16 \t AccHead 90.70 \t AccTail 69.44\n",
      "Epoch: [073] \t Loss 0.3188 \t Acc 89.85 \t AccHead 90.70 \t AccTail 78.87\n",
      "Epoch: [074] \t Loss 0.3132 \t Acc 87.45 \t AccHead 89.10 \t AccTail 66.05\n",
      "Epoch: [075] \t Loss 0.3197 \t Acc 88.97 \t AccHead 89.55 \t AccTail 81.47\n",
      "Epoch: [076] \t Loss 0.3139 \t Acc 88.34 \t AccHead 90.17 \t AccTail 64.59\n",
      "Epoch: [077] \t Loss 0.3073 \t Acc 91.17 \t AccHead 92.35 \t AccTail 75.95\n",
      "Epoch: [078] \t Loss 0.3117 \t Acc 90.41 \t AccHead 92.29 \t AccTail 66.15\n",
      "Epoch: [079] \t Loss 0.2998 \t Acc 88.96 \t AccHead 91.14 \t AccTail 60.79\n",
      "Epoch: [080] \t Loss 0.2940 \t Acc 88.30 \t AccHead 90.20 \t AccTail 63.75\n",
      "Epoch: [081] \t Loss 0.2990 \t Acc 89.36 \t AccHead 90.24 \t AccTail 77.90\n",
      "Epoch: [082] \t Loss 0.2867 \t Acc 90.38 \t AccHead 91.41 \t AccTail 77.09\n",
      "Epoch: [083] \t Loss 0.2948 \t Acc 90.62 \t AccHead 92.05 \t AccTail 72.18\n",
      "Epoch: [084] \t Loss 0.2853 \t Acc 89.18 \t AccHead 91.31 \t AccTail 61.61\n",
      "Epoch: [085] \t Loss 0.2799 \t Acc 91.19 \t AccHead 92.18 \t AccTail 78.42\n",
      "Epoch: [086] \t Loss 0.2779 \t Acc 89.41 \t AccHead 90.90 \t AccTail 70.11\n",
      "Epoch: [087] \t Loss 0.2767 \t Acc 90.58 \t AccHead 92.27 \t AccTail 68.65\n",
      "Epoch: [088] \t Loss 0.2707 \t Acc 90.15 \t AccHead 91.38 \t AccTail 74.26\n",
      "Epoch: [089] \t Loss 0.2877 \t Acc 90.67 \t AccHead 91.67 \t AccTail 77.72\n",
      "Epoch: [090] \t Loss 0.2678 \t Acc 91.07 \t AccHead 91.89 \t AccTail 80.40\n",
      "Epoch: [091] \t Loss 0.2529 \t Acc 91.26 \t AccHead 93.08 \t AccTail 67.71\n",
      "Epoch: [092] \t Loss 0.2631 \t Acc 89.87 \t AccHead 91.49 \t AccTail 69.02\n",
      "Epoch: [093] \t Loss 0.2496 \t Acc 88.62 \t AccHead 90.37 \t AccTail 65.82\n",
      "Epoch: [094] \t Loss 0.2777 \t Acc 91.22 \t AccHead 92.49 \t AccTail 74.79\n",
      "Epoch: [095] \t Loss 0.2582 \t Acc 89.31 \t AccHead 91.37 \t AccTail 62.62\n",
      "Epoch: [096] \t Loss 0.2576 \t Acc 90.20 \t AccHead 90.96 \t AccTail 80.34\n",
      "Epoch: [097] \t Loss 0.2549 \t Acc 89.50 \t AccHead 90.96 \t AccTail 70.54\n",
      "Epoch: [098] \t Loss 0.2367 \t Acc 91.59 \t AccHead 92.74 \t AccTail 76.60\n",
      "Epoch: [099] \t Loss 0.2618 \t Acc 91.60 \t AccHead 93.14 \t AccTail 71.63\n",
      "Epoch: [100] \t Loss 0.2455 \t Acc 90.13 \t AccHead 90.91 \t AccTail 79.97\n",
      "Epoch: [101] \t Loss 0.2528 \t Acc 92.11 \t AccHead 93.67 \t AccTail 71.69\n",
      "Epoch: [102] \t Loss 0.2493 \t Acc 90.68 \t AccHead 91.23 \t AccTail 83.55\n",
      "Epoch: [103] \t Loss 0.2396 \t Acc 92.38 \t AccHead 93.33 \t AccTail 80.03\n",
      "Epoch: [104] \t Loss 0.2476 \t Acc 90.93 \t AccHead 93.04 \t AccTail 63.55\n",
      "Epoch: [105] \t Loss 0.2263 \t Acc 90.56 \t AccHead 92.48 \t AccTail 65.82\n",
      "Epoch: [106] \t Loss 0.2267 \t Acc 93.54 \t AccHead 94.33 \t AccTail 83.21\n",
      "Epoch: [107] \t Loss 0.2316 \t Acc 89.77 \t AccHead 91.29 \t AccTail 70.03\n",
      "Epoch: [108] \t Loss 0.2417 \t Acc 91.60 \t AccHead 92.15 \t AccTail 84.42\n",
      "Epoch: [109] \t Loss 0.2235 \t Acc 91.93 \t AccHead 92.83 \t AccTail 80.37\n",
      "Epoch: [110] \t Loss 0.2102 \t Acc 92.08 \t AccHead 94.01 \t AccTail 66.90\n",
      "Epoch: [111] \t Loss 0.2327 \t Acc 90.53 \t AccHead 91.12 \t AccTail 82.91\n",
      "Epoch: [112] \t Loss 0.2266 \t Acc 92.03 \t AccHead 93.51 \t AccTail 72.84\n",
      "Epoch: [113] \t Loss 0.2103 \t Acc 92.28 \t AccHead 93.50 \t AccTail 76.59\n",
      "Epoch: [114] \t Loss 0.2284 \t Acc 91.86 \t AccHead 93.38 \t AccTail 72.28\n",
      "Epoch: [115] \t Loss 0.2176 \t Acc 93.17 \t AccHead 94.64 \t AccTail 74.12\n",
      "Epoch: [116] \t Loss 0.2193 \t Acc 92.75 \t AccHead 93.27 \t AccTail 86.00\n",
      "Epoch: [117] \t Loss 0.1993 \t Acc 93.55 \t AccHead 94.27 \t AccTail 84.14\n",
      "Epoch: [118] \t Loss 0.2055 \t Acc 93.01 \t AccHead 93.76 \t AccTail 83.24\n",
      "Epoch: [119] \t Loss 0.2267 \t Acc 92.88 \t AccHead 93.92 \t AccTail 79.38\n",
      "Epoch: [120] \t Loss 0.1872 \t Acc 92.09 \t AccHead 92.60 \t AccTail 85.41\n",
      "Epoch: [121] \t Loss 0.2071 \t Acc 92.99 \t AccHead 93.84 \t AccTail 82.01\n",
      "Epoch: [122] \t Loss 0.2070 \t Acc 91.47 \t AccHead 93.22 \t AccTail 68.83\n",
      "Epoch: [123] \t Loss 0.2213 \t Acc 92.91 \t AccHead 94.48 \t AccTail 72.40\n",
      "Epoch: [124] \t Loss 0.2127 \t Acc 91.20 \t AccHead 92.15 \t AccTail 78.90\n",
      "Epoch: [125] \t Loss 0.2010 \t Acc 92.57 \t AccHead 93.45 \t AccTail 81.11\n",
      "Epoch: [126] \t Loss 0.1940 \t Acc 93.33 \t AccHead 94.28 \t AccTail 80.99\n",
      "Epoch: [127] \t Loss 0.2168 \t Acc 92.26 \t AccHead 92.58 \t AccTail 88.14\n",
      "Epoch: [128] \t Loss 0.1919 \t Acc 95.15 \t AccHead 95.56 \t AccTail 89.80\n",
      "Epoch: [129] \t Loss 0.1986 \t Acc 92.61 \t AccHead 94.07 \t AccTail 73.77\n",
      "Epoch: [130] \t Loss 0.2051 \t Acc 93.15 \t AccHead 94.77 \t AccTail 72.21\n",
      "Epoch: [131] \t Loss 0.2054 \t Acc 93.64 \t AccHead 94.82 \t AccTail 78.24\n",
      "Epoch: [132] \t Loss 0.2007 \t Acc 92.48 \t AccHead 92.96 \t AccTail 86.28\n",
      "Epoch: [133] \t Loss 0.1972 \t Acc 93.68 \t AccHead 94.52 \t AccTail 82.74\n",
      "Epoch: [134] \t Loss 0.1891 \t Acc 94.01 \t AccHead 94.38 \t AccTail 89.28\n",
      "Epoch: [135] \t Loss 0.1893 \t Acc 93.13 \t AccHead 93.92 \t AccTail 82.93\n",
      "Epoch: [136] \t Loss 0.1889 \t Acc 92.53 \t AccHead 93.32 \t AccTail 82.29\n",
      "Epoch: [137] \t Loss 0.2100 \t Acc 94.34 \t AccHead 95.14 \t AccTail 83.95\n",
      "Epoch: [138] \t Loss 0.1783 \t Acc 92.49 \t AccHead 93.35 \t AccTail 81.33\n",
      "Epoch: [139] \t Loss 0.2089 \t Acc 93.11 \t AccHead 93.69 \t AccTail 85.59\n",
      "Epoch: [140] \t Loss 0.1924 \t Acc 94.18 \t AccHead 95.28 \t AccTail 79.77\n",
      "Epoch: [141] \t Loss 0.2071 \t Acc 93.92 \t AccHead 94.75 \t AccTail 83.14\n",
      "Epoch: [142] \t Loss 0.1856 \t Acc 93.78 \t AccHead 94.73 \t AccTail 81.52\n",
      "Epoch: [143] \t Loss 0.1810 \t Acc 94.44 \t AccHead 95.99 \t AccTail 74.40\n",
      "Epoch: [144] \t Loss 0.1915 \t Acc 91.89 \t AccHead 92.99 \t AccTail 77.67\n",
      "Epoch: [145] \t Loss 0.2025 \t Acc 92.54 \t AccHead 93.84 \t AccTail 75.74\n",
      "Epoch: [146] \t Loss 0.1978 \t Acc 93.76 \t AccHead 95.04 \t AccTail 77.23\n",
      "Epoch: [147] \t Loss 0.1714 \t Acc 93.54 \t AccHead 94.82 \t AccTail 76.91\n",
      "Epoch: [148] \t Loss 0.1759 \t Acc 93.57 \t AccHead 94.31 \t AccTail 84.02\n",
      "Epoch: [149] \t Loss 0.1918 \t Acc 93.64 \t AccHead 94.06 \t AccTail 88.17\n",
      "Epoch: [150] \t Loss 0.1907 \t Acc 93.83 \t AccHead 94.82 \t AccTail 81.02\n",
      "Epoch: [151] \t Loss 0.1110 \t Acc 97.59 \t AccHead 98.02 \t AccTail 91.94\n",
      "Epoch: [152] \t Loss 0.0837 \t Acc 98.35 \t AccHead 98.49 \t AccTail 96.46\n",
      "Epoch: [153] \t Loss 0.0641 \t Acc 98.52 \t AccHead 98.77 \t AccTail 95.33\n",
      "Epoch: [154] \t Loss 0.0599 \t Acc 98.74 \t AccHead 98.94 \t AccTail 96.18\n",
      "Epoch: [155] \t Loss 0.0499 \t Acc 98.95 \t AccHead 99.07 \t AccTail 97.44\n",
      "Epoch: [156] \t Loss 0.0463 \t Acc 99.00 \t AccHead 99.11 \t AccTail 97.45\n",
      "Epoch: [157] \t Loss 0.0450 \t Acc 99.06 \t AccHead 99.27 \t AccTail 96.32\n",
      "Epoch: [158] \t Loss 0.0416 \t Acc 99.25 \t AccHead 99.31 \t AccTail 98.44\n",
      "Epoch: [159] \t Loss 0.0363 \t Acc 99.36 \t AccHead 99.41 \t AccTail 98.72\n",
      "Epoch: [160] \t Loss 0.0314 \t Acc 99.28 \t AccHead 99.36 \t AccTail 98.30\n",
      "Epoch: [161] \t Loss 0.0350 \t Acc 99.34 \t AccHead 99.48 \t AccTail 97.59\n",
      "Epoch: [162] \t Loss 0.0313 \t Acc 99.37 \t AccHead 99.50 \t AccTail 97.74\n",
      "Epoch: [163] \t Loss 0.0308 \t Acc 99.47 \t AccHead 99.56 \t AccTail 98.31\n",
      "Epoch: [164] \t Loss 0.0262 \t Acc 99.52 \t AccHead 99.56 \t AccTail 99.01\n",
      "Epoch: [165] \t Loss 0.0264 \t Acc 99.54 \t AccHead 99.67 \t AccTail 97.88\n",
      "Epoch: [166] \t Loss 0.0264 \t Acc 99.54 \t AccHead 99.58 \t AccTail 99.01\n",
      "Epoch: [167] \t Loss 0.0266 \t Acc 99.47 \t AccHead 99.54 \t AccTail 98.59\n",
      "Epoch: [168] \t Loss 0.0228 \t Acc 99.57 \t AccHead 99.57 \t AccTail 99.57\n",
      "Epoch: [169] \t Loss 0.0212 \t Acc 99.67 \t AccHead 99.72 \t AccTail 99.01\n",
      "Epoch: [170] \t Loss 0.0204 \t Acc 99.56 \t AccHead 99.61 \t AccTail 99.01\n",
      "Epoch: [171] \t Loss 0.0194 \t Acc 99.58 \t AccHead 99.67 \t AccTail 98.44\n",
      "Epoch: [172] \t Loss 0.0191 \t Acc 99.73 \t AccHead 99.74 \t AccTail 99.57\n",
      "Epoch: [173] \t Loss 0.0190 \t Acc 99.66 \t AccHead 99.73 \t AccTail 98.73\n",
      "Epoch: [174] \t Loss 0.0178 \t Acc 99.73 \t AccHead 99.76 \t AccTail 99.29\n",
      "Epoch: [175] \t Loss 0.0189 \t Acc 99.60 \t AccHead 99.66 \t AccTail 98.87\n",
      "Epoch: [176] \t Loss 0.0198 \t Acc 99.68 \t AccHead 99.72 \t AccTail 99.15\n",
      "Epoch: [177] \t Loss 0.0166 \t Acc 99.66 \t AccHead 99.72 \t AccTail 98.87\n",
      "Epoch: [178] \t Loss 0.0200 \t Acc 99.79 \t AccHead 99.83 \t AccTail 99.29\n",
      "Epoch: [179] \t Loss 0.0172 \t Acc 99.81 \t AccHead 99.89 \t AccTail 98.73\n",
      "Epoch: [180] \t Loss 0.0161 \t Acc 99.67 \t AccHead 99.69 \t AccTail 99.30\n",
      "Epoch: [181] \t Loss 0.0154 \t Acc 99.76 \t AccHead 99.83 \t AccTail 98.87\n",
      "Epoch: [182] \t Loss 0.0158 \t Acc 99.73 \t AccHead 99.75 \t AccTail 99.43\n",
      "Epoch: [183] \t Loss 0.0156 \t Acc 99.68 \t AccHead 99.73 \t AccTail 99.01\n",
      "Epoch: [184] \t Loss 0.0154 \t Acc 99.68 \t AccHead 99.69 \t AccTail 99.44\n",
      "Epoch: [185] \t Loss 0.0128 \t Acc 99.82 \t AccHead 99.83 \t AccTail 99.72\n",
      "Epoch: [186] \t Loss 0.0147 \t Acc 99.83 \t AccHead 99.85 \t AccTail 99.58\n",
      "Epoch: [187] \t Loss 0.0124 \t Acc 99.77 \t AccHead 99.78 \t AccTail 99.58\n",
      "Epoch: [188] \t Loss 0.0139 \t Acc 99.77 \t AccHead 99.80 \t AccTail 99.29\n",
      "Epoch: [189] \t Loss 0.0130 \t Acc 99.76 \t AccHead 99.78 \t AccTail 99.43\n",
      "Epoch: [190] \t Loss 0.0140 \t Acc 99.83 \t AccHead 99.85 \t AccTail 99.58\n",
      "Epoch: [191] \t Loss 0.0138 \t Acc 99.82 \t AccHead 99.83 \t AccTail 99.72\n",
      "Epoch: [192] \t Loss 0.0106 \t Acc 99.83 \t AccHead 99.85 \t AccTail 99.58\n",
      "Epoch: [193] \t Loss 0.0113 \t Acc 99.74 \t AccHead 99.78 \t AccTail 99.15\n",
      "Epoch: [194] \t Loss 0.0122 \t Acc 99.87 \t AccHead 99.86 \t AccTail 100.00\n",
      "Epoch: [195] \t Loss 0.0106 \t Acc 99.83 \t AccHead 99.85 \t AccTail 99.58\n",
      "Epoch: [196] \t Loss 0.0116 \t Acc 99.80 \t AccHead 99.80 \t AccTail 99.72\n",
      "Epoch: [197] \t Loss 0.0110 \t Acc 99.87 \t AccHead 99.89 \t AccTail 99.58\n",
      "Epoch: [198] \t Loss 0.0105 \t Acc 99.82 \t AccHead 99.85 \t AccTail 99.44\n",
      "Epoch: [199] \t Loss 0.0100 \t Acc 99.86 \t AccHead 99.88 \t AccTail 99.57\n",
      "Epoch: [200] \t Loss 0.0123 \t Acc 99.85 \t AccHead 99.90 \t AccTail 99.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 16:24:10,499]\u001b[0m Trial 11 finished with value: 54.47285842895508 and parameters: {'n_epoch': 200, 'weight_decay': 0.00022118694089239097}. Best is trial 5 with value: 56.24178695678711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 54.47 \t AccHead 78.06 \t AccTail 30.37\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sampler = optuna.samplers.TPESampler()\n",
    "    study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "    study.optimize(func=train_model, n_trials=12)\n",
    "    joblib.dump(study, 'set_10_exp_01.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18f8d902-6d9f-4ba3-9ddc-d4f62e2b40eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T16:24:10.607274Z",
     "iopub.status.busy": "2022-06-18T16:24:10.607159Z",
     "iopub.status.idle": "2022-06-18T16:24:10.612973Z",
     "shell.execute_reply": "2022-06-18T16:24:10.612439Z",
     "shell.execute_reply.started": "2022-06-18T16:24:10.607261Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FrozenTrial(number=0, values=[10.10815715789795], datetime_start=datetime.datetime(2022, 6, 18, 13, 16, 46, 538324), datetime_complete=datetime.datetime(2022, 6, 18, 13, 27, 50, 88341), params={'n_epoch': 90, 'weight_decay': 0.04693209296935963}, distributions={'n_epoch': CategoricalDistribution(choices=(90, 200)), 'weight_decay': LogUniformDistribution(high=0.1, low=1e-05)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=0, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=1, values=[23.885574340820312], datetime_start=datetime.datetime(2022, 6, 18, 13, 27, 50, 92326), datetime_complete=datetime.datetime(2022, 6, 18, 13, 52, 37, 912480), params={'n_epoch': 200, 'weight_decay': 0.009352899646879149}, distributions={'n_epoch': CategoricalDistribution(choices=(90, 200)), 'weight_decay': LogUniformDistribution(high=0.1, low=1e-05)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=1, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=2, values=[50.338623046875], datetime_start=datetime.datetime(2022, 6, 18, 13, 52, 37, 916067), datetime_complete=datetime.datetime(2022, 6, 18, 14, 3, 40, 385116), params={'n_epoch': 90, 'weight_decay': 1.2327520262024438e-05}, distributions={'n_epoch': CategoricalDistribution(choices=(90, 200)), 'weight_decay': LogUniformDistribution(high=0.1, low=1e-05)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=2, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=3, values=[31.567773818969727], datetime_start=datetime.datetime(2022, 6, 18, 14, 3, 40, 388897), datetime_complete=datetime.datetime(2022, 6, 18, 14, 14, 44, 466555), params={'n_epoch': 90, 'weight_decay': 0.002394531093789722}, distributions={'n_epoch': CategoricalDistribution(choices=(90, 200)), 'weight_decay': LogUniformDistribution(high=0.1, low=1e-05)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=3, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=4, values=[10.10815715789795], datetime_start=datetime.datetime(2022, 6, 18, 14, 14, 44, 468771), datetime_complete=datetime.datetime(2022, 6, 18, 14, 25, 55, 489271), params={'n_epoch': 90, 'weight_decay': 0.0689012572886808}, distributions={'n_epoch': CategoricalDistribution(choices=(90, 200)), 'weight_decay': LogUniformDistribution(high=0.1, low=1e-05)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=4, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=5, values=[56.24178695678711], datetime_start=datetime.datetime(2022, 6, 18, 14, 25, 55, 491708), datetime_complete=datetime.datetime(2022, 6, 18, 14, 50, 44, 195008), params={'n_epoch': 200, 'weight_decay': 0.0004882461261877769}, distributions={'n_epoch': CategoricalDistribution(choices=(90, 200)), 'weight_decay': LogUniformDistribution(high=0.1, low=1e-05)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=5, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=6, values=[49.76245880126953], datetime_start=datetime.datetime(2022, 6, 18, 14, 50, 44, 199218), datetime_complete=datetime.datetime(2022, 6, 18, 15, 1, 50, 327840), params={'n_epoch': 90, 'weight_decay': 0.0006718561699566825}, distributions={'n_epoch': CategoricalDistribution(choices=(90, 200)), 'weight_decay': LogUniformDistribution(high=0.1, low=1e-05)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=6, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=7, values=[52.198524475097656], datetime_start=datetime.datetime(2022, 6, 18, 15, 1, 50, 331337), datetime_complete=datetime.datetime(2022, 6, 18, 15, 13, 0, 172766), params={'n_epoch': 90, 'weight_decay': 4.201741854557997e-05}, distributions={'n_epoch': CategoricalDistribution(choices=(90, 200)), 'weight_decay': LogUniformDistribution(high=0.1, low=1e-05)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=7, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=8, values=[30.071767807006836], datetime_start=datetime.datetime(2022, 6, 18, 15, 13, 0, 175964), datetime_complete=datetime.datetime(2022, 6, 18, 15, 24, 5, 88155), params={'n_epoch': 90, 'weight_decay': 0.003177707639070479}, distributions={'n_epoch': CategoricalDistribution(choices=(90, 200)), 'weight_decay': LogUniformDistribution(high=0.1, low=1e-05)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=8, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=9, values=[39.21965026855469], datetime_start=datetime.datetime(2022, 6, 18, 15, 24, 5, 91635), datetime_complete=datetime.datetime(2022, 6, 18, 15, 35, 22, 563424), params={'n_epoch': 90, 'weight_decay': 0.0016234028607792713}, distributions={'n_epoch': CategoricalDistribution(choices=(90, 200)), 'weight_decay': LogUniformDistribution(high=0.1, low=1e-05)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=9, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=10, values=[56.11037826538086], datetime_start=datetime.datetime(2022, 6, 18, 15, 35, 22, 566249), datetime_complete=datetime.datetime(2022, 6, 18, 15, 59, 54, 49086), params={'n_epoch': 200, 'weight_decay': 0.00024735153950860374}, distributions={'n_epoch': CategoricalDistribution(choices=(90, 200)), 'weight_decay': LogUniformDistribution(high=0.1, low=1e-05)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=10, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=11, values=[54.47285842895508], datetime_start=datetime.datetime(2022, 6, 18, 15, 59, 54, 53105), datetime_complete=datetime.datetime(2022, 6, 18, 16, 24, 10, 498656), params={'n_epoch': 200, 'weight_decay': 0.00022118694089239097}, distributions={'n_epoch': CategoricalDistribution(choices=(90, 200)), 'weight_decay': LogUniformDistribution(high=0.1, low=1e-05)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=11, state=TrialState.COMPLETE, value=None)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "912c5e4b-0fc1-49dc-8a00-847bbfd3b648",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T16:24:10.614095Z",
     "iopub.status.busy": "2022-06-18T16:24:10.613639Z",
     "iopub.status.idle": "2022-06-18T16:24:10.631630Z",
     "shell.execute_reply": "2022-06-18T16:24:10.630692Z",
     "shell.execute_reply.started": "2022-06-18T16:24:10.614078Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_n_epoch</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10.108157</td>\n",
       "      <td>0 days 00:11:03.550017</td>\n",
       "      <td>90</td>\n",
       "      <td>0.046932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23.885574</td>\n",
       "      <td>0 days 00:24:47.820154</td>\n",
       "      <td>200</td>\n",
       "      <td>0.009353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>50.338623</td>\n",
       "      <td>0 days 00:11:02.469049</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31.567774</td>\n",
       "      <td>0 days 00:11:04.077658</td>\n",
       "      <td>90</td>\n",
       "      <td>0.002395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10.108157</td>\n",
       "      <td>0 days 00:11:11.020500</td>\n",
       "      <td>90</td>\n",
       "      <td>0.068901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>56.241787</td>\n",
       "      <td>0 days 00:24:48.703300</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>49.762459</td>\n",
       "      <td>0 days 00:11:06.128622</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>52.198524</td>\n",
       "      <td>0 days 00:11:09.841429</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>30.071768</td>\n",
       "      <td>0 days 00:11:04.912191</td>\n",
       "      <td>90</td>\n",
       "      <td>0.003178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>39.219650</td>\n",
       "      <td>0 days 00:11:17.471789</td>\n",
       "      <td>90</td>\n",
       "      <td>0.001623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number      value               duration  params_n_epoch  \\\n",
       "0       0  10.108157 0 days 00:11:03.550017              90   \n",
       "1       1  23.885574 0 days 00:24:47.820154             200   \n",
       "2       2  50.338623 0 days 00:11:02.469049              90   \n",
       "3       3  31.567774 0 days 00:11:04.077658              90   \n",
       "4       4  10.108157 0 days 00:11:11.020500              90   \n",
       "5       5  56.241787 0 days 00:24:48.703300             200   \n",
       "6       6  49.762459 0 days 00:11:06.128622              90   \n",
       "7       7  52.198524 0 days 00:11:09.841429              90   \n",
       "8       8  30.071768 0 days 00:11:04.912191              90   \n",
       "9       9  39.219650 0 days 00:11:17.471789              90   \n",
       "\n",
       "   params_weight_decay  \n",
       "0             0.046932  \n",
       "1             0.009353  \n",
       "2             0.000012  \n",
       "3             0.002395  \n",
       "4             0.068901  \n",
       "5             0.000488  \n",
       "6             0.000672  \n",
       "7             0.000042  \n",
       "8             0.003178  \n",
       "9             0.001623  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install optuna\n",
    "study = joblib.load('set_10_exp_01.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4e1739b-9a0c-4abf-aaab-2a3657582a94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T16:24:10.632415Z",
     "iopub.status.busy": "2022-06-18T16:24:10.632299Z",
     "iopub.status.idle": "2022-06-18T16:24:10.643750Z",
     "shell.execute_reply": "2022-06-18T16:24:10.643030Z",
     "shell.execute_reply.started": "2022-06-18T16:24:10.632403Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_n_epoch</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12.665388</td>\n",
       "      <td>0 days 00:00:14.831324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23.866278</td>\n",
       "      <td>0 days 00:00:18.664764</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15.463085</td>\n",
       "      <td>0 days 00:00:25.052409</td>\n",
       "      <td>3</td>\n",
       "      <td>0.046026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number      value               duration  params_n_epoch  \\\n",
       "0       0  12.665388 0 days 00:00:14.831324               1   \n",
       "1       1  23.866278 0 days 00:00:18.664764               2   \n",
       "2       2  15.463085 0 days 00:00:25.052409               3   \n",
       "\n",
       "   params_weight_decay  \n",
       "0             0.000028  \n",
       "1             0.000070  \n",
       "2             0.046026  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install optuna\n",
    "study = joblib.load('mnist_optuna.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0316bba-62bf-4d26-9d89-d542410b29ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T13:14:53.008945Z",
     "iopub.status.busy": "2022-06-18T13:14:53.008498Z",
     "iopub.status.idle": "2022-06-18T13:14:53.038832Z",
     "shell.execute_reply": "2022-06-18T13:14:53.038141Z",
     "shell.execute_reply.started": "2022-06-18T13:14:53.008897Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_n_epoch</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35.335155</td>\n",
       "      <td>0 days 00:35:15.375066</td>\n",
       "      <td>200</td>\n",
       "      <td>0.007382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>44.302902</td>\n",
       "      <td>0 days 00:34:58.414487</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>24.699223</td>\n",
       "      <td>0 days 00:35:06.414250</td>\n",
       "      <td>200</td>\n",
       "      <td>0.015852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>42.867252</td>\n",
       "      <td>0 days 00:34:57.689213</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>41.684361</td>\n",
       "      <td>0 days 00:15:56.394683</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>44.646648</td>\n",
       "      <td>0 days 00:35:09.745846</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>41.492268</td>\n",
       "      <td>0 days 00:15:56.506590</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>41.077747</td>\n",
       "      <td>0 days 00:34:48.574028</td>\n",
       "      <td>200</td>\n",
       "      <td>0.002343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>44.211910</td>\n",
       "      <td>0 days 00:35:02.353758</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>38.236782</td>\n",
       "      <td>0 days 00:15:44.087744</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10.110201</td>\n",
       "      <td>0 days 00:35:10.911606</td>\n",
       "      <td>200</td>\n",
       "      <td>0.084512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>43.494087</td>\n",
       "      <td>0 days 00:35:07.986056</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number      value               duration  params_n_epoch  \\\n",
       "0        0  35.335155 0 days 00:35:15.375066             200   \n",
       "1        1  44.302902 0 days 00:34:58.414487             200   \n",
       "2        2  24.699223 0 days 00:35:06.414250             200   \n",
       "3        3  42.867252 0 days 00:34:57.689213             200   \n",
       "4        4  41.684361 0 days 00:15:56.394683              90   \n",
       "5        5  44.646648 0 days 00:35:09.745846             200   \n",
       "6        6  41.492268 0 days 00:15:56.506590              90   \n",
       "7        7  41.077747 0 days 00:34:48.574028             200   \n",
       "8        8  44.211910 0 days 00:35:02.353758             200   \n",
       "9        9  38.236782 0 days 00:15:44.087744              90   \n",
       "10      10  10.110201 0 days 00:35:10.911606             200   \n",
       "11      11  43.494087 0 days 00:35:07.986056             200   \n",
       "\n",
       "    params_weight_decay  \n",
       "0              0.007382  \n",
       "1              0.000257  \n",
       "2              0.015852  \n",
       "3              0.000022  \n",
       "4              0.000154  \n",
       "5              0.000288  \n",
       "6              0.000235  \n",
       "7              0.002343  \n",
       "8              0.000421  \n",
       "9              0.000979  \n",
       "10             0.084512  \n",
       "11             0.000036  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install optuna\n",
    "study = joblib.load('set_10_step_01.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caeb452c-7cf7-4db3-a9fb-a28a456bd0bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T13:43:22.005225Z",
     "iopub.status.busy": "2022-06-16T13:43:22.004866Z",
     "iopub.status.idle": "2022-06-16T16:05:54.034562Z",
     "shell.execute_reply": "2022-06-16T16:05:54.033298Z",
     "shell.execute_reply.started": "2022-06-16T13:43:22.005208Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 13:43:59,760]\u001b[0m A new study created in memory with name: no-name-2dc00495-a06a-42a2-996f-da507754b1c1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls num list(train_dataset):\n",
      "[4000, 3097, 2397, 1856, 1437, 1113, 861, 667, 516, 400]\n",
      "cls num list(val_dataset):\n",
      "[1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]\n",
      "Epoch: [001] \t Loss 2.5907 \t Acc 36.99 \t AccHead 47.26 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.6007 \t Acc 43.44 \t AccHead 55.50 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.4940 \t Acc 47.23 \t AccHead 60.36 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.4637 \t Acc 43.28 \t AccHead 52.61 \t AccTail 9.65\n",
      "Epoch: [005] \t Loss 1.4298 \t Acc 45.63 \t AccHead 57.01 \t AccTail 4.59\n",
      "Epoch: [006] \t Loss 1.3918 \t Acc 46.58 \t AccHead 55.32 \t AccTail 15.09\n",
      "Epoch: [007] \t Loss 1.3958 \t Acc 45.08 \t AccHead 55.94 \t AccTail 6.02\n",
      "Epoch: [008] \t Loss 1.3762 \t Acc 49.43 \t AccHead 58.98 \t AccTail 15.07\n",
      "Epoch: [009] \t Loss 1.3572 \t Acc 48.31 \t AccHead 59.56 \t AccTail 7.84\n",
      "Epoch: [010] \t Loss 1.3540 \t Acc 38.43 \t AccHead 47.56 \t AccTail 5.60\n",
      "Epoch: [011] \t Loss 1.3442 \t Acc 49.77 \t AccHead 59.18 \t AccTail 15.90\n",
      "Epoch: [012] \t Loss 1.3365 \t Acc 51.45 \t AccHead 57.20 \t AccTail 30.74\n",
      "Epoch: [013] \t Loss 1.3282 \t Acc 50.18 \t AccHead 59.64 \t AccTail 16.04\n",
      "Epoch: [014] \t Loss 1.3403 \t Acc 52.50 \t AccHead 60.94 \t AccTail 22.02\n",
      "Epoch: [015] \t Loss 1.3174 \t Acc 53.49 \t AccHead 60.06 \t AccTail 29.72\n",
      "Epoch: [016] \t Loss 1.3066 \t Acc 49.90 \t AccHead 60.03 \t AccTail 13.35\n",
      "Epoch: [017] \t Loss 1.3034 \t Acc 47.14 \t AccHead 58.70 \t AccTail 5.49\n",
      "Epoch: [018] \t Loss 1.3043 \t Acc 42.50 \t AccHead 49.61 \t AccTail 16.88\n",
      "Epoch: [019] \t Loss 1.3087 \t Acc 50.68 \t AccHead 61.39 \t AccTail 12.11\n",
      "Epoch: [020] \t Loss 1.3041 \t Acc 51.00 \t AccHead 61.56 \t AccTail 12.97\n",
      "Epoch: [021] \t Loss 1.3104 \t Acc 46.76 \t AccHead 58.39 \t AccTail 4.87\n",
      "Epoch: [022] \t Loss 1.2999 \t Acc 46.09 \t AccHead 53.27 \t AccTail 20.23\n",
      "Epoch: [023] \t Loss 1.3181 \t Acc 53.38 \t AccHead 62.90 \t AccTail 19.06\n",
      "Epoch: [024] \t Loss 1.3028 \t Acc 51.25 \t AccHead 56.17 \t AccTail 33.55\n",
      "Epoch: [025] \t Loss 1.3152 \t Acc 43.09 \t AccHead 49.40 \t AccTail 20.35\n",
      "Epoch: [026] \t Loss 1.2986 \t Acc 48.04 \t AccHead 51.36 \t AccTail 36.12\n",
      "Epoch: [027] \t Loss 1.3008 \t Acc 46.75 \t AccHead 55.90 \t AccTail 13.79\n",
      "Epoch: [028] \t Loss 1.3110 \t Acc 50.27 \t AccHead 59.15 \t AccTail 18.23\n",
      "Epoch: [029] \t Loss 1.3014 \t Acc 48.88 \t AccHead 58.79 \t AccTail 13.19\n",
      "Epoch: [030] \t Loss 1.3067 \t Acc 52.12 \t AccHead 61.40 \t AccTail 18.69\n",
      "Epoch: [031] \t Loss 1.2961 \t Acc 51.62 \t AccHead 60.39 \t AccTail 20.05\n",
      "Epoch: [032] \t Loss 1.2996 \t Acc 48.39 \t AccHead 56.35 \t AccTail 19.75\n",
      "Epoch: [033] \t Loss 1.2949 \t Acc 54.14 \t AccHead 63.14 \t AccTail 21.75\n",
      "Epoch: [034] \t Loss 1.2956 \t Acc 52.45 \t AccHead 62.00 \t AccTail 18.04\n",
      "Epoch: [035] \t Loss 1.3060 \t Acc 49.17 \t AccHead 60.48 \t AccTail 8.51\n",
      "Epoch: [036] \t Loss 1.3173 \t Acc 43.39 \t AccHead 48.33 \t AccTail 25.64\n",
      "Epoch: [037] \t Loss 1.2974 \t Acc 52.49 \t AccHead 60.50 \t AccTail 23.60\n",
      "Epoch: [038] \t Loss 1.2975 \t Acc 48.90 \t AccHead 56.05 \t AccTail 23.20\n",
      "Epoch: [039] \t Loss 1.3022 \t Acc 43.97 \t AccHead 47.01 \t AccTail 33.01\n",
      "Epoch: [040] \t Loss 1.3014 \t Acc 49.67 \t AccHead 55.28 \t AccTail 29.52\n",
      "Epoch: [041] \t Loss 1.3162 \t Acc 54.07 \t AccHead 65.89 \t AccTail 11.57\n",
      "Epoch: [042] \t Loss 1.2992 \t Acc 53.77 \t AccHead 65.43 \t AccTail 11.68\n",
      "Epoch: [043] \t Loss 1.3316 \t Acc 45.38 \t AccHead 49.91 \t AccTail 29.09\n",
      "Epoch: [044] \t Loss 1.3058 \t Acc 54.31 \t AccHead 64.80 \t AccTail 16.51\n",
      "Epoch: [045] \t Loss 1.2961 \t Acc 47.37 \t AccHead 54.75 \t AccTail 20.76\n",
      "Epoch: [046] \t Loss 1.3082 \t Acc 43.49 \t AccHead 47.92 \t AccTail 27.50\n",
      "Epoch: [047] \t Loss 1.3077 \t Acc 51.93 \t AccHead 58.47 \t AccTail 28.40\n",
      "Epoch: [048] \t Loss 1.3046 \t Acc 50.02 \t AccHead 58.87 \t AccTail 18.14\n",
      "Epoch: [049] \t Loss 1.3182 \t Acc 50.00 \t AccHead 61.76 \t AccTail 7.52\n",
      "Epoch: [050] \t Loss 1.3177 \t Acc 44.07 \t AccHead 50.97 \t AccTail 19.19\n",
      "Epoch: [051] \t Loss 1.2894 \t Acc 50.32 \t AccHead 57.66 \t AccTail 23.85\n",
      "Epoch: [052] \t Loss 1.3145 \t Acc 51.02 \t AccHead 61.29 \t AccTail 13.99\n",
      "Epoch: [053] \t Loss 1.2919 \t Acc 54.65 \t AccHead 66.07 \t AccTail 13.55\n",
      "Epoch: [054] \t Loss 1.3084 \t Acc 47.85 \t AccHead 52.46 \t AccTail 31.26\n",
      "Epoch: [055] \t Loss 1.3046 \t Acc 46.95 \t AccHead 55.08 \t AccTail 17.70\n",
      "Epoch: [056] \t Loss 1.3130 \t Acc 41.82 \t AccHead 50.17 \t AccTail 11.80\n",
      "Epoch: [057] \t Loss 1.3128 \t Acc 43.76 \t AccHead 46.22 \t AccTail 34.86\n",
      "Epoch: [058] \t Loss 1.3121 \t Acc 48.16 \t AccHead 55.82 \t AccTail 20.60\n",
      "Epoch: [059] \t Loss 1.3231 \t Acc 50.92 \t AccHead 61.37 \t AccTail 13.35\n",
      "Epoch: [060] \t Loss 1.3040 \t Acc 50.49 \t AccHead 54.76 \t AccTail 35.12\n",
      "Epoch: [061] \t Loss 1.3186 \t Acc 47.59 \t AccHead 59.85 \t AccTail 3.51\n",
      "Epoch: [062] \t Loss 1.3094 \t Acc 48.69 \t AccHead 60.32 \t AccTail 6.82\n",
      "Epoch: [063] \t Loss 1.3248 \t Acc 52.31 \t AccHead 62.89 \t AccTail 14.21\n",
      "Epoch: [064] \t Loss 1.3119 \t Acc 48.63 \t AccHead 59.63 \t AccTail 9.10\n",
      "Epoch: [065] \t Loss 1.3017 \t Acc 49.98 \t AccHead 59.66 \t AccTail 15.11\n",
      "Epoch: [066] \t Loss 1.3164 \t Acc 51.33 \t AccHead 61.47 \t AccTail 14.83\n",
      "Epoch: [067] \t Loss 1.2980 \t Acc 49.05 \t AccHead 52.90 \t AccTail 35.18\n",
      "Epoch: [068] \t Loss 1.3160 \t Acc 49.41 \t AccHead 60.24 \t AccTail 10.53\n",
      "Epoch: [069] \t Loss 1.3086 \t Acc 41.79 \t AccHead 47.19 \t AccTail 22.35\n",
      "Epoch: [070] \t Loss 1.3173 \t Acc 54.66 \t AccHead 62.15 \t AccTail 27.66\n",
      "Epoch: [071] \t Loss 1.3228 \t Acc 51.40 \t AccHead 62.43 \t AccTail 11.76\n",
      "Epoch: [072] \t Loss 1.3254 \t Acc 44.54 \t AccHead 49.49 \t AccTail 26.68\n",
      "Epoch: [073] \t Loss 1.3174 \t Acc 47.24 \t AccHead 58.09 \t AccTail 8.11\n",
      "Epoch: [074] \t Loss 1.3111 \t Acc 51.40 \t AccHead 60.83 \t AccTail 17.45\n",
      "Epoch: [075] \t Loss 1.3094 \t Acc 54.52 \t AccHead 62.60 \t AccTail 25.42\n",
      "Epoch: [076] \t Loss 1.3114 \t Acc 40.72 \t AccHead 50.11 \t AccTail 6.90\n",
      "Epoch: [077] \t Loss 1.3072 \t Acc 50.65 \t AccHead 56.39 \t AccTail 29.98\n",
      "Epoch: [078] \t Loss 1.3209 \t Acc 48.20 \t AccHead 58.77 \t AccTail 10.16\n",
      "Epoch: [079] \t Loss 1.3218 \t Acc 39.57 \t AccHead 46.91 \t AccTail 13.18\n",
      "Epoch: [080] \t Loss 1.3274 \t Acc 51.29 \t AccHead 59.91 \t AccTail 20.18\n",
      "Epoch: [081] \t Loss 1.3383 \t Acc 52.27 \t AccHead 58.88 \t AccTail 28.44\n",
      "Epoch: [082] \t Loss 1.3065 \t Acc 43.97 \t AccHead 51.34 \t AccTail 17.38\n",
      "Epoch: [083] \t Loss 1.3434 \t Acc 53.78 \t AccHead 62.38 \t AccTail 22.83\n",
      "Epoch: [084] \t Loss 1.3296 \t Acc 48.89 \t AccHead 60.32 \t AccTail 7.67\n",
      "Epoch: [085] \t Loss 1.3115 \t Acc 53.65 \t AccHead 62.45 \t AccTail 22.06\n",
      "Epoch: [086] \t Loss 1.3249 \t Acc 44.69 \t AccHead 52.88 \t AccTail 15.15\n",
      "Epoch: [087] \t Loss 1.3250 \t Acc 42.79 \t AccHead 51.91 \t AccTail 9.96\n",
      "Epoch: [088] \t Loss 1.3170 \t Acc 51.00 \t AccHead 55.45 \t AccTail 34.94\n",
      "Epoch: [089] \t Loss 1.3259 \t Acc 47.21 \t AccHead 56.63 \t AccTail 13.33\n",
      "Epoch: [090] \t Loss 1.3162 \t Acc 49.52 \t AccHead 59.22 \t AccTail 14.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 13:58:06,218]\u001b[0m Trial 0 finished with value: 31.87702178955078 and parameters: {'weight_decay': 0.0056017282604733}. Best is trial 0 with value: 31.87702178955078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 31.88 \t AccHead 49.50 \t AccTail 13.85\n",
      "Epoch: [001] \t Loss 2.4694 \t Acc 36.44 \t AccHead 46.58 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.6600 \t Acc 42.75 \t AccHead 54.61 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.5249 \t Acc 43.95 \t AccHead 55.71 \t AccTail 1.64\n",
      "Epoch: [004] \t Loss 1.4902 \t Acc 48.68 \t AccHead 60.75 \t AccTail 5.13\n",
      "Epoch: [005] \t Loss 1.4418 \t Acc 45.60 \t AccHead 51.68 \t AccTail 23.75\n",
      "Epoch: [006] \t Loss 1.4002 \t Acc 44.33 \t AccHead 50.19 \t AccTail 23.24\n",
      "Epoch: [007] \t Loss 1.3724 \t Acc 41.86 \t AccHead 50.66 \t AccTail 10.11\n",
      "Epoch: [008] \t Loss 1.3467 \t Acc 46.80 \t AccHead 53.34 \t AccTail 23.23\n",
      "Epoch: [009] \t Loss 1.3384 \t Acc 47.74 \t AccHead 56.19 \t AccTail 17.23\n",
      "Epoch: [010] \t Loss 1.3173 \t Acc 51.19 \t AccHead 59.88 \t AccTail 19.92\n",
      "Epoch: [011] \t Loss 1.2967 \t Acc 50.55 \t AccHead 56.01 \t AccTail 30.90\n",
      "Epoch: [012] \t Loss 1.2884 \t Acc 51.11 \t AccHead 59.81 \t AccTail 19.71\n",
      "Epoch: [013] \t Loss 1.3045 \t Acc 49.48 \t AccHead 60.04 \t AccTail 11.46\n",
      "Epoch: [014] \t Loss 1.3035 \t Acc 47.98 \t AccHead 52.53 \t AccTail 31.59\n",
      "Epoch: [015] \t Loss 1.2870 \t Acc 42.92 \t AccHead 44.70 \t AccTail 36.51\n",
      "Epoch: [016] \t Loss 1.2819 \t Acc 50.15 \t AccHead 59.41 \t AccTail 16.78\n",
      "Epoch: [017] \t Loss 1.2775 \t Acc 48.91 \t AccHead 53.60 \t AccTail 32.01\n",
      "Epoch: [018] \t Loss 1.2799 \t Acc 44.27 \t AccHead 50.72 \t AccTail 21.04\n",
      "Epoch: [019] \t Loss 1.2914 \t Acc 51.82 \t AccHead 62.02 \t AccTail 15.05\n",
      "Epoch: [020] \t Loss 1.2803 \t Acc 42.78 \t AccHead 51.40 \t AccTail 11.76\n",
      "Epoch: [021] \t Loss 1.2847 \t Acc 50.40 \t AccHead 62.64 \t AccTail 6.36\n",
      "Epoch: [022] \t Loss 1.2747 \t Acc 38.01 \t AccHead 48.29 \t AccTail 1.02\n",
      "Epoch: [023] \t Loss 1.2684 \t Acc 53.24 \t AccHead 63.78 \t AccTail 15.26\n",
      "Epoch: [024] \t Loss 1.2686 \t Acc 51.54 \t AccHead 58.24 \t AccTail 27.41\n",
      "Epoch: [025] \t Loss 1.2758 \t Acc 41.42 \t AccHead 49.03 \t AccTail 13.95\n",
      "Epoch: [026] \t Loss 1.2780 \t Acc 41.34 \t AccHead 47.78 \t AccTail 18.17\n",
      "Epoch: [027] \t Loss 1.2692 \t Acc 50.25 \t AccHead 59.80 \t AccTail 15.79\n",
      "Epoch: [028] \t Loss 1.2866 \t Acc 52.02 \t AccHead 61.02 \t AccTail 19.63\n",
      "Epoch: [029] \t Loss 1.2852 \t Acc 54.44 \t AccHead 63.21 \t AccTail 22.96\n",
      "Epoch: [030] \t Loss 1.2836 \t Acc 50.58 \t AccHead 60.87 \t AccTail 13.44\n",
      "Epoch: [031] \t Loss 1.2694 \t Acc 52.12 \t AccHead 60.06 \t AccTail 23.57\n",
      "Epoch: [032] \t Loss 1.2769 \t Acc 51.64 \t AccHead 58.73 \t AccTail 26.20\n",
      "Epoch: [033] \t Loss 1.2633 \t Acc 53.54 \t AccHead 64.98 \t AccTail 12.34\n",
      "Epoch: [034] \t Loss 1.2616 \t Acc 55.61 \t AccHead 65.59 \t AccTail 19.61\n",
      "Epoch: [035] \t Loss 1.2454 \t Acc 46.05 \t AccHead 54.05 \t AccTail 17.26\n",
      "Epoch: [036] \t Loss 1.2668 \t Acc 54.60 \t AccHead 63.11 \t AccTail 23.94\n",
      "Epoch: [037] \t Loss 1.2649 \t Acc 49.23 \t AccHead 56.70 \t AccTail 22.33\n",
      "Epoch: [038] \t Loss 1.2711 \t Acc 54.29 \t AccHead 63.26 \t AccTail 21.98\n",
      "Epoch: [039] \t Loss 1.2766 \t Acc 56.27 \t AccHead 66.33 \t AccTail 20.05\n",
      "Epoch: [040] \t Loss 1.2566 \t Acc 53.11 \t AccHead 58.91 \t AccTail 32.22\n",
      "Epoch: [041] \t Loss 1.2902 \t Acc 53.00 \t AccHead 62.11 \t AccTail 20.11\n",
      "Epoch: [042] \t Loss 1.2794 \t Acc 50.90 \t AccHead 62.74 \t AccTail 8.21\n",
      "Epoch: [043] \t Loss 1.2856 \t Acc 52.41 \t AccHead 59.84 \t AccTail 25.64\n",
      "Epoch: [044] \t Loss 1.2809 \t Acc 46.91 \t AccHead 54.55 \t AccTail 19.35\n",
      "Epoch: [045] \t Loss 1.2850 \t Acc 44.43 \t AccHead 51.06 \t AccTail 20.49\n",
      "Epoch: [046] \t Loss 1.2860 \t Acc 52.20 \t AccHead 61.18 \t AccTail 19.81\n",
      "Epoch: [047] \t Loss 1.2912 \t Acc 39.85 \t AccHead 43.26 \t AccTail 27.54\n",
      "Epoch: [048] \t Loss 1.2815 \t Acc 46.55 \t AccHead 50.30 \t AccTail 33.03\n",
      "Epoch: [049] \t Loss 1.2973 \t Acc 55.31 \t AccHead 65.58 \t AccTail 18.42\n",
      "Epoch: [050] \t Loss 1.2972 \t Acc 51.18 \t AccHead 61.68 \t AccTail 13.36\n",
      "Epoch: [051] \t Loss 1.2834 \t Acc 47.64 \t AccHead 56.39 \t AccTail 16.11\n",
      "Epoch: [052] \t Loss 1.2920 \t Acc 51.67 \t AccHead 56.66 \t AccTail 33.70\n",
      "Epoch: [053] \t Loss 1.2877 \t Acc 54.34 \t AccHead 61.11 \t AccTail 29.93\n",
      "Epoch: [054] \t Loss 1.2676 \t Acc 46.21 \t AccHead 56.65 \t AccTail 8.66\n",
      "Epoch: [055] \t Loss 1.2898 \t Acc 52.66 \t AccHead 62.06 \t AccTail 18.86\n",
      "Epoch: [056] \t Loss 1.2896 \t Acc 49.41 \t AccHead 56.33 \t AccTail 24.49\n",
      "Epoch: [057] \t Loss 1.2704 \t Acc 51.16 \t AccHead 61.38 \t AccTail 14.37\n",
      "Epoch: [058] \t Loss 1.2807 \t Acc 52.34 \t AccHead 62.00 \t AccTail 17.57\n",
      "Epoch: [059] \t Loss 1.2916 \t Acc 46.08 \t AccHead 52.96 \t AccTail 21.35\n",
      "Epoch: [060] \t Loss 1.2809 \t Acc 57.01 \t AccHead 67.40 \t AccTail 19.59\n",
      "Epoch: [061] \t Loss 1.2776 \t Acc 47.95 \t AccHead 53.35 \t AccTail 28.46\n",
      "Epoch: [062] \t Loss 1.2914 \t Acc 51.12 \t AccHead 59.59 \t AccTail 20.57\n",
      "Epoch: [063] \t Loss 1.2623 \t Acc 54.87 \t AccHead 66.51 \t AccTail 12.84\n",
      "Epoch: [064] \t Loss 1.2777 \t Acc 49.46 \t AccHead 59.00 \t AccTail 15.11\n",
      "Epoch: [065] \t Loss 1.2644 \t Acc 43.36 \t AccHead 49.37 \t AccTail 21.73\n",
      "Epoch: [066] \t Loss 1.3145 \t Acc 52.00 \t AccHead 60.16 \t AccTail 22.60\n",
      "Epoch: [067] \t Loss 1.2644 \t Acc 54.56 \t AccHead 61.26 \t AccTail 30.40\n",
      "Epoch: [068] \t Loss 1.2786 \t Acc 51.73 \t AccHead 62.10 \t AccTail 14.40\n",
      "Epoch: [069] \t Loss 1.2943 \t Acc 42.16 \t AccHead 47.32 \t AccTail 23.57\n",
      "Epoch: [070] \t Loss 1.2763 \t Acc 54.20 \t AccHead 61.50 \t AccTail 27.92\n",
      "Epoch: [071] \t Loss 1.2894 \t Acc 49.11 \t AccHead 57.46 \t AccTail 19.05\n",
      "Epoch: [072] \t Loss 1.2805 \t Acc 54.53 \t AccHead 64.29 \t AccTail 19.49\n",
      "Epoch: [073] \t Loss 1.2706 \t Acc 49.94 \t AccHead 56.63 \t AccTail 25.86\n",
      "Epoch: [074] \t Loss 1.2699 \t Acc 50.98 \t AccHead 60.78 \t AccTail 15.75\n",
      "Epoch: [075] \t Loss 1.2836 \t Acc 43.23 \t AccHead 50.76 \t AccTail 16.13\n",
      "Epoch: [076] \t Loss 1.2793 \t Acc 50.83 \t AccHead 62.46 \t AccTail 8.97\n",
      "Epoch: [077] \t Loss 1.2937 \t Acc 47.75 \t AccHead 56.92 \t AccTail 14.70\n",
      "Epoch: [078] \t Loss 1.3103 \t Acc 52.94 \t AccHead 61.68 \t AccTail 21.45\n",
      "Epoch: [079] \t Loss 1.2773 \t Acc 44.84 \t AccHead 50.62 \t AccTail 24.04\n",
      "Epoch: [080] \t Loss 1.2891 \t Acc 51.55 \t AccHead 60.55 \t AccTail 19.15\n",
      "Epoch: [081] \t Loss 1.2819 \t Acc 44.14 \t AccHead 55.49 \t AccTail 3.23\n",
      "Epoch: [082] \t Loss 1.2831 \t Acc 50.75 \t AccHead 60.20 \t AccTail 16.83\n",
      "Epoch: [083] \t Loss 1.2902 \t Acc 47.12 \t AccHead 58.26 \t AccTail 6.99\n",
      "Epoch: [084] \t Loss 1.2899 \t Acc 54.63 \t AccHead 63.85 \t AccTail 21.46\n",
      "Epoch: [085] \t Loss 1.2830 \t Acc 40.56 \t AccHead 50.04 \t AccTail 6.43\n",
      "Epoch: [086] \t Loss 1.2782 \t Acc 54.47 \t AccHead 62.73 \t AccTail 24.77\n",
      "Epoch: [087] \t Loss 1.2799 \t Acc 52.97 \t AccHead 62.66 \t AccTail 18.02\n",
      "Epoch: [088] \t Loss 1.2924 \t Acc 52.34 \t AccHead 59.05 \t AccTail 28.18\n",
      "Epoch: [089] \t Loss 1.2825 \t Acc 49.93 \t AccHead 60.20 \t AccTail 12.94\n",
      "Epoch: [090] \t Loss 1.2919 \t Acc 54.46 \t AccHead 64.25 \t AccTail 19.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 14:12:17,815]\u001b[0m Trial 1 finished with value: 39.98786163330078 and parameters: {'weight_decay': 0.004970988889117699}. Best is trial 1 with value: 39.98786163330078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 39.99 \t AccHead 58.02 \t AccTail 21.54\n",
      "Epoch: [001] \t Loss 2.5081 \t Acc 35.40 \t AccHead 45.23 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.8718 \t Acc 42.18 \t AccHead 53.90 \t AccTail 0.03\n",
      "Epoch: [003] \t Loss 1.6512 \t Acc 46.12 \t AccHead 57.86 \t AccTail 3.85\n",
      "Epoch: [004] \t Loss 1.5032 \t Acc 48.35 \t AccHead 60.58 \t AccTail 4.22\n",
      "Epoch: [005] \t Loss 1.4333 \t Acc 48.64 \t AccHead 58.99 \t AccTail 11.35\n",
      "Epoch: [006] \t Loss 1.3700 \t Acc 53.22 \t AccHead 62.73 \t AccTail 18.90\n",
      "Epoch: [007] \t Loss 1.3086 \t Acc 56.02 \t AccHead 62.95 \t AccTail 31.04\n",
      "Epoch: [008] \t Loss 1.2581 \t Acc 57.34 \t AccHead 67.12 \t AccTail 22.14\n",
      "Epoch: [009] \t Loss 1.2051 \t Acc 59.61 \t AccHead 67.15 \t AccTail 32.47\n",
      "Epoch: [010] \t Loss 1.1582 \t Acc 57.61 \t AccHead 62.56 \t AccTail 39.80\n",
      "Epoch: [011] \t Loss 1.1155 \t Acc 61.92 \t AccHead 70.23 \t AccTail 31.94\n",
      "Epoch: [012] \t Loss 1.0673 \t Acc 63.53 \t AccHead 70.05 \t AccTail 40.06\n",
      "Epoch: [013] \t Loss 1.0353 \t Acc 62.16 \t AccHead 67.91 \t AccTail 41.43\n",
      "Epoch: [014] \t Loss 1.0227 \t Acc 62.87 \t AccHead 72.69 \t AccTail 27.40\n",
      "Epoch: [015] \t Loss 0.9771 \t Acc 64.35 \t AccHead 71.28 \t AccTail 39.34\n",
      "Epoch: [016] \t Loss 0.9520 \t Acc 66.78 \t AccHead 74.10 \t AccTail 40.45\n",
      "Epoch: [017] \t Loss 0.9319 \t Acc 68.06 \t AccHead 74.37 \t AccTail 45.37\n",
      "Epoch: [018] \t Loss 0.9106 \t Acc 69.67 \t AccHead 77.31 \t AccTail 42.17\n",
      "Epoch: [019] \t Loss 0.9013 \t Acc 68.77 \t AccHead 74.50 \t AccTail 48.16\n",
      "Epoch: [020] \t Loss 0.8835 \t Acc 67.05 \t AccHead 72.67 \t AccTail 46.85\n",
      "Epoch: [021] \t Loss 0.8614 \t Acc 69.45 \t AccHead 73.33 \t AccTail 55.47\n",
      "Epoch: [022] \t Loss 0.8521 \t Acc 69.92 \t AccHead 75.10 \t AccTail 51.32\n",
      "Epoch: [023] \t Loss 0.8269 \t Acc 71.12 \t AccHead 77.42 \t AccTail 48.44\n",
      "Epoch: [024] \t Loss 0.8093 \t Acc 70.00 \t AccHead 78.08 \t AccTail 40.96\n",
      "Epoch: [025] \t Loss 0.8156 \t Acc 71.64 \t AccHead 78.52 \t AccTail 46.87\n",
      "Epoch: [026] \t Loss 0.7999 \t Acc 69.99 \t AccHead 72.97 \t AccTail 59.25\n",
      "Epoch: [027] \t Loss 0.7883 \t Acc 73.76 \t AccHead 78.17 \t AccTail 57.88\n",
      "Epoch: [028] \t Loss 0.7678 \t Acc 72.21 \t AccHead 78.15 \t AccTail 50.82\n",
      "Epoch: [029] \t Loss 0.7838 \t Acc 72.55 \t AccHead 77.18 \t AccTail 55.87\n",
      "Epoch: [030] \t Loss 0.7543 \t Acc 64.76 \t AccHead 72.35 \t AccTail 37.42\n",
      "Epoch: [031] \t Loss 0.7497 \t Acc 73.77 \t AccHead 78.96 \t AccTail 55.12\n",
      "Epoch: [032] \t Loss 0.7554 \t Acc 73.71 \t AccHead 81.25 \t AccTail 46.54\n",
      "Epoch: [033] \t Loss 0.7368 \t Acc 74.11 \t AccHead 76.53 \t AccTail 65.44\n",
      "Epoch: [034] \t Loss 0.7274 \t Acc 74.10 \t AccHead 76.38 \t AccTail 65.87\n",
      "Epoch: [035] \t Loss 0.7143 \t Acc 74.93 \t AccHead 78.15 \t AccTail 63.35\n",
      "Epoch: [036] \t Loss 0.7144 \t Acc 72.07 \t AccHead 75.70 \t AccTail 58.98\n",
      "Epoch: [037] \t Loss 0.7241 \t Acc 75.79 \t AccHead 80.84 \t AccTail 57.65\n",
      "Epoch: [038] \t Loss 0.7104 \t Acc 72.69 \t AccHead 80.13 \t AccTail 45.96\n",
      "Epoch: [039] \t Loss 0.7003 \t Acc 76.69 \t AccHead 80.66 \t AccTail 62.38\n",
      "Epoch: [040] \t Loss 0.6945 \t Acc 76.14 \t AccHead 81.88 \t AccTail 55.51\n",
      "Epoch: [041] \t Loss 0.6982 \t Acc 73.31 \t AccHead 80.10 \t AccTail 48.85\n",
      "Epoch: [042] \t Loss 0.6918 \t Acc 73.97 \t AccHead 80.20 \t AccTail 51.52\n",
      "Epoch: [043] \t Loss 0.6957 \t Acc 75.88 \t AccHead 81.14 \t AccTail 56.95\n",
      "Epoch: [044] \t Loss 0.6917 \t Acc 77.71 \t AccHead 80.60 \t AccTail 67.31\n",
      "Epoch: [045] \t Loss 0.6845 \t Acc 74.60 \t AccHead 79.15 \t AccTail 58.21\n",
      "Epoch: [046] \t Loss 0.6745 \t Acc 76.92 \t AccHead 83.35 \t AccTail 53.71\n",
      "Epoch: [047] \t Loss 0.6704 \t Acc 72.77 \t AccHead 78.65 \t AccTail 51.59\n",
      "Epoch: [048] \t Loss 0.6715 \t Acc 77.83 \t AccHead 80.26 \t AccTail 69.08\n",
      "Epoch: [049] \t Loss 0.6601 \t Acc 75.01 \t AccHead 81.74 \t AccTail 50.79\n",
      "Epoch: [050] \t Loss 0.6716 \t Acc 77.20 \t AccHead 81.08 \t AccTail 63.27\n",
      "Epoch: [051] \t Loss 0.6654 \t Acc 78.18 \t AccHead 81.86 \t AccTail 64.95\n",
      "Epoch: [052] \t Loss 0.6611 \t Acc 75.38 \t AccHead 79.58 \t AccTail 60.27\n",
      "Epoch: [053] \t Loss 0.6659 \t Acc 73.00 \t AccHead 79.35 \t AccTail 50.13\n",
      "Epoch: [054] \t Loss 0.6531 \t Acc 76.83 \t AccHead 78.42 \t AccTail 71.10\n",
      "Epoch: [055] \t Loss 0.6474 \t Acc 78.83 \t AccHead 83.44 \t AccTail 62.20\n",
      "Epoch: [056] \t Loss 0.6542 \t Acc 78.09 \t AccHead 81.94 \t AccTail 64.17\n",
      "Epoch: [057] \t Loss 0.6423 \t Acc 77.93 \t AccHead 80.13 \t AccTail 70.04\n",
      "Epoch: [058] \t Loss 0.6537 \t Acc 78.79 \t AccHead 84.48 \t AccTail 58.27\n",
      "Epoch: [059] \t Loss 0.6435 \t Acc 78.02 \t AccHead 81.09 \t AccTail 66.95\n",
      "Epoch: [060] \t Loss 0.6348 \t Acc 77.79 \t AccHead 81.42 \t AccTail 64.73\n",
      "Epoch: [061] \t Loss 0.6449 \t Acc 69.67 \t AccHead 72.83 \t AccTail 58.26\n",
      "Epoch: [062] \t Loss 0.6503 \t Acc 79.36 \t AccHead 84.20 \t AccTail 61.90\n",
      "Epoch: [063] \t Loss 0.6278 \t Acc 75.28 \t AccHead 80.49 \t AccTail 56.51\n",
      "Epoch: [064] \t Loss 0.6505 \t Acc 76.95 \t AccHead 81.35 \t AccTail 61.13\n",
      "Epoch: [065] \t Loss 0.6388 \t Acc 78.90 \t AccHead 84.57 \t AccTail 58.47\n",
      "Epoch: [066] \t Loss 0.6373 \t Acc 76.48 \t AccHead 81.71 \t AccTail 57.66\n",
      "Epoch: [067] \t Loss 0.6162 \t Acc 77.75 \t AccHead 81.16 \t AccTail 65.49\n",
      "Epoch: [068] \t Loss 0.6237 \t Acc 73.62 \t AccHead 75.57 \t AccTail 66.58\n",
      "Epoch: [069] \t Loss 0.6201 \t Acc 75.73 \t AccHead 82.66 \t AccTail 50.75\n",
      "Epoch: [070] \t Loss 0.6249 \t Acc 76.91 \t AccHead 80.86 \t AccTail 62.71\n",
      "Epoch: [071] \t Loss 0.6259 \t Acc 77.65 \t AccHead 82.86 \t AccTail 58.87\n",
      "Epoch: [072] \t Loss 0.6324 \t Acc 76.86 \t AccHead 79.02 \t AccTail 69.08\n",
      "Epoch: [073] \t Loss 0.6377 \t Acc 77.78 \t AccHead 80.94 \t AccTail 66.41\n",
      "Epoch: [074] \t Loss 0.6155 \t Acc 76.32 \t AccHead 82.18 \t AccTail 55.17\n",
      "Epoch: [075] \t Loss 0.6148 \t Acc 77.20 \t AccHead 80.00 \t AccTail 67.11\n",
      "Epoch: [076] \t Loss 0.6214 \t Acc 74.11 \t AccHead 79.60 \t AccTail 54.33\n",
      "Epoch: [077] \t Loss 0.6122 \t Acc 79.48 \t AccHead 83.16 \t AccTail 66.24\n",
      "Epoch: [078] \t Loss 0.6176 \t Acc 78.83 \t AccHead 83.25 \t AccTail 62.90\n",
      "Epoch: [079] \t Loss 0.6182 \t Acc 78.51 \t AccHead 80.98 \t AccTail 69.64\n",
      "Epoch: [080] \t Loss 0.6039 \t Acc 75.76 \t AccHead 80.50 \t AccTail 58.67\n",
      "Epoch: [081] \t Loss 0.6231 \t Acc 78.38 \t AccHead 83.17 \t AccTail 61.15\n",
      "Epoch: [082] \t Loss 0.6083 \t Acc 75.02 \t AccHead 77.41 \t AccTail 66.40\n",
      "Epoch: [083] \t Loss 0.6034 \t Acc 78.10 \t AccHead 81.11 \t AccTail 67.28\n",
      "Epoch: [084] \t Loss 0.6274 \t Acc 77.37 \t AccHead 81.97 \t AccTail 60.86\n",
      "Epoch: [085] \t Loss 0.6013 \t Acc 77.64 \t AccHead 82.11 \t AccTail 61.54\n",
      "Epoch: [086] \t Loss 0.6150 \t Acc 77.79 \t AccHead 79.30 \t AccTail 72.33\n",
      "Epoch: [087] \t Loss 0.5958 \t Acc 75.23 \t AccHead 83.14 \t AccTail 46.69\n",
      "Epoch: [088] \t Loss 0.6212 \t Acc 76.79 \t AccHead 80.76 \t AccTail 62.52\n",
      "Epoch: [089] \t Loss 0.5912 \t Acc 80.19 \t AccHead 83.96 \t AccTail 66.61\n",
      "Epoch: [090] \t Loss 0.6054 \t Acc 77.41 \t AccHead 80.80 \t AccTail 65.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 14:26:34,358]\u001b[0m Trial 2 finished with value: 64.19902801513672 and parameters: {'weight_decay': 0.000634057481051503}. Best is trial 2 with value: 64.19902801513672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 64.20 \t AccHead 71.84 \t AccTail 56.38\n",
      "Epoch: [001] \t Loss 2.5669 \t Acc 41.10 \t AccHead 52.52 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.6818 \t Acc 43.18 \t AccHead 55.17 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.5326 \t Acc 47.60 \t AccHead 60.41 \t AccTail 1.39\n",
      "Epoch: [004] \t Loss 1.4627 \t Acc 44.38 \t AccHead 54.39 \t AccTail 8.23\n",
      "Epoch: [005] \t Loss 1.4255 \t Acc 50.15 \t AccHead 58.89 \t AccTail 18.71\n",
      "Epoch: [006] \t Loss 1.3770 \t Acc 48.83 \t AccHead 57.87 \t AccTail 16.23\n",
      "Epoch: [007] \t Loss 1.3511 \t Acc 50.73 \t AccHead 60.52 \t AccTail 15.44\n",
      "Epoch: [008] \t Loss 1.3164 \t Acc 48.27 \t AccHead 56.12 \t AccTail 19.98\n",
      "Epoch: [009] \t Loss 1.2859 \t Acc 52.26 \t AccHead 61.40 \t AccTail 19.39\n",
      "Epoch: [010] \t Loss 1.2443 \t Acc 50.49 \t AccHead 59.56 \t AccTail 17.74\n",
      "Epoch: [011] \t Loss 1.2300 \t Acc 56.72 \t AccHead 67.90 \t AccTail 16.55\n",
      "Epoch: [012] \t Loss 1.2272 \t Acc 57.81 \t AccHead 65.30 \t AccTail 30.80\n",
      "Epoch: [013] \t Loss 1.2000 \t Acc 54.43 \t AccHead 63.75 \t AccTail 20.79\n",
      "Epoch: [014] \t Loss 1.2254 \t Acc 55.30 \t AccHead 62.37 \t AccTail 29.89\n",
      "Epoch: [015] \t Loss 1.1834 \t Acc 56.43 \t AccHead 65.33 \t AccTail 24.38\n",
      "Epoch: [016] \t Loss 1.1709 \t Acc 54.16 \t AccHead 61.97 \t AccTail 26.05\n",
      "Epoch: [017] \t Loss 1.1756 \t Acc 56.00 \t AccHead 60.81 \t AccTail 38.68\n",
      "Epoch: [018] \t Loss 1.1604 \t Acc 52.90 \t AccHead 63.72 \t AccTail 13.97\n",
      "Epoch: [019] \t Loss 1.1655 \t Acc 55.42 \t AccHead 67.32 \t AccTail 12.47\n",
      "Epoch: [020] \t Loss 1.1659 \t Acc 54.11 \t AccHead 62.30 \t AccTail 24.65\n",
      "Epoch: [021] \t Loss 1.1485 \t Acc 57.94 \t AccHead 62.72 \t AccTail 40.74\n",
      "Epoch: [022] \t Loss 1.1603 \t Acc 55.76 \t AccHead 61.26 \t AccTail 35.93\n",
      "Epoch: [023] \t Loss 1.1409 \t Acc 53.97 \t AccHead 61.90 \t AccTail 25.39\n",
      "Epoch: [024] \t Loss 1.1279 \t Acc 57.41 \t AccHead 66.96 \t AccTail 23.01\n",
      "Epoch: [025] \t Loss 1.1471 \t Acc 58.34 \t AccHead 63.13 \t AccTail 41.16\n",
      "Epoch: [026] \t Loss 1.1462 \t Acc 57.74 \t AccHead 66.58 \t AccTail 25.93\n",
      "Epoch: [027] \t Loss 1.1511 \t Acc 57.47 \t AccHead 69.12 \t AccTail 15.58\n",
      "Epoch: [028] \t Loss 1.1591 \t Acc 53.97 \t AccHead 60.23 \t AccTail 31.41\n",
      "Epoch: [029] \t Loss 1.1398 \t Acc 58.38 \t AccHead 64.95 \t AccTail 34.70\n",
      "Epoch: [030] \t Loss 1.1342 \t Acc 50.35 \t AccHead 58.86 \t AccTail 19.65\n",
      "Epoch: [031] \t Loss 1.1374 \t Acc 54.83 \t AccHead 63.30 \t AccTail 24.27\n",
      "Epoch: [032] \t Loss 1.1309 \t Acc 58.34 \t AccHead 64.72 \t AccTail 35.34\n",
      "Epoch: [033] \t Loss 1.1308 \t Acc 55.93 \t AccHead 62.85 \t AccTail 31.02\n",
      "Epoch: [034] \t Loss 1.1345 \t Acc 41.44 \t AccHead 41.45 \t AccTail 41.43\n",
      "Epoch: [035] \t Loss 1.1305 \t Acc 58.24 \t AccHead 63.87 \t AccTail 37.99\n",
      "Epoch: [036] \t Loss 1.1450 \t Acc 57.41 \t AccHead 66.78 \t AccTail 23.73\n",
      "Epoch: [037] \t Loss 1.1536 \t Acc 59.12 \t AccHead 67.59 \t AccTail 28.58\n",
      "Epoch: [038] \t Loss 1.1592 \t Acc 50.58 \t AccHead 56.23 \t AccTail 30.28\n",
      "Epoch: [039] \t Loss 1.1215 \t Acc 54.96 \t AccHead 60.66 \t AccTail 34.48\n",
      "Epoch: [040] \t Loss 1.1372 \t Acc 54.00 \t AccHead 61.85 \t AccTail 25.74\n",
      "Epoch: [041] \t Loss 1.1337 \t Acc 53.14 \t AccHead 61.73 \t AccTail 22.19\n",
      "Epoch: [042] \t Loss 1.1567 \t Acc 53.48 \t AccHead 61.72 \t AccTail 23.81\n",
      "Epoch: [043] \t Loss 1.1384 \t Acc 57.34 \t AccHead 66.80 \t AccTail 23.27\n",
      "Epoch: [044] \t Loss 1.1297 \t Acc 43.10 \t AccHead 52.47 \t AccTail 9.36\n",
      "Epoch: [045] \t Loss 1.1365 \t Acc 52.83 \t AccHead 59.09 \t AccTail 30.29\n",
      "Epoch: [046] \t Loss 1.1346 \t Acc 57.34 \t AccHead 68.29 \t AccTail 17.84\n",
      "Epoch: [047] \t Loss 1.1370 \t Acc 60.78 \t AccHead 69.18 \t AccTail 30.49\n",
      "Epoch: [048] \t Loss 1.1223 \t Acc 56.18 \t AccHead 64.77 \t AccTail 25.26\n",
      "Epoch: [049] \t Loss 1.1407 \t Acc 59.41 \t AccHead 66.43 \t AccTail 34.13\n",
      "Epoch: [050] \t Loss 1.1353 \t Acc 56.53 \t AccHead 62.76 \t AccTail 34.10\n",
      "Epoch: [051] \t Loss 1.1460 \t Acc 52.63 \t AccHead 56.28 \t AccTail 39.48\n",
      "Epoch: [052] \t Loss 1.1411 \t Acc 52.15 \t AccHead 58.97 \t AccTail 27.60\n",
      "Epoch: [053] \t Loss 1.1314 \t Acc 57.61 \t AccHead 65.42 \t AccTail 29.45\n",
      "Epoch: [054] \t Loss 1.1259 \t Acc 51.57 \t AccHead 64.90 \t AccTail 3.51\n",
      "Epoch: [055] \t Loss 1.1447 \t Acc 52.87 \t AccHead 57.82 \t AccTail 35.00\n",
      "Epoch: [056] \t Loss 1.1301 \t Acc 55.94 \t AccHead 63.36 \t AccTail 29.21\n",
      "Epoch: [057] \t Loss 1.1335 \t Acc 58.85 \t AccHead 65.83 \t AccTail 33.71\n",
      "Epoch: [058] \t Loss 1.1252 \t Acc 58.22 \t AccHead 63.95 \t AccTail 37.55\n",
      "Epoch: [059] \t Loss 1.1330 \t Acc 57.34 \t AccHead 63.15 \t AccTail 36.46\n",
      "Epoch: [060] \t Loss 1.1289 \t Acc 56.87 \t AccHead 65.24 \t AccTail 26.76\n",
      "Epoch: [061] \t Loss 1.1341 \t Acc 60.57 \t AccHead 67.30 \t AccTail 36.32\n",
      "Epoch: [062] \t Loss 1.1414 \t Acc 57.79 \t AccHead 63.96 \t AccTail 35.59\n",
      "Epoch: [063] \t Loss 1.1264 \t Acc 48.18 \t AccHead 49.76 \t AccTail 42.47\n",
      "Epoch: [064] \t Loss 1.1242 \t Acc 56.72 \t AccHead 63.20 \t AccTail 33.42\n",
      "Epoch: [065] \t Loss 1.1360 \t Acc 57.65 \t AccHead 63.76 \t AccTail 35.65\n",
      "Epoch: [066] \t Loss 1.1351 \t Acc 49.42 \t AccHead 57.89 \t AccTail 18.92\n",
      "Epoch: [067] \t Loss 1.1484 \t Acc 56.19 \t AccHead 62.23 \t AccTail 34.45\n",
      "Epoch: [068] \t Loss 1.1459 \t Acc 49.99 \t AccHead 58.44 \t AccTail 19.52\n",
      "Epoch: [069] \t Loss 1.1281 \t Acc 57.01 \t AccHead 64.53 \t AccTail 29.96\n",
      "Epoch: [070] \t Loss 1.1377 \t Acc 59.05 \t AccHead 68.08 \t AccTail 26.53\n",
      "Epoch: [071] \t Loss 1.1459 \t Acc 53.89 \t AccHead 59.98 \t AccTail 31.96\n",
      "Epoch: [072] \t Loss 1.1562 \t Acc 56.30 \t AccHead 65.27 \t AccTail 23.96\n",
      "Epoch: [073] \t Loss 1.1388 \t Acc 55.04 \t AccHead 62.56 \t AccTail 28.01\n",
      "Epoch: [074] \t Loss 1.1481 \t Acc 53.70 \t AccHead 65.39 \t AccTail 11.54\n",
      "Epoch: [075] \t Loss 1.1482 \t Acc 55.48 \t AccHead 62.28 \t AccTail 31.03\n",
      "Epoch: [076] \t Loss 1.1416 \t Acc 58.25 \t AccHead 68.59 \t AccTail 20.95\n",
      "Epoch: [077] \t Loss 1.1552 \t Acc 58.29 \t AccHead 68.15 \t AccTail 22.76\n",
      "Epoch: [078] \t Loss 1.1342 \t Acc 59.41 \t AccHead 64.91 \t AccTail 39.59\n",
      "Epoch: [079] \t Loss 1.1454 \t Acc 54.79 \t AccHead 56.79 \t AccTail 47.58\n",
      "Epoch: [080] \t Loss 1.1369 \t Acc 46.64 \t AccHead 56.34 \t AccTail 11.72\n",
      "Epoch: [081] \t Loss 1.1364 \t Acc 52.74 \t AccHead 61.31 \t AccTail 21.83\n",
      "Epoch: [082] \t Loss 1.1413 \t Acc 39.72 \t AccHead 48.02 \t AccTail 9.87\n",
      "Epoch: [083] \t Loss 1.1355 \t Acc 52.41 \t AccHead 62.27 \t AccTail 16.89\n",
      "Epoch: [084] \t Loss 1.1325 \t Acc 56.97 \t AccHead 65.82 \t AccTail 25.12\n",
      "Epoch: [085] \t Loss 1.1365 \t Acc 57.80 \t AccHead 64.27 \t AccTail 34.46\n",
      "Epoch: [086] \t Loss 1.1395 \t Acc 46.83 \t AccHead 52.24 \t AccTail 27.36\n",
      "Epoch: [087] \t Loss 1.1575 \t Acc 58.20 \t AccHead 63.67 \t AccTail 38.53\n",
      "Epoch: [088] \t Loss 1.1556 \t Acc 58.46 \t AccHead 63.87 \t AccTail 38.97\n",
      "Epoch: [089] \t Loss 1.1370 \t Acc 56.69 \t AccHead 69.34 \t AccTail 11.19\n",
      "Epoch: [090] \t Loss 1.1259 \t Acc 54.59 \t AccHead 61.47 \t AccTail 29.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 14:40:48,412]\u001b[0m Trial 3 finished with value: 43.11286163330078 and parameters: {'weight_decay': 0.003425702823021724}. Best is trial 2 with value: 64.19902801513672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 43.11 \t AccHead 56.82 \t AccTail 29.09\n",
      "Epoch: [001] \t Loss 2.4695 \t Acc 40.26 \t AccHead 51.42 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.6620 \t Acc 45.33 \t AccHead 57.76 \t AccTail 0.48\n",
      "Epoch: [003] \t Loss 1.5143 \t Acc 44.96 \t AccHead 54.76 \t AccTail 9.65\n",
      "Epoch: [004] \t Loss 1.4476 \t Acc 46.40 \t AccHead 57.68 \t AccTail 5.75\n",
      "Epoch: [005] \t Loss 1.3920 \t Acc 52.53 \t AccHead 60.29 \t AccTail 24.58\n",
      "Epoch: [006] \t Loss 1.3592 \t Acc 53.46 \t AccHead 64.55 \t AccTail 13.53\n",
      "Epoch: [007] \t Loss 1.2978 \t Acc 53.21 \t AccHead 59.94 \t AccTail 28.94\n",
      "Epoch: [008] \t Loss 1.2606 \t Acc 54.97 \t AccHead 65.58 \t AccTail 16.78\n",
      "Epoch: [009] \t Loss 1.2390 \t Acc 56.96 \t AccHead 65.56 \t AccTail 25.99\n",
      "Epoch: [010] \t Loss 1.1980 \t Acc 57.94 \t AccHead 66.92 \t AccTail 25.54\n",
      "Epoch: [011] \t Loss 1.1813 \t Acc 58.60 \t AccHead 65.58 \t AccTail 33.47\n",
      "Epoch: [012] \t Loss 1.1589 \t Acc 58.34 \t AccHead 67.08 \t AccTail 26.89\n",
      "Epoch: [013] \t Loss 1.1446 \t Acc 57.60 \t AccHead 62.26 \t AccTail 40.81\n",
      "Epoch: [014] \t Loss 1.1380 \t Acc 56.98 \t AccHead 62.57 \t AccTail 36.89\n",
      "Epoch: [015] \t Loss 1.1230 \t Acc 51.13 \t AccHead 61.20 \t AccTail 14.83\n",
      "Epoch: [016] \t Loss 1.1232 \t Acc 55.46 \t AccHead 64.94 \t AccTail 21.26\n",
      "Epoch: [017] \t Loss 1.0943 \t Acc 59.53 \t AccHead 64.83 \t AccTail 40.42\n",
      "Epoch: [018] \t Loss 1.1033 \t Acc 58.41 \t AccHead 65.28 \t AccTail 33.75\n",
      "Epoch: [019] \t Loss 1.1001 \t Acc 62.01 \t AccHead 70.43 \t AccTail 31.65\n",
      "Epoch: [020] \t Loss 1.0859 \t Acc 59.10 \t AccHead 66.95 \t AccTail 30.82\n",
      "Epoch: [021] \t Loss 1.0851 \t Acc 54.58 \t AccHead 59.29 \t AccTail 37.61\n",
      "Epoch: [022] \t Loss 1.0974 \t Acc 60.38 \t AccHead 67.78 \t AccTail 33.70\n",
      "Epoch: [023] \t Loss 1.0695 \t Acc 48.14 \t AccHead 55.21 \t AccTail 22.70\n",
      "Epoch: [024] \t Loss 1.0834 \t Acc 59.02 \t AccHead 62.80 \t AccTail 45.42\n",
      "Epoch: [025] \t Loss 1.0714 \t Acc 57.68 \t AccHead 64.04 \t AccTail 34.70\n",
      "Epoch: [026] \t Loss 1.0746 \t Acc 60.01 \t AccHead 69.10 \t AccTail 27.28\n",
      "Epoch: [027] \t Loss 1.0590 \t Acc 56.93 \t AccHead 61.63 \t AccTail 39.99\n",
      "Epoch: [028] \t Loss 1.0656 \t Acc 57.10 \t AccHead 62.19 \t AccTail 38.80\n",
      "Epoch: [029] \t Loss 1.0395 \t Acc 57.34 \t AccHead 64.06 \t AccTail 33.16\n",
      "Epoch: [030] \t Loss 1.0483 \t Acc 57.65 \t AccHead 66.20 \t AccTail 26.86\n",
      "Epoch: [031] \t Loss 1.0569 \t Acc 63.96 \t AccHead 74.52 \t AccTail 25.85\n",
      "Epoch: [032] \t Loss 1.0637 \t Acc 64.01 \t AccHead 72.38 \t AccTail 33.87\n",
      "Epoch: [033] \t Loss 1.0585 \t Acc 58.22 \t AccHead 64.11 \t AccTail 37.05\n",
      "Epoch: [034] \t Loss 1.0492 \t Acc 57.28 \t AccHead 65.16 \t AccTail 28.94\n",
      "Epoch: [035] \t Loss 1.0443 \t Acc 60.97 \t AccHead 67.90 \t AccTail 35.97\n",
      "Epoch: [036] \t Loss 1.0666 \t Acc 59.49 \t AccHead 63.11 \t AccTail 46.40\n",
      "Epoch: [037] \t Loss 1.0420 \t Acc 52.36 \t AccHead 58.34 \t AccTail 30.81\n",
      "Epoch: [038] \t Loss 1.0612 \t Acc 61.66 \t AccHead 68.93 \t AccTail 35.56\n",
      "Epoch: [039] \t Loss 1.0440 \t Acc 56.42 \t AccHead 66.71 \t AccTail 19.40\n",
      "Epoch: [040] \t Loss 1.0420 \t Acc 61.66 \t AccHead 67.94 \t AccTail 38.99\n",
      "Epoch: [041] \t Loss 1.0566 \t Acc 60.68 \t AccHead 67.80 \t AccTail 35.06\n",
      "Epoch: [042] \t Loss 1.0490 \t Acc 56.89 \t AccHead 56.81 \t AccTail 57.17\n",
      "Epoch: [043] \t Loss 1.0596 \t Acc 58.27 \t AccHead 64.20 \t AccTail 36.93\n",
      "Epoch: [044] \t Loss 1.0430 \t Acc 61.84 \t AccHead 66.61 \t AccTail 44.70\n",
      "Epoch: [045] \t Loss 1.0554 \t Acc 60.19 \t AccHead 67.35 \t AccTail 34.43\n",
      "Epoch: [046] \t Loss 1.0595 \t Acc 60.94 \t AccHead 72.65 \t AccTail 18.75\n",
      "Epoch: [047] \t Loss 1.0537 \t Acc 58.54 \t AccHead 67.10 \t AccTail 27.64\n",
      "Epoch: [048] \t Loss 1.0349 \t Acc 65.13 \t AccHead 74.23 \t AccTail 32.38\n",
      "Epoch: [049] \t Loss 1.0409 \t Acc 57.95 \t AccHead 63.33 \t AccTail 38.54\n",
      "Epoch: [050] \t Loss 1.0421 \t Acc 63.34 \t AccHead 70.11 \t AccTail 38.98\n",
      "Epoch: [051] \t Loss 1.0529 \t Acc 62.68 \t AccHead 71.95 \t AccTail 29.34\n",
      "Epoch: [052] \t Loss 1.0405 \t Acc 55.12 \t AccHead 63.64 \t AccTail 24.48\n",
      "Epoch: [053] \t Loss 1.0464 \t Acc 55.12 \t AccHead 64.36 \t AccTail 21.73\n",
      "Epoch: [054] \t Loss 1.0606 \t Acc 53.15 \t AccHead 61.81 \t AccTail 21.89\n",
      "Epoch: [055] \t Loss 1.0566 \t Acc 60.75 \t AccHead 67.72 \t AccTail 35.67\n",
      "Epoch: [056] \t Loss 1.0490 \t Acc 58.22 \t AccHead 66.99 \t AccTail 26.58\n",
      "Epoch: [057] \t Loss 1.0456 \t Acc 56.30 \t AccHead 64.07 \t AccTail 28.29\n",
      "Epoch: [058] \t Loss 1.0440 \t Acc 62.77 \t AccHead 68.94 \t AccTail 40.52\n",
      "Epoch: [059] \t Loss 1.0302 \t Acc 58.57 \t AccHead 63.48 \t AccTail 40.90\n",
      "Epoch: [060] \t Loss 1.0476 \t Acc 63.77 \t AccHead 71.59 \t AccTail 35.63\n",
      "Epoch: [061] \t Loss 1.0557 \t Acc 60.28 \t AccHead 69.34 \t AccTail 27.65\n",
      "Epoch: [062] \t Loss 1.0424 \t Acc 58.52 \t AccHead 61.80 \t AccTail 46.72\n",
      "Epoch: [063] \t Loss 1.0550 \t Acc 58.74 \t AccHead 66.12 \t AccTail 32.18\n",
      "Epoch: [064] \t Loss 1.0511 \t Acc 61.29 \t AccHead 67.61 \t AccTail 38.52\n",
      "Epoch: [065] \t Loss 1.0298 \t Acc 61.97 \t AccHead 71.38 \t AccTail 28.15\n",
      "Epoch: [066] \t Loss 1.0439 \t Acc 59.58 \t AccHead 64.45 \t AccTail 42.05\n",
      "Epoch: [067] \t Loss 1.0351 \t Acc 59.20 \t AccHead 67.48 \t AccTail 29.38\n",
      "Epoch: [068] \t Loss 1.0327 \t Acc 48.28 \t AccHead 56.83 \t AccTail 17.50\n",
      "Epoch: [069] \t Loss 1.0551 \t Acc 58.77 \t AccHead 65.47 \t AccTail 34.63\n",
      "Epoch: [070] \t Loss 1.0372 \t Acc 58.53 \t AccHead 64.35 \t AccTail 37.61\n",
      "Epoch: [071] \t Loss 1.0400 \t Acc 54.36 \t AccHead 56.22 \t AccTail 47.61\n",
      "Epoch: [072] \t Loss 1.0427 \t Acc 64.34 \t AccHead 72.83 \t AccTail 33.82\n",
      "Epoch: [073] \t Loss 1.0383 \t Acc 55.13 \t AccHead 65.72 \t AccTail 17.07\n",
      "Epoch: [074] \t Loss 1.0355 \t Acc 64.10 \t AccHead 72.23 \t AccTail 34.79\n",
      "Epoch: [075] \t Loss 1.0323 \t Acc 48.60 \t AccHead 56.82 \t AccTail 18.96\n",
      "Epoch: [076] \t Loss 1.0501 \t Acc 57.67 \t AccHead 67.95 \t AccTail 20.51\n",
      "Epoch: [077] \t Loss 1.0546 \t Acc 53.54 \t AccHead 58.27 \t AccTail 36.51\n",
      "Epoch: [078] \t Loss 1.0265 \t Acc 55.86 \t AccHead 64.99 \t AccTail 22.94\n",
      "Epoch: [079] \t Loss 1.0406 \t Acc 59.05 \t AccHead 66.69 \t AccTail 31.49\n",
      "Epoch: [080] \t Loss 1.0413 \t Acc 56.71 \t AccHead 65.69 \t AccTail 24.36\n",
      "Epoch: [081] \t Loss 1.0355 \t Acc 58.54 \t AccHead 62.61 \t AccTail 43.94\n",
      "Epoch: [082] \t Loss 1.0468 \t Acc 46.07 \t AccHead 54.73 \t AccTail 14.84\n",
      "Epoch: [083] \t Loss 1.0377 \t Acc 59.98 \t AccHead 65.99 \t AccTail 38.31\n",
      "Epoch: [084] \t Loss 1.0273 \t Acc 58.13 \t AccHead 65.51 \t AccTail 31.56\n",
      "Epoch: [085] \t Loss 1.0479 \t Acc 58.13 \t AccHead 68.75 \t AccTail 19.77\n",
      "Epoch: [086] \t Loss 1.0473 \t Acc 62.08 \t AccHead 70.03 \t AccTail 33.46\n",
      "Epoch: [087] \t Loss 1.0587 \t Acc 64.13 \t AccHead 71.23 \t AccTail 38.59\n",
      "Epoch: [088] \t Loss 1.0333 \t Acc 59.96 \t AccHead 65.59 \t AccTail 39.68\n",
      "Epoch: [089] \t Loss 1.0369 \t Acc 59.25 \t AccHead 65.83 \t AccTail 35.47\n",
      "Epoch: [090] \t Loss 1.0551 \t Acc 63.18 \t AccHead 67.48 \t AccTail 47.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 14:55:05,955]\u001b[0m Trial 4 finished with value: 52.740692138671875 and parameters: {'weight_decay': 0.002611693908520877}. Best is trial 2 with value: 64.19902801513672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 52.74 \t AccHead 63.20 \t AccTail 42.04\n",
      "Epoch: [001] \t Loss 2.3251 \t Acc 32.37 \t AccHead 41.34 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.6009 \t Acc 44.72 \t AccHead 57.03 \t AccTail 0.31\n",
      "Epoch: [003] \t Loss 1.4756 \t Acc 38.48 \t AccHead 46.15 \t AccTail 10.88\n",
      "Epoch: [004] \t Loss 1.4152 \t Acc 48.99 \t AccHead 59.95 \t AccTail 9.58\n",
      "Epoch: [005] \t Loss 1.3728 \t Acc 50.09 \t AccHead 59.50 \t AccTail 16.15\n",
      "Epoch: [006] \t Loss 1.3433 \t Acc 49.24 \t AccHead 53.30 \t AccTail 34.60\n",
      "Epoch: [007] \t Loss 1.3186 \t Acc 51.30 \t AccHead 57.86 \t AccTail 27.64\n",
      "Epoch: [008] \t Loss 1.2998 \t Acc 51.18 \t AccHead 59.16 \t AccTail 22.48\n",
      "Epoch: [009] \t Loss 1.2642 \t Acc 50.36 \t AccHead 58.02 \t AccTail 22.79\n",
      "Epoch: [010] \t Loss 1.2605 \t Acc 58.56 \t AccHead 69.09 \t AccTail 20.73\n",
      "Epoch: [011] \t Loss 1.2396 \t Acc 53.55 \t AccHead 60.83 \t AccTail 27.35\n",
      "Epoch: [012] \t Loss 1.2440 \t Acc 57.12 \t AccHead 65.82 \t AccTail 25.85\n",
      "Epoch: [013] \t Loss 1.2407 \t Acc 53.24 \t AccHead 63.99 \t AccTail 14.48\n",
      "Epoch: [014] \t Loss 1.2213 \t Acc 54.20 \t AccHead 61.14 \t AccTail 29.22\n",
      "Epoch: [015] \t Loss 1.2408 \t Acc 45.30 \t AccHead 52.46 \t AccTail 19.47\n",
      "Epoch: [016] \t Loss 1.2192 \t Acc 44.54 \t AccHead 53.96 \t AccTail 10.57\n",
      "Epoch: [017] \t Loss 1.2147 \t Acc 58.85 \t AccHead 68.41 \t AccTail 24.43\n",
      "Epoch: [018] \t Loss 1.2115 \t Acc 58.10 \t AccHead 62.97 \t AccTail 40.54\n",
      "Epoch: [019] \t Loss 1.2043 \t Acc 44.75 \t AccHead 53.49 \t AccTail 13.32\n",
      "Epoch: [020] \t Loss 1.2060 \t Acc 47.08 \t AccHead 55.93 \t AccTail 15.27\n",
      "Epoch: [021] \t Loss 1.2148 \t Acc 53.33 \t AccHead 60.65 \t AccTail 26.95\n",
      "Epoch: [022] \t Loss 1.2158 \t Acc 54.32 \t AccHead 62.95 \t AccTail 23.28\n",
      "Epoch: [023] \t Loss 1.2175 \t Acc 51.24 \t AccHead 57.66 \t AccTail 28.05\n",
      "Epoch: [024] \t Loss 1.2223 \t Acc 54.45 \t AccHead 62.48 \t AccTail 25.54\n",
      "Epoch: [025] \t Loss 1.2238 \t Acc 53.11 \t AccHead 60.62 \t AccTail 26.03\n",
      "Epoch: [026] \t Loss 1.2165 \t Acc 49.32 \t AccHead 57.96 \t AccTail 18.18\n",
      "Epoch: [027] \t Loss 1.2142 \t Acc 53.75 \t AccHead 62.20 \t AccTail 23.33\n",
      "Epoch: [028] \t Loss 1.2062 \t Acc 53.24 \t AccHead 61.30 \t AccTail 24.24\n",
      "Epoch: [029] \t Loss 1.2054 \t Acc 56.94 \t AccHead 66.82 \t AccTail 21.46\n",
      "Epoch: [030] \t Loss 1.2226 \t Acc 56.46 \t AccHead 64.09 \t AccTail 29.01\n",
      "Epoch: [031] \t Loss 1.2248 \t Acc 55.43 \t AccHead 64.24 \t AccTail 23.67\n",
      "Epoch: [032] \t Loss 1.1956 \t Acc 53.70 \t AccHead 63.27 \t AccTail 19.28\n",
      "Epoch: [033] \t Loss 1.2174 \t Acc 54.88 \t AccHead 64.01 \t AccTail 22.01\n",
      "Epoch: [034] \t Loss 1.2006 \t Acc 49.25 \t AccHead 56.23 \t AccTail 24.15\n",
      "Epoch: [035] \t Loss 1.2134 \t Acc 50.52 \t AccHead 58.10 \t AccTail 23.22\n",
      "Epoch: [036] \t Loss 1.2094 \t Acc 57.23 \t AccHead 67.03 \t AccTail 21.92\n",
      "Epoch: [037] \t Loss 1.2059 \t Acc 51.23 \t AccHead 58.91 \t AccTail 23.54\n",
      "Epoch: [038] \t Loss 1.2075 \t Acc 46.17 \t AccHead 51.56 \t AccTail 26.72\n",
      "Epoch: [039] \t Loss 1.2138 \t Acc 57.46 \t AccHead 65.74 \t AccTail 27.57\n",
      "Epoch: [040] \t Loss 1.1862 \t Acc 48.19 \t AccHead 54.47 \t AccTail 25.61\n",
      "Epoch: [041] \t Loss 1.2247 \t Acc 54.47 \t AccHead 65.95 \t AccTail 13.03\n",
      "Epoch: [042] \t Loss 1.2058 \t Acc 52.76 \t AccHead 61.16 \t AccTail 22.50\n",
      "Epoch: [043] \t Loss 1.2155 \t Acc 52.80 \t AccHead 60.00 \t AccTail 26.89\n",
      "Epoch: [044] \t Loss 1.2013 \t Acc 47.39 \t AccHead 49.97 \t AccTail 38.12\n",
      "Epoch: [045] \t Loss 1.2007 \t Acc 49.29 \t AccHead 56.87 \t AccTail 21.98\n",
      "Epoch: [046] \t Loss 1.2232 \t Acc 48.83 \t AccHead 57.67 \t AccTail 16.92\n",
      "Epoch: [047] \t Loss 1.2414 \t Acc 55.26 \t AccHead 64.77 \t AccTail 21.02\n",
      "Epoch: [048] \t Loss 1.2284 \t Acc 51.73 \t AccHead 57.13 \t AccTail 32.31\n",
      "Epoch: [049] \t Loss 1.2258 \t Acc 50.52 \t AccHead 57.86 \t AccTail 24.13\n",
      "Epoch: [050] \t Loss 1.2189 \t Acc 55.08 \t AccHead 61.07 \t AccTail 33.49\n",
      "Epoch: [051] \t Loss 1.2262 \t Acc 43.06 \t AccHead 45.97 \t AccTail 32.55\n",
      "Epoch: [052] \t Loss 1.2287 \t Acc 52.89 \t AccHead 61.33 \t AccTail 22.41\n",
      "Epoch: [053] \t Loss 1.2212 \t Acc 53.01 \t AccHead 61.98 \t AccTail 20.69\n",
      "Epoch: [054] \t Loss 1.2249 \t Acc 52.57 \t AccHead 61.09 \t AccTail 21.90\n",
      "Epoch: [055] \t Loss 1.2385 \t Acc 52.84 \t AccHead 61.85 \t AccTail 20.40\n",
      "Epoch: [056] \t Loss 1.2279 \t Acc 56.59 \t AccHead 64.08 \t AccTail 29.68\n",
      "Epoch: [057] \t Loss 1.2041 \t Acc 53.48 \t AccHead 59.61 \t AccTail 31.44\n",
      "Epoch: [058] \t Loss 1.2006 \t Acc 43.29 \t AccHead 49.03 \t AccTail 22.62\n",
      "Epoch: [059] \t Loss 1.2182 \t Acc 57.96 \t AccHead 66.56 \t AccTail 26.99\n",
      "Epoch: [060] \t Loss 1.2179 \t Acc 43.10 \t AccHead 48.10 \t AccTail 25.06\n",
      "Epoch: [061] \t Loss 1.2111 \t Acc 44.82 \t AccHead 51.72 \t AccTail 19.98\n",
      "Epoch: [062] \t Loss 1.2118 \t Acc 52.95 \t AccHead 64.71 \t AccTail 10.59\n",
      "Epoch: [063] \t Loss 1.2255 \t Acc 54.71 \t AccHead 63.47 \t AccTail 23.12\n",
      "Epoch: [064] \t Loss 1.2090 \t Acc 54.44 \t AccHead 61.71 \t AccTail 28.23\n",
      "Epoch: [065] \t Loss 1.2122 \t Acc 46.44 \t AccHead 53.97 \t AccTail 19.35\n",
      "Epoch: [066] \t Loss 1.2281 \t Acc 53.89 \t AccHead 56.80 \t AccTail 43.44\n",
      "Epoch: [067] \t Loss 1.2111 \t Acc 49.38 \t AccHead 57.99 \t AccTail 18.34\n",
      "Epoch: [068] \t Loss 1.2110 \t Acc 54.15 \t AccHead 64.73 \t AccTail 16.02\n",
      "Epoch: [069] \t Loss 1.2379 \t Acc 52.18 \t AccHead 63.73 \t AccTail 10.54\n",
      "Epoch: [070] \t Loss 1.2091 \t Acc 49.14 \t AccHead 57.59 \t AccTail 18.73\n",
      "Epoch: [071] \t Loss 1.2164 \t Acc 51.08 \t AccHead 59.06 \t AccTail 22.34\n",
      "Epoch: [072] \t Loss 1.2193 \t Acc 51.59 \t AccHead 59.93 \t AccTail 21.64\n",
      "Epoch: [073] \t Loss 1.2164 \t Acc 50.29 \t AccHead 57.58 \t AccTail 24.05\n",
      "Epoch: [074] \t Loss 1.2286 \t Acc 52.81 \t AccHead 61.72 \t AccTail 20.72\n",
      "Epoch: [075] \t Loss 1.2236 \t Acc 50.55 \t AccHead 61.05 \t AccTail 12.67\n",
      "Epoch: [076] \t Loss 1.2468 \t Acc 55.00 \t AccHead 63.54 \t AccTail 24.28\n",
      "Epoch: [077] \t Loss 1.2289 \t Acc 52.58 \t AccHead 61.18 \t AccTail 21.59\n",
      "Epoch: [078] \t Loss 1.2346 \t Acc 45.83 \t AccHead 56.01 \t AccTail 9.08\n",
      "Epoch: [079] \t Loss 1.2168 \t Acc 47.93 \t AccHead 57.02 \t AccTail 15.11\n",
      "Epoch: [080] \t Loss 1.2453 \t Acc 45.36 \t AccHead 51.20 \t AccTail 24.32\n",
      "Epoch: [081] \t Loss 1.2295 \t Acc 55.00 \t AccHead 63.69 \t AccTail 23.73\n",
      "Epoch: [082] \t Loss 1.2240 \t Acc 53.41 \t AccHead 62.00 \t AccTail 22.55\n",
      "Epoch: [083] \t Loss 1.2258 \t Acc 49.98 \t AccHead 61.02 \t AccTail 10.24\n",
      "Epoch: [084] \t Loss 1.2097 \t Acc 54.34 \t AccHead 61.02 \t AccTail 30.32\n",
      "Epoch: [085] \t Loss 1.2243 \t Acc 53.65 \t AccHead 65.34 \t AccTail 11.55\n",
      "Epoch: [086] \t Loss 1.2332 \t Acc 52.79 \t AccHead 62.93 \t AccTail 16.26\n",
      "Epoch: [087] \t Loss 1.2264 \t Acc 54.44 \t AccHead 63.94 \t AccTail 20.25\n",
      "Epoch: [088] \t Loss 1.2135 \t Acc 51.76 \t AccHead 57.20 \t AccTail 32.19\n",
      "Epoch: [089] \t Loss 1.2382 \t Acc 51.37 \t AccHead 60.08 \t AccTail 20.00\n",
      "Epoch: [090] \t Loss 1.2105 \t Acc 49.10 \t AccHead 54.62 \t AccTail 29.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 15:09:22,757]\u001b[0m Trial 5 finished with value: 38.72370529174805 and parameters: {'weight_decay': 0.004206910685021199}. Best is trial 2 with value: 64.19902801513672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 38.72 \t AccHead 48.16 \t AccTail 29.07\n",
      "Epoch: [001] \t Loss 2.3342 \t Acc 41.22 \t AccHead 52.66 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.6246 \t Acc 43.83 \t AccHead 54.83 \t AccTail 4.11\n",
      "Epoch: [003] \t Loss 1.5052 \t Acc 47.48 \t AccHead 58.03 \t AccTail 9.48\n",
      "Epoch: [004] \t Loss 1.4183 \t Acc 49.49 \t AccHead 57.42 \t AccTail 20.95\n",
      "Epoch: [005] \t Loss 1.3693 \t Acc 50.52 \t AccHead 59.30 \t AccTail 18.95\n",
      "Epoch: [006] \t Loss 1.3115 \t Acc 53.97 \t AccHead 64.73 \t AccTail 15.20\n",
      "Epoch: [007] \t Loss 1.2601 \t Acc 55.89 \t AccHead 66.59 \t AccTail 17.37\n",
      "Epoch: [008] \t Loss 1.2174 \t Acc 53.76 \t AccHead 64.17 \t AccTail 16.27\n",
      "Epoch: [009] \t Loss 1.1821 \t Acc 58.79 \t AccHead 66.55 \t AccTail 30.78\n",
      "Epoch: [010] \t Loss 1.1450 \t Acc 55.41 \t AccHead 64.66 \t AccTail 22.17\n",
      "Epoch: [011] \t Loss 1.1282 \t Acc 60.57 \t AccHead 69.04 \t AccTail 30.10\n",
      "Epoch: [012] \t Loss 1.1122 \t Acc 51.12 \t AccHead 58.16 \t AccTail 25.82\n",
      "Epoch: [013] \t Loss 1.0936 \t Acc 61.29 \t AccHead 69.88 \t AccTail 30.32\n",
      "Epoch: [014] \t Loss 1.0855 \t Acc 59.41 \t AccHead 64.88 \t AccTail 39.75\n",
      "Epoch: [015] \t Loss 1.0572 \t Acc 56.69 \t AccHead 65.90 \t AccTail 23.51\n",
      "Epoch: [016] \t Loss 1.0603 \t Acc 50.20 \t AccHead 60.28 \t AccTail 13.90\n",
      "Epoch: [017] \t Loss 1.0629 \t Acc 59.53 \t AccHead 64.05 \t AccTail 43.29\n",
      "Epoch: [018] \t Loss 1.0364 \t Acc 61.99 \t AccHead 68.68 \t AccTail 37.89\n",
      "Epoch: [019] \t Loss 1.0448 \t Acc 61.71 \t AccHead 72.06 \t AccTail 24.55\n",
      "Epoch: [020] \t Loss 1.0393 \t Acc 54.20 \t AccHead 61.43 \t AccTail 28.07\n",
      "Epoch: [021] \t Loss 1.0124 \t Acc 60.28 \t AccHead 66.12 \t AccTail 39.22\n",
      "Epoch: [022] \t Loss 1.0341 \t Acc 58.40 \t AccHead 65.74 \t AccTail 31.94\n",
      "Epoch: [023] \t Loss 1.0181 \t Acc 49.38 \t AccHead 50.07 \t AccTail 46.89\n",
      "Epoch: [024] \t Loss 1.0131 \t Acc 63.99 \t AccHead 73.06 \t AccTail 31.24\n",
      "Epoch: [025] \t Loss 1.0070 \t Acc 59.87 \t AccHead 69.52 \t AccTail 25.13\n",
      "Epoch: [026] \t Loss 1.0085 \t Acc 53.89 \t AccHead 65.90 \t AccTail 10.59\n",
      "Epoch: [027] \t Loss 1.0142 \t Acc 60.67 \t AccHead 66.24 \t AccTail 40.64\n",
      "Epoch: [028] \t Loss 1.0055 \t Acc 62.23 \t AccHead 68.27 \t AccTail 40.50\n",
      "Epoch: [029] \t Loss 1.0093 \t Acc 63.26 \t AccHead 69.38 \t AccTail 41.23\n",
      "Epoch: [030] \t Loss 0.9920 \t Acc 64.56 \t AccHead 72.35 \t AccTail 36.49\n",
      "Epoch: [031] \t Loss 0.9973 \t Acc 63.11 \t AccHead 66.20 \t AccTail 51.96\n",
      "Epoch: [032] \t Loss 0.9957 \t Acc 66.10 \t AccHead 75.15 \t AccTail 33.48\n",
      "Epoch: [033] \t Loss 0.9828 \t Acc 65.93 \t AccHead 73.12 \t AccTail 40.02\n",
      "Epoch: [034] \t Loss 0.9838 \t Acc 63.56 \t AccHead 68.35 \t AccTail 46.34\n",
      "Epoch: [035] \t Loss 0.9878 \t Acc 60.62 \t AccHead 70.17 \t AccTail 26.28\n",
      "Epoch: [036] \t Loss 0.9891 \t Acc 59.97 \t AccHead 63.34 \t AccTail 47.85\n",
      "Epoch: [037] \t Loss 0.9773 \t Acc 58.08 \t AccHead 64.70 \t AccTail 34.24\n",
      "Epoch: [038] \t Loss 0.9923 \t Acc 51.90 \t AccHead 54.44 \t AccTail 42.77\n",
      "Epoch: [039] \t Loss 0.9700 \t Acc 65.29 \t AccHead 71.24 \t AccTail 43.88\n",
      "Epoch: [040] \t Loss 0.9849 \t Acc 59.50 \t AccHead 64.90 \t AccTail 40.07\n",
      "Epoch: [041] \t Loss 0.9954 \t Acc 63.24 \t AccHead 71.11 \t AccTail 34.91\n",
      "Epoch: [042] \t Loss 0.9701 \t Acc 62.32 \t AccHead 70.46 \t AccTail 32.99\n",
      "Epoch: [043] \t Loss 0.9805 \t Acc 54.96 \t AccHead 64.81 \t AccTail 19.52\n",
      "Epoch: [044] \t Loss 0.9755 \t Acc 64.67 \t AccHead 67.36 \t AccTail 54.96\n",
      "Epoch: [045] \t Loss 0.9768 \t Acc 63.75 \t AccHead 72.39 \t AccTail 32.58\n",
      "Epoch: [046] \t Loss 0.9817 \t Acc 56.18 \t AccHead 63.02 \t AccTail 31.48\n",
      "Epoch: [047] \t Loss 0.9812 \t Acc 64.14 \t AccHead 69.23 \t AccTail 45.80\n",
      "Epoch: [048] \t Loss 0.9728 \t Acc 65.87 \t AccHead 73.23 \t AccTail 39.33\n",
      "Epoch: [049] \t Loss 0.9803 \t Acc 61.48 \t AccHead 67.11 \t AccTail 41.19\n",
      "Epoch: [050] \t Loss 0.9638 \t Acc 59.14 \t AccHead 69.03 \t AccTail 23.50\n",
      "Epoch: [051] \t Loss 0.9769 \t Acc 60.65 \t AccHead 69.01 \t AccTail 30.53\n",
      "Epoch: [052] \t Loss 0.9699 \t Acc 64.65 \t AccHead 71.20 \t AccTail 41.01\n",
      "Epoch: [053] \t Loss 0.9606 \t Acc 60.45 \t AccHead 60.87 \t AccTail 58.94\n",
      "Epoch: [054] \t Loss 0.9805 \t Acc 64.35 \t AccHead 72.96 \t AccTail 33.34\n",
      "Epoch: [055] \t Loss 0.9601 \t Acc 60.54 \t AccHead 64.34 \t AccTail 46.88\n",
      "Epoch: [056] \t Loss 0.9603 \t Acc 65.38 \t AccHead 72.81 \t AccTail 38.54\n",
      "Epoch: [057] \t Loss 0.9482 \t Acc 64.96 \t AccHead 73.98 \t AccTail 32.51\n",
      "Epoch: [058] \t Loss 0.9745 \t Acc 59.11 \t AccHead 64.13 \t AccTail 41.04\n",
      "Epoch: [059] \t Loss 0.9675 \t Acc 60.77 \t AccHead 67.79 \t AccTail 35.50\n",
      "Epoch: [060] \t Loss 0.9556 \t Acc 62.75 \t AccHead 70.08 \t AccTail 36.37\n",
      "Epoch: [061] \t Loss 0.9788 \t Acc 61.78 \t AccHead 66.45 \t AccTail 44.98\n",
      "Epoch: [062] \t Loss 0.9574 \t Acc 64.23 \t AccHead 70.27 \t AccTail 42.50\n",
      "Epoch: [063] \t Loss 0.9577 \t Acc 62.80 \t AccHead 68.83 \t AccTail 41.08\n",
      "Epoch: [064] \t Loss 0.9560 \t Acc 64.00 \t AccHead 68.57 \t AccTail 47.54\n",
      "Epoch: [065] \t Loss 0.9598 \t Acc 65.63 \t AccHead 69.82 \t AccTail 50.52\n",
      "Epoch: [066] \t Loss 0.9513 \t Acc 62.25 \t AccHead 72.27 \t AccTail 26.20\n",
      "Epoch: [067] \t Loss 0.9672 \t Acc 63.77 \t AccHead 69.91 \t AccTail 41.63\n",
      "Epoch: [068] \t Loss 0.9601 \t Acc 64.63 \t AccHead 71.25 \t AccTail 40.76\n",
      "Epoch: [069] \t Loss 0.9530 \t Acc 64.66 \t AccHead 68.35 \t AccTail 51.33\n",
      "Epoch: [070] \t Loss 0.9746 \t Acc 62.78 \t AccHead 69.70 \t AccTail 37.85\n",
      "Epoch: [071] \t Loss 0.9585 \t Acc 63.21 \t AccHead 68.40 \t AccTail 44.54\n",
      "Epoch: [072] \t Loss 0.9621 \t Acc 63.89 \t AccHead 73.74 \t AccTail 28.47\n",
      "Epoch: [073] \t Loss 0.9600 \t Acc 65.69 \t AccHead 71.11 \t AccTail 46.23\n",
      "Epoch: [074] \t Loss 0.9673 \t Acc 61.40 \t AccHead 68.08 \t AccTail 37.38\n",
      "Epoch: [075] \t Loss 0.9697 \t Acc 65.80 \t AccHead 74.17 \t AccTail 35.64\n",
      "Epoch: [076] \t Loss 0.9566 \t Acc 65.29 \t AccHead 72.29 \t AccTail 40.06\n",
      "Epoch: [077] \t Loss 0.9713 \t Acc 64.43 \t AccHead 66.72 \t AccTail 56.13\n",
      "Epoch: [078] \t Loss 0.9611 \t Acc 59.95 \t AccHead 66.35 \t AccTail 36.94\n",
      "Epoch: [079] \t Loss 0.9449 \t Acc 59.83 \t AccHead 62.61 \t AccTail 49.80\n",
      "Epoch: [080] \t Loss 0.9491 \t Acc 63.58 \t AccHead 71.70 \t AccTail 34.30\n",
      "Epoch: [081] \t Loss 0.9432 \t Acc 61.58 \t AccHead 67.22 \t AccTail 41.30\n",
      "Epoch: [082] \t Loss 0.9633 \t Acc 64.09 \t AccHead 72.36 \t AccTail 34.28\n",
      "Epoch: [083] \t Loss 0.9593 \t Acc 57.15 \t AccHead 63.38 \t AccTail 34.75\n",
      "Epoch: [084] \t Loss 0.9509 \t Acc 64.38 \t AccHead 69.20 \t AccTail 47.03\n",
      "Epoch: [085] \t Loss 0.9742 \t Acc 53.46 \t AccHead 51.86 \t AccTail 59.24\n",
      "Epoch: [086] \t Loss 0.9666 \t Acc 65.59 \t AccHead 70.36 \t AccTail 48.44\n",
      "Epoch: [087] \t Loss 0.9585 \t Acc 61.72 \t AccHead 69.47 \t AccTail 33.81\n",
      "Epoch: [088] \t Loss 0.9618 \t Acc 56.46 \t AccHead 63.42 \t AccTail 31.40\n",
      "Epoch: [089] \t Loss 0.9739 \t Acc 62.33 \t AccHead 68.76 \t AccTail 39.13\n",
      "Epoch: [090] \t Loss 0.9661 \t Acc 60.11 \t AccHead 64.26 \t AccTail 45.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 15:23:29,909]\u001b[0m Trial 6 finished with value: 53.772247314453125 and parameters: {'weight_decay': 0.0021088605466807603}. Best is trial 2 with value: 64.19902801513672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 53.77 \t AccHead 62.20 \t AccTail 45.15\n",
      "Epoch: [001] \t Loss 2.5895 \t Acc 34.49 \t AccHead 44.06 \t AccTail 0.03\n",
      "Epoch: [002] \t Loss 1.7147 \t Acc 41.76 \t AccHead 53.33 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.5705 \t Acc 43.96 \t AccHead 55.72 \t AccTail 1.70\n",
      "Epoch: [004] \t Loss 1.4695 \t Acc 46.43 \t AccHead 55.64 \t AccTail 13.27\n",
      "Epoch: [005] \t Loss 1.4073 \t Acc 49.42 \t AccHead 59.88 \t AccTail 11.72\n",
      "Epoch: [006] \t Loss 1.3584 \t Acc 53.42 \t AccHead 61.72 \t AccTail 23.54\n",
      "Epoch: [007] \t Loss 1.2903 \t Acc 52.81 \t AccHead 63.67 \t AccTail 13.61\n",
      "Epoch: [008] \t Loss 1.2259 \t Acc 58.62 \t AccHead 66.24 \t AccTail 31.11\n",
      "Epoch: [009] \t Loss 1.1710 \t Acc 56.56 \t AccHead 65.08 \t AccTail 25.90\n",
      "Epoch: [010] \t Loss 1.1198 \t Acc 59.86 \t AccHead 63.52 \t AccTail 46.66\n",
      "Epoch: [011] \t Loss 1.0926 \t Acc 58.35 \t AccHead 66.88 \t AccTail 27.67\n",
      "Epoch: [012] \t Loss 1.0621 \t Acc 60.73 \t AccHead 65.39 \t AccTail 43.96\n",
      "Epoch: [013] \t Loss 1.0471 \t Acc 62.00 \t AccHead 70.37 \t AccTail 31.92\n",
      "Epoch: [014] \t Loss 1.0216 \t Acc 63.84 \t AccHead 72.77 \t AccTail 31.62\n",
      "Epoch: [015] \t Loss 1.0067 \t Acc 61.81 \t AccHead 69.30 \t AccTail 34.83\n",
      "Epoch: [016] \t Loss 0.9975 \t Acc 66.12 \t AccHead 72.66 \t AccTail 42.60\n",
      "Epoch: [017] \t Loss 0.9804 \t Acc 66.54 \t AccHead 73.03 \t AccTail 43.22\n",
      "Epoch: [018] \t Loss 0.9498 \t Acc 65.85 \t AccHead 74.91 \t AccTail 33.19\n",
      "Epoch: [019] \t Loss 0.9444 \t Acc 68.29 \t AccHead 75.54 \t AccTail 42.24\n",
      "Epoch: [020] \t Loss 0.9356 \t Acc 67.19 \t AccHead 70.73 \t AccTail 54.41\n",
      "Epoch: [021] \t Loss 0.9342 \t Acc 66.66 \t AccHead 71.47 \t AccTail 49.33\n",
      "Epoch: [022] \t Loss 0.9048 \t Acc 67.30 \t AccHead 74.39 \t AccTail 41.78\n",
      "Epoch: [023] \t Loss 0.9162 \t Acc 68.49 \t AccHead 73.87 \t AccTail 49.08\n",
      "Epoch: [024] \t Loss 0.9088 \t Acc 68.81 \t AccHead 75.92 \t AccTail 43.26\n",
      "Epoch: [025] \t Loss 0.8944 \t Acc 65.77 \t AccHead 74.91 \t AccTail 32.81\n",
      "Epoch: [026] \t Loss 0.8875 \t Acc 66.55 \t AccHead 71.18 \t AccTail 49.89\n",
      "Epoch: [027] \t Loss 0.8719 \t Acc 64.42 \t AccHead 71.98 \t AccTail 37.19\n",
      "Epoch: [028] \t Loss 0.8695 \t Acc 66.06 \t AccHead 71.19 \t AccTail 47.55\n",
      "Epoch: [029] \t Loss 0.8711 \t Acc 66.98 \t AccHead 71.28 \t AccTail 51.46\n",
      "Epoch: [030] \t Loss 0.8642 \t Acc 70.65 \t AccHead 77.90 \t AccTail 44.50\n",
      "Epoch: [031] \t Loss 0.8533 \t Acc 70.15 \t AccHead 73.60 \t AccTail 57.75\n",
      "Epoch: [032] \t Loss 0.8501 \t Acc 69.29 \t AccHead 76.38 \t AccTail 43.76\n",
      "Epoch: [033] \t Loss 0.8480 \t Acc 63.85 \t AccHead 65.80 \t AccTail 56.85\n",
      "Epoch: [034] \t Loss 0.8542 \t Acc 67.20 \t AccHead 69.98 \t AccTail 57.15\n",
      "Epoch: [035] \t Loss 0.8498 \t Acc 64.79 \t AccHead 71.74 \t AccTail 39.84\n",
      "Epoch: [036] \t Loss 0.8394 \t Acc 69.42 \t AccHead 74.55 \t AccTail 50.95\n",
      "Epoch: [037] \t Loss 0.8441 \t Acc 62.72 \t AccHead 68.53 \t AccTail 41.74\n",
      "Epoch: [038] \t Loss 0.8403 \t Acc 72.15 \t AccHead 76.23 \t AccTail 57.49\n",
      "Epoch: [039] \t Loss 0.8342 \t Acc 68.18 \t AccHead 72.11 \t AccTail 54.03\n",
      "Epoch: [040] \t Loss 0.8273 \t Acc 68.82 \t AccHead 73.91 \t AccTail 50.48\n",
      "Epoch: [041] \t Loss 0.8245 \t Acc 68.48 \t AccHead 78.85 \t AccTail 31.14\n",
      "Epoch: [042] \t Loss 0.8168 \t Acc 64.75 \t AccHead 71.89 \t AccTail 39.00\n",
      "Epoch: [043] \t Loss 0.8263 \t Acc 68.74 \t AccHead 73.49 \t AccTail 51.61\n",
      "Epoch: [044] \t Loss 0.8237 \t Acc 68.68 \t AccHead 68.74 \t AccTail 68.45\n",
      "Epoch: [045] \t Loss 0.8185 \t Acc 69.09 \t AccHead 72.78 \t AccTail 55.76\n",
      "Epoch: [046] \t Loss 0.8284 \t Acc 70.91 \t AccHead 76.37 \t AccTail 51.29\n",
      "Epoch: [047] \t Loss 0.8082 \t Acc 70.18 \t AccHead 76.40 \t AccTail 47.82\n",
      "Epoch: [048] \t Loss 0.8090 \t Acc 68.24 \t AccHead 77.26 \t AccTail 35.73\n",
      "Epoch: [049] \t Loss 0.8246 \t Acc 69.53 \t AccHead 75.06 \t AccTail 49.65\n",
      "Epoch: [050] \t Loss 0.8060 \t Acc 68.80 \t AccHead 73.77 \t AccTail 50.90\n",
      "Epoch: [051] \t Loss 0.8109 \t Acc 70.41 \t AccHead 78.20 \t AccTail 42.34\n",
      "Epoch: [052] \t Loss 0.7981 \t Acc 72.52 \t AccHead 78.01 \t AccTail 52.76\n",
      "Epoch: [053] \t Loss 0.8052 \t Acc 66.76 \t AccHead 67.99 \t AccTail 62.33\n",
      "Epoch: [054] \t Loss 0.8139 \t Acc 73.28 \t AccHead 78.48 \t AccTail 54.53\n",
      "Epoch: [055] \t Loss 0.8117 \t Acc 70.15 \t AccHead 78.29 \t AccTail 40.82\n",
      "Epoch: [056] \t Loss 0.7942 \t Acc 73.38 \t AccHead 77.01 \t AccTail 60.33\n",
      "Epoch: [057] \t Loss 0.8056 \t Acc 67.48 \t AccHead 73.00 \t AccTail 47.62\n",
      "Epoch: [058] \t Loss 0.8075 \t Acc 72.52 \t AccHead 78.20 \t AccTail 52.11\n",
      "Epoch: [059] \t Loss 0.7926 \t Acc 71.30 \t AccHead 79.75 \t AccTail 40.93\n",
      "Epoch: [060] \t Loss 0.7971 \t Acc 70.54 \t AccHead 76.01 \t AccTail 50.90\n",
      "Epoch: [061] \t Loss 0.7896 \t Acc 71.21 \t AccHead 77.32 \t AccTail 49.19\n",
      "Epoch: [062] \t Loss 0.7973 \t Acc 72.53 \t AccHead 78.24 \t AccTail 52.00\n",
      "Epoch: [063] \t Loss 0.7753 \t Acc 71.08 \t AccHead 75.17 \t AccTail 56.35\n",
      "Epoch: [064] \t Loss 0.8070 \t Acc 70.39 \t AccHead 70.99 \t AccTail 68.23\n",
      "Epoch: [065] \t Loss 0.7832 \t Acc 68.20 \t AccHead 70.96 \t AccTail 58.23\n",
      "Epoch: [066] \t Loss 0.7867 \t Acc 68.11 \t AccHead 67.44 \t AccTail 70.51\n",
      "Epoch: [067] \t Loss 0.7972 \t Acc 70.53 \t AccHead 76.60 \t AccTail 48.64\n",
      "Epoch: [068] \t Loss 0.7818 \t Acc 65.66 \t AccHead 74.39 \t AccTail 34.26\n",
      "Epoch: [069] \t Loss 0.7823 \t Acc 71.67 \t AccHead 77.47 \t AccTail 50.79\n",
      "Epoch: [070] \t Loss 0.7975 \t Acc 72.72 \t AccHead 78.46 \t AccTail 52.09\n",
      "Epoch: [071] \t Loss 0.7736 \t Acc 69.35 \t AccHead 72.29 \t AccTail 58.75\n",
      "Epoch: [072] \t Loss 0.7914 \t Acc 66.27 \t AccHead 66.18 \t AccTail 66.61\n",
      "Epoch: [073] \t Loss 0.7648 \t Acc 72.96 \t AccHead 77.80 \t AccTail 55.53\n",
      "Epoch: [074] \t Loss 0.7842 \t Acc 71.55 \t AccHead 76.48 \t AccTail 53.83\n",
      "Epoch: [075] \t Loss 0.7776 \t Acc 71.60 \t AccHead 77.15 \t AccTail 51.67\n",
      "Epoch: [076] \t Loss 0.7895 \t Acc 71.78 \t AccHead 79.37 \t AccTail 44.48\n",
      "Epoch: [077] \t Loss 0.7845 \t Acc 70.53 \t AccHead 73.73 \t AccTail 59.03\n",
      "Epoch: [078] \t Loss 0.7788 \t Acc 71.24 \t AccHead 74.72 \t AccTail 58.65\n",
      "Epoch: [079] \t Loss 0.7872 \t Acc 73.16 \t AccHead 76.30 \t AccTail 61.82\n",
      "Epoch: [080] \t Loss 0.7577 \t Acc 70.86 \t AccHead 77.95 \t AccTail 45.33\n",
      "Epoch: [081] \t Loss 0.7793 \t Acc 71.49 \t AccHead 74.17 \t AccTail 61.84\n",
      "Epoch: [082] \t Loss 0.7754 \t Acc 70.74 \t AccHead 74.84 \t AccTail 55.99\n",
      "Epoch: [083] \t Loss 0.7926 \t Acc 69.05 \t AccHead 75.90 \t AccTail 44.40\n",
      "Epoch: [084] \t Loss 0.7725 \t Acc 72.90 \t AccHead 81.48 \t AccTail 41.99\n",
      "Epoch: [085] \t Loss 0.7955 \t Acc 67.67 \t AccHead 73.26 \t AccTail 47.55\n",
      "Epoch: [086] \t Loss 0.7885 \t Acc 71.61 \t AccHead 80.27 \t AccTail 40.36\n",
      "Epoch: [087] \t Loss 0.7755 \t Acc 71.09 \t AccHead 78.66 \t AccTail 43.82\n",
      "Epoch: [088] \t Loss 0.7786 \t Acc 71.04 \t AccHead 74.74 \t AccTail 57.72\n",
      "Epoch: [089] \t Loss 0.7786 \t Acc 71.09 \t AccHead 75.54 \t AccTail 55.06\n",
      "Epoch: [090] \t Loss 0.7593 \t Acc 69.06 \t AccHead 76.80 \t AccTail 41.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 15:37:43,111]\u001b[0m Trial 7 finished with value: 55.805015563964844 and parameters: {'weight_decay': 0.00118475894378094}. Best is trial 2 with value: 64.19902801513672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 55.81 \t AccHead 69.68 \t AccTail 41.61\n",
      "Epoch: [001] \t Loss 2.5708 \t Acc 38.80 \t AccHead 49.58 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.7285 \t Acc 41.58 \t AccHead 53.13 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.6000 \t Acc 43.63 \t AccHead 55.73 \t AccTail 0.03\n",
      "Epoch: [004] \t Loss 1.5106 \t Acc 47.39 \t AccHead 59.06 \t AccTail 5.32\n",
      "Epoch: [005] \t Loss 1.4675 \t Acc 51.14 \t AccHead 62.83 \t AccTail 9.08\n",
      "Epoch: [006] \t Loss 1.4310 \t Acc 50.90 \t AccHead 59.49 \t AccTail 20.03\n",
      "Epoch: [007] \t Loss 1.3403 \t Acc 53.54 \t AccHead 60.86 \t AccTail 27.15\n",
      "Epoch: [008] \t Loss 1.3062 \t Acc 54.31 \t AccHead 62.80 \t AccTail 23.70\n",
      "Epoch: [009] \t Loss 1.2609 \t Acc 56.02 \t AccHead 61.76 \t AccTail 35.30\n",
      "Epoch: [010] \t Loss 1.2145 \t Acc 59.93 \t AccHead 70.43 \t AccTail 22.19\n",
      "Epoch: [011] \t Loss 1.1648 \t Acc 62.46 \t AccHead 70.93 \t AccTail 31.90\n",
      "Epoch: [012] \t Loss 1.0983 \t Acc 63.56 \t AccHead 72.03 \t AccTail 33.09\n",
      "Epoch: [013] \t Loss 1.0739 \t Acc 64.89 \t AccHead 72.69 \t AccTail 36.70\n",
      "Epoch: [014] \t Loss 1.0326 \t Acc 65.61 \t AccHead 72.21 \t AccTail 41.87\n",
      "Epoch: [015] \t Loss 0.9935 \t Acc 66.26 \t AccHead 73.55 \t AccTail 40.04\n",
      "Epoch: [016] \t Loss 0.9695 \t Acc 69.43 \t AccHead 75.62 \t AccTail 47.16\n",
      "Epoch: [017] \t Loss 0.9370 \t Acc 68.91 \t AccHead 75.18 \t AccTail 46.32\n",
      "Epoch: [018] \t Loss 0.9038 \t Acc 70.62 \t AccHead 76.16 \t AccTail 50.69\n",
      "Epoch: [019] \t Loss 0.8727 \t Acc 71.12 \t AccHead 78.06 \t AccTail 46.15\n",
      "Epoch: [020] \t Loss 0.8503 \t Acc 71.00 \t AccHead 79.29 \t AccTail 41.10\n",
      "Epoch: [021] \t Loss 0.8397 \t Acc 72.00 \t AccHead 77.74 \t AccTail 51.29\n",
      "Epoch: [022] \t Loss 0.8079 \t Acc 72.11 \t AccHead 76.69 \t AccTail 55.62\n",
      "Epoch: [023] \t Loss 0.7897 \t Acc 73.37 \t AccHead 78.33 \t AccTail 55.47\n",
      "Epoch: [024] \t Loss 0.7761 \t Acc 73.67 \t AccHead 78.43 \t AccTail 56.50\n",
      "Epoch: [025] \t Loss 0.7570 \t Acc 75.36 \t AccHead 78.13 \t AccTail 65.40\n",
      "Epoch: [026] \t Loss 0.7398 \t Acc 76.99 \t AccHead 81.69 \t AccTail 60.01\n",
      "Epoch: [027] \t Loss 0.7137 \t Acc 76.13 \t AccHead 81.51 \t AccTail 56.75\n",
      "Epoch: [028] \t Loss 0.6955 \t Acc 76.17 \t AccHead 80.68 \t AccTail 59.95\n",
      "Epoch: [029] \t Loss 0.6902 \t Acc 75.39 \t AccHead 81.13 \t AccTail 54.70\n",
      "Epoch: [030] \t Loss 0.6728 \t Acc 77.81 \t AccHead 82.65 \t AccTail 60.32\n",
      "Epoch: [031] \t Loss 0.6512 \t Acc 78.41 \t AccHead 83.10 \t AccTail 61.53\n",
      "Epoch: [032] \t Loss 0.6351 \t Acc 79.50 \t AccHead 82.05 \t AccTail 70.32\n",
      "Epoch: [033] \t Loss 0.6225 \t Acc 79.87 \t AccHead 83.75 \t AccTail 65.95\n",
      "Epoch: [034] \t Loss 0.6115 \t Acc 80.23 \t AccHead 83.77 \t AccTail 67.53\n",
      "Epoch: [035] \t Loss 0.5956 \t Acc 80.79 \t AccHead 84.31 \t AccTail 68.11\n",
      "Epoch: [036] \t Loss 0.5871 \t Acc 81.05 \t AccHead 84.69 \t AccTail 67.92\n",
      "Epoch: [037] \t Loss 0.5655 \t Acc 80.79 \t AccHead 84.04 \t AccTail 69.10\n",
      "Epoch: [038] \t Loss 0.5646 \t Acc 81.98 \t AccHead 86.20 \t AccTail 66.75\n",
      "Epoch: [039] \t Loss 0.5521 \t Acc 81.13 \t AccHead 85.32 \t AccTail 66.04\n",
      "Epoch: [040] \t Loss 0.5349 \t Acc 82.50 \t AccHead 87.41 \t AccTail 64.83\n",
      "Epoch: [041] \t Loss 0.5464 \t Acc 80.92 \t AccHead 83.58 \t AccTail 71.35\n",
      "Epoch: [042] \t Loss 0.5126 \t Acc 82.37 \t AccHead 85.74 \t AccTail 70.24\n",
      "Epoch: [043] \t Loss 0.5104 \t Acc 82.15 \t AccHead 84.30 \t AccTail 74.42\n",
      "Epoch: [044] \t Loss 0.5048 \t Acc 83.82 \t AccHead 87.12 \t AccTail 71.94\n",
      "Epoch: [045] \t Loss 0.4905 \t Acc 83.16 \t AccHead 88.84 \t AccTail 62.75\n",
      "Epoch: [046] \t Loss 0.4758 \t Acc 84.60 \t AccHead 87.10 \t AccTail 75.59\n",
      "Epoch: [047] \t Loss 0.4750 \t Acc 85.22 \t AccHead 88.67 \t AccTail 72.76\n",
      "Epoch: [048] \t Loss 0.4584 \t Acc 85.38 \t AccHead 88.51 \t AccTail 74.12\n",
      "Epoch: [049] \t Loss 0.4553 \t Acc 84.04 \t AccHead 86.87 \t AccTail 73.84\n",
      "Epoch: [050] \t Loss 0.4339 \t Acc 86.17 \t AccHead 87.71 \t AccTail 80.64\n",
      "Epoch: [051] \t Loss 0.4349 \t Acc 84.98 \t AccHead 87.62 \t AccTail 75.47\n",
      "Epoch: [052] \t Loss 0.4269 \t Acc 85.63 \t AccHead 88.91 \t AccTail 73.83\n",
      "Epoch: [053] \t Loss 0.4092 \t Acc 86.01 \t AccHead 90.17 \t AccTail 71.03\n",
      "Epoch: [054] \t Loss 0.4225 \t Acc 85.75 \t AccHead 87.28 \t AccTail 80.26\n",
      "Epoch: [055] \t Loss 0.4067 \t Acc 85.93 \t AccHead 89.17 \t AccTail 74.25\n",
      "Epoch: [056] \t Loss 0.3918 \t Acc 86.33 \t AccHead 89.26 \t AccTail 75.79\n",
      "Epoch: [057] \t Loss 0.3790 \t Acc 87.57 \t AccHead 90.77 \t AccTail 76.05\n",
      "Epoch: [058] \t Loss 0.3733 \t Acc 86.35 \t AccHead 90.29 \t AccTail 72.16\n",
      "Epoch: [059] \t Loss 0.3763 \t Acc 89.07 \t AccHead 91.81 \t AccTail 79.22\n",
      "Epoch: [060] \t Loss 0.3612 \t Acc 87.54 \t AccHead 88.78 \t AccTail 83.07\n",
      "Epoch: [061] \t Loss 0.3657 \t Acc 88.15 \t AccHead 90.41 \t AccTail 80.02\n",
      "Epoch: [062] \t Loss 0.3622 \t Acc 87.59 \t AccHead 89.81 \t AccTail 79.60\n",
      "Epoch: [063] \t Loss 0.3417 \t Acc 88.88 \t AccHead 90.66 \t AccTail 82.49\n",
      "Epoch: [064] \t Loss 0.3329 \t Acc 88.69 \t AccHead 90.72 \t AccTail 81.37\n",
      "Epoch: [065] \t Loss 0.3270 \t Acc 89.43 \t AccHead 90.91 \t AccTail 84.06\n",
      "Epoch: [066] \t Loss 0.3282 \t Acc 89.92 \t AccHead 91.04 \t AccTail 85.86\n",
      "Epoch: [067] \t Loss 0.3284 \t Acc 89.55 \t AccHead 91.17 \t AccTail 83.72\n",
      "Epoch: [068] \t Loss 0.3288 \t Acc 87.32 \t AccHead 90.85 \t AccTail 74.63\n",
      "Epoch: [069] \t Loss 0.3196 \t Acc 89.29 \t AccHead 89.46 \t AccTail 88.68\n",
      "Epoch: [070] \t Loss 0.3141 \t Acc 89.52 \t AccHead 91.46 \t AccTail 82.50\n",
      "Epoch: [071] \t Loss 0.2959 \t Acc 91.17 \t AccHead 92.92 \t AccTail 84.88\n",
      "Epoch: [072] \t Loss 0.3079 \t Acc 89.59 \t AccHead 90.68 \t AccTail 85.66\n",
      "Epoch: [073] \t Loss 0.2839 \t Acc 91.18 \t AccHead 91.99 \t AccTail 88.25\n",
      "Epoch: [074] \t Loss 0.2849 \t Acc 91.16 \t AccHead 92.25 \t AccTail 87.23\n",
      "Epoch: [075] \t Loss 0.2783 \t Acc 89.86 \t AccHead 91.13 \t AccTail 85.30\n",
      "Epoch: [076] \t Loss 0.2783 \t Acc 89.79 \t AccHead 91.21 \t AccTail 84.67\n",
      "Epoch: [077] \t Loss 0.2686 \t Acc 91.68 \t AccHead 92.92 \t AccTail 87.25\n",
      "Epoch: [078] \t Loss 0.2650 \t Acc 92.05 \t AccHead 94.53 \t AccTail 83.08\n",
      "Epoch: [079] \t Loss 0.2690 \t Acc 91.38 \t AccHead 91.77 \t AccTail 89.98\n",
      "Epoch: [080] \t Loss 0.2673 \t Acc 90.10 \t AccHead 90.97 \t AccTail 86.97\n",
      "Epoch: [081] \t Loss 0.2597 \t Acc 93.15 \t AccHead 94.73 \t AccTail 87.44\n",
      "Epoch: [082] \t Loss 0.2493 \t Acc 92.47 \t AccHead 93.74 \t AccTail 87.88\n",
      "Epoch: [083] \t Loss 0.2383 \t Acc 92.05 \t AccHead 93.46 \t AccTail 86.97\n",
      "Epoch: [084] \t Loss 0.2348 \t Acc 92.18 \t AccHead 93.00 \t AccTail 89.23\n",
      "Epoch: [085] \t Loss 0.2443 \t Acc 90.83 \t AccHead 91.24 \t AccTail 89.37\n",
      "Epoch: [086] \t Loss 0.2401 \t Acc 92.66 \t AccHead 94.73 \t AccTail 85.16\n",
      "Epoch: [087] \t Loss 0.2247 \t Acc 92.48 \t AccHead 93.07 \t AccTail 90.38\n",
      "Epoch: [088] \t Loss 0.2425 \t Acc 93.09 \t AccHead 94.29 \t AccTail 88.73\n",
      "Epoch: [089] \t Loss 0.2154 \t Acc 92.81 \t AccHead 93.04 \t AccTail 91.99\n",
      "Epoch: [090] \t Loss 0.2135 \t Acc 92.58 \t AccHead 93.41 \t AccTail 89.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 15:51:51,521]\u001b[0m Trial 8 finished with value: 67.64765167236328 and parameters: {'weight_decay': 2.2929010089254153e-05}. Best is trial 8 with value: 67.64765167236328.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 67.65 \t AccHead 76.40 \t AccTail 58.69\n",
      "Epoch: [001] \t Loss 2.3135 \t Acc 43.83 \t AccHead 55.98 \t AccTail 0.03\n",
      "Epoch: [002] \t Loss 1.5653 \t Acc 47.15 \t AccHead 58.05 \t AccTail 7.83\n",
      "Epoch: [003] \t Loss 1.4773 \t Acc 45.05 \t AccHead 57.01 \t AccTail 2.04\n",
      "Epoch: [004] \t Loss 1.4308 \t Acc 48.84 \t AccHead 60.10 \t AccTail 8.29\n",
      "Epoch: [005] \t Loss 1.3824 \t Acc 49.42 \t AccHead 60.71 \t AccTail 8.80\n",
      "Epoch: [006] \t Loss 1.3526 \t Acc 50.84 \t AccHead 61.95 \t AccTail 10.94\n",
      "Epoch: [007] \t Loss 1.3388 \t Acc 46.79 \t AccHead 54.27 \t AccTail 19.85\n",
      "Epoch: [008] \t Loss 1.3019 \t Acc 54.00 \t AccHead 64.43 \t AccTail 16.52\n",
      "Epoch: [009] \t Loss 1.2770 \t Acc 48.05 \t AccHead 54.08 \t AccTail 26.34\n",
      "Epoch: [010] \t Loss 1.2619 \t Acc 52.85 \t AccHead 60.35 \t AccTail 25.75\n",
      "Epoch: [011] \t Loss 1.2365 \t Acc 53.41 \t AccHead 61.55 \t AccTail 24.15\n",
      "Epoch: [012] \t Loss 1.2503 \t Acc 48.98 \t AccHead 59.80 \t AccTail 10.09\n",
      "Epoch: [013] \t Loss 1.2405 \t Acc 55.63 \t AccHead 63.79 \t AccTail 26.31\n",
      "Epoch: [014] \t Loss 1.2400 \t Acc 52.97 \t AccHead 58.13 \t AccTail 34.39\n",
      "Epoch: [015] \t Loss 1.2350 \t Acc 44.16 \t AccHead 52.30 \t AccTail 14.92\n",
      "Epoch: [016] \t Loss 1.2351 \t Acc 51.59 \t AccHead 63.40 \t AccTail 9.08\n",
      "Epoch: [017] \t Loss 1.2097 \t Acc 52.77 \t AccHead 62.92 \t AccTail 16.25\n",
      "Epoch: [018] \t Loss 1.2259 \t Acc 54.61 \t AccHead 63.16 \t AccTail 23.82\n",
      "Epoch: [019] \t Loss 1.2187 \t Acc 52.91 \t AccHead 61.17 \t AccTail 23.25\n",
      "Epoch: [020] \t Loss 1.2337 \t Acc 54.26 \t AccHead 63.38 \t AccTail 21.38\n",
      "Epoch: [021] \t Loss 1.2138 \t Acc 57.97 \t AccHead 66.86 \t AccTail 26.02\n",
      "Epoch: [022] \t Loss 1.2189 \t Acc 40.30 \t AccHead 47.58 \t AccTail 14.07\n",
      "Epoch: [023] \t Loss 1.2250 \t Acc 56.32 \t AccHead 65.90 \t AccTail 21.81\n",
      "Epoch: [024] \t Loss 1.2151 \t Acc 46.59 \t AccHead 55.40 \t AccTail 14.83\n",
      "Epoch: [025] \t Loss 1.2002 \t Acc 55.65 \t AccHead 67.58 \t AccTail 12.66\n",
      "Epoch: [026] \t Loss 1.2047 \t Acc 54.94 \t AccHead 62.76 \t AccTail 26.75\n",
      "Epoch: [027] \t Loss 1.2179 \t Acc 56.96 \t AccHead 67.34 \t AccTail 19.56\n",
      "Epoch: [028] \t Loss 1.2016 \t Acc 53.43 \t AccHead 63.99 \t AccTail 15.46\n",
      "Epoch: [029] \t Loss 1.2119 \t Acc 48.15 \t AccHead 53.12 \t AccTail 30.31\n",
      "Epoch: [030] \t Loss 1.2123 \t Acc 50.71 \t AccHead 54.88 \t AccTail 35.73\n",
      "Epoch: [031] \t Loss 1.2090 \t Acc 53.08 \t AccHead 60.10 \t AccTail 27.77\n",
      "Epoch: [032] \t Loss 1.1940 \t Acc 51.64 \t AccHead 58.63 \t AccTail 26.46\n",
      "Epoch: [033] \t Loss 1.2141 \t Acc 49.58 \t AccHead 53.40 \t AccTail 35.82\n",
      "Epoch: [034] \t Loss 1.2110 \t Acc 51.73 \t AccHead 56.77 \t AccTail 33.61\n",
      "Epoch: [035] \t Loss 1.2002 \t Acc 41.78 \t AccHead 42.81 \t AccTail 38.08\n",
      "Epoch: [036] \t Loss 1.2223 \t Acc 51.99 \t AccHead 61.00 \t AccTail 19.52\n",
      "Epoch: [037] \t Loss 1.2309 \t Acc 52.99 \t AccHead 65.45 \t AccTail 8.20\n",
      "Epoch: [038] \t Loss 1.2122 \t Acc 47.96 \t AccHead 51.43 \t AccTail 35.43\n",
      "Epoch: [039] \t Loss 1.2159 \t Acc 48.20 \t AccHead 54.94 \t AccTail 23.92\n",
      "Epoch: [040] \t Loss 1.2119 \t Acc 52.02 \t AccHead 56.90 \t AccTail 34.48\n",
      "Epoch: [041] \t Loss 1.2151 \t Acc 55.39 \t AccHead 64.06 \t AccTail 24.19\n",
      "Epoch: [042] \t Loss 1.2161 \t Acc 43.79 \t AccHead 50.66 \t AccTail 19.08\n",
      "Epoch: [043] \t Loss 1.2033 \t Acc 54.04 \t AccHead 61.88 \t AccTail 25.82\n",
      "Epoch: [044] \t Loss 1.2021 \t Acc 51.91 \t AccHead 58.73 \t AccTail 27.36\n",
      "Epoch: [045] \t Loss 1.2059 \t Acc 55.94 \t AccHead 64.50 \t AccTail 25.07\n",
      "Epoch: [046] \t Loss 1.2157 \t Acc 55.26 \t AccHead 66.60 \t AccTail 14.44\n",
      "Epoch: [047] \t Loss 1.2116 \t Acc 54.42 \t AccHead 58.79 \t AccTail 38.64\n",
      "Epoch: [048] \t Loss 1.2075 \t Acc 53.77 \t AccHead 61.92 \t AccTail 24.46\n",
      "Epoch: [049] \t Loss 1.2164 \t Acc 46.91 \t AccHead 54.53 \t AccTail 19.47\n",
      "Epoch: [050] \t Loss 1.2078 \t Acc 45.55 \t AccHead 56.40 \t AccTail 6.35\n",
      "Epoch: [051] \t Loss 1.2132 \t Acc 53.26 \t AccHead 61.93 \t AccTail 22.05\n",
      "Epoch: [052] \t Loss 1.1870 \t Acc 56.10 \t AccHead 64.04 \t AccTail 27.46\n",
      "Epoch: [053] \t Loss 1.2175 \t Acc 51.11 \t AccHead 58.02 \t AccTail 26.22\n",
      "Epoch: [054] \t Loss 1.1999 \t Acc 50.69 \t AccHead 57.10 \t AccTail 27.55\n",
      "Epoch: [055] \t Loss 1.2098 \t Acc 48.75 \t AccHead 52.31 \t AccTail 35.92\n",
      "Epoch: [056] \t Loss 1.2111 \t Acc 54.50 \t AccHead 63.03 \t AccTail 23.78\n",
      "Epoch: [057] \t Loss 1.2062 \t Acc 53.62 \t AccHead 61.88 \t AccTail 23.87\n",
      "Epoch: [058] \t Loss 1.2075 \t Acc 55.24 \t AccHead 63.00 \t AccTail 27.35\n",
      "Epoch: [059] \t Loss 1.1998 \t Acc 53.05 \t AccHead 58.99 \t AccTail 31.74\n",
      "Epoch: [060] \t Loss 1.1997 \t Acc 53.40 \t AccHead 58.86 \t AccTail 33.72\n",
      "Epoch: [061] \t Loss 1.2138 \t Acc 54.59 \t AccHead 63.40 \t AccTail 22.87\n",
      "Epoch: [062] \t Loss 1.2002 \t Acc 55.82 \t AccHead 66.75 \t AccTail 16.39\n",
      "Epoch: [063] \t Loss 1.2021 \t Acc 53.57 \t AccHead 63.24 \t AccTail 18.75\n",
      "Epoch: [064] \t Loss 1.2153 \t Acc 44.74 \t AccHead 46.36 \t AccTail 38.91\n",
      "Epoch: [065] \t Loss 1.2145 \t Acc 38.49 \t AccHead 44.01 \t AccTail 18.62\n",
      "Epoch: [066] \t Loss 1.2137 \t Acc 46.01 \t AccHead 51.74 \t AccTail 25.37\n",
      "Epoch: [067] \t Loss 1.2092 \t Acc 45.29 \t AccHead 53.37 \t AccTail 16.21\n",
      "Epoch: [068] \t Loss 1.2040 \t Acc 49.27 \t AccHead 59.12 \t AccTail 13.76\n",
      "Epoch: [069] \t Loss 1.2191 \t Acc 50.27 \t AccHead 56.65 \t AccTail 27.27\n",
      "Epoch: [070] \t Loss 1.2116 \t Acc 51.93 \t AccHead 61.55 \t AccTail 17.34\n",
      "Epoch: [071] \t Loss 1.2124 \t Acc 51.48 \t AccHead 59.26 \t AccTail 23.43\n",
      "Epoch: [072] \t Loss 1.2253 \t Acc 37.91 \t AccHead 44.40 \t AccTail 14.46\n",
      "Epoch: [073] \t Loss 1.2181 \t Acc 51.22 \t AccHead 61.32 \t AccTail 14.80\n",
      "Epoch: [074] \t Loss 1.2179 \t Acc 55.79 \t AccHead 62.94 \t AccTail 30.07\n",
      "Epoch: [075] \t Loss 1.2166 \t Acc 56.56 \t AccHead 67.11 \t AccTail 18.56\n",
      "Epoch: [076] \t Loss 1.2201 \t Acc 56.75 \t AccHead 66.20 \t AccTail 22.76\n",
      "Epoch: [077] \t Loss 1.2280 \t Acc 49.50 \t AccHead 59.86 \t AccTail 12.26\n",
      "Epoch: [078] \t Loss 1.2119 \t Acc 53.34 \t AccHead 60.69 \t AccTail 26.86\n",
      "Epoch: [079] \t Loss 1.2083 \t Acc 55.84 \t AccHead 66.05 \t AccTail 18.96\n",
      "Epoch: [080] \t Loss 1.2033 \t Acc 50.31 \t AccHead 58.98 \t AccTail 19.13\n",
      "Epoch: [081] \t Loss 1.2249 \t Acc 53.25 \t AccHead 61.94 \t AccTail 21.91\n",
      "Epoch: [082] \t Loss 1.2240 \t Acc 53.09 \t AccHead 56.63 \t AccTail 40.35\n",
      "Epoch: [083] \t Loss 1.2064 \t Acc 56.07 \t AccHead 64.06 \t AccTail 27.32\n",
      "Epoch: [084] \t Loss 1.2194 \t Acc 52.25 \t AccHead 60.00 \t AccTail 24.27\n",
      "Epoch: [085] \t Loss 1.2044 \t Acc 55.21 \t AccHead 64.28 \t AccTail 22.54\n",
      "Epoch: [086] \t Loss 1.2246 \t Acc 56.78 \t AccHead 68.95 \t AccTail 12.89\n",
      "Epoch: [087] \t Loss 1.2165 \t Acc 56.31 \t AccHead 66.26 \t AccTail 20.30\n",
      "Epoch: [088] \t Loss 1.2292 \t Acc 47.65 \t AccHead 56.32 \t AccTail 16.46\n",
      "Epoch: [089] \t Loss 1.1976 \t Acc 52.69 \t AccHead 58.18 \t AccTail 32.92\n",
      "Epoch: [090] \t Loss 1.2072 \t Acc 55.26 \t AccHead 62.69 \t AccTail 28.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 16:05:54,014]\u001b[0m Trial 9 finished with value: 38.612457275390625 and parameters: {'weight_decay': 0.004171034596129968}. Best is trial 8 with value: 67.64765167236328.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 38.61 \t AccHead 54.80 \t AccTail 22.05\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'CIFAR10' #['CIFAR10', 'CIFAR100']\n",
    "IMB_TYPE = 'exp' #['exp', 'step']\n",
    "IMB_FACTOR = 0.1 #[0.1, 0.01]\n",
    "train_loader, test_loader, num_classes = get_loaders()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sampler = optuna.samplers.TPESampler()\n",
    "    study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "    study.optimize(func=train_model, n_trials=10)\n",
    "    joblib.dump(study, 'set_10_exp_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6094cb3f-a8ee-45e0-b8aa-79c9fd0c5f6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T16:05:54.037475Z",
     "iopub.status.busy": "2022-06-16T16:05:54.037054Z",
     "iopub.status.idle": "2022-06-16T16:05:54.065494Z",
     "shell.execute_reply": "2022-06-16T16:05:54.065053Z",
     "shell.execute_reply.started": "2022-06-16T16:05:54.037429Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31.877022</td>\n",
       "      <td>0 days 00:14:06.456049</td>\n",
       "      <td>0.005602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39.987862</td>\n",
       "      <td>0 days 00:14:11.593239</td>\n",
       "      <td>0.004971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>64.199028</td>\n",
       "      <td>0 days 00:14:16.540441</td>\n",
       "      <td>0.000634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>43.112862</td>\n",
       "      <td>0 days 00:14:14.050488</td>\n",
       "      <td>0.003426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>52.740692</td>\n",
       "      <td>0 days 00:14:17.540152</td>\n",
       "      <td>0.002612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>38.723705</td>\n",
       "      <td>0 days 00:14:16.798418</td>\n",
       "      <td>0.004207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>53.772247</td>\n",
       "      <td>0 days 00:14:07.148492</td>\n",
       "      <td>0.002109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>55.805016</td>\n",
       "      <td>0 days 00:14:13.198820</td>\n",
       "      <td>0.001185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>67.647652</td>\n",
       "      <td>0 days 00:14:08.406153</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>38.612457</td>\n",
       "      <td>0 days 00:14:02.489840</td>\n",
       "      <td>0.004171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number      value               duration  params_weight_decay\n",
       "0       0  31.877022 0 days 00:14:06.456049             0.005602\n",
       "1       1  39.987862 0 days 00:14:11.593239             0.004971\n",
       "2       2  64.199028 0 days 00:14:16.540441             0.000634\n",
       "3       3  43.112862 0 days 00:14:14.050488             0.003426\n",
       "4       4  52.740692 0 days 00:14:17.540152             0.002612\n",
       "5       5  38.723705 0 days 00:14:16.798418             0.004207\n",
       "6       6  53.772247 0 days 00:14:07.148492             0.002109\n",
       "7       7  55.805016 0 days 00:14:13.198820             0.001185\n",
       "8       8  67.647652 0 days 00:14:08.406153             0.000023\n",
       "9       9  38.612457 0 days 00:14:02.489840             0.004171"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = joblib.load('set_10_exp_1.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "597cc61a-3a05-4169-91f6-78521e1068d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T16:05:54.066455Z",
     "iopub.status.busy": "2022-06-16T16:05:54.066204Z",
     "iopub.status.idle": "2022-06-16T18:52:53.746406Z",
     "shell.execute_reply": "2022-06-16T18:52:53.745222Z",
     "shell.execute_reply.started": "2022-06-16T16:05:54.066436Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 16:06:31,360]\u001b[0m A new study created in memory with name: no-name-5257d5c7-9bd6-44ea-86bb-3a68c00d76c8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls num list(train_dataset):\n",
      "[4000, 4000, 4000, 4000, 4000, 400, 400, 400, 400, 400]\n",
      "cls num list(val_dataset):\n",
      "[1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]\n",
      "Epoch: [001] \t Loss 2.2730 \t Acc 41.02 \t AccHead 45.01 \t AccTail 0.05\n",
      "Epoch: [002] \t Loss 1.5382 \t Acc 49.14 \t AccHead 53.92 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.3723 \t Acc 53.84 \t AccHead 59.08 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.2844 \t Acc 56.14 \t AccHead 61.59 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.2165 \t Acc 57.43 \t AccHead 62.79 \t AccTail 2.47\n",
      "Epoch: [006] \t Loss 1.1578 \t Acc 61.91 \t AccHead 67.60 \t AccTail 3.31\n",
      "Epoch: [007] \t Loss 1.1107 \t Acc 63.77 \t AccHead 69.63 \t AccTail 3.51\n",
      "Epoch: [008] \t Loss 1.0437 \t Acc 65.85 \t AccHead 71.59 \t AccTail 6.86\n",
      "Epoch: [009] \t Loss 0.9999 \t Acc 68.38 \t AccHead 74.60 \t AccTail 4.44\n",
      "Epoch: [010] \t Loss 0.9576 \t Acc 70.20 \t AccHead 76.21 \t AccTail 8.35\n",
      "Epoch: [011] \t Loss 0.9262 \t Acc 70.58 \t AccHead 76.26 \t AccTail 12.16\n",
      "Epoch: [012] \t Loss 0.8893 \t Acc 72.74 \t AccHead 78.24 \t AccTail 16.27\n",
      "Epoch: [013] \t Loss 0.8625 \t Acc 72.82 \t AccHead 78.19 \t AccTail 17.76\n",
      "Epoch: [014] \t Loss 0.8276 \t Acc 73.47 \t AccHead 78.77 \t AccTail 18.93\n",
      "Epoch: [015] \t Loss 0.8000 \t Acc 72.78 \t AccHead 78.41 \t AccTail 14.81\n",
      "Epoch: [016] \t Loss 0.7817 \t Acc 74.95 \t AccHead 79.85 \t AccTail 24.59\n",
      "Epoch: [017] \t Loss 0.7678 \t Acc 75.19 \t AccHead 79.64 \t AccTail 29.35\n",
      "Epoch: [018] \t Loss 0.7479 \t Acc 74.34 \t AccHead 79.66 \t AccTail 19.56\n",
      "Epoch: [019] \t Loss 0.7367 \t Acc 71.89 \t AccHead 76.04 \t AccTail 29.23\n",
      "Epoch: [020] \t Loss 0.7085 \t Acc 77.16 \t AccHead 81.67 \t AccTail 30.72\n",
      "Epoch: [021] \t Loss 0.7027 \t Acc 76.38 \t AccHead 80.86 \t AccTail 30.24\n",
      "Epoch: [022] \t Loss 0.6817 \t Acc 77.52 \t AccHead 82.20 \t AccTail 29.41\n",
      "Epoch: [023] \t Loss 0.6766 \t Acc 78.59 \t AccHead 84.02 \t AccTail 22.62\n",
      "Epoch: [024] \t Loss 0.6648 \t Acc 76.61 \t AccHead 80.74 \t AccTail 34.16\n",
      "Epoch: [025] \t Loss 0.6557 \t Acc 79.41 \t AccHead 83.83 \t AccTail 33.97\n",
      "Epoch: [026] \t Loss 0.6404 \t Acc 77.89 \t AccHead 81.72 \t AccTail 38.49\n",
      "Epoch: [027] \t Loss 0.6245 \t Acc 78.74 \t AccHead 83.36 \t AccTail 31.15\n",
      "Epoch: [028] \t Loss 0.6286 \t Acc 76.19 \t AccHead 80.15 \t AccTail 35.45\n",
      "Epoch: [029] \t Loss 0.6118 \t Acc 78.38 \t AccHead 82.77 \t AccTail 33.28\n",
      "Epoch: [030] \t Loss 0.6047 \t Acc 79.97 \t AccHead 83.60 \t AccTail 42.57\n",
      "Epoch: [031] \t Loss 0.6065 \t Acc 78.80 \t AccHead 82.39 \t AccTail 41.85\n",
      "Epoch: [032] \t Loss 0.5880 \t Acc 80.89 \t AccHead 84.84 \t AccTail 40.26\n",
      "Epoch: [033] \t Loss 0.5906 \t Acc 80.70 \t AccHead 84.69 \t AccTail 39.69\n",
      "Epoch: [034] \t Loss 0.5716 \t Acc 79.98 \t AccHead 83.73 \t AccTail 41.50\n",
      "Epoch: [035] \t Loss 0.5702 \t Acc 79.07 \t AccHead 82.99 \t AccTail 38.79\n",
      "Epoch: [036] \t Loss 0.5665 \t Acc 81.58 \t AccHead 85.29 \t AccTail 43.37\n",
      "Epoch: [037] \t Loss 0.5650 \t Acc 81.29 \t AccHead 84.14 \t AccTail 52.01\n",
      "Epoch: [038] \t Loss 0.5650 \t Acc 80.79 \t AccHead 83.94 \t AccTail 48.40\n",
      "Epoch: [039] \t Loss 0.5538 \t Acc 81.86 \t AccHead 85.71 \t AccTail 42.16\n",
      "Epoch: [040] \t Loss 0.5454 \t Acc 81.60 \t AccHead 85.80 \t AccTail 38.38\n",
      "Epoch: [041] \t Loss 0.5464 \t Acc 81.50 \t AccHead 85.28 \t AccTail 42.60\n",
      "Epoch: [042] \t Loss 0.5383 \t Acc 81.46 \t AccHead 85.26 \t AccTail 42.42\n",
      "Epoch: [043] \t Loss 0.5321 \t Acc 80.20 \t AccHead 83.32 \t AccTail 48.09\n",
      "Epoch: [044] \t Loss 0.5322 \t Acc 82.93 \t AccHead 87.37 \t AccTail 37.09\n",
      "Epoch: [045] \t Loss 0.5337 \t Acc 82.43 \t AccHead 85.75 \t AccTail 48.35\n",
      "Epoch: [046] \t Loss 0.5269 \t Acc 78.64 \t AccHead 81.46 \t AccTail 49.66\n",
      "Epoch: [047] \t Loss 0.5103 \t Acc 82.73 \t AccHead 86.79 \t AccTail 40.87\n",
      "Epoch: [048] \t Loss 0.5163 \t Acc 82.87 \t AccHead 86.39 \t AccTail 46.62\n",
      "Epoch: [049] \t Loss 0.5118 \t Acc 83.85 \t AccHead 87.69 \t AccTail 44.27\n",
      "Epoch: [050] \t Loss 0.5116 \t Acc 84.62 \t AccHead 88.02 \t AccTail 49.72\n",
      "Epoch: [051] \t Loss 0.5111 \t Acc 81.65 \t AccHead 85.36 \t AccTail 43.48\n",
      "Epoch: [052] \t Loss 0.5064 \t Acc 84.52 \t AccHead 87.95 \t AccTail 49.25\n",
      "Epoch: [053] \t Loss 0.5097 \t Acc 83.69 \t AccHead 87.32 \t AccTail 46.34\n",
      "Epoch: [054] \t Loss 0.4977 \t Acc 84.06 \t AccHead 87.31 \t AccTail 50.59\n",
      "Epoch: [055] \t Loss 0.4861 \t Acc 84.76 \t AccHead 88.18 \t AccTail 49.54\n",
      "Epoch: [056] \t Loss 0.4884 \t Acc 82.58 \t AccHead 85.85 \t AccTail 48.94\n",
      "Epoch: [057] \t Loss 0.4868 \t Acc 83.08 \t AccHead 86.72 \t AccTail 45.67\n",
      "Epoch: [058] \t Loss 0.4827 \t Acc 83.95 \t AccHead 86.85 \t AccTail 54.12\n",
      "Epoch: [059] \t Loss 0.4842 \t Acc 84.28 \t AccHead 88.03 \t AccTail 45.67\n",
      "Epoch: [060] \t Loss 0.4744 \t Acc 83.85 \t AccHead 87.29 \t AccTail 48.38\n",
      "Epoch: [061] \t Loss 0.4734 \t Acc 82.52 \t AccHead 86.53 \t AccTail 41.31\n",
      "Epoch: [062] \t Loss 0.4785 \t Acc 84.72 \t AccHead 87.70 \t AccTail 54.05\n",
      "Epoch: [063] \t Loss 0.4807 \t Acc 86.02 \t AccHead 89.04 \t AccTail 55.02\n",
      "Epoch: [064] \t Loss 0.4747 \t Acc 84.16 \t AccHead 86.69 \t AccTail 58.14\n",
      "Epoch: [065] \t Loss 0.4730 \t Acc 85.11 \t AccHead 88.34 \t AccTail 51.83\n",
      "Epoch: [066] \t Loss 0.4744 \t Acc 85.10 \t AccHead 88.05 \t AccTail 54.78\n",
      "Epoch: [067] \t Loss 0.4627 \t Acc 84.00 \t AccHead 87.38 \t AccTail 49.12\n",
      "Epoch: [068] \t Loss 0.4598 \t Acc 84.42 \t AccHead 87.75 \t AccTail 50.15\n",
      "Epoch: [069] \t Loss 0.4484 \t Acc 84.01 \t AccHead 87.37 \t AccTail 49.48\n",
      "Epoch: [070] \t Loss 0.4558 \t Acc 86.09 \t AccHead 89.14 \t AccTail 54.72\n",
      "Epoch: [071] \t Loss 0.4560 \t Acc 85.54 \t AccHead 88.84 \t AccTail 51.63\n",
      "Epoch: [072] \t Loss 0.4646 \t Acc 85.42 \t AccHead 88.63 \t AccTail 52.35\n",
      "Epoch: [073] \t Loss 0.4515 \t Acc 82.39 \t AccHead 85.16 \t AccTail 53.77\n",
      "Epoch: [074] \t Loss 0.4553 \t Acc 80.71 \t AccHead 84.48 \t AccTail 41.85\n",
      "Epoch: [075] \t Loss 0.4535 \t Acc 83.37 \t AccHead 86.38 \t AccTail 52.43\n",
      "Epoch: [076] \t Loss 0.4487 \t Acc 85.91 \t AccHead 88.62 \t AccTail 58.07\n",
      "Epoch: [077] \t Loss 0.4483 \t Acc 85.81 \t AccHead 89.01 \t AccTail 52.86\n",
      "Epoch: [078] \t Loss 0.4454 \t Acc 79.41 \t AccHead 82.83 \t AccTail 44.30\n",
      "Epoch: [079] \t Loss 0.4555 \t Acc 84.19 \t AccHead 87.31 \t AccTail 52.06\n",
      "Epoch: [080] \t Loss 0.4398 \t Acc 85.56 \t AccHead 88.55 \t AccTail 54.85\n",
      "Epoch: [081] \t Loss 0.4383 \t Acc 86.04 \t AccHead 89.43 \t AccTail 51.19\n",
      "Epoch: [082] \t Loss 0.4421 \t Acc 85.54 \t AccHead 88.16 \t AccTail 58.47\n",
      "Epoch: [083] \t Loss 0.4376 \t Acc 86.76 \t AccHead 90.06 \t AccTail 52.76\n",
      "Epoch: [084] \t Loss 0.4396 \t Acc 86.18 \t AccHead 88.14 \t AccTail 65.96\n",
      "Epoch: [085] \t Loss 0.4382 \t Acc 82.94 \t AccHead 85.26 \t AccTail 59.03\n",
      "Epoch: [086] \t Loss 0.4421 \t Acc 84.11 \t AccHead 86.73 \t AccTail 57.19\n",
      "Epoch: [087] \t Loss 0.4242 \t Acc 83.72 \t AccHead 87.89 \t AccTail 40.92\n",
      "Epoch: [088] \t Loss 0.4325 \t Acc 85.41 \t AccHead 87.87 \t AccTail 60.09\n",
      "Epoch: [089] \t Loss 0.4345 \t Acc 83.71 \t AccHead 87.37 \t AccTail 45.94\n",
      "Epoch: [090] \t Loss 0.4273 \t Acc 85.65 \t AccHead 88.74 \t AccTail 53.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 16:23:09,457]\u001b[0m Trial 0 finished with value: 63.54545593261719 and parameters: {'weight_decay': 0.00027216068742182424}. Best is trial 0 with value: 63.54545593261719.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 63.55 \t AccHead 83.60 \t AccTail 43.08\n",
      "Epoch: [001] \t Loss 1.9292 \t Acc 45.01 \t AccHead 49.39 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.4164 \t Acc 50.06 \t AccHead 54.94 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.3222 \t Acc 54.41 \t AccHead 59.70 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.2549 \t Acc 53.57 \t AccHead 58.78 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.2041 \t Acc 55.43 \t AccHead 60.79 \t AccTail 0.10\n",
      "Epoch: [006] \t Loss 1.1478 \t Acc 59.63 \t AccHead 65.41 \t AccTail 0.21\n",
      "Epoch: [007] \t Loss 1.1185 \t Acc 58.46 \t AccHead 64.02 \t AccTail 1.29\n",
      "Epoch: [008] \t Loss 1.1204 \t Acc 62.28 \t AccHead 68.08 \t AccTail 2.58\n",
      "Epoch: [009] \t Loss 1.0985 \t Acc 59.66 \t AccHead 65.36 \t AccTail 0.98\n",
      "Epoch: [010] \t Loss 1.0816 \t Acc 56.31 \t AccHead 61.47 \t AccTail 3.05\n",
      "Epoch: [011] \t Loss 1.0829 \t Acc 59.32 \t AccHead 65.00 \t AccTail 0.88\n",
      "Epoch: [012] \t Loss 1.0701 \t Acc 54.97 \t AccHead 60.22 \t AccTail 0.88\n",
      "Epoch: [013] \t Loss 1.0627 \t Acc 60.31 \t AccHead 66.10 \t AccTail 0.87\n",
      "Epoch: [014] \t Loss 1.0498 \t Acc 58.54 \t AccHead 63.97 \t AccTail 2.63\n",
      "Epoch: [015] \t Loss 1.0430 \t Acc 64.26 \t AccHead 70.18 \t AccTail 3.25\n",
      "Epoch: [016] \t Loss 1.0590 \t Acc 64.18 \t AccHead 70.29 \t AccTail 1.19\n",
      "Epoch: [017] \t Loss 1.0523 \t Acc 54.47 \t AccHead 59.19 \t AccTail 5.93\n",
      "Epoch: [018] \t Loss 1.0643 \t Acc 62.65 \t AccHead 68.44 \t AccTail 3.14\n",
      "Epoch: [019] \t Loss 1.0454 \t Acc 54.77 \t AccHead 59.35 \t AccTail 7.68\n",
      "Epoch: [020] \t Loss 1.0397 \t Acc 55.08 \t AccHead 59.41 \t AccTail 10.47\n",
      "Epoch: [021] \t Loss 1.0227 \t Acc 61.17 \t AccHead 67.09 \t AccTail 0.26\n",
      "Epoch: [022] \t Loss 1.0279 \t Acc 65.10 \t AccHead 70.21 \t AccTail 12.47\n",
      "Epoch: [023] \t Loss 1.0273 \t Acc 57.23 \t AccHead 62.42 \t AccTail 3.76\n",
      "Epoch: [024] \t Loss 1.0507 \t Acc 63.76 \t AccHead 69.67 \t AccTail 2.94\n",
      "Epoch: [025] \t Loss 1.0322 \t Acc 63.24 \t AccHead 68.60 \t AccTail 8.19\n",
      "Epoch: [026] \t Loss 1.0363 \t Acc 61.52 \t AccHead 66.65 \t AccTail 8.86\n",
      "Epoch: [027] \t Loss 1.0354 \t Acc 57.71 \t AccHead 63.12 \t AccTail 2.11\n",
      "Epoch: [028] \t Loss 1.0317 \t Acc 58.48 \t AccHead 63.74 \t AccTail 4.34\n",
      "Epoch: [029] \t Loss 1.0237 \t Acc 61.80 \t AccHead 66.05 \t AccTail 18.13\n",
      "Epoch: [030] \t Loss 1.0338 \t Acc 63.03 \t AccHead 67.98 \t AccTail 12.26\n",
      "Epoch: [031] \t Loss 1.0275 \t Acc 67.08 \t AccHead 72.86 \t AccTail 7.58\n",
      "Epoch: [032] \t Loss 1.0168 \t Acc 63.16 \t AccHead 68.32 \t AccTail 10.10\n",
      "Epoch: [033] \t Loss 1.0227 \t Acc 59.06 \t AccHead 63.11 \t AccTail 17.33\n",
      "Epoch: [034] \t Loss 1.0327 \t Acc 62.30 \t AccHead 66.66 \t AccTail 17.44\n",
      "Epoch: [035] \t Loss 1.0170 \t Acc 61.05 \t AccHead 66.70 \t AccTail 2.94\n",
      "Epoch: [036] \t Loss 1.0360 \t Acc 66.39 \t AccHead 72.59 \t AccTail 2.73\n",
      "Epoch: [037] \t Loss 1.0110 \t Acc 57.65 \t AccHead 62.59 \t AccTail 6.81\n",
      "Epoch: [038] \t Loss 1.0130 \t Acc 62.09 \t AccHead 67.10 \t AccTail 10.57\n",
      "Epoch: [039] \t Loss 1.0057 \t Acc 60.84 \t AccHead 65.34 \t AccTail 14.41\n",
      "Epoch: [040] \t Loss 1.0140 \t Acc 61.64 \t AccHead 66.34 \t AccTail 13.17\n",
      "Epoch: [041] \t Loss 1.0209 \t Acc 63.72 \t AccHead 69.25 \t AccTail 6.91\n",
      "Epoch: [042] \t Loss 1.0141 \t Acc 63.99 \t AccHead 69.20 \t AccTail 10.42\n",
      "Epoch: [043] \t Loss 1.0226 \t Acc 62.29 \t AccHead 68.00 \t AccTail 3.46\n",
      "Epoch: [044] \t Loss 1.0253 \t Acc 59.17 \t AccHead 64.34 \t AccTail 5.89\n",
      "Epoch: [045] \t Loss 1.0160 \t Acc 62.61 \t AccHead 68.01 \t AccTail 7.15\n",
      "Epoch: [046] \t Loss 1.0244 \t Acc 59.48 \t AccHead 65.11 \t AccTail 1.65\n",
      "Epoch: [047] \t Loss 1.0114 \t Acc 56.07 \t AccHead 60.84 \t AccTail 7.07\n",
      "Epoch: [048] \t Loss 1.0125 \t Acc 63.59 \t AccHead 68.82 \t AccTail 9.74\n",
      "Epoch: [049] \t Loss 1.0238 \t Acc 61.60 \t AccHead 66.31 \t AccTail 13.29\n",
      "Epoch: [050] \t Loss 1.0089 \t Acc 52.75 \t AccHead 56.57 \t AccTail 13.47\n",
      "Epoch: [051] \t Loss 1.0124 \t Acc 58.92 \t AccHead 63.83 \t AccTail 8.32\n",
      "Epoch: [052] \t Loss 1.0263 \t Acc 66.70 \t AccHead 71.69 \t AccTail 15.22\n",
      "Epoch: [053] \t Loss 1.0101 \t Acc 60.53 \t AccHead 65.92 \t AccTail 5.10\n",
      "Epoch: [054] \t Loss 1.0306 \t Acc 61.14 \t AccHead 66.27 \t AccTail 8.36\n",
      "Epoch: [055] \t Loss 1.0167 \t Acc 62.87 \t AccHead 68.57 \t AccTail 4.18\n",
      "Epoch: [056] \t Loss 1.0080 \t Acc 63.67 \t AccHead 69.38 \t AccTail 5.15\n",
      "Epoch: [057] \t Loss 1.0059 \t Acc 62.48 \t AccHead 68.12 \t AccTail 4.38\n",
      "Epoch: [058] \t Loss 1.0145 \t Acc 57.92 \t AccHead 61.72 \t AccTail 18.87\n",
      "Epoch: [059] \t Loss 1.0181 \t Acc 61.20 \t AccHead 66.22 \t AccTail 9.54\n",
      "Epoch: [060] \t Loss 1.0198 \t Acc 66.05 \t AccHead 71.99 \t AccTail 5.00\n",
      "Epoch: [061] \t Loss 1.0242 \t Acc 59.15 \t AccHead 64.04 \t AccTail 8.78\n",
      "Epoch: [062] \t Loss 1.0233 \t Acc 61.54 \t AccHead 66.62 \t AccTail 9.37\n",
      "Epoch: [063] \t Loss 1.0196 \t Acc 65.39 \t AccHead 71.45 \t AccTail 3.09\n",
      "Epoch: [064] \t Loss 1.0255 \t Acc 57.51 \t AccHead 62.75 \t AccTail 3.71\n",
      "Epoch: [065] \t Loss 1.0242 \t Acc 56.97 \t AccHead 62.01 \t AccTail 5.05\n",
      "Epoch: [066] \t Loss 1.0272 \t Acc 57.62 \t AccHead 62.32 \t AccTail 9.10\n",
      "Epoch: [067] \t Loss 1.0267 \t Acc 59.11 \t AccHead 63.66 \t AccTail 12.37\n",
      "Epoch: [068] \t Loss 1.0227 \t Acc 59.29 \t AccHead 64.77 \t AccTail 3.04\n",
      "Epoch: [069] \t Loss 1.0256 \t Acc 63.54 \t AccHead 68.68 \t AccTail 10.64\n",
      "Epoch: [070] \t Loss 1.0302 \t Acc 57.06 \t AccHead 61.61 \t AccTail 10.21\n",
      "Epoch: [071] \t Loss 1.0208 \t Acc 62.65 \t AccHead 68.01 \t AccTail 7.53\n",
      "Epoch: [072] \t Loss 1.0498 \t Acc 64.58 \t AccHead 70.40 \t AccTail 4.75\n",
      "Epoch: [073] \t Loss 1.0334 \t Acc 59.03 \t AccHead 63.88 \t AccTail 9.04\n",
      "Epoch: [074] \t Loss 1.0305 \t Acc 57.03 \t AccHead 62.30 \t AccTail 2.84\n",
      "Epoch: [075] \t Loss 1.0213 \t Acc 65.55 \t AccHead 71.29 \t AccTail 6.59\n",
      "Epoch: [076] \t Loss 1.0247 \t Acc 62.41 \t AccHead 68.00 \t AccTail 4.90\n",
      "Epoch: [077] \t Loss 1.0177 \t Acc 57.66 \t AccHead 62.64 \t AccTail 6.40\n",
      "Epoch: [078] \t Loss 1.0256 \t Acc 57.57 \t AccHead 60.59 \t AccTail 26.42\n",
      "Epoch: [079] \t Loss 1.0304 \t Acc 63.04 \t AccHead 68.46 \t AccTail 7.28\n",
      "Epoch: [080] \t Loss 1.0279 \t Acc 63.69 \t AccHead 69.10 \t AccTail 7.91\n",
      "Epoch: [081] \t Loss 1.0171 \t Acc 63.47 \t AccHead 67.76 \t AccTail 19.41\n",
      "Epoch: [082] \t Loss 1.0056 \t Acc 49.75 \t AccHead 53.87 \t AccTail 7.43\n",
      "Epoch: [083] \t Loss 1.0092 \t Acc 60.90 \t AccHead 66.51 \t AccTail 3.15\n",
      "Epoch: [084] \t Loss 1.0254 \t Acc 54.40 \t AccHead 59.44 \t AccTail 2.48\n",
      "Epoch: [085] \t Loss 1.0219 \t Acc 60.64 \t AccHead 65.77 \t AccTail 7.98\n",
      "Epoch: [086] \t Loss 1.0290 \t Acc 63.08 \t AccHead 68.91 \t AccTail 3.25\n",
      "Epoch: [087] \t Loss 1.0134 \t Acc 60.85 \t AccHead 65.40 \t AccTail 14.12\n",
      "Epoch: [088] \t Loss 1.0314 \t Acc 59.98 \t AccHead 65.46 \t AccTail 3.56\n",
      "Epoch: [089] \t Loss 1.0297 \t Acc 61.97 \t AccHead 67.44 \t AccTail 5.72\n",
      "Epoch: [090] \t Loss 1.0371 \t Acc 58.60 \t AccHead 63.02 \t AccTail 13.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 16:39:58,490]\u001b[0m Trial 1 finished with value: 40.272727966308594 and parameters: {'weight_decay': 0.0028880082949761313}. Best is trial 0 with value: 63.54545593261719.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 40.27 \t AccHead 64.10 \t AccTail 15.96\n",
      "Epoch: [001] \t Loss 2.5968 \t Acc 41.83 \t AccHead 45.90 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.5579 \t Acc 48.72 \t AccHead 53.46 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.4341 \t Acc 52.46 \t AccHead 57.56 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.3369 \t Acc 55.00 \t AccHead 60.34 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.2886 \t Acc 55.84 \t AccHead 61.26 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.2365 \t Acc 55.44 \t AccHead 60.76 \t AccTail 0.72\n",
      "Epoch: [007] \t Loss 1.1924 \t Acc 60.23 \t AccHead 65.74 \t AccTail 3.56\n",
      "Epoch: [008] \t Loss 1.1546 \t Acc 62.18 \t AccHead 67.93 \t AccTail 3.04\n",
      "Epoch: [009] \t Loss 1.1101 \t Acc 63.96 \t AccHead 69.91 \t AccTail 2.73\n",
      "Epoch: [010] \t Loss 1.0621 \t Acc 64.15 \t AccHead 69.85 \t AccTail 5.57\n",
      "Epoch: [011] \t Loss 1.0220 \t Acc 65.90 \t AccHead 71.66 \t AccTail 6.70\n",
      "Epoch: [012] \t Loss 0.9919 \t Acc 67.10 \t AccHead 73.15 \t AccTail 4.94\n",
      "Epoch: [013] \t Loss 0.9538 \t Acc 68.91 \t AccHead 74.21 \t AccTail 14.22\n",
      "Epoch: [014] \t Loss 0.9289 \t Acc 70.78 \t AccHead 76.49 \t AccTail 12.12\n",
      "Epoch: [015] \t Loss 0.8927 \t Acc 68.97 \t AccHead 74.71 \t AccTail 10.04\n",
      "Epoch: [016] \t Loss 0.8716 \t Acc 71.54 \t AccHead 77.16 \t AccTail 13.67\n",
      "Epoch: [017] \t Loss 0.8469 \t Acc 72.86 \t AccHead 77.82 \t AccTail 21.79\n",
      "Epoch: [018] \t Loss 0.8250 \t Acc 73.47 \t AccHead 78.39 \t AccTail 22.73\n",
      "Epoch: [019] \t Loss 0.8017 \t Acc 72.81 \t AccHead 77.83 \t AccTail 21.19\n",
      "Epoch: [020] \t Loss 0.7884 \t Acc 75.35 \t AccHead 80.06 \t AccTail 26.90\n",
      "Epoch: [021] \t Loss 0.7594 \t Acc 74.38 \t AccHead 79.66 \t AccTail 20.01\n",
      "Epoch: [022] \t Loss 0.7402 \t Acc 75.37 \t AccHead 79.74 \t AccTail 30.38\n",
      "Epoch: [023] \t Loss 0.7236 \t Acc 74.35 \t AccHead 78.78 \t AccTail 28.83\n",
      "Epoch: [024] \t Loss 0.7069 \t Acc 77.08 \t AccHead 81.58 \t AccTail 30.70\n",
      "Epoch: [025] \t Loss 0.6908 \t Acc 78.53 \t AccHead 83.41 \t AccTail 28.30\n",
      "Epoch: [026] \t Loss 0.6808 \t Acc 78.07 \t AccHead 82.49 \t AccTail 32.51\n",
      "Epoch: [027] \t Loss 0.6683 \t Acc 79.39 \t AccHead 83.53 \t AccTail 36.72\n",
      "Epoch: [028] \t Loss 0.6457 \t Acc 79.41 \t AccHead 83.50 \t AccTail 37.34\n",
      "Epoch: [029] \t Loss 0.6439 \t Acc 77.60 \t AccHead 81.38 \t AccTail 38.71\n",
      "Epoch: [030] \t Loss 0.6270 \t Acc 77.74 \t AccHead 81.89 \t AccTail 35.00\n",
      "Epoch: [031] \t Loss 0.6160 \t Acc 81.47 \t AccHead 85.53 \t AccTail 39.75\n",
      "Epoch: [032] \t Loss 0.5974 \t Acc 80.11 \t AccHead 83.72 \t AccTail 42.87\n",
      "Epoch: [033] \t Loss 0.5879 \t Acc 80.76 \t AccHead 84.47 \t AccTail 42.52\n",
      "Epoch: [034] \t Loss 0.5815 \t Acc 80.45 \t AccHead 84.15 \t AccTail 42.35\n",
      "Epoch: [035] \t Loss 0.5743 \t Acc 81.62 \t AccHead 85.31 \t AccTail 43.62\n",
      "Epoch: [036] \t Loss 0.5589 \t Acc 82.77 \t AccHead 86.69 \t AccTail 42.44\n",
      "Epoch: [037] \t Loss 0.5452 \t Acc 82.73 \t AccHead 86.19 \t AccTail 47.17\n",
      "Epoch: [038] \t Loss 0.5334 \t Acc 82.95 \t AccHead 86.90 \t AccTail 42.12\n",
      "Epoch: [039] \t Loss 0.5220 \t Acc 83.16 \t AccHead 86.86 \t AccTail 45.05\n",
      "Epoch: [040] \t Loss 0.5233 \t Acc 83.61 \t AccHead 86.51 \t AccTail 53.72\n",
      "Epoch: [041] \t Loss 0.4969 \t Acc 84.42 \t AccHead 87.76 \t AccTail 50.08\n",
      "Epoch: [042] \t Loss 0.5099 \t Acc 82.58 \t AccHead 86.41 \t AccTail 43.20\n",
      "Epoch: [043] \t Loss 0.5000 \t Acc 84.68 \t AccHead 88.64 \t AccTail 43.94\n",
      "Epoch: [044] \t Loss 0.4811 \t Acc 84.85 \t AccHead 88.76 \t AccTail 44.64\n",
      "Epoch: [045] \t Loss 0.4676 \t Acc 84.63 \t AccHead 87.83 \t AccTail 51.68\n",
      "Epoch: [046] \t Loss 0.4586 \t Acc 85.29 \t AccHead 88.59 \t AccTail 51.39\n",
      "Epoch: [047] \t Loss 0.4551 \t Acc 86.08 \t AccHead 88.98 \t AccTail 56.19\n",
      "Epoch: [048] \t Loss 0.4425 \t Acc 84.41 \t AccHead 87.19 \t AccTail 55.80\n",
      "Epoch: [049] \t Loss 0.4447 \t Acc 86.12 \t AccHead 89.00 \t AccTail 56.45\n",
      "Epoch: [050] \t Loss 0.4264 \t Acc 86.68 \t AccHead 89.33 \t AccTail 59.44\n",
      "Epoch: [051] \t Loss 0.4329 \t Acc 86.80 \t AccHead 89.60 \t AccTail 58.02\n",
      "Epoch: [052] \t Loss 0.4237 \t Acc 87.34 \t AccHead 89.90 \t AccTail 60.98\n",
      "Epoch: [053] \t Loss 0.4124 \t Acc 87.87 \t AccHead 90.18 \t AccTail 64.09\n",
      "Epoch: [054] \t Loss 0.4042 \t Acc 85.50 \t AccHead 87.57 \t AccTail 64.26\n",
      "Epoch: [055] \t Loss 0.3988 \t Acc 85.59 \t AccHead 88.01 \t AccTail 60.68\n",
      "Epoch: [056] \t Loss 0.3922 \t Acc 87.24 \t AccHead 89.66 \t AccTail 62.26\n",
      "Epoch: [057] \t Loss 0.3875 \t Acc 87.74 \t AccHead 90.31 \t AccTail 61.28\n",
      "Epoch: [058] \t Loss 0.3780 \t Acc 88.39 \t AccHead 90.23 \t AccTail 69.50\n",
      "Epoch: [059] \t Loss 0.3694 \t Acc 87.55 \t AccHead 89.32 \t AccTail 69.35\n",
      "Epoch: [060] \t Loss 0.3636 \t Acc 88.80 \t AccHead 90.82 \t AccTail 68.06\n",
      "Epoch: [061] \t Loss 0.3602 \t Acc 89.41 \t AccHead 91.65 \t AccTail 66.34\n",
      "Epoch: [062] \t Loss 0.3523 \t Acc 89.09 \t AccHead 91.59 \t AccTail 63.45\n",
      "Epoch: [063] \t Loss 0.3455 \t Acc 89.27 \t AccHead 91.37 \t AccTail 67.68\n",
      "Epoch: [064] \t Loss 0.3466 \t Acc 89.62 \t AccHead 91.63 \t AccTail 68.94\n",
      "Epoch: [065] \t Loss 0.3399 \t Acc 89.08 \t AccHead 90.81 \t AccTail 71.27\n",
      "Epoch: [066] \t Loss 0.3342 \t Acc 89.16 \t AccHead 91.28 \t AccTail 67.39\n",
      "Epoch: [067] \t Loss 0.3286 \t Acc 89.05 \t AccHead 91.11 \t AccTail 67.80\n",
      "Epoch: [068] \t Loss 0.3226 \t Acc 90.38 \t AccHead 92.14 \t AccTail 72.30\n",
      "Epoch: [069] \t Loss 0.3156 \t Acc 90.05 \t AccHead 91.61 \t AccTail 74.02\n",
      "Epoch: [070] \t Loss 0.3098 \t Acc 90.83 \t AccHead 92.66 \t AccTail 71.95\n",
      "Epoch: [071] \t Loss 0.3080 \t Acc 90.63 \t AccHead 91.84 \t AccTail 78.18\n",
      "Epoch: [072] \t Loss 0.3009 \t Acc 90.78 \t AccHead 92.65 \t AccTail 71.61\n",
      "Epoch: [073] \t Loss 0.2956 \t Acc 90.86 \t AccHead 92.84 \t AccTail 70.48\n",
      "Epoch: [074] \t Loss 0.2939 \t Acc 90.88 \t AccHead 92.44 \t AccTail 74.83\n",
      "Epoch: [075] \t Loss 0.2816 \t Acc 91.49 \t AccHead 93.18 \t AccTail 74.11\n",
      "Epoch: [076] \t Loss 0.2755 \t Acc 91.64 \t AccHead 93.14 \t AccTail 76.16\n",
      "Epoch: [077] \t Loss 0.2836 \t Acc 91.58 \t AccHead 93.12 \t AccTail 75.66\n",
      "Epoch: [078] \t Loss 0.2717 \t Acc 92.26 \t AccHead 93.71 \t AccTail 77.28\n",
      "Epoch: [079] \t Loss 0.2769 \t Acc 91.07 \t AccHead 92.69 \t AccTail 74.41\n",
      "Epoch: [080] \t Loss 0.2710 \t Acc 91.54 \t AccHead 92.81 \t AccTail 78.51\n",
      "Epoch: [081] \t Loss 0.2568 \t Acc 91.79 \t AccHead 93.33 \t AccTail 75.93\n",
      "Epoch: [082] \t Loss 0.2602 \t Acc 92.13 \t AccHead 92.86 \t AccTail 84.62\n",
      "Epoch: [083] \t Loss 0.2533 \t Acc 92.26 \t AccHead 93.92 \t AccTail 75.14\n",
      "Epoch: [084] \t Loss 0.2415 \t Acc 92.40 \t AccHead 93.41 \t AccTail 81.94\n",
      "Epoch: [085] \t Loss 0.2483 \t Acc 92.24 \t AccHead 93.73 \t AccTail 76.87\n",
      "Epoch: [086] \t Loss 0.2488 \t Acc 93.01 \t AccHead 94.55 \t AccTail 77.12\n",
      "Epoch: [087] \t Loss 0.2379 \t Acc 92.13 \t AccHead 93.85 \t AccTail 74.46\n",
      "Epoch: [088] \t Loss 0.2239 \t Acc 92.30 \t AccHead 93.22 \t AccTail 82.84\n",
      "Epoch: [089] \t Loss 0.2292 \t Acc 92.72 \t AccHead 93.64 \t AccTail 83.16\n",
      "Epoch: [090] \t Loss 0.2307 \t Acc 93.06 \t AccHead 94.12 \t AccTail 82.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 16:56:45,232]\u001b[0m Trial 2 finished with value: 63.30303192138672 and parameters: {'weight_decay': 2.5458692765052378e-05}. Best is trial 0 with value: 63.54545593261719.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 63.30 \t AccHead 83.16 \t AccTail 43.04\n",
      "Epoch: [001] \t Loss 2.3055 \t Acc 43.13 \t AccHead 47.33 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.5125 \t Acc 51.09 \t AccHead 56.06 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.3752 \t Acc 53.62 \t AccHead 58.84 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.2893 \t Acc 57.16 \t AccHead 62.71 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.2368 \t Acc 56.86 \t AccHead 62.34 \t AccTail 0.36\n",
      "Epoch: [006] \t Loss 1.1851 \t Acc 61.39 \t AccHead 67.30 \t AccTail 0.72\n",
      "Epoch: [007] \t Loss 1.1456 \t Acc 63.64 \t AccHead 69.56 \t AccTail 2.73\n",
      "Epoch: [008] \t Loss 1.0962 \t Acc 62.90 \t AccHead 68.71 \t AccTail 3.14\n",
      "Epoch: [009] \t Loss 1.0708 \t Acc 63.61 \t AccHead 69.20 \t AccTail 6.08\n",
      "Epoch: [010] \t Loss 1.0218 \t Acc 67.23 \t AccHead 73.19 \t AccTail 5.98\n",
      "Epoch: [011] \t Loss 0.9808 \t Acc 67.71 \t AccHead 73.44 \t AccTail 8.81\n",
      "Epoch: [012] \t Loss 0.9492 \t Acc 70.71 \t AccHead 76.70 \t AccTail 8.94\n",
      "Epoch: [013] \t Loss 0.9167 \t Acc 69.22 \t AccHead 74.79 \t AccTail 12.00\n",
      "Epoch: [014] \t Loss 0.9034 \t Acc 71.16 \t AccHead 76.86 \t AccTail 12.52\n",
      "Epoch: [015] \t Loss 0.8682 \t Acc 72.21 \t AccHead 77.21 \t AccTail 20.84\n",
      "Epoch: [016] \t Loss 0.8425 \t Acc 72.71 \t AccHead 78.36 \t AccTail 14.50\n",
      "Epoch: [017] \t Loss 0.8162 \t Acc 74.14 \t AccHead 78.91 \t AccTail 25.09\n",
      "Epoch: [018] \t Loss 0.7903 \t Acc 74.68 \t AccHead 79.49 \t AccTail 25.21\n",
      "Epoch: [019] \t Loss 0.7705 \t Acc 74.29 \t AccHead 79.36 \t AccTail 22.03\n",
      "Epoch: [020] \t Loss 0.7601 \t Acc 73.82 \t AccHead 78.46 \t AccTail 26.08\n",
      "Epoch: [021] \t Loss 0.7381 \t Acc 76.74 \t AccHead 81.72 \t AccTail 25.53\n",
      "Epoch: [022] \t Loss 0.7137 \t Acc 77.22 \t AccHead 82.11 \t AccTail 26.91\n",
      "Epoch: [023] \t Loss 0.7063 \t Acc 78.10 \t AccHead 82.75 \t AccTail 30.25\n",
      "Epoch: [024] \t Loss 0.6927 \t Acc 75.91 \t AccHead 80.41 \t AccTail 29.68\n",
      "Epoch: [025] \t Loss 0.6702 \t Acc 79.47 \t AccHead 84.21 \t AccTail 30.69\n",
      "Epoch: [026] \t Loss 0.6553 \t Acc 78.97 \t AccHead 83.70 \t AccTail 30.42\n",
      "Epoch: [027] \t Loss 0.6427 \t Acc 79.69 \t AccHead 83.90 \t AccTail 36.26\n",
      "Epoch: [028] \t Loss 0.6310 \t Acc 80.09 \t AccHead 84.70 \t AccTail 32.73\n",
      "Epoch: [029] \t Loss 0.6224 \t Acc 80.25 \t AccHead 84.56 \t AccTail 35.90\n",
      "Epoch: [030] \t Loss 0.5947 \t Acc 81.73 \t AccHead 85.86 \t AccTail 39.20\n",
      "Epoch: [031] \t Loss 0.5958 \t Acc 81.84 \t AccHead 86.02 \t AccTail 38.81\n",
      "Epoch: [032] \t Loss 0.5844 \t Acc 82.31 \t AccHead 85.95 \t AccTail 44.93\n",
      "Epoch: [033] \t Loss 0.5675 \t Acc 82.25 \t AccHead 86.80 \t AccTail 35.48\n",
      "Epoch: [034] \t Loss 0.5666 \t Acc 81.19 \t AccHead 85.17 \t AccTail 40.28\n",
      "Epoch: [035] \t Loss 0.5455 \t Acc 81.85 \t AccHead 85.32 \t AccTail 46.24\n",
      "Epoch: [036] \t Loss 0.5442 \t Acc 81.85 \t AccHead 85.30 \t AccTail 46.31\n",
      "Epoch: [037] \t Loss 0.5282 \t Acc 82.06 \t AccHead 85.47 \t AccTail 47.06\n",
      "Epoch: [038] \t Loss 0.5211 \t Acc 83.38 \t AccHead 87.35 \t AccTail 42.58\n",
      "Epoch: [039] \t Loss 0.5134 \t Acc 83.21 \t AccHead 85.91 \t AccTail 55.41\n",
      "Epoch: [040] \t Loss 0.5023 \t Acc 84.87 \t AccHead 88.25 \t AccTail 50.15\n",
      "Epoch: [041] \t Loss 0.4995 \t Acc 84.02 \t AccHead 87.76 \t AccTail 45.51\n",
      "Epoch: [042] \t Loss 0.4866 \t Acc 84.19 \t AccHead 87.48 \t AccTail 50.39\n",
      "Epoch: [043] \t Loss 0.4700 \t Acc 84.37 \t AccHead 87.82 \t AccTail 48.87\n",
      "Epoch: [044] \t Loss 0.4689 \t Acc 85.48 \t AccHead 88.57 \t AccTail 53.69\n",
      "Epoch: [045] \t Loss 0.4594 \t Acc 85.91 \t AccHead 88.60 \t AccTail 58.23\n",
      "Epoch: [046] \t Loss 0.4524 \t Acc 86.25 \t AccHead 89.32 \t AccTail 54.63\n",
      "Epoch: [047] \t Loss 0.4512 \t Acc 84.70 \t AccHead 87.81 \t AccTail 52.76\n",
      "Epoch: [048] \t Loss 0.4460 \t Acc 84.84 \t AccHead 87.83 \t AccTail 54.15\n",
      "Epoch: [049] \t Loss 0.4370 \t Acc 86.65 \t AccHead 89.56 \t AccTail 56.69\n",
      "Epoch: [050] \t Loss 0.4309 \t Acc 85.27 \t AccHead 88.42 \t AccTail 52.76\n",
      "Epoch: [051] \t Loss 0.4139 \t Acc 87.58 \t AccHead 90.10 \t AccTail 61.58\n",
      "Epoch: [052] \t Loss 0.4125 \t Acc 86.23 \t AccHead 89.20 \t AccTail 55.69\n",
      "Epoch: [053] \t Loss 0.4048 \t Acc 86.93 \t AccHead 89.61 \t AccTail 59.29\n",
      "Epoch: [054] \t Loss 0.4073 \t Acc 86.69 \t AccHead 89.20 \t AccTail 60.89\n",
      "Epoch: [055] \t Loss 0.4001 \t Acc 86.67 \t AccHead 89.57 \t AccTail 56.76\n",
      "Epoch: [056] \t Loss 0.3873 \t Acc 86.16 \t AccHead 88.28 \t AccTail 64.29\n",
      "Epoch: [057] \t Loss 0.3874 \t Acc 87.51 \t AccHead 90.25 \t AccTail 59.32\n",
      "Epoch: [058] \t Loss 0.3747 \t Acc 87.38 \t AccHead 90.00 \t AccTail 60.38\n",
      "Epoch: [059] \t Loss 0.3710 \t Acc 87.92 \t AccHead 90.94 \t AccTail 56.87\n",
      "Epoch: [060] \t Loss 0.3656 \t Acc 88.29 \t AccHead 90.48 \t AccTail 65.74\n",
      "Epoch: [061] \t Loss 0.3615 \t Acc 87.74 \t AccHead 90.27 \t AccTail 61.78\n",
      "Epoch: [062] \t Loss 0.3577 \t Acc 89.01 \t AccHead 90.86 \t AccTail 69.96\n",
      "Epoch: [063] \t Loss 0.3401 \t Acc 88.11 \t AccHead 90.39 \t AccTail 64.66\n",
      "Epoch: [064] \t Loss 0.3497 \t Acc 88.92 \t AccHead 91.43 \t AccTail 63.15\n",
      "Epoch: [065] \t Loss 0.3490 \t Acc 88.63 \t AccHead 90.90 \t AccTail 65.33\n",
      "Epoch: [066] \t Loss 0.3412 \t Acc 88.87 \t AccHead 91.08 \t AccTail 66.20\n",
      "Epoch: [067] \t Loss 0.3340 \t Acc 89.82 \t AccHead 91.69 \t AccTail 70.55\n",
      "Epoch: [068] \t Loss 0.3312 \t Acc 89.57 \t AccHead 91.52 \t AccTail 69.54\n",
      "Epoch: [069] \t Loss 0.3263 \t Acc 90.01 \t AccHead 91.74 \t AccTail 72.24\n",
      "Epoch: [070] \t Loss 0.3201 \t Acc 88.93 \t AccHead 91.25 \t AccTail 65.10\n",
      "Epoch: [071] \t Loss 0.3107 \t Acc 89.46 \t AccHead 91.35 \t AccTail 70.05\n",
      "Epoch: [072] \t Loss 0.3116 \t Acc 90.34 \t AccHead 92.50 \t AccTail 68.07\n",
      "Epoch: [073] \t Loss 0.2944 \t Acc 90.81 \t AccHead 92.38 \t AccTail 74.61\n",
      "Epoch: [074] \t Loss 0.2966 \t Acc 90.52 \t AccHead 92.23 \t AccTail 72.96\n",
      "Epoch: [075] \t Loss 0.3025 \t Acc 90.16 \t AccHead 92.40 \t AccTail 67.16\n",
      "Epoch: [076] \t Loss 0.2931 \t Acc 90.34 \t AccHead 92.65 \t AccTail 66.65\n",
      "Epoch: [077] \t Loss 0.2996 \t Acc 90.44 \t AccHead 92.22 \t AccTail 72.12\n",
      "Epoch: [078] \t Loss 0.2902 \t Acc 90.57 \t AccHead 92.74 \t AccTail 68.21\n",
      "Epoch: [079] \t Loss 0.2835 \t Acc 91.42 \t AccHead 93.19 \t AccTail 73.31\n",
      "Epoch: [080] \t Loss 0.2791 \t Acc 90.48 \t AccHead 92.33 \t AccTail 71.41\n",
      "Epoch: [081] \t Loss 0.2811 \t Acc 90.64 \t AccHead 91.92 \t AccTail 77.40\n",
      "Epoch: [082] \t Loss 0.2724 \t Acc 91.65 \t AccHead 93.12 \t AccTail 76.50\n",
      "Epoch: [083] \t Loss 0.2633 \t Acc 92.47 \t AccHead 93.68 \t AccTail 80.02\n",
      "Epoch: [084] \t Loss 0.2651 \t Acc 91.58 \t AccHead 93.19 \t AccTail 74.99\n",
      "Epoch: [085] \t Loss 0.2626 \t Acc 91.25 \t AccHead 92.71 \t AccTail 76.31\n",
      "Epoch: [086] \t Loss 0.2538 \t Acc 91.47 \t AccHead 93.08 \t AccTail 74.92\n",
      "Epoch: [087] \t Loss 0.2579 \t Acc 91.23 \t AccHead 92.49 \t AccTail 78.34\n",
      "Epoch: [088] \t Loss 0.2508 \t Acc 92.32 \t AccHead 94.11 \t AccTail 73.87\n",
      "Epoch: [089] \t Loss 0.2500 \t Acc 91.90 \t AccHead 93.05 \t AccTail 80.05\n",
      "Epoch: [090] \t Loss 0.2578 \t Acc 92.26 \t AccHead 93.66 \t AccTail 77.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 17:13:21,008]\u001b[0m Trial 3 finished with value: 64.98989868164062 and parameters: {'weight_decay': 5.190465447448724e-05}. Best is trial 3 with value: 64.98989868164062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 64.99 \t AccHead 84.40 \t AccTail 45.18\n",
      "Epoch: [001] \t Loss 2.3804 \t Acc 38.39 \t AccHead 42.12 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.5776 \t Acc 46.27 \t AccHead 50.77 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.4019 \t Acc 51.89 \t AccHead 56.94 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.3289 \t Acc 53.66 \t AccHead 58.88 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.2669 \t Acc 56.56 \t AccHead 62.05 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.2155 \t Acc 59.86 \t AccHead 65.64 \t AccTail 0.41\n",
      "Epoch: [007] \t Loss 1.1662 \t Acc 61.10 \t AccHead 66.97 \t AccTail 0.72\n",
      "Epoch: [008] \t Loss 1.0945 \t Acc 61.48 \t AccHead 66.93 \t AccTail 5.42\n",
      "Epoch: [009] \t Loss 1.0469 \t Acc 63.67 \t AccHead 69.49 \t AccTail 3.86\n",
      "Epoch: [010] \t Loss 1.0018 \t Acc 67.00 \t AccHead 72.72 \t AccTail 8.24\n",
      "Epoch: [011] \t Loss 0.9727 \t Acc 64.27 \t AccHead 70.07 \t AccTail 4.54\n",
      "Epoch: [012] \t Loss 0.9458 \t Acc 66.00 \t AccHead 72.24 \t AccTail 1.91\n",
      "Epoch: [013] \t Loss 0.9230 \t Acc 65.77 \t AccHead 71.54 \t AccTail 6.25\n",
      "Epoch: [014] \t Loss 0.8949 \t Acc 68.15 \t AccHead 73.64 \t AccTail 11.66\n",
      "Epoch: [015] \t Loss 0.8783 \t Acc 72.18 \t AccHead 77.72 \t AccTail 15.17\n",
      "Epoch: [016] \t Loss 0.8522 \t Acc 72.21 \t AccHead 76.70 \t AccTail 26.04\n",
      "Epoch: [017] \t Loss 0.8368 \t Acc 69.32 \t AccHead 74.58 \t AccTail 15.26\n",
      "Epoch: [018] \t Loss 0.8235 \t Acc 71.76 \t AccHead 77.32 \t AccTail 14.57\n",
      "Epoch: [019] \t Loss 0.8187 \t Acc 73.36 \t AccHead 78.63 \t AccTail 19.22\n",
      "Epoch: [020] \t Loss 0.7967 \t Acc 74.24 \t AccHead 79.84 \t AccTail 16.60\n",
      "Epoch: [021] \t Loss 0.7925 \t Acc 73.20 \t AccHead 78.75 \t AccTail 16.10\n",
      "Epoch: [022] \t Loss 0.7834 \t Acc 75.18 \t AccHead 80.50 \t AccTail 20.53\n",
      "Epoch: [023] \t Loss 0.7632 \t Acc 72.32 \t AccHead 77.60 \t AccTail 18.02\n",
      "Epoch: [024] \t Loss 0.7702 \t Acc 75.30 \t AccHead 80.26 \t AccTail 24.19\n",
      "Epoch: [025] \t Loss 0.7501 \t Acc 71.08 \t AccHead 74.89 \t AccTail 32.03\n",
      "Epoch: [026] \t Loss 0.7419 \t Acc 75.74 \t AccHead 80.25 \t AccTail 29.41\n",
      "Epoch: [027] \t Loss 0.7333 \t Acc 74.04 \t AccHead 79.45 \t AccTail 18.35\n",
      "Epoch: [028] \t Loss 0.7399 \t Acc 76.50 \t AccHead 81.90 \t AccTail 20.98\n",
      "Epoch: [029] \t Loss 0.7242 \t Acc 72.62 \t AccHead 76.97 \t AccTail 27.98\n",
      "Epoch: [030] \t Loss 0.7163 \t Acc 74.63 \t AccHead 79.50 \t AccTail 24.59\n",
      "Epoch: [031] \t Loss 0.7258 \t Acc 71.01 \t AccHead 74.75 \t AccTail 32.65\n",
      "Epoch: [032] \t Loss 0.7174 \t Acc 74.28 \t AccHead 78.20 \t AccTail 33.95\n",
      "Epoch: [033] \t Loss 0.7075 \t Acc 77.42 \t AccHead 82.70 \t AccTail 23.04\n",
      "Epoch: [034] \t Loss 0.6992 \t Acc 77.50 \t AccHead 81.39 \t AccTail 37.61\n",
      "Epoch: [035] \t Loss 0.6943 \t Acc 72.62 \t AccHead 76.42 \t AccTail 33.49\n",
      "Epoch: [036] \t Loss 0.6972 \t Acc 73.64 \t AccHead 78.13 \t AccTail 27.34\n",
      "Epoch: [037] \t Loss 0.6904 \t Acc 76.55 \t AccHead 80.57 \t AccTail 35.14\n",
      "Epoch: [038] \t Loss 0.6954 \t Acc 75.59 \t AccHead 80.18 \t AccTail 28.56\n",
      "Epoch: [039] \t Loss 0.6870 \t Acc 71.66 \t AccHead 74.75 \t AccTail 39.86\n",
      "Epoch: [040] \t Loss 0.6884 \t Acc 78.44 \t AccHead 82.46 \t AccTail 37.06\n",
      "Epoch: [041] \t Loss 0.6842 \t Acc 73.83 \t AccHead 77.81 \t AccTail 32.87\n",
      "Epoch: [042] \t Loss 0.6814 \t Acc 78.44 \t AccHead 82.58 \t AccTail 35.75\n",
      "Epoch: [043] \t Loss 0.6634 \t Acc 78.66 \t AccHead 81.88 \t AccTail 45.57\n",
      "Epoch: [044] \t Loss 0.6615 \t Acc 78.90 \t AccHead 82.84 \t AccTail 38.37\n",
      "Epoch: [045] \t Loss 0.6689 \t Acc 77.59 \t AccHead 81.61 \t AccTail 36.14\n",
      "Epoch: [046] \t Loss 0.6677 \t Acc 77.23 \t AccHead 81.88 \t AccTail 29.45\n",
      "Epoch: [047] \t Loss 0.6748 \t Acc 76.73 \t AccHead 80.22 \t AccTail 40.86\n",
      "Epoch: [048] \t Loss 0.6663 \t Acc 75.14 \t AccHead 79.27 \t AccTail 32.75\n",
      "Epoch: [049] \t Loss 0.6707 \t Acc 73.54 \t AccHead 77.92 \t AccTail 28.42\n",
      "Epoch: [050] \t Loss 0.6554 \t Acc 77.64 \t AccHead 81.77 \t AccTail 35.04\n",
      "Epoch: [051] \t Loss 0.6563 \t Acc 77.07 \t AccHead 81.85 \t AccTail 27.92\n",
      "Epoch: [052] \t Loss 0.6550 \t Acc 76.78 \t AccHead 81.94 \t AccTail 23.76\n",
      "Epoch: [053] \t Loss 0.6586 \t Acc 79.15 \t AccHead 83.36 \t AccTail 35.94\n",
      "Epoch: [054] \t Loss 0.6475 \t Acc 78.73 \t AccHead 82.22 \t AccTail 42.92\n",
      "Epoch: [055] \t Loss 0.6558 \t Acc 78.72 \t AccHead 82.73 \t AccTail 37.41\n",
      "Epoch: [056] \t Loss 0.6441 \t Acc 75.38 \t AccHead 78.31 \t AccTail 45.25\n",
      "Epoch: [057] \t Loss 0.6497 \t Acc 78.70 \t AccHead 83.10 \t AccTail 33.42\n",
      "Epoch: [058] \t Loss 0.6485 \t Acc 78.61 \t AccHead 83.26 \t AccTail 30.67\n",
      "Epoch: [059] \t Loss 0.6482 \t Acc 78.87 \t AccHead 83.50 \t AccTail 31.36\n",
      "Epoch: [060] \t Loss 0.6442 \t Acc 79.52 \t AccHead 83.69 \t AccTail 36.73\n",
      "Epoch: [061] \t Loss 0.6445 \t Acc 79.66 \t AccHead 84.11 \t AccTail 33.83\n",
      "Epoch: [062] \t Loss 0.6337 \t Acc 79.37 \t AccHead 84.08 \t AccTail 30.96\n",
      "Epoch: [063] \t Loss 0.6399 \t Acc 77.22 \t AccHead 80.37 \t AccTail 44.82\n",
      "Epoch: [064] \t Loss 0.6431 \t Acc 78.27 \t AccHead 81.62 \t AccTail 43.73\n",
      "Epoch: [065] \t Loss 0.6426 \t Acc 77.86 \t AccHead 82.48 \t AccTail 30.24\n",
      "Epoch: [066] \t Loss 0.6362 \t Acc 79.47 \t AccHead 83.48 \t AccTail 38.18\n",
      "Epoch: [067] \t Loss 0.6408 \t Acc 71.19 \t AccHead 75.44 \t AccTail 27.41\n",
      "Epoch: [068] \t Loss 0.6449 \t Acc 78.98 \t AccHead 82.00 \t AccTail 47.75\n",
      "Epoch: [069] \t Loss 0.6352 \t Acc 76.94 \t AccHead 81.70 \t AccTail 27.99\n",
      "Epoch: [070] \t Loss 0.6235 \t Acc 74.14 \t AccHead 78.18 \t AccTail 32.63\n",
      "Epoch: [071] \t Loss 0.6337 \t Acc 80.03 \t AccHead 84.55 \t AccTail 33.33\n",
      "Epoch: [072] \t Loss 0.6371 \t Acc 76.11 \t AccHead 80.04 \t AccTail 35.57\n",
      "Epoch: [073] \t Loss 0.6395 \t Acc 74.19 \t AccHead 78.07 \t AccTail 34.19\n",
      "Epoch: [074] \t Loss 0.6339 \t Acc 79.35 \t AccHead 84.08 \t AccTail 30.71\n",
      "Epoch: [075] \t Loss 0.6317 \t Acc 76.64 \t AccHead 79.74 \t AccTail 44.81\n",
      "Epoch: [076] \t Loss 0.6328 \t Acc 77.32 \t AccHead 81.90 \t AccTail 30.17\n",
      "Epoch: [077] \t Loss 0.6203 \t Acc 78.40 \t AccHead 82.75 \t AccTail 33.71\n",
      "Epoch: [078] \t Loss 0.6289 \t Acc 79.18 \t AccHead 82.71 \t AccTail 42.93\n",
      "Epoch: [079] \t Loss 0.6247 \t Acc 78.08 \t AccHead 82.24 \t AccTail 35.34\n",
      "Epoch: [080] \t Loss 0.6302 \t Acc 80.23 \t AccHead 84.07 \t AccTail 40.70\n",
      "Epoch: [081] \t Loss 0.6278 \t Acc 77.80 \t AccHead 82.03 \t AccTail 34.25\n",
      "Epoch: [082] \t Loss 0.6401 \t Acc 74.38 \t AccHead 78.31 \t AccTail 33.97\n",
      "Epoch: [083] \t Loss 0.6224 \t Acc 79.27 \t AccHead 83.37 \t AccTail 37.20\n",
      "Epoch: [084] \t Loss 0.6255 \t Acc 78.23 \t AccHead 81.42 \t AccTail 45.44\n",
      "Epoch: [085] \t Loss 0.6229 \t Acc 77.56 \t AccHead 81.60 \t AccTail 36.01\n",
      "Epoch: [086] \t Loss 0.6260 \t Acc 74.89 \t AccHead 79.00 \t AccTail 32.61\n",
      "Epoch: [087] \t Loss 0.6330 \t Acc 77.60 \t AccHead 81.09 \t AccTail 41.67\n",
      "Epoch: [088] \t Loss 0.6247 \t Acc 77.11 \t AccHead 81.49 \t AccTail 31.91\n",
      "Epoch: [089] \t Loss 0.6241 \t Acc 78.49 \t AccHead 83.10 \t AccTail 31.08\n",
      "Epoch: [090] \t Loss 0.6147 \t Acc 74.31 \t AccHead 79.03 \t AccTail 25.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 17:29:53,605]\u001b[0m Trial 4 finished with value: 52.121212005615234 and parameters: {'weight_decay': 0.0006945173639950066}. Best is trial 3 with value: 64.98989868164062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 52.12 \t AccHead 77.84 \t AccTail 25.88\n",
      "Epoch: [001] \t Loss 2.1839 \t Acc 43.43 \t AccHead 47.65 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.5895 \t Acc 47.41 \t AccHead 52.02 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.3929 \t Acc 53.97 \t AccHead 59.21 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.3158 \t Acc 56.75 \t AccHead 62.27 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.2401 \t Acc 58.90 \t AccHead 64.55 \t AccTail 0.77\n",
      "Epoch: [006] \t Loss 1.1801 \t Acc 59.65 \t AccHead 65.21 \t AccTail 2.48\n",
      "Epoch: [007] \t Loss 1.1347 \t Acc 60.04 \t AccHead 65.64 \t AccTail 2.27\n",
      "Epoch: [008] \t Loss 1.0969 \t Acc 62.60 \t AccHead 68.59 \t AccTail 0.98\n",
      "Epoch: [009] \t Loss 1.0571 \t Acc 65.73 \t AccHead 71.72 \t AccTail 4.12\n",
      "Epoch: [010] \t Loss 1.0128 \t Acc 66.96 \t AccHead 72.77 \t AccTail 7.16\n",
      "Epoch: [011] \t Loss 0.9829 \t Acc 66.33 \t AccHead 71.96 \t AccTail 8.51\n",
      "Epoch: [012] \t Loss 0.9535 \t Acc 69.19 \t AccHead 74.94 \t AccTail 10.10\n",
      "Epoch: [013] \t Loss 0.9231 \t Acc 69.20 \t AccHead 74.38 \t AccTail 15.97\n",
      "Epoch: [014] \t Loss 0.9018 \t Acc 70.93 \t AccHead 75.91 \t AccTail 19.78\n",
      "Epoch: [015] \t Loss 0.8720 \t Acc 72.37 \t AccHead 78.00 \t AccTail 14.49\n",
      "Epoch: [016] \t Loss 0.8443 \t Acc 72.53 \t AccHead 78.27 \t AccTail 13.51\n",
      "Epoch: [017] \t Loss 0.8232 \t Acc 74.03 \t AccHead 79.55 \t AccTail 17.32\n",
      "Epoch: [018] \t Loss 0.8038 \t Acc 74.55 \t AccHead 79.23 \t AccTail 26.35\n",
      "Epoch: [019] \t Loss 0.7733 \t Acc 75.48 \t AccHead 80.82 \t AccTail 20.41\n",
      "Epoch: [020] \t Loss 0.7571 \t Acc 75.79 \t AccHead 80.30 \t AccTail 29.51\n",
      "Epoch: [021] \t Loss 0.7366 \t Acc 75.47 \t AccHead 80.11 \t AccTail 27.69\n",
      "Epoch: [022] \t Loss 0.7266 \t Acc 76.58 \t AccHead 81.01 \t AccTail 31.01\n",
      "Epoch: [023] \t Loss 0.6970 \t Acc 76.89 \t AccHead 81.30 \t AccTail 31.55\n",
      "Epoch: [024] \t Loss 0.6835 \t Acc 78.59 \t AccHead 83.02 \t AccTail 33.02\n",
      "Epoch: [025] \t Loss 0.6727 \t Acc 78.70 \t AccHead 83.48 \t AccTail 29.62\n",
      "Epoch: [026] \t Loss 0.6576 \t Acc 78.70 \t AccHead 82.62 \t AccTail 38.31\n",
      "Epoch: [027] \t Loss 0.6387 \t Acc 79.81 \t AccHead 84.37 \t AccTail 32.85\n",
      "Epoch: [028] \t Loss 0.6279 \t Acc 80.05 \t AccHead 83.85 \t AccTail 41.00\n",
      "Epoch: [029] \t Loss 0.6156 \t Acc 81.09 \t AccHead 85.34 \t AccTail 37.37\n",
      "Epoch: [030] \t Loss 0.6016 \t Acc 81.36 \t AccHead 85.27 \t AccTail 41.00\n",
      "Epoch: [031] \t Loss 0.5938 \t Acc 80.23 \t AccHead 84.29 \t AccTail 38.45\n",
      "Epoch: [032] \t Loss 0.5745 \t Acc 82.19 \t AccHead 86.22 \t AccTail 40.86\n",
      "Epoch: [033] \t Loss 0.5572 \t Acc 82.09 \t AccHead 85.95 \t AccTail 42.35\n",
      "Epoch: [034] \t Loss 0.5539 \t Acc 82.95 \t AccHead 86.47 \t AccTail 46.64\n",
      "Epoch: [035] \t Loss 0.5466 \t Acc 83.14 \t AccHead 87.02 \t AccTail 43.15\n",
      "Epoch: [036] \t Loss 0.5265 \t Acc 83.77 \t AccHead 87.12 \t AccTail 49.30\n",
      "Epoch: [037] \t Loss 0.5223 \t Acc 83.47 \t AccHead 86.52 \t AccTail 52.08\n",
      "Epoch: [038] \t Loss 0.5114 \t Acc 81.21 \t AccHead 84.28 \t AccTail 49.64\n",
      "Epoch: [039] \t Loss 0.5068 \t Acc 84.63 \t AccHead 88.98 \t AccTail 39.93\n",
      "Epoch: [040] \t Loss 0.4857 \t Acc 85.02 \t AccHead 87.96 \t AccTail 54.80\n",
      "Epoch: [041] \t Loss 0.5206 \t Acc 84.47 \t AccHead 87.96 \t AccTail 48.58\n",
      "Epoch: [042] \t Loss 0.4801 \t Acc 84.86 \t AccHead 89.00 \t AccTail 42.34\n",
      "Epoch: [043] \t Loss 0.4721 \t Acc 85.35 \t AccHead 88.35 \t AccTail 54.49\n",
      "Epoch: [044] \t Loss 0.4613 \t Acc 86.22 \t AccHead 89.25 \t AccTail 55.13\n",
      "Epoch: [045] \t Loss 0.4351 \t Acc 86.73 \t AccHead 89.60 \t AccTail 57.19\n",
      "Epoch: [046] \t Loss 0.4385 \t Acc 85.81 \t AccHead 89.56 \t AccTail 47.19\n",
      "Epoch: [047] \t Loss 0.4293 \t Acc 85.71 \t AccHead 88.17 \t AccTail 60.52\n",
      "Epoch: [048] \t Loss 0.4155 \t Acc 86.04 \t AccHead 89.06 \t AccTail 54.99\n",
      "Epoch: [049] \t Loss 0.4148 \t Acc 87.06 \t AccHead 89.69 \t AccTail 59.96\n",
      "Epoch: [050] \t Loss 0.4055 \t Acc 86.53 \t AccHead 89.15 \t AccTail 59.48\n",
      "Epoch: [051] \t Loss 0.3986 \t Acc 85.52 \t AccHead 87.65 \t AccTail 63.61\n",
      "Epoch: [052] \t Loss 0.3951 \t Acc 87.98 \t AccHead 90.86 \t AccTail 58.29\n",
      "Epoch: [053] \t Loss 0.3884 \t Acc 87.81 \t AccHead 90.01 \t AccTail 65.15\n",
      "Epoch: [054] \t Loss 0.3731 \t Acc 88.56 \t AccHead 90.98 \t AccTail 63.76\n",
      "Epoch: [055] \t Loss 0.3697 \t Acc 88.95 \t AccHead 91.26 \t AccTail 65.29\n",
      "Epoch: [056] \t Loss 0.3626 \t Acc 88.94 \t AccHead 91.19 \t AccTail 65.79\n",
      "Epoch: [057] \t Loss 0.3648 \t Acc 88.82 \t AccHead 91.03 \t AccTail 66.06\n",
      "Epoch: [058] \t Loss 0.3543 \t Acc 88.61 \t AccHead 90.93 \t AccTail 64.80\n",
      "Epoch: [059] \t Loss 0.3540 \t Acc 88.89 \t AccHead 91.50 \t AccTail 62.04\n",
      "Epoch: [060] \t Loss 0.3386 \t Acc 88.46 \t AccHead 91.17 \t AccTail 60.59\n",
      "Epoch: [061] \t Loss 0.3380 \t Acc 90.15 \t AccHead 92.41 \t AccTail 66.86\n",
      "Epoch: [062] \t Loss 0.3298 \t Acc 89.57 \t AccHead 91.78 \t AccTail 66.94\n",
      "Epoch: [063] \t Loss 0.3249 \t Acc 90.58 \t AccHead 92.08 \t AccTail 75.10\n",
      "Epoch: [064] \t Loss 0.3142 \t Acc 89.82 \t AccHead 91.37 \t AccTail 73.93\n",
      "Epoch: [065] \t Loss 0.3057 \t Acc 90.05 \t AccHead 91.83 \t AccTail 71.80\n",
      "Epoch: [066] \t Loss 0.2963 \t Acc 90.43 \t AccHead 91.88 \t AccTail 75.52\n",
      "Epoch: [067] \t Loss 0.2963 \t Acc 90.88 \t AccHead 92.35 \t AccTail 75.82\n",
      "Epoch: [068] \t Loss 0.2892 \t Acc 89.69 \t AccHead 91.92 \t AccTail 66.75\n",
      "Epoch: [069] \t Loss 0.2862 \t Acc 91.59 \t AccHead 93.08 \t AccTail 76.25\n",
      "Epoch: [070] \t Loss 0.2817 \t Acc 91.31 \t AccHead 92.56 \t AccTail 78.45\n",
      "Epoch: [071] \t Loss 0.2765 \t Acc 91.85 \t AccHead 93.82 \t AccTail 71.53\n",
      "Epoch: [072] \t Loss 0.2743 \t Acc 91.00 \t AccHead 92.77 \t AccTail 72.72\n",
      "Epoch: [073] \t Loss 0.2692 \t Acc 91.03 \t AccHead 92.48 \t AccTail 76.12\n",
      "Epoch: [074] \t Loss 0.2661 \t Acc 91.63 \t AccHead 93.28 \t AccTail 74.70\n",
      "Epoch: [075] \t Loss 0.2478 \t Acc 91.97 \t AccHead 93.44 \t AccTail 76.79\n",
      "Epoch: [076] \t Loss 0.2492 \t Acc 91.78 \t AccHead 93.18 \t AccTail 77.34\n",
      "Epoch: [077] \t Loss 0.2571 \t Acc 91.70 \t AccHead 93.24 \t AccTail 75.86\n",
      "Epoch: [078] \t Loss 0.2389 \t Acc 92.56 \t AccHead 93.97 \t AccTail 78.09\n",
      "Epoch: [079] \t Loss 0.2412 \t Acc 92.20 \t AccHead 93.39 \t AccTail 79.94\n",
      "Epoch: [080] \t Loss 0.2385 \t Acc 93.20 \t AccHead 94.05 \t AccTail 84.50\n",
      "Epoch: [081] \t Loss 0.2293 \t Acc 93.36 \t AccHead 94.49 \t AccTail 81.71\n",
      "Epoch: [082] \t Loss 0.2312 \t Acc 92.16 \t AccHead 93.25 \t AccTail 80.94\n",
      "Epoch: [083] \t Loss 0.2276 \t Acc 92.90 \t AccHead 93.78 \t AccTail 83.75\n",
      "Epoch: [084] \t Loss 0.2224 \t Acc 93.64 \t AccHead 94.69 \t AccTail 82.79\n",
      "Epoch: [085] \t Loss 0.2149 \t Acc 93.20 \t AccHead 94.51 \t AccTail 79.68\n",
      "Epoch: [086] \t Loss 0.2151 \t Acc 93.67 \t AccHead 94.63 \t AccTail 83.77\n",
      "Epoch: [087] \t Loss 0.2155 \t Acc 92.52 \t AccHead 93.25 \t AccTail 85.05\n",
      "Epoch: [088] \t Loss 0.2122 \t Acc 94.33 \t AccHead 95.22 \t AccTail 85.09\n",
      "Epoch: [089] \t Loss 0.2113 \t Acc 93.19 \t AccHead 93.94 \t AccTail 85.47\n",
      "Epoch: [090] \t Loss 0.2004 \t Acc 94.15 \t AccHead 95.26 \t AccTail 82.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 17:46:26,317]\u001b[0m Trial 5 finished with value: 63.82828140258789 and parameters: {'weight_decay': 1.4097685456529355e-05}. Best is trial 3 with value: 64.98989868164062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 63.83 \t AccHead 84.34 \t AccTail 42.90\n",
      "Epoch: [001] \t Loss 2.2678 \t Acc 22.39 \t AccHead 24.56 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.5789 \t Acc 49.78 \t AccHead 54.63 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.3810 \t Acc 52.01 \t AccHead 57.08 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.2968 \t Acc 53.64 \t AccHead 58.84 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.2473 \t Acc 57.37 \t AccHead 62.94 \t AccTail 0.10\n",
      "Epoch: [006] \t Loss 1.1773 \t Acc 61.12 \t AccHead 67.05 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 1.1064 \t Acc 64.46 \t AccHead 70.57 \t AccTail 1.60\n",
      "Epoch: [008] \t Loss 1.0570 \t Acc 65.19 \t AccHead 71.30 \t AccTail 2.22\n",
      "Epoch: [009] \t Loss 1.0127 \t Acc 66.79 \t AccHead 72.93 \t AccTail 3.81\n",
      "Epoch: [010] \t Loss 0.9743 \t Acc 65.84 \t AccHead 71.93 \t AccTail 3.19\n",
      "Epoch: [011] \t Loss 0.9577 \t Acc 67.38 \t AccHead 72.82 \t AccTail 11.39\n",
      "Epoch: [012] \t Loss 0.9263 \t Acc 69.52 \t AccHead 75.42 \t AccTail 8.86\n",
      "Epoch: [013] \t Loss 0.9066 \t Acc 69.96 \t AccHead 74.96 \t AccTail 18.56\n",
      "Epoch: [014] \t Loss 0.8891 \t Acc 67.00 \t AccHead 72.11 \t AccTail 14.34\n",
      "Epoch: [015] \t Loss 0.8785 \t Acc 69.10 \t AccHead 74.46 \t AccTail 13.97\n",
      "Epoch: [016] \t Loss 0.8545 \t Acc 69.15 \t AccHead 74.32 \t AccTail 15.68\n",
      "Epoch: [017] \t Loss 0.8281 \t Acc 70.64 \t AccHead 75.14 \t AccTail 24.33\n",
      "Epoch: [018] \t Loss 0.8114 \t Acc 69.33 \t AccHead 75.07 \t AccTail 10.31\n",
      "Epoch: [019] \t Loss 0.8055 \t Acc 72.72 \t AccHead 77.56 \t AccTail 22.99\n",
      "Epoch: [020] \t Loss 0.8097 \t Acc 65.92 \t AccHead 70.48 \t AccTail 18.87\n",
      "Epoch: [021] \t Loss 0.7908 \t Acc 70.38 \t AccHead 75.95 \t AccTail 13.12\n",
      "Epoch: [022] \t Loss 0.7787 \t Acc 70.69 \t AccHead 75.79 \t AccTail 18.25\n",
      "Epoch: [023] \t Loss 0.7716 \t Acc 74.74 \t AccHead 79.79 \t AccTail 22.76\n",
      "Epoch: [024] \t Loss 0.7664 \t Acc 73.64 \t AccHead 77.12 \t AccTail 37.80\n",
      "Epoch: [025] \t Loss 0.7623 \t Acc 75.44 \t AccHead 80.43 \t AccTail 23.97\n",
      "Epoch: [026] \t Loss 0.7628 \t Acc 71.73 \t AccHead 76.26 \t AccTail 25.05\n",
      "Epoch: [027] \t Loss 0.7493 \t Acc 74.76 \t AccHead 79.92 \t AccTail 21.63\n",
      "Epoch: [028] \t Loss 0.7570 \t Acc 76.59 \t AccHead 81.85 \t AccTail 22.51\n",
      "Epoch: [029] \t Loss 0.7392 \t Acc 73.34 \t AccHead 78.22 \t AccTail 23.12\n",
      "Epoch: [030] \t Loss 0.7363 \t Acc 73.71 \t AccHead 78.57 \t AccTail 23.79\n",
      "Epoch: [031] \t Loss 0.7354 \t Acc 76.03 \t AccHead 79.93 \t AccTail 35.93\n",
      "Epoch: [032] \t Loss 0.7357 \t Acc 70.64 \t AccHead 74.85 \t AccTail 27.41\n",
      "Epoch: [033] \t Loss 0.7307 \t Acc 74.52 \t AccHead 79.02 \t AccTail 28.15\n",
      "Epoch: [034] \t Loss 0.7195 \t Acc 74.37 \t AccHead 78.00 \t AccTail 37.02\n",
      "Epoch: [035] \t Loss 0.7245 \t Acc 75.17 \t AccHead 79.35 \t AccTail 32.25\n",
      "Epoch: [036] \t Loss 0.7122 \t Acc 73.34 \t AccHead 76.84 \t AccTail 37.30\n",
      "Epoch: [037] \t Loss 0.7103 \t Acc 74.77 \t AccHead 79.75 \t AccTail 23.56\n",
      "Epoch: [038] \t Loss 0.7123 \t Acc 72.31 \t AccHead 76.37 \t AccTail 30.44\n",
      "Epoch: [039] \t Loss 0.7128 \t Acc 74.75 \t AccHead 78.24 \t AccTail 38.90\n",
      "Epoch: [040] \t Loss 0.7117 \t Acc 71.52 \t AccHead 75.80 \t AccTail 27.47\n",
      "Epoch: [041] \t Loss 0.7035 \t Acc 73.95 \t AccHead 78.24 \t AccTail 29.86\n",
      "Epoch: [042] \t Loss 0.7097 \t Acc 74.11 \t AccHead 77.74 \t AccTail 36.80\n",
      "Epoch: [043] \t Loss 0.7081 \t Acc 75.67 \t AccHead 80.71 \t AccTail 23.83\n",
      "Epoch: [044] \t Loss 0.6994 \t Acc 75.83 \t AccHead 80.02 \t AccTail 32.68\n",
      "Epoch: [045] \t Loss 0.7005 \t Acc 74.40 \t AccHead 79.20 \t AccTail 24.99\n",
      "Epoch: [046] \t Loss 0.7082 \t Acc 74.05 \t AccHead 78.58 \t AccTail 27.40\n",
      "Epoch: [047] \t Loss 0.6931 \t Acc 78.01 \t AccHead 83.44 \t AccTail 21.96\n",
      "Epoch: [048] \t Loss 0.6980 \t Acc 74.69 \t AccHead 79.96 \t AccTail 20.53\n",
      "Epoch: [049] \t Loss 0.6886 \t Acc 75.92 \t AccHead 80.44 \t AccTail 29.51\n",
      "Epoch: [050] \t Loss 0.6993 \t Acc 76.67 \t AccHead 81.49 \t AccTail 27.13\n",
      "Epoch: [051] \t Loss 0.6911 \t Acc 76.24 \t AccHead 81.99 \t AccTail 17.07\n",
      "Epoch: [052] \t Loss 0.6953 \t Acc 77.80 \t AccHead 81.86 \t AccTail 36.03\n",
      "Epoch: [053] \t Loss 0.6860 \t Acc 64.62 \t AccHead 68.21 \t AccTail 27.57\n",
      "Epoch: [054] \t Loss 0.6898 \t Acc 74.92 \t AccHead 79.24 \t AccTail 30.59\n",
      "Epoch: [055] \t Loss 0.6919 \t Acc 75.33 \t AccHead 79.42 \t AccTail 33.18\n",
      "Epoch: [056] \t Loss 0.6922 \t Acc 73.97 \t AccHead 77.23 \t AccTail 40.50\n",
      "Epoch: [057] \t Loss 0.6798 \t Acc 74.62 \t AccHead 79.08 \t AccTail 28.81\n",
      "Epoch: [058] \t Loss 0.6687 \t Acc 76.53 \t AccHead 80.79 \t AccTail 32.72\n",
      "Epoch: [059] \t Loss 0.6803 \t Acc 77.69 \t AccHead 81.99 \t AccTail 33.47\n",
      "Epoch: [060] \t Loss 0.6882 \t Acc 77.07 \t AccHead 81.15 \t AccTail 35.07\n",
      "Epoch: [061] \t Loss 0.6717 \t Acc 78.07 \t AccHead 82.90 \t AccTail 28.35\n",
      "Epoch: [062] \t Loss 0.6799 \t Acc 77.78 \t AccHead 81.63 \t AccTail 38.07\n",
      "Epoch: [063] \t Loss 0.6764 \t Acc 77.92 \t AccHead 81.82 \t AccTail 37.74\n",
      "Epoch: [064] \t Loss 0.6695 \t Acc 77.97 \t AccHead 81.72 \t AccTail 39.45\n",
      "Epoch: [065] \t Loss 0.6749 \t Acc 74.90 \t AccHead 78.88 \t AccTail 34.09\n",
      "Epoch: [066] \t Loss 0.6876 \t Acc 78.68 \t AccHead 83.39 \t AccTail 30.26\n",
      "Epoch: [067] \t Loss 0.6754 \t Acc 75.04 \t AccHead 80.02 \t AccTail 23.85\n",
      "Epoch: [068] \t Loss 0.6744 \t Acc 74.19 \t AccHead 77.61 \t AccTail 39.03\n",
      "Epoch: [069] \t Loss 0.6733 \t Acc 76.77 \t AccHead 81.23 \t AccTail 30.77\n",
      "Epoch: [070] \t Loss 0.6776 \t Acc 76.32 \t AccHead 80.07 \t AccTail 37.85\n",
      "Epoch: [071] \t Loss 0.6688 \t Acc 74.22 \t AccHead 77.78 \t AccTail 37.63\n",
      "Epoch: [072] \t Loss 0.6588 \t Acc 74.69 \t AccHead 79.11 \t AccTail 29.17\n",
      "Epoch: [073] \t Loss 0.6663 \t Acc 77.34 \t AccHead 81.41 \t AccTail 35.42\n",
      "Epoch: [074] \t Loss 0.6717 \t Acc 77.38 \t AccHead 81.70 \t AccTail 32.89\n",
      "Epoch: [075] \t Loss 0.6721 \t Acc 74.89 \t AccHead 79.01 \t AccTail 32.60\n",
      "Epoch: [076] \t Loss 0.6625 \t Acc 77.65 \t AccHead 82.37 \t AccTail 29.03\n",
      "Epoch: [077] \t Loss 0.6641 \t Acc 75.49 \t AccHead 79.18 \t AccTail 37.53\n",
      "Epoch: [078] \t Loss 0.6600 \t Acc 78.11 \t AccHead 82.32 \t AccTail 34.73\n",
      "Epoch: [079] \t Loss 0.6754 \t Acc 77.86 \t AccHead 81.78 \t AccTail 37.53\n",
      "Epoch: [080] \t Loss 0.6730 \t Acc 73.99 \t AccHead 77.99 \t AccTail 32.80\n",
      "Epoch: [081] \t Loss 0.6794 \t Acc 78.07 \t AccHead 82.06 \t AccTail 37.07\n",
      "Epoch: [082] \t Loss 0.6628 \t Acc 78.05 \t AccHead 82.24 \t AccTail 34.91\n",
      "Epoch: [083] \t Loss 0.6618 \t Acc 76.75 \t AccHead 81.14 \t AccTail 31.61\n",
      "Epoch: [084] \t Loss 0.6642 \t Acc 76.21 \t AccHead 80.98 \t AccTail 27.13\n",
      "Epoch: [085] \t Loss 0.6547 \t Acc 76.63 \t AccHead 81.39 \t AccTail 27.75\n",
      "Epoch: [086] \t Loss 0.6673 \t Acc 78.07 \t AccHead 83.17 \t AccTail 25.58\n",
      "Epoch: [087] \t Loss 0.6672 \t Acc 76.24 \t AccHead 79.88 \t AccTail 38.80\n",
      "Epoch: [088] \t Loss 0.6619 \t Acc 71.25 \t AccHead 75.67 \t AccTail 25.79\n",
      "Epoch: [089] \t Loss 0.6677 \t Acc 76.49 \t AccHead 79.75 \t AccTail 42.93\n",
      "Epoch: [090] \t Loss 0.6701 \t Acc 77.43 \t AccHead 82.18 \t AccTail 28.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 18:03:03,610]\u001b[0m Trial 6 finished with value: 56.181819915771484 and parameters: {'weight_decay': 0.0008062816179667281}. Best is trial 3 with value: 64.98989868164062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 56.18 \t AccHead 80.68 \t AccTail 31.18\n",
      "Epoch: [001] \t Loss 2.1132 \t Acc 38.74 \t AccHead 42.50 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.4581 \t Acc 50.06 \t AccHead 54.92 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.3431 \t Acc 54.33 \t AccHead 59.62 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.2965 \t Acc 52.53 \t AccHead 57.63 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.2571 \t Acc 54.41 \t AccHead 59.68 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.2117 \t Acc 58.89 \t AccHead 64.61 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 1.1876 \t Acc 58.76 \t AccHead 64.47 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 1.1545 \t Acc 57.26 \t AccHead 62.48 \t AccTail 3.60\n",
      "Epoch: [009] \t Loss 1.1331 \t Acc 55.11 \t AccHead 59.89 \t AccTail 6.02\n",
      "Epoch: [010] \t Loss 1.1217 \t Acc 59.03 \t AccHead 64.71 \t AccTail 0.52\n",
      "Epoch: [011] \t Loss 1.1217 \t Acc 58.56 \t AccHead 64.21 \t AccTail 0.41\n",
      "Epoch: [012] \t Loss 1.0987 \t Acc 56.57 \t AccHead 61.70 \t AccTail 3.87\n",
      "Epoch: [013] \t Loss 1.0975 \t Acc 60.25 \t AccHead 65.43 \t AccTail 7.05\n",
      "Epoch: [014] \t Loss 1.0946 \t Acc 57.97 \t AccHead 63.40 \t AccTail 2.11\n",
      "Epoch: [015] \t Loss 1.0948 \t Acc 59.04 \t AccHead 64.74 \t AccTail 0.46\n",
      "Epoch: [016] \t Loss 1.0972 \t Acc 59.78 \t AccHead 65.59 \t AccTail 0.05\n",
      "Epoch: [017] \t Loss 1.0995 \t Acc 56.33 \t AccHead 61.32 \t AccTail 4.90\n",
      "Epoch: [018] \t Loss 1.0999 \t Acc 48.82 \t AccHead 53.15 \t AccTail 4.38\n",
      "Epoch: [019] \t Loss 1.1032 \t Acc 62.04 \t AccHead 67.49 \t AccTail 6.13\n",
      "Epoch: [020] \t Loss 1.0770 \t Acc 48.79 \t AccHead 52.59 \t AccTail 9.61\n",
      "Epoch: [021] \t Loss 1.0681 \t Acc 47.35 \t AccHead 51.91 \t AccTail 0.36\n",
      "Epoch: [022] \t Loss 1.0887 \t Acc 62.88 \t AccHead 68.91 \t AccTail 0.83\n",
      "Epoch: [023] \t Loss 1.0701 \t Acc 58.65 \t AccHead 63.74 \t AccTail 6.20\n",
      "Epoch: [024] \t Loss 1.0776 \t Acc 62.49 \t AccHead 68.36 \t AccTail 2.06\n",
      "Epoch: [025] \t Loss 1.0915 \t Acc 60.42 \t AccHead 66.11 \t AccTail 1.91\n",
      "Epoch: [026] \t Loss 1.0804 \t Acc 63.75 \t AccHead 68.89 \t AccTail 10.74\n",
      "Epoch: [027] \t Loss 1.0639 \t Acc 61.63 \t AccHead 66.81 \t AccTail 8.31\n",
      "Epoch: [028] \t Loss 1.0729 \t Acc 57.89 \t AccHead 62.96 \t AccTail 5.63\n",
      "Epoch: [029] \t Loss 1.0755 \t Acc 62.45 \t AccHead 68.32 \t AccTail 2.06\n",
      "Epoch: [030] \t Loss 1.0599 \t Acc 63.36 \t AccHead 69.16 \t AccTail 3.81\n",
      "Epoch: [031] \t Loss 1.0676 \t Acc 50.10 \t AccHead 53.79 \t AccTail 12.12\n",
      "Epoch: [032] \t Loss 1.0586 \t Acc 59.33 \t AccHead 64.57 \t AccTail 5.51\n",
      "Epoch: [033] \t Loss 1.0996 \t Acc 54.52 \t AccHead 59.51 \t AccTail 3.20\n",
      "Epoch: [034] \t Loss 1.0748 \t Acc 56.98 \t AccHead 62.33 \t AccTail 1.96\n",
      "Epoch: [035] \t Loss 1.0794 \t Acc 64.20 \t AccHead 70.41 \t AccTail 0.26\n",
      "Epoch: [036] \t Loss 1.0878 \t Acc 60.30 \t AccHead 64.77 \t AccTail 14.34\n",
      "Epoch: [037] \t Loss 1.0837 \t Acc 58.37 \t AccHead 62.37 \t AccTail 17.05\n",
      "Epoch: [038] \t Loss 1.0757 \t Acc 57.68 \t AccHead 62.57 \t AccTail 7.42\n",
      "Epoch: [039] \t Loss 1.0910 \t Acc 65.61 \t AccHead 71.80 \t AccTail 1.96\n",
      "Epoch: [040] \t Loss 1.0748 \t Acc 59.71 \t AccHead 65.20 \t AccTail 3.15\n",
      "Epoch: [041] \t Loss 1.0853 \t Acc 61.78 \t AccHead 66.86 \t AccTail 9.53\n",
      "Epoch: [042] \t Loss 1.0747 \t Acc 56.09 \t AccHead 61.16 \t AccTail 4.02\n",
      "Epoch: [043] \t Loss 1.0709 \t Acc 56.55 \t AccHead 61.31 \t AccTail 7.59\n",
      "Epoch: [044] \t Loss 1.0761 \t Acc 59.19 \t AccHead 64.52 \t AccTail 4.38\n",
      "Epoch: [045] \t Loss 1.0860 \t Acc 48.63 \t AccHead 53.11 \t AccTail 2.58\n",
      "Epoch: [046] \t Loss 1.0635 \t Acc 57.37 \t AccHead 62.86 \t AccTail 0.93\n",
      "Epoch: [047] \t Loss 1.0717 \t Acc 59.06 \t AccHead 64.38 \t AccTail 4.28\n",
      "Epoch: [048] \t Loss 1.0753 \t Acc 54.84 \t AccHead 59.58 \t AccTail 5.99\n",
      "Epoch: [049] \t Loss 1.0765 \t Acc 54.96 \t AccHead 60.01 \t AccTail 3.09\n",
      "Epoch: [050] \t Loss 1.0762 \t Acc 52.65 \t AccHead 57.49 \t AccTail 2.94\n",
      "Epoch: [051] \t Loss 1.0725 \t Acc 54.05 \t AccHead 59.29 \t AccTail 0.15\n",
      "Epoch: [052] \t Loss 1.0824 \t Acc 55.22 \t AccHead 60.29 \t AccTail 2.94\n",
      "Epoch: [053] \t Loss 1.0736 \t Acc 58.71 \t AccHead 64.41 \t AccTail 0.21\n",
      "Epoch: [054] \t Loss 1.0971 \t Acc 55.11 \t AccHead 60.27 \t AccTail 2.06\n",
      "Epoch: [055] \t Loss 1.0955 \t Acc 60.51 \t AccHead 66.06 \t AccTail 3.45\n",
      "Epoch: [056] \t Loss 1.0764 \t Acc 61.21 \t AccHead 65.55 \t AccTail 16.48\n",
      "Epoch: [057] \t Loss 1.0729 \t Acc 60.78 \t AccHead 66.40 \t AccTail 2.94\n",
      "Epoch: [058] \t Loss 1.0837 \t Acc 53.30 \t AccHead 58.28 \t AccTail 2.01\n",
      "Epoch: [059] \t Loss 1.0829 \t Acc 62.89 \t AccHead 68.27 \t AccTail 7.53\n",
      "Epoch: [060] \t Loss 1.0799 \t Acc 59.38 \t AccHead 64.91 \t AccTail 2.58\n",
      "Epoch: [061] \t Loss 1.0951 \t Acc 52.69 \t AccHead 57.42 \t AccTail 3.97\n",
      "Epoch: [062] \t Loss 1.0791 \t Acc 57.66 \t AccHead 62.54 \t AccTail 7.43\n",
      "Epoch: [063] \t Loss 1.0752 \t Acc 60.55 \t AccHead 65.98 \t AccTail 4.55\n",
      "Epoch: [064] \t Loss 1.0791 \t Acc 62.57 \t AccHead 68.50 \t AccTail 1.55\n",
      "Epoch: [065] \t Loss 1.0842 \t Acc 57.81 \t AccHead 63.35 \t AccTail 0.72\n",
      "Epoch: [066] \t Loss 1.0889 \t Acc 61.65 \t AccHead 67.40 \t AccTail 2.58\n",
      "Epoch: [067] \t Loss 1.0812 \t Acc 56.69 \t AccHead 61.55 \t AccTail 6.75\n",
      "Epoch: [068] \t Loss 1.0864 \t Acc 55.85 \t AccHead 60.93 \t AccTail 3.61\n",
      "Epoch: [069] \t Loss 1.0877 \t Acc 56.16 \t AccHead 61.01 \t AccTail 6.25\n",
      "Epoch: [070] \t Loss 1.0926 \t Acc 58.17 \t AccHead 63.27 \t AccTail 5.68\n",
      "Epoch: [071] \t Loss 1.0833 \t Acc 57.00 \t AccHead 62.25 \t AccTail 2.89\n",
      "Epoch: [072] \t Loss 1.0873 \t Acc 50.33 \t AccHead 54.85 \t AccTail 3.82\n",
      "Epoch: [073] \t Loss 1.0933 \t Acc 60.06 \t AccHead 65.72 \t AccTail 1.81\n",
      "Epoch: [074] \t Loss 1.0811 \t Acc 61.71 \t AccHead 67.61 \t AccTail 0.88\n",
      "Epoch: [075] \t Loss 1.0897 \t Acc 59.39 \t AccHead 64.71 \t AccTail 4.69\n",
      "Epoch: [076] \t Loss 1.0681 \t Acc 60.52 \t AccHead 66.01 \t AccTail 4.17\n",
      "Epoch: [077] \t Loss 1.0951 \t Acc 64.06 \t AccHead 69.72 \t AccTail 5.83\n",
      "Epoch: [078] \t Loss 1.0704 \t Acc 59.16 \t AccHead 64.24 \t AccTail 6.95\n",
      "Epoch: [079] \t Loss 1.0682 \t Acc 58.26 \t AccHead 62.21 \t AccTail 17.57\n",
      "Epoch: [080] \t Loss 1.0792 \t Acc 61.30 \t AccHead 67.17 \t AccTail 0.83\n",
      "Epoch: [081] \t Loss 1.0732 \t Acc 58.63 \t AccHead 64.06 \t AccTail 2.88\n",
      "Epoch: [082] \t Loss 1.0817 \t Acc 59.20 \t AccHead 64.69 \t AccTail 2.68\n",
      "Epoch: [083] \t Loss 1.0734 \t Acc 52.81 \t AccHead 57.90 \t AccTail 0.52\n",
      "Epoch: [084] \t Loss 1.0835 \t Acc 55.22 \t AccHead 59.49 \t AccTail 11.20\n",
      "Epoch: [085] \t Loss 1.0846 \t Acc 62.19 \t AccHead 67.97 \t AccTail 2.73\n",
      "Epoch: [086] \t Loss 1.0762 \t Acc 57.89 \t AccHead 63.36 \t AccTail 1.70\n",
      "Epoch: [087] \t Loss 1.0786 \t Acc 60.23 \t AccHead 65.06 \t AccTail 10.56\n",
      "Epoch: [088] \t Loss 1.0811 \t Acc 57.25 \t AccHead 62.54 \t AccTail 2.78\n",
      "Epoch: [089] \t Loss 1.0840 \t Acc 54.37 \t AccHead 59.53 \t AccTail 1.24\n",
      "Epoch: [090] \t Loss 1.0655 \t Acc 54.33 \t AccHead 59.43 \t AccTail 1.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 18:19:44,598]\u001b[0m Trial 7 finished with value: 33.07070541381836 and parameters: {'weight_decay': 0.003320941271394761}. Best is trial 3 with value: 64.98989868164062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 33.07 \t AccHead 61.88 \t AccTail 3.67\n",
      "Epoch: [001] \t Loss 2.4242 \t Acc 35.83 \t AccHead 39.30 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.5649 \t Acc 47.43 \t AccHead 52.02 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.4300 \t Acc 51.32 \t AccHead 56.31 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.3596 \t Acc 51.47 \t AccHead 56.47 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.3145 \t Acc 54.36 \t AccHead 59.65 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.2656 \t Acc 54.47 \t AccHead 59.78 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 1.2200 \t Acc 59.55 \t AccHead 65.32 \t AccTail 0.05\n",
      "Epoch: [008] \t Loss 1.1881 \t Acc 56.27 \t AccHead 61.67 \t AccTail 0.77\n",
      "Epoch: [009] \t Loss 1.1363 \t Acc 61.68 \t AccHead 67.41 \t AccTail 2.78\n",
      "Epoch: [010] \t Loss 1.0999 \t Acc 63.78 \t AccHead 69.91 \t AccTail 0.88\n",
      "Epoch: [011] \t Loss 1.0568 \t Acc 64.88 \t AccHead 70.94 \t AccTail 2.63\n",
      "Epoch: [012] \t Loss 1.0211 \t Acc 66.31 \t AccHead 72.39 \t AccTail 3.86\n",
      "Epoch: [013] \t Loss 0.9959 \t Acc 67.37 \t AccHead 73.47 \t AccTail 4.73\n",
      "Epoch: [014] \t Loss 0.9619 \t Acc 69.10 \t AccHead 74.88 \t AccTail 9.60\n",
      "Epoch: [015] \t Loss 0.9216 \t Acc 69.65 \t AccHead 75.79 \t AccTail 6.45\n",
      "Epoch: [016] \t Loss 0.8925 \t Acc 70.46 \t AccHead 76.19 \t AccTail 11.56\n",
      "Epoch: [017] \t Loss 0.8773 \t Acc 71.91 \t AccHead 77.43 \t AccTail 15.18\n",
      "Epoch: [018] \t Loss 0.8546 \t Acc 72.34 \t AccHead 77.36 \t AccTail 20.57\n",
      "Epoch: [019] \t Loss 0.8261 \t Acc 71.97 \t AccHead 77.31 \t AccTail 17.07\n",
      "Epoch: [020] \t Loss 0.7993 \t Acc 70.99 \t AccHead 76.14 \t AccTail 17.99\n",
      "Epoch: [021] \t Loss 0.7835 \t Acc 73.61 \t AccHead 79.07 \t AccTail 17.56\n",
      "Epoch: [022] \t Loss 0.7659 \t Acc 73.72 \t AccHead 79.15 \t AccTail 17.66\n",
      "Epoch: [023] \t Loss 0.7507 \t Acc 76.51 \t AccHead 81.70 \t AccTail 23.05\n",
      "Epoch: [024] \t Loss 0.7249 \t Acc 77.23 \t AccHead 82.67 \t AccTail 21.24\n",
      "Epoch: [025] \t Loss 0.7177 \t Acc 77.07 \t AccHead 82.22 \t AccTail 24.16\n",
      "Epoch: [026] \t Loss 0.6938 \t Acc 78.60 \t AccHead 83.39 \t AccTail 29.37\n",
      "Epoch: [027] \t Loss 0.6805 \t Acc 78.03 \t AccHead 82.52 \t AccTail 31.80\n",
      "Epoch: [028] \t Loss 0.6605 \t Acc 78.93 \t AccHead 83.52 \t AccTail 31.71\n",
      "Epoch: [029] \t Loss 0.6517 \t Acc 79.30 \t AccHead 83.69 \t AccTail 34.23\n",
      "Epoch: [030] \t Loss 0.6339 \t Acc 77.95 \t AccHead 82.15 \t AccTail 34.66\n",
      "Epoch: [031] \t Loss 0.6242 \t Acc 81.13 \t AccHead 85.30 \t AccTail 38.22\n",
      "Epoch: [032] \t Loss 0.6163 \t Acc 80.14 \t AccHead 84.70 \t AccTail 33.18\n",
      "Epoch: [033] \t Loss 0.5997 \t Acc 81.72 \t AccHead 85.59 \t AccTail 41.83\n",
      "Epoch: [034] \t Loss 0.5955 \t Acc 81.02 \t AccHead 85.14 \t AccTail 38.70\n",
      "Epoch: [035] \t Loss 0.5725 \t Acc 81.17 \t AccHead 85.89 \t AccTail 32.59\n",
      "Epoch: [036] \t Loss 0.5728 \t Acc 81.45 \t AccHead 84.83 \t AccTail 46.63\n",
      "Epoch: [037] \t Loss 0.5508 \t Acc 82.79 \t AccHead 86.59 \t AccTail 43.73\n",
      "Epoch: [038] \t Loss 0.5432 \t Acc 82.61 \t AccHead 86.12 \t AccTail 46.57\n",
      "Epoch: [039] \t Loss 0.5439 \t Acc 82.83 \t AccHead 86.71 \t AccTail 42.94\n",
      "Epoch: [040] \t Loss 0.5256 \t Acc 83.47 \t AccHead 87.21 \t AccTail 44.97\n",
      "Epoch: [041] \t Loss 0.5158 \t Acc 83.67 \t AccHead 87.70 \t AccTail 42.19\n",
      "Epoch: [042] \t Loss 0.5025 \t Acc 84.32 \t AccHead 88.03 \t AccTail 46.07\n",
      "Epoch: [043] \t Loss 0.4973 \t Acc 83.52 \t AccHead 86.88 \t AccTail 49.05\n",
      "Epoch: [044] \t Loss 0.4916 \t Acc 84.20 \t AccHead 87.69 \t AccTail 48.38\n",
      "Epoch: [045] \t Loss 0.4758 \t Acc 83.88 \t AccHead 87.12 \t AccTail 50.59\n",
      "Epoch: [046] \t Loss 0.4788 \t Acc 83.25 \t AccHead 86.53 \t AccTail 49.46\n",
      "Epoch: [047] \t Loss 0.4655 \t Acc 85.23 \t AccHead 88.43 \t AccTail 52.27\n",
      "Epoch: [048] \t Loss 0.4630 \t Acc 83.85 \t AccHead 86.72 \t AccTail 54.43\n",
      "Epoch: [049] \t Loss 0.4508 \t Acc 86.17 \t AccHead 88.95 \t AccTail 57.60\n",
      "Epoch: [050] \t Loss 0.4387 \t Acc 86.20 \t AccHead 89.18 \t AccTail 55.57\n",
      "Epoch: [051] \t Loss 0.4310 \t Acc 87.10 \t AccHead 89.97 \t AccTail 57.62\n",
      "Epoch: [052] \t Loss 0.4237 \t Acc 85.70 \t AccHead 88.82 \t AccTail 53.58\n",
      "Epoch: [053] \t Loss 0.4197 \t Acc 87.01 \t AccHead 90.48 \t AccTail 51.32\n",
      "Epoch: [054] \t Loss 0.4065 \t Acc 85.57 \t AccHead 87.83 \t AccTail 62.28\n",
      "Epoch: [055] \t Loss 0.4080 \t Acc 87.45 \t AccHead 90.31 \t AccTail 58.03\n",
      "Epoch: [056] \t Loss 0.3998 \t Acc 86.47 \t AccHead 89.78 \t AccTail 52.55\n",
      "Epoch: [057] \t Loss 0.3873 \t Acc 87.22 \t AccHead 89.66 \t AccTail 62.00\n",
      "Epoch: [058] \t Loss 0.3885 \t Acc 87.48 \t AccHead 90.01 \t AccTail 61.44\n",
      "Epoch: [059] \t Loss 0.3724 \t Acc 88.28 \t AccHead 91.24 \t AccTail 57.81\n",
      "Epoch: [060] \t Loss 0.3749 \t Acc 87.65 \t AccHead 90.25 \t AccTail 60.92\n",
      "Epoch: [061] \t Loss 0.3582 \t Acc 88.99 \t AccHead 91.52 \t AccTail 62.97\n",
      "Epoch: [062] \t Loss 0.3560 \t Acc 88.16 \t AccHead 90.33 \t AccTail 65.79\n",
      "Epoch: [063] \t Loss 0.3582 \t Acc 88.04 \t AccHead 90.15 \t AccTail 66.34\n",
      "Epoch: [064] \t Loss 0.3493 \t Acc 88.30 \t AccHead 90.25 \t AccTail 68.30\n",
      "Epoch: [065] \t Loss 0.3426 \t Acc 88.45 \t AccHead 90.23 \t AccTail 70.14\n",
      "Epoch: [066] \t Loss 0.3399 \t Acc 89.36 \t AccHead 91.94 \t AccTail 62.83\n",
      "Epoch: [067] \t Loss 0.3348 \t Acc 89.44 \t AccHead 91.32 \t AccTail 70.09\n",
      "Epoch: [068] \t Loss 0.3371 \t Acc 89.65 \t AccHead 92.19 \t AccTail 63.45\n",
      "Epoch: [069] \t Loss 0.3093 \t Acc 89.34 \t AccHead 91.47 \t AccTail 67.37\n",
      "Epoch: [070] \t Loss 0.3153 \t Acc 89.43 \t AccHead 90.86 \t AccTail 74.78\n",
      "Epoch: [071] \t Loss 0.3137 \t Acc 90.04 \t AccHead 92.20 \t AccTail 67.90\n",
      "Epoch: [072] \t Loss 0.3024 \t Acc 90.47 \t AccHead 92.76 \t AccTail 66.89\n",
      "Epoch: [073] \t Loss 0.2967 \t Acc 90.25 \t AccHead 92.10 \t AccTail 71.12\n",
      "Epoch: [074] \t Loss 0.2897 \t Acc 91.15 \t AccHead 92.81 \t AccTail 74.09\n",
      "Epoch: [075] \t Loss 0.2852 \t Acc 91.01 \t AccHead 92.52 \t AccTail 75.55\n",
      "Epoch: [076] \t Loss 0.2922 \t Acc 91.47 \t AccHead 93.60 \t AccTail 69.52\n",
      "Epoch: [077] \t Loss 0.2777 \t Acc 91.69 \t AccHead 93.47 \t AccTail 73.40\n",
      "Epoch: [078] \t Loss 0.2750 \t Acc 92.22 \t AccHead 94.02 \t AccTail 73.64\n",
      "Epoch: [079] \t Loss 0.2753 \t Acc 92.05 \t AccHead 93.61 \t AccTail 75.90\n",
      "Epoch: [080] \t Loss 0.2701 \t Acc 91.92 \t AccHead 93.12 \t AccTail 79.60\n",
      "Epoch: [081] \t Loss 0.2654 \t Acc 92.01 \t AccHead 93.81 \t AccTail 73.56\n",
      "Epoch: [082] \t Loss 0.2542 \t Acc 91.38 \t AccHead 92.70 \t AccTail 77.84\n",
      "Epoch: [083] \t Loss 0.2591 \t Acc 92.62 \t AccHead 93.99 \t AccTail 78.48\n",
      "Epoch: [084] \t Loss 0.2474 \t Acc 92.11 \t AccHead 93.74 \t AccTail 75.39\n",
      "Epoch: [085] \t Loss 0.2426 \t Acc 91.75 \t AccHead 93.75 \t AccTail 71.14\n",
      "Epoch: [086] \t Loss 0.2411 \t Acc 92.69 \t AccHead 94.08 \t AccTail 78.35\n",
      "Epoch: [087] \t Loss 0.2427 \t Acc 92.20 \t AccHead 94.05 \t AccTail 73.15\n",
      "Epoch: [088] \t Loss 0.2412 \t Acc 92.72 \t AccHead 93.96 \t AccTail 79.95\n",
      "Epoch: [089] \t Loss 0.2344 \t Acc 92.18 \t AccHead 93.34 \t AccTail 80.32\n",
      "Epoch: [090] \t Loss 0.2374 \t Acc 90.96 \t AccHead 92.42 \t AccTail 75.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 18:36:08,601]\u001b[0m Trial 8 finished with value: 62.838382720947266 and parameters: {'weight_decay': 2.1791249080876122e-05}. Best is trial 3 with value: 64.98989868164062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 62.84 \t AccHead 83.72 \t AccTail 41.53\n",
      "Epoch: [001] \t Loss 2.5869 \t Acc 42.08 \t AccHead 46.18 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.5668 \t Acc 48.01 \t AccHead 52.67 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.4069 \t Acc 51.70 \t AccHead 56.74 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.3291 \t Acc 54.50 \t AccHead 59.79 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.2735 \t Acc 56.16 \t AccHead 61.61 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.2328 \t Acc 58.56 \t AccHead 64.24 \t AccTail 0.10\n",
      "Epoch: [007] \t Loss 1.1927 \t Acc 58.83 \t AccHead 64.54 \t AccTail 0.05\n",
      "Epoch: [008] \t Loss 1.1558 \t Acc 61.41 \t AccHead 67.33 \t AccTail 0.62\n",
      "Epoch: [009] \t Loss 1.1043 \t Acc 62.65 \t AccHead 68.26 \t AccTail 4.90\n",
      "Epoch: [010] \t Loss 1.0580 \t Acc 64.39 \t AccHead 69.93 \t AccTail 7.42\n",
      "Epoch: [011] \t Loss 1.0231 \t Acc 65.05 \t AccHead 70.87 \t AccTail 5.21\n",
      "Epoch: [012] \t Loss 0.9873 \t Acc 69.15 \t AccHead 74.98 \t AccTail 9.14\n",
      "Epoch: [013] \t Loss 0.9485 \t Acc 68.61 \t AccHead 74.51 \t AccTail 7.98\n",
      "Epoch: [014] \t Loss 0.9121 \t Acc 70.47 \t AccHead 75.57 \t AccTail 18.05\n",
      "Epoch: [015] \t Loss 0.8882 \t Acc 69.99 \t AccHead 75.15 \t AccTail 17.00\n",
      "Epoch: [016] \t Loss 0.8514 \t Acc 70.84 \t AccHead 76.37 \t AccTail 13.96\n",
      "Epoch: [017] \t Loss 0.8404 \t Acc 72.70 \t AccHead 77.76 \t AccTail 20.59\n",
      "Epoch: [018] \t Loss 0.8149 \t Acc 72.72 \t AccHead 77.42 \t AccTail 24.36\n",
      "Epoch: [019] \t Loss 0.7857 \t Acc 73.62 \t AccHead 78.66 \t AccTail 21.83\n",
      "Epoch: [020] \t Loss 0.7740 \t Acc 70.15 \t AccHead 75.04 \t AccTail 19.93\n",
      "Epoch: [021] \t Loss 0.7559 \t Acc 75.79 \t AccHead 80.70 \t AccTail 25.06\n",
      "Epoch: [022] \t Loss 0.7319 \t Acc 76.17 \t AccHead 81.29 \t AccTail 23.52\n",
      "Epoch: [023] \t Loss 0.7243 \t Acc 76.68 \t AccHead 81.54 \t AccTail 26.61\n",
      "Epoch: [024] \t Loss 0.7013 \t Acc 77.68 \t AccHead 81.70 \t AccTail 36.34\n",
      "Epoch: [025] \t Loss 0.6914 \t Acc 75.90 \t AccHead 81.25 \t AccTail 20.89\n",
      "Epoch: [026] \t Loss 0.6698 \t Acc 78.22 \t AccHead 81.83 \t AccTail 41.04\n",
      "Epoch: [027] \t Loss 0.6591 \t Acc 77.45 \t AccHead 83.24 \t AccTail 17.73\n",
      "Epoch: [028] \t Loss 0.6421 \t Acc 75.91 \t AccHead 79.56 \t AccTail 38.37\n",
      "Epoch: [029] \t Loss 0.6341 \t Acc 79.15 \t AccHead 83.10 \t AccTail 38.53\n",
      "Epoch: [030] \t Loss 0.6280 \t Acc 79.63 \t AccHead 83.58 \t AccTail 39.02\n",
      "Epoch: [031] \t Loss 0.6073 \t Acc 80.96 \t AccHead 85.09 \t AccTail 38.39\n",
      "Epoch: [032] \t Loss 0.5940 \t Acc 80.71 \t AccHead 84.71 \t AccTail 39.56\n",
      "Epoch: [033] \t Loss 0.5817 \t Acc 80.35 \t AccHead 83.93 \t AccTail 43.44\n",
      "Epoch: [034] \t Loss 0.5743 \t Acc 81.19 \t AccHead 84.87 \t AccTail 43.32\n",
      "Epoch: [035] \t Loss 0.5683 \t Acc 81.95 \t AccHead 86.44 \t AccTail 35.76\n",
      "Epoch: [036] \t Loss 0.5520 \t Acc 80.91 \t AccHead 85.65 \t AccTail 32.13\n",
      "Epoch: [037] \t Loss 0.5576 \t Acc 82.04 \t AccHead 85.59 \t AccTail 45.48\n",
      "Epoch: [038] \t Loss 0.5367 \t Acc 81.50 \t AccHead 85.25 \t AccTail 42.89\n",
      "Epoch: [039] \t Loss 0.5260 \t Acc 81.01 \t AccHead 84.55 \t AccTail 44.55\n",
      "Epoch: [040] \t Loss 0.5256 \t Acc 82.37 \t AccHead 85.91 \t AccTail 45.90\n",
      "Epoch: [041] \t Loss 0.5273 \t Acc 80.15 \t AccHead 83.29 \t AccTail 47.81\n",
      "Epoch: [042] \t Loss 0.5051 \t Acc 83.67 \t AccHead 87.07 \t AccTail 48.63\n",
      "Epoch: [043] \t Loss 0.5104 \t Acc 82.14 \t AccHead 86.19 \t AccTail 40.52\n",
      "Epoch: [044] \t Loss 0.5010 \t Acc 85.49 \t AccHead 87.98 \t AccTail 59.93\n",
      "Epoch: [045] \t Loss 0.4830 \t Acc 83.98 \t AccHead 86.98 \t AccTail 53.22\n",
      "Epoch: [046] \t Loss 0.4848 \t Acc 83.73 \t AccHead 86.96 \t AccTail 50.34\n",
      "Epoch: [047] \t Loss 0.4803 \t Acc 85.32 \t AccHead 88.78 \t AccTail 49.79\n",
      "Epoch: [048] \t Loss 0.4630 \t Acc 84.45 \t AccHead 87.24 \t AccTail 55.85\n",
      "Epoch: [049] \t Loss 0.4702 \t Acc 82.01 \t AccHead 84.28 \t AccTail 58.72\n",
      "Epoch: [050] \t Loss 0.4588 \t Acc 85.24 \t AccHead 87.76 \t AccTail 59.28\n",
      "Epoch: [051] \t Loss 0.4468 \t Acc 85.44 \t AccHead 88.99 \t AccTail 48.86\n",
      "Epoch: [052] \t Loss 0.4489 \t Acc 85.49 \t AccHead 88.41 \t AccTail 55.44\n",
      "Epoch: [053] \t Loss 0.4466 \t Acc 85.13 \t AccHead 88.17 \t AccTail 53.82\n",
      "Epoch: [054] \t Loss 0.4378 \t Acc 85.54 \t AccHead 88.22 \t AccTail 57.92\n",
      "Epoch: [055] \t Loss 0.4338 \t Acc 85.80 \t AccHead 88.25 \t AccTail 60.60\n",
      "Epoch: [056] \t Loss 0.4358 \t Acc 86.46 \t AccHead 89.86 \t AccTail 51.47\n",
      "Epoch: [057] \t Loss 0.4236 \t Acc 85.25 \t AccHead 88.01 \t AccTail 56.93\n",
      "Epoch: [058] \t Loss 0.4247 \t Acc 85.41 \t AccHead 88.29 \t AccTail 55.85\n",
      "Epoch: [059] \t Loss 0.4172 \t Acc 85.54 \t AccHead 88.06 \t AccTail 59.69\n",
      "Epoch: [060] \t Loss 0.4128 \t Acc 87.01 \t AccHead 90.15 \t AccTail 54.72\n",
      "Epoch: [061] \t Loss 0.4014 \t Acc 86.40 \t AccHead 89.82 \t AccTail 51.16\n",
      "Epoch: [062] \t Loss 0.4006 \t Acc 86.57 \t AccHead 89.44 \t AccTail 57.14\n",
      "Epoch: [063] \t Loss 0.3926 \t Acc 85.84 \t AccHead 88.78 \t AccTail 55.57\n",
      "Epoch: [064] \t Loss 0.3975 \t Acc 87.59 \t AccHead 90.82 \t AccTail 54.36\n",
      "Epoch: [065] \t Loss 0.3984 \t Acc 87.16 \t AccHead 89.95 \t AccTail 58.48\n",
      "Epoch: [066] \t Loss 0.3881 \t Acc 85.69 \t AccHead 88.33 \t AccTail 58.55\n",
      "Epoch: [067] \t Loss 0.3748 \t Acc 87.51 \t AccHead 90.26 \t AccTail 59.23\n",
      "Epoch: [068] \t Loss 0.3813 \t Acc 88.01 \t AccHead 90.47 \t AccTail 62.68\n",
      "Epoch: [069] \t Loss 0.3704 \t Acc 88.26 \t AccHead 90.39 \t AccTail 66.37\n",
      "Epoch: [070] \t Loss 0.3693 \t Acc 88.22 \t AccHead 90.32 \t AccTail 66.65\n",
      "Epoch: [071] \t Loss 0.3784 \t Acc 87.78 \t AccHead 89.76 \t AccTail 67.37\n",
      "Epoch: [072] \t Loss 0.3708 \t Acc 88.35 \t AccHead 91.16 \t AccTail 59.41\n",
      "Epoch: [073] \t Loss 0.3637 \t Acc 87.19 \t AccHead 90.01 \t AccTail 58.12\n",
      "Epoch: [074] \t Loss 0.3690 \t Acc 88.73 \t AccHead 90.35 \t AccTail 72.11\n",
      "Epoch: [075] \t Loss 0.3570 \t Acc 88.78 \t AccHead 91.40 \t AccTail 61.84\n",
      "Epoch: [076] \t Loss 0.3500 \t Acc 88.46 \t AccHead 90.59 \t AccTail 66.62\n",
      "Epoch: [077] \t Loss 0.3509 \t Acc 88.17 \t AccHead 89.74 \t AccTail 72.01\n",
      "Epoch: [078] \t Loss 0.3535 \t Acc 89.09 \t AccHead 90.72 \t AccTail 72.37\n",
      "Epoch: [079] \t Loss 0.3380 \t Acc 86.73 \t AccHead 88.83 \t AccTail 65.10\n",
      "Epoch: [080] \t Loss 0.3424 \t Acc 89.00 \t AccHead 90.71 \t AccTail 71.35\n",
      "Epoch: [081] \t Loss 0.3318 \t Acc 88.69 \t AccHead 91.14 \t AccTail 63.43\n",
      "Epoch: [082] \t Loss 0.3291 \t Acc 86.02 \t AccHead 87.77 \t AccTail 68.08\n",
      "Epoch: [083] \t Loss 0.3399 \t Acc 88.28 \t AccHead 90.63 \t AccTail 64.07\n",
      "Epoch: [084] \t Loss 0.3248 \t Acc 88.88 \t AccHead 90.68 \t AccTail 70.23\n",
      "Epoch: [085] \t Loss 0.3266 \t Acc 88.19 \t AccHead 90.94 \t AccTail 59.95\n",
      "Epoch: [086] \t Loss 0.3276 \t Acc 89.99 \t AccHead 91.79 \t AccTail 71.38\n",
      "Epoch: [087] \t Loss 0.3282 \t Acc 90.17 \t AccHead 92.68 \t AccTail 64.47\n",
      "Epoch: [088] \t Loss 0.3256 \t Acc 88.97 \t AccHead 91.19 \t AccTail 66.10\n",
      "Epoch: [089] \t Loss 0.3174 \t Acc 89.05 \t AccHead 90.71 \t AccTail 71.94\n",
      "Epoch: [090] \t Loss 0.3050 \t Acc 89.01 \t AccHead 91.12 \t AccTail 67.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-16 18:52:53,729]\u001b[0m Trial 9 finished with value: 63.272727966308594 and parameters: {'weight_decay': 0.00012069432561766284}. Best is trial 3 with value: 64.98989868164062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 63.27 \t AccHead 82.48 \t AccTail 43.67\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'CIFAR10' #['CIFAR10', 'CIFAR100']\n",
    "IMB_TYPE = 'step' #['exp', 'step']\n",
    "IMB_FACTOR = 0.1 #[0.1, 0.01]\n",
    "train_loader, test_loader, num_classes = get_loaders()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sampler = optuna.samplers.TPESampler()\n",
    "    study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "    study.optimize(func=train_model, n_trials=10)\n",
    "    joblib.dump(study, 'set_10_step_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52cb8ac1-4aa3-458c-b509-778eec2f0b22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T18:52:53.749141Z",
     "iopub.status.busy": "2022-06-16T18:52:53.748715Z",
     "iopub.status.idle": "2022-06-16T18:52:53.777416Z",
     "shell.execute_reply": "2022-06-16T18:52:53.776582Z",
     "shell.execute_reply.started": "2022-06-16T18:52:53.749089Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>63.545456</td>\n",
       "      <td>0 days 00:16:38.094424</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>40.272728</td>\n",
       "      <td>0 days 00:16:49.030045</td>\n",
       "      <td>0.002888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>63.303032</td>\n",
       "      <td>0 days 00:16:46.738419</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>64.989899</td>\n",
       "      <td>0 days 00:16:35.773399</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>52.121212</td>\n",
       "      <td>0 days 00:16:32.594171</td>\n",
       "      <td>0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>63.828281</td>\n",
       "      <td>0 days 00:16:32.708094</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>56.181820</td>\n",
       "      <td>0 days 00:16:37.289671</td>\n",
       "      <td>0.000806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>33.070705</td>\n",
       "      <td>0 days 00:16:40.985060</td>\n",
       "      <td>0.003321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>62.838383</td>\n",
       "      <td>0 days 00:16:23.999368</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>63.272728</td>\n",
       "      <td>0 days 00:16:45.124516</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number      value               duration  params_weight_decay\n",
       "0       0  63.545456 0 days 00:16:38.094424             0.000272\n",
       "1       1  40.272728 0 days 00:16:49.030045             0.002888\n",
       "2       2  63.303032 0 days 00:16:46.738419             0.000025\n",
       "3       3  64.989899 0 days 00:16:35.773399             0.000052\n",
       "4       4  52.121212 0 days 00:16:32.594171             0.000695\n",
       "5       5  63.828281 0 days 00:16:32.708094             0.000014\n",
       "6       6  56.181820 0 days 00:16:37.289671             0.000806\n",
       "7       7  33.070705 0 days 00:16:40.985060             0.003321\n",
       "8       8  62.838383 0 days 00:16:23.999368             0.000022\n",
       "9       9  63.272728 0 days 00:16:45.124516             0.000121"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = joblib.load('set_10_step_1.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c88771b9-9292-4cef-a5f9-ae31dcd0e738",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T03:58:56.162168Z",
     "iopub.status.busy": "2022-06-17T03:58:56.161699Z",
     "iopub.status.idle": "2022-06-17T03:58:56.173306Z",
     "shell.execute_reply": "2022-06-17T03:58:56.172122Z",
     "shell.execute_reply.started": "2022-06-17T03:58:56.162116Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(trial):\n",
    "    cfg = {\n",
    "        'n_epoch': trial.suggest_categorical('n_epoch', [90, 200]),\n",
    "        'weight_decay': trial.suggest_loguniform('weight_decay', 1e-5, 1e-1),\n",
    "    }\n",
    "\n",
    "    model = ResNet18(num_classes)\n",
    "    model = model.cuda()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=cfg['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=150, gamma=0.1)\n",
    "\n",
    "    train(cfg['n_epoch'], model, train_loader, criterion, optimizer, scheduler)\n",
    "    test_accuracy = test(model, test_loader)\n",
    "    \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90b37bbf-4490-414f-af2e-dfdbb223002a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T03:59:16.161069Z",
     "iopub.status.busy": "2022-06-17T03:59:16.160632Z",
     "iopub.status.idle": "2022-06-17T10:03:08.074765Z",
     "shell.execute_reply": "2022-06-17T10:03:08.073482Z",
     "shell.execute_reply.started": "2022-06-17T03:59:16.161021Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 03:59:53,537]\u001b[0m A new study created in memory with name: no-name-1ab214c3-ed24-4b54-aa4c-479bd490f2bf\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls num list(train_dataset):\n",
      "[4000, 4000, 4000, 4000, 4000, 40, 40, 40, 40, 40]\n",
      "cls num list(val_dataset):\n",
      "[1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]\n",
      "Epoch: [001] \t Loss 1.8358 \t Acc 46.34 \t AccHead 46.73 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.1913 \t Acc 50.63 \t AccHead 51.05 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.1232 \t Acc 53.39 \t AccHead 53.84 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.1030 \t Acc 52.93 \t AccHead 53.37 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.0955 \t Acc 48.13 \t AccHead 48.53 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.0986 \t Acc 52.58 \t AccHead 53.02 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 1.0850 \t Acc 55.49 \t AccHead 55.96 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 1.0658 \t Acc 54.37 \t AccHead 54.83 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 1.0568 \t Acc 45.61 \t AccHead 45.99 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 1.0612 \t Acc 48.83 \t AccHead 49.23 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 1.0593 \t Acc 53.61 \t AccHead 54.06 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 1.0414 \t Acc 59.57 \t AccHead 60.07 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 1.0398 \t Acc 56.60 \t AccHead 57.07 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 1.0455 \t Acc 56.05 \t AccHead 56.52 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 1.0467 \t Acc 54.88 \t AccHead 55.34 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 1.0606 \t Acc 57.77 \t AccHead 58.25 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 1.0641 \t Acc 55.38 \t AccHead 55.84 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 1.0516 \t Acc 43.78 \t AccHead 44.15 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 1.0648 \t Acc 50.07 \t AccHead 50.49 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 1.0670 \t Acc 56.69 \t AccHead 57.17 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 1.0546 \t Acc 54.27 \t AccHead 54.73 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 1.0576 \t Acc 57.43 \t AccHead 57.91 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 1.0578 \t Acc 56.60 \t AccHead 57.08 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 1.0577 \t Acc 40.30 \t AccHead 40.63 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 1.0681 \t Acc 56.00 \t AccHead 56.47 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 1.0513 \t Acc 49.02 \t AccHead 49.44 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 1.0543 \t Acc 53.38 \t AccHead 53.83 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 1.0741 \t Acc 53.47 \t AccHead 53.92 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 1.0677 \t Acc 55.11 \t AccHead 55.57 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 1.0654 \t Acc 53.23 \t AccHead 53.68 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 1.0577 \t Acc 43.89 \t AccHead 44.26 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 1.0690 \t Acc 52.54 \t AccHead 52.98 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 1.0747 \t Acc 59.10 \t AccHead 59.59 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 1.0690 \t Acc 41.77 \t AccHead 42.12 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 1.0688 \t Acc 40.72 \t AccHead 41.07 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 1.0665 \t Acc 51.08 \t AccHead 51.51 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 1.0739 \t Acc 52.64 \t AccHead 53.08 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 1.0794 \t Acc 35.05 \t AccHead 35.34 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 1.0517 \t Acc 55.49 \t AccHead 55.96 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 1.0614 \t Acc 55.22 \t AccHead 55.68 \t AccTail 0.00\n",
      "Epoch: [041] \t Loss 1.0720 \t Acc 53.28 \t AccHead 53.72 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 1.0897 \t Acc 53.93 \t AccHead 54.38 \t AccTail 0.00\n",
      "Epoch: [043] \t Loss 1.0695 \t Acc 56.12 \t AccHead 56.58 \t AccTail 0.00\n",
      "Epoch: [044] \t Loss 1.0659 \t Acc 58.19 \t AccHead 58.68 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 1.0651 \t Acc 53.77 \t AccHead 54.22 \t AccTail 0.00\n",
      "Epoch: [046] \t Loss 1.0602 \t Acc 45.05 \t AccHead 45.43 \t AccTail 0.00\n",
      "Epoch: [047] \t Loss 1.0657 \t Acc 54.11 \t AccHead 54.56 \t AccTail 0.00\n",
      "Epoch: [048] \t Loss 1.0717 \t Acc 46.92 \t AccHead 47.32 \t AccTail 0.00\n",
      "Epoch: [049] \t Loss 1.0837 \t Acc 52.52 \t AccHead 52.95 \t AccTail 0.00\n",
      "Epoch: [050] \t Loss 1.0691 \t Acc 58.14 \t AccHead 58.62 \t AccTail 0.00\n",
      "Epoch: [051] \t Loss 1.0776 \t Acc 53.32 \t AccHead 53.77 \t AccTail 0.00\n",
      "Epoch: [052] \t Loss 1.0793 \t Acc 55.20 \t AccHead 55.66 \t AccTail 0.00\n",
      "Epoch: [053] \t Loss 1.0613 \t Acc 57.97 \t AccHead 58.46 \t AccTail 0.00\n",
      "Epoch: [054] \t Loss 1.0840 \t Acc 51.15 \t AccHead 51.58 \t AccTail 0.00\n",
      "Epoch: [055] \t Loss 1.0748 \t Acc 48.41 \t AccHead 48.80 \t AccTail 0.00\n",
      "Epoch: [056] \t Loss 1.0688 \t Acc 52.00 \t AccHead 52.43 \t AccTail 0.00\n",
      "Epoch: [057] \t Loss 1.0884 \t Acc 50.69 \t AccHead 51.12 \t AccTail 0.00\n",
      "Epoch: [058] \t Loss 1.0884 \t Acc 59.56 \t AccHead 60.06 \t AccTail 0.00\n",
      "Epoch: [059] \t Loss 1.0767 \t Acc 50.01 \t AccHead 50.43 \t AccTail 0.00\n",
      "Epoch: [060] \t Loss 1.0859 \t Acc 50.42 \t AccHead 50.84 \t AccTail 0.00\n",
      "Epoch: [061] \t Loss 1.0796 \t Acc 55.49 \t AccHead 55.95 \t AccTail 0.00\n",
      "Epoch: [062] \t Loss 1.0868 \t Acc 46.51 \t AccHead 46.90 \t AccTail 0.00\n",
      "Epoch: [063] \t Loss 1.0847 \t Acc 53.92 \t AccHead 54.37 \t AccTail 0.00\n",
      "Epoch: [064] \t Loss 1.0764 \t Acc 52.38 \t AccHead 52.82 \t AccTail 0.00\n",
      "Epoch: [065] \t Loss 1.0718 \t Acc 45.24 \t AccHead 45.62 \t AccTail 0.00\n",
      "Epoch: [066] \t Loss 1.0807 \t Acc 50.07 \t AccHead 50.49 \t AccTail 0.00\n",
      "Epoch: [067] \t Loss 1.0842 \t Acc 55.25 \t AccHead 55.71 \t AccTail 0.00\n",
      "Epoch: [068] \t Loss 1.0719 \t Acc 44.89 \t AccHead 45.27 \t AccTail 0.00\n",
      "Epoch: [069] \t Loss 1.0873 \t Acc 55.65 \t AccHead 56.11 \t AccTail 0.00\n",
      "Epoch: [070] \t Loss 1.0856 \t Acc 49.29 \t AccHead 49.71 \t AccTail 0.00\n",
      "Epoch: [071] \t Loss 1.0877 \t Acc 54.85 \t AccHead 55.31 \t AccTail 0.00\n",
      "Epoch: [072] \t Loss 1.0909 \t Acc 54.15 \t AccHead 54.60 \t AccTail 0.00\n",
      "Epoch: [073] \t Loss 1.0909 \t Acc 52.27 \t AccHead 52.71 \t AccTail 0.00\n",
      "Epoch: [074] \t Loss 1.0854 \t Acc 45.31 \t AccHead 45.69 \t AccTail 0.00\n",
      "Epoch: [075] \t Loss 1.0781 \t Acc 52.84 \t AccHead 53.28 \t AccTail 0.00\n",
      "Epoch: [076] \t Loss 1.0984 \t Acc 49.15 \t AccHead 49.56 \t AccTail 0.00\n",
      "Epoch: [077] \t Loss 1.0733 \t Acc 56.23 \t AccHead 56.70 \t AccTail 0.00\n",
      "Epoch: [078] \t Loss 1.0833 \t Acc 57.58 \t AccHead 58.06 \t AccTail 0.00\n",
      "Epoch: [079] \t Loss 1.0967 \t Acc 40.95 \t AccHead 41.29 \t AccTail 0.00\n",
      "Epoch: [080] \t Loss 1.0905 \t Acc 56.12 \t AccHead 56.59 \t AccTail 0.00\n",
      "Epoch: [081] \t Loss 1.0714 \t Acc 54.30 \t AccHead 54.75 \t AccTail 0.00\n",
      "Epoch: [082] \t Loss 1.1010 \t Acc 42.44 \t AccHead 42.79 \t AccTail 0.00\n",
      "Epoch: [083] \t Loss 1.0834 \t Acc 56.32 \t AccHead 56.80 \t AccTail 0.00\n",
      "Epoch: [084] \t Loss 1.0887 \t Acc 57.43 \t AccHead 57.92 \t AccTail 0.00\n",
      "Epoch: [085] \t Loss 1.0904 \t Acc 60.26 \t AccHead 60.76 \t AccTail 0.00\n",
      "Epoch: [086] \t Loss 1.0842 \t Acc 55.39 \t AccHead 55.86 \t AccTail 0.00\n",
      "Epoch: [087] \t Loss 1.1059 \t Acc 49.04 \t AccHead 49.45 \t AccTail 0.00\n",
      "Epoch: [088] \t Loss 1.0939 \t Acc 48.39 \t AccHead 48.79 \t AccTail 0.00\n",
      "Epoch: [089] \t Loss 1.0833 \t Acc 58.90 \t AccHead 59.39 \t AccTail 0.00\n",
      "Epoch: [090] \t Loss 1.0794 \t Acc 59.18 \t AccHead 59.67 \t AccTail 0.00\n",
      "Epoch: [091] \t Loss 1.0819 \t Acc 51.30 \t AccHead 51.73 \t AccTail 0.00\n",
      "Epoch: [092] \t Loss 1.0834 \t Acc 55.66 \t AccHead 56.12 \t AccTail 0.00\n",
      "Epoch: [093] \t Loss 1.0895 \t Acc 55.35 \t AccHead 55.81 \t AccTail 0.00\n",
      "Epoch: [094] \t Loss 1.0842 \t Acc 49.04 \t AccHead 49.45 \t AccTail 0.00\n",
      "Epoch: [095] \t Loss 1.0873 \t Acc 54.33 \t AccHead 54.78 \t AccTail 0.00\n",
      "Epoch: [096] \t Loss 1.0940 \t Acc 56.09 \t AccHead 56.55 \t AccTail 0.00\n",
      "Epoch: [097] \t Loss 1.0895 \t Acc 49.11 \t AccHead 49.52 \t AccTail 0.00\n",
      "Epoch: [098] \t Loss 1.1084 \t Acc 42.65 \t AccHead 43.00 \t AccTail 0.00\n",
      "Epoch: [099] \t Loss 1.0766 \t Acc 52.80 \t AccHead 53.24 \t AccTail 0.00\n",
      "Epoch: [100] \t Loss 1.0993 \t Acc 50.59 \t AccHead 51.01 \t AccTail 0.00\n",
      "Epoch: [101] \t Loss 1.1077 \t Acc 53.56 \t AccHead 54.01 \t AccTail 0.00\n",
      "Epoch: [102] \t Loss 1.0865 \t Acc 48.51 \t AccHead 48.91 \t AccTail 0.00\n",
      "Epoch: [103] \t Loss 1.0816 \t Acc 43.36 \t AccHead 43.72 \t AccTail 0.00\n",
      "Epoch: [104] \t Loss 1.0825 \t Acc 47.39 \t AccHead 47.78 \t AccTail 0.00\n",
      "Epoch: [105] \t Loss 1.0764 \t Acc 58.41 \t AccHead 58.90 \t AccTail 0.00\n",
      "Epoch: [106] \t Loss 1.0979 \t Acc 55.53 \t AccHead 56.00 \t AccTail 0.00\n",
      "Epoch: [107] \t Loss 1.0958 \t Acc 55.38 \t AccHead 55.85 \t AccTail 0.00\n",
      "Epoch: [108] \t Loss 1.0871 \t Acc 43.04 \t AccHead 43.40 \t AccTail 0.00\n",
      "Epoch: [109] \t Loss 1.0840 \t Acc 51.49 \t AccHead 51.92 \t AccTail 0.00\n",
      "Epoch: [110] \t Loss 1.0830 \t Acc 31.50 \t AccHead 31.77 \t AccTail 0.00\n",
      "Epoch: [111] \t Loss 1.0855 \t Acc 42.19 \t AccHead 42.54 \t AccTail 0.00\n",
      "Epoch: [112] \t Loss 1.0993 \t Acc 55.09 \t AccHead 55.55 \t AccTail 0.00\n",
      "Epoch: [113] \t Loss 1.0885 \t Acc 47.29 \t AccHead 47.68 \t AccTail 0.00\n",
      "Epoch: [114] \t Loss 1.1020 \t Acc 50.22 \t AccHead 50.64 \t AccTail 0.00\n",
      "Epoch: [115] \t Loss 1.0902 \t Acc 53.89 \t AccHead 54.34 \t AccTail 0.00\n",
      "Epoch: [116] \t Loss 1.0986 \t Acc 45.78 \t AccHead 46.16 \t AccTail 0.00\n",
      "Epoch: [117] \t Loss 1.0865 \t Acc 54.81 \t AccHead 55.27 \t AccTail 0.00\n",
      "Epoch: [118] \t Loss 1.1013 \t Acc 48.97 \t AccHead 49.39 \t AccTail 0.00\n",
      "Epoch: [119] \t Loss 1.0882 \t Acc 48.47 \t AccHead 48.87 \t AccTail 0.00\n",
      "Epoch: [120] \t Loss 1.0915 \t Acc 56.20 \t AccHead 56.67 \t AccTail 0.00\n",
      "Epoch: [121] \t Loss 1.1012 \t Acc 53.54 \t AccHead 53.99 \t AccTail 0.00\n",
      "Epoch: [122] \t Loss 1.0878 \t Acc 53.75 \t AccHead 54.20 \t AccTail 0.00\n",
      "Epoch: [123] \t Loss 1.0757 \t Acc 55.60 \t AccHead 56.06 \t AccTail 0.00\n",
      "Epoch: [124] \t Loss 1.0872 \t Acc 55.09 \t AccHead 55.54 \t AccTail 0.00\n",
      "Epoch: [125] \t Loss 1.0887 \t Acc 59.69 \t AccHead 60.19 \t AccTail 0.00\n",
      "Epoch: [126] \t Loss 1.0918 \t Acc 37.91 \t AccHead 38.23 \t AccTail 0.00\n",
      "Epoch: [127] \t Loss 1.1009 \t Acc 51.00 \t AccHead 51.43 \t AccTail 0.00\n",
      "Epoch: [128] \t Loss 1.0942 \t Acc 54.46 \t AccHead 54.92 \t AccTail 0.00\n",
      "Epoch: [129] \t Loss 1.1059 \t Acc 51.54 \t AccHead 51.97 \t AccTail 0.00\n",
      "Epoch: [130] \t Loss 1.1115 \t Acc 47.22 \t AccHead 47.61 \t AccTail 0.00\n",
      "Epoch: [131] \t Loss 1.0991 \t Acc 49.54 \t AccHead 49.95 \t AccTail 0.00\n",
      "Epoch: [132] \t Loss 1.0948 \t Acc 49.70 \t AccHead 50.12 \t AccTail 0.00\n",
      "Epoch: [133] \t Loss 1.0918 \t Acc 52.49 \t AccHead 52.93 \t AccTail 0.00\n",
      "Epoch: [134] \t Loss 1.0879 \t Acc 51.52 \t AccHead 51.95 \t AccTail 0.00\n",
      "Epoch: [135] \t Loss 1.0973 \t Acc 51.62 \t AccHead 52.05 \t AccTail 0.00\n",
      "Epoch: [136] \t Loss 1.0955 \t Acc 56.41 \t AccHead 56.88 \t AccTail 0.00\n",
      "Epoch: [137] \t Loss 1.1029 \t Acc 53.69 \t AccHead 54.14 \t AccTail 0.00\n",
      "Epoch: [138] \t Loss 1.0869 \t Acc 55.65 \t AccHead 56.11 \t AccTail 0.00\n",
      "Epoch: [139] \t Loss 1.0994 \t Acc 36.13 \t AccHead 36.43 \t AccTail 0.00\n",
      "Epoch: [140] \t Loss 1.1014 \t Acc 39.71 \t AccHead 40.04 \t AccTail 0.00\n",
      "Epoch: [141] \t Loss 1.0934 \t Acc 52.91 \t AccHead 53.35 \t AccTail 0.00\n",
      "Epoch: [142] \t Loss 1.0982 \t Acc 47.28 \t AccHead 47.68 \t AccTail 0.00\n",
      "Epoch: [143] \t Loss 1.1068 \t Acc 50.92 \t AccHead 51.34 \t AccTail 0.00\n",
      "Epoch: [144] \t Loss 1.0926 \t Acc 56.72 \t AccHead 57.19 \t AccTail 0.00\n",
      "Epoch: [145] \t Loss 1.0974 \t Acc 53.99 \t AccHead 54.44 \t AccTail 0.00\n",
      "Epoch: [146] \t Loss 1.0882 \t Acc 52.38 \t AccHead 52.81 \t AccTail 0.00\n",
      "Epoch: [147] \t Loss 1.1226 \t Acc 47.69 \t AccHead 48.08 \t AccTail 0.00\n",
      "Epoch: [148] \t Loss 1.0929 \t Acc 48.91 \t AccHead 49.32 \t AccTail 0.00\n",
      "Epoch: [149] \t Loss 1.0873 \t Acc 50.58 \t AccHead 51.00 \t AccTail 0.00\n",
      "Epoch: [150] \t Loss 1.0985 \t Acc 40.64 \t AccHead 40.99 \t AccTail 0.00\n",
      "Epoch: [151] \t Loss 0.9663 \t Acc 66.00 \t AccHead 66.56 \t AccTail 0.00\n",
      "Epoch: [152] \t Loss 0.9074 \t Acc 65.90 \t AccHead 66.45 \t AccTail 0.00\n",
      "Epoch: [153] \t Loss 0.8934 \t Acc 66.16 \t AccHead 66.71 \t AccTail 0.00\n",
      "Epoch: [154] \t Loss 0.8789 \t Acc 67.51 \t AccHead 68.07 \t AccTail 0.00\n",
      "Epoch: [155] \t Loss 0.8788 \t Acc 64.94 \t AccHead 65.48 \t AccTail 0.00\n",
      "Epoch: [156] \t Loss 0.8731 \t Acc 65.02 \t AccHead 65.57 \t AccTail 0.00\n",
      "Epoch: [157] \t Loss 0.8709 \t Acc 66.06 \t AccHead 66.61 \t AccTail 0.00\n",
      "Epoch: [158] \t Loss 0.8666 \t Acc 64.89 \t AccHead 65.43 \t AccTail 0.00\n",
      "Epoch: [159] \t Loss 0.8707 \t Acc 66.60 \t AccHead 67.16 \t AccTail 0.00\n",
      "Epoch: [160] \t Loss 0.8595 \t Acc 67.21 \t AccHead 67.78 \t AccTail 0.00\n",
      "Epoch: [161] \t Loss 0.8572 \t Acc 67.15 \t AccHead 67.71 \t AccTail 0.00\n",
      "Epoch: [162] \t Loss 0.8532 \t Acc 67.03 \t AccHead 67.59 \t AccTail 0.00\n",
      "Epoch: [163] \t Loss 0.8516 \t Acc 67.64 \t AccHead 68.21 \t AccTail 0.00\n",
      "Epoch: [164] \t Loss 0.8496 \t Acc 66.48 \t AccHead 67.03 \t AccTail 0.00\n",
      "Epoch: [165] \t Loss 0.8465 \t Acc 67.87 \t AccHead 68.44 \t AccTail 0.00\n",
      "Epoch: [166] \t Loss 0.8331 \t Acc 69.18 \t AccHead 69.76 \t AccTail 0.00\n",
      "Epoch: [167] \t Loss 0.8361 \t Acc 70.20 \t AccHead 70.79 \t AccTail 0.00\n",
      "Epoch: [168] \t Loss 0.8341 \t Acc 69.58 \t AccHead 70.16 \t AccTail 0.00\n",
      "Epoch: [169] \t Loss 0.8344 \t Acc 65.29 \t AccHead 65.83 \t AccTail 0.00\n",
      "Epoch: [170] \t Loss 0.8283 \t Acc 69.08 \t AccHead 69.66 \t AccTail 0.00\n",
      "Epoch: [171] \t Loss 0.8163 \t Acc 69.33 \t AccHead 69.89 \t AccTail 0.00\n",
      "Epoch: [172] \t Loss 0.8228 \t Acc 67.32 \t AccHead 67.88 \t AccTail 0.00\n",
      "Epoch: [173] \t Loss 0.8182 \t Acc 70.03 \t AccHead 70.61 \t AccTail 0.00\n",
      "Epoch: [174] \t Loss 0.8177 \t Acc 69.18 \t AccHead 69.76 \t AccTail 0.00\n",
      "Epoch: [175] \t Loss 0.8126 \t Acc 68.99 \t AccHead 69.56 \t AccTail 0.00\n",
      "Epoch: [176] \t Loss 0.8152 \t Acc 69.13 \t AccHead 69.70 \t AccTail 0.00\n",
      "Epoch: [177] \t Loss 0.8133 \t Acc 65.08 \t AccHead 65.63 \t AccTail 0.00\n",
      "Epoch: [178] \t Loss 0.8131 \t Acc 69.02 \t AccHead 69.59 \t AccTail 0.00\n",
      "Epoch: [179] \t Loss 0.8113 \t Acc 62.76 \t AccHead 63.28 \t AccTail 0.00\n",
      "Epoch: [180] \t Loss 0.8093 \t Acc 70.44 \t AccHead 71.03 \t AccTail 0.00\n",
      "Epoch: [181] \t Loss 0.8121 \t Acc 70.15 \t AccHead 70.73 \t AccTail 0.00\n",
      "Epoch: [182] \t Loss 0.8039 \t Acc 69.02 \t AccHead 69.60 \t AccTail 0.00\n",
      "Epoch: [183] \t Loss 0.8100 \t Acc 66.73 \t AccHead 67.29 \t AccTail 0.00\n",
      "Epoch: [184] \t Loss 0.8072 \t Acc 69.74 \t AccHead 70.32 \t AccTail 0.00\n",
      "Epoch: [185] \t Loss 0.8114 \t Acc 68.36 \t AccHead 68.93 \t AccTail 0.00\n",
      "Epoch: [186] \t Loss 0.8080 \t Acc 69.09 \t AccHead 69.67 \t AccTail 0.00\n",
      "Epoch: [187] \t Loss 0.8002 \t Acc 67.73 \t AccHead 68.30 \t AccTail 0.00\n",
      "Epoch: [188] \t Loss 0.7960 \t Acc 65.12 \t AccHead 65.66 \t AccTail 0.00\n",
      "Epoch: [189] \t Loss 0.8025 \t Acc 69.69 \t AccHead 70.27 \t AccTail 0.00\n",
      "Epoch: [190] \t Loss 0.7938 \t Acc 70.84 \t AccHead 71.44 \t AccTail 0.00\n",
      "Epoch: [191] \t Loss 0.7915 \t Acc 71.10 \t AccHead 71.70 \t AccTail 0.00\n",
      "Epoch: [192] \t Loss 0.7927 \t Acc 66.65 \t AccHead 67.20 \t AccTail 0.00\n",
      "Epoch: [193] \t Loss 0.7923 \t Acc 69.23 \t AccHead 69.81 \t AccTail 0.00\n",
      "Epoch: [194] \t Loss 0.7987 \t Acc 67.07 \t AccHead 67.63 \t AccTail 0.00\n",
      "Epoch: [195] \t Loss 0.7901 \t Acc 63.74 \t AccHead 64.27 \t AccTail 0.00\n",
      "Epoch: [196] \t Loss 0.7878 \t Acc 71.84 \t AccHead 72.44 \t AccTail 0.00\n",
      "Epoch: [197] \t Loss 0.7908 \t Acc 68.32 \t AccHead 68.89 \t AccTail 0.00\n",
      "Epoch: [198] \t Loss 0.7874 \t Acc 62.39 \t AccHead 62.91 \t AccTail 0.00\n",
      "Epoch: [199] \t Loss 0.7957 \t Acc 68.03 \t AccHead 68.60 \t AccTail 0.00\n",
      "Epoch: [200] \t Loss 0.8024 \t Acc 72.30 \t AccHead 72.91 \t AccTail 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 04:35:08,914]\u001b[0m Trial 0 finished with value: 35.33515548706055 and parameters: {'n_epoch': 200, 'weight_decay': 0.007381922467256987}. Best is trial 0 with value: 35.33515548706055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 35.34 \t AccHead 69.90 \t AccTail 0.00\n",
      "Epoch: [001] \t Loss 2.2022 \t Acc 37.07 \t AccHead 37.38 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.3420 \t Acc 53.99 \t AccHead 54.44 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.1420 \t Acc 56.05 \t AccHead 56.51 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.0641 \t Acc 59.01 \t AccHead 59.50 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.0092 \t Acc 63.43 \t AccHead 63.96 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 0.9587 \t Acc 62.31 \t AccHead 62.83 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 0.9082 \t Acc 68.30 \t AccHead 68.87 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 0.8511 \t Acc 69.25 \t AccHead 69.83 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 0.8218 \t Acc 72.76 \t AccHead 73.37 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 0.7763 \t Acc 72.69 \t AccHead 73.30 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 0.7442 \t Acc 74.85 \t AccHead 75.48 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 0.7259 \t Acc 71.86 \t AccHead 72.46 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 0.6984 \t Acc 75.30 \t AccHead 75.93 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 0.6696 \t Acc 75.66 \t AccHead 76.29 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 0.6458 \t Acc 77.65 \t AccHead 78.30 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 0.6272 \t Acc 78.30 \t AccHead 78.96 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 0.5998 \t Acc 78.71 \t AccHead 79.37 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 0.5900 \t Acc 79.72 \t AccHead 80.39 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 0.5762 \t Acc 80.23 \t AccHead 80.91 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 0.5581 \t Acc 80.47 \t AccHead 81.14 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 0.5492 \t Acc 81.24 \t AccHead 81.91 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 0.5424 \t Acc 82.76 \t AccHead 83.45 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 0.5162 \t Acc 80.58 \t AccHead 81.25 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 0.5134 \t Acc 82.78 \t AccHead 83.48 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 0.5072 \t Acc 81.85 \t AccHead 82.54 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 0.5025 \t Acc 84.63 \t AccHead 85.33 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 0.4835 \t Acc 82.69 \t AccHead 83.38 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 0.4826 \t Acc 82.32 \t AccHead 83.00 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 0.4848 \t Acc 83.03 \t AccHead 83.72 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 0.4690 \t Acc 84.80 \t AccHead 85.51 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 0.4574 \t Acc 82.52 \t AccHead 83.21 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 0.4472 \t Acc 86.31 \t AccHead 87.03 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 0.4495 \t Acc 84.38 \t AccHead 85.08 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 0.4411 \t Acc 83.45 \t AccHead 84.14 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 0.4459 \t Acc 85.76 \t AccHead 86.48 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 0.4379 \t Acc 83.81 \t AccHead 84.50 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 0.4361 \t Acc 86.52 \t AccHead 87.24 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 0.4156 \t Acc 84.36 \t AccHead 85.06 \t AccTail 0.60\n",
      "Epoch: [039] \t Loss 0.4202 \t Acc 84.67 \t AccHead 85.38 \t AccTail 0.60\n",
      "Epoch: [040] \t Loss 0.4123 \t Acc 85.73 \t AccHead 86.42 \t AccTail 2.41\n",
      "Epoch: [041] \t Loss 0.4158 \t Acc 85.94 \t AccHead 86.64 \t AccTail 1.21\n",
      "Epoch: [042] \t Loss 0.4040 \t Acc 85.60 \t AccHead 86.27 \t AccTail 5.99\n",
      "Epoch: [043] \t Loss 0.4071 \t Acc 84.16 \t AccHead 84.84 \t AccTail 1.81\n",
      "Epoch: [044] \t Loss 0.4061 \t Acc 87.09 \t AccHead 87.80 \t AccTail 2.40\n",
      "Epoch: [045] \t Loss 0.3922 \t Acc 86.00 \t AccHead 86.68 \t AccTail 4.79\n",
      "Epoch: [046] \t Loss 0.3971 \t Acc 86.08 \t AccHead 86.78 \t AccTail 1.81\n",
      "Epoch: [047] \t Loss 0.3961 \t Acc 86.23 \t AccHead 86.95 \t AccTail 0.60\n",
      "Epoch: [048] \t Loss 0.3825 \t Acc 84.95 \t AccHead 85.65 \t AccTail 1.80\n",
      "Epoch: [049] \t Loss 0.3863 \t Acc 87.89 \t AccHead 88.59 \t AccTail 2.45\n",
      "Epoch: [050] \t Loss 0.3745 \t Acc 87.41 \t AccHead 88.11 \t AccTail 3.59\n",
      "Epoch: [051] \t Loss 0.3751 \t Acc 86.84 \t AccHead 87.49 \t AccTail 9.64\n",
      "Epoch: [052] \t Loss 0.3747 \t Acc 88.01 \t AccHead 88.65 \t AccTail 10.78\n",
      "Epoch: [053] \t Loss 0.3759 \t Acc 87.88 \t AccHead 88.55 \t AccTail 7.19\n",
      "Epoch: [054] \t Loss 0.3721 \t Acc 86.62 \t AccHead 87.30 \t AccTail 4.82\n",
      "Epoch: [055] \t Loss 0.3622 \t Acc 88.10 \t AccHead 88.80 \t AccTail 5.39\n",
      "Epoch: [056] \t Loss 0.3712 \t Acc 88.67 \t AccHead 89.41 \t AccTail 1.20\n",
      "Epoch: [057] \t Loss 0.3640 \t Acc 87.31 \t AccHead 87.91 \t AccTail 15.57\n",
      "Epoch: [058] \t Loss 0.3671 \t Acc 87.37 \t AccHead 88.01 \t AccTail 9.64\n",
      "Epoch: [059] \t Loss 0.3620 \t Acc 89.51 \t AccHead 90.25 \t AccTail 0.60\n",
      "Epoch: [060] \t Loss 0.3591 \t Acc 88.37 \t AccHead 89.04 \t AccTail 8.38\n",
      "Epoch: [061] \t Loss 0.3559 \t Acc 85.33 \t AccHead 85.93 \t AccTail 14.37\n",
      "Epoch: [062] \t Loss 0.3562 \t Acc 89.16 \t AccHead 89.82 \t AccTail 10.24\n",
      "Epoch: [063] \t Loss 0.3520 \t Acc 88.20 \t AccHead 88.90 \t AccTail 4.19\n",
      "Epoch: [064] \t Loss 0.3505 \t Acc 85.71 \t AccHead 86.28 \t AccTail 17.47\n",
      "Epoch: [065] \t Loss 0.3510 \t Acc 88.56 \t AccHead 89.16 \t AccTail 17.37\n",
      "Epoch: [066] \t Loss 0.3468 \t Acc 89.33 \t AccHead 90.00 \t AccTail 9.04\n",
      "Epoch: [067] \t Loss 0.3410 \t Acc 87.65 \t AccHead 88.23 \t AccTail 17.96\n",
      "Epoch: [068] \t Loss 0.3411 \t Acc 89.59 \t AccHead 90.26 \t AccTail 9.15\n",
      "Epoch: [069] \t Loss 0.3387 \t Acc 89.06 \t AccHead 89.70 \t AccTail 13.17\n",
      "Epoch: [070] \t Loss 0.3435 \t Acc 89.56 \t AccHead 90.22 \t AccTail 10.78\n",
      "Epoch: [071] \t Loss 0.3370 \t Acc 87.91 \t AccHead 88.53 \t AccTail 13.77\n",
      "Epoch: [072] \t Loss 0.3332 \t Acc 88.49 \t AccHead 88.98 \t AccTail 30.54\n",
      "Epoch: [073] \t Loss 0.3341 \t Acc 86.41 \t AccHead 87.01 \t AccTail 13.25\n",
      "Epoch: [074] \t Loss 0.3309 \t Acc 89.03 \t AccHead 89.63 \t AccTail 16.87\n",
      "Epoch: [075] \t Loss 0.3285 \t Acc 89.41 \t AccHead 90.03 \t AccTail 14.37\n",
      "Epoch: [076] \t Loss 0.3240 \t Acc 88.03 \t AccHead 88.51 \t AccTail 31.14\n",
      "Epoch: [077] \t Loss 0.3205 \t Acc 85.98 \t AccHead 86.58 \t AccTail 13.86\n",
      "Epoch: [078] \t Loss 0.3244 \t Acc 90.20 \t AccHead 90.81 \t AccTail 17.47\n",
      "Epoch: [079] \t Loss 0.3191 \t Acc 90.40 \t AccHead 91.03 \t AccTail 14.97\n",
      "Epoch: [080] \t Loss 0.3169 \t Acc 90.19 \t AccHead 90.73 \t AccTail 26.35\n",
      "Epoch: [081] \t Loss 0.3204 \t Acc 87.92 \t AccHead 88.39 \t AccTail 31.33\n",
      "Epoch: [082] \t Loss 0.3143 \t Acc 89.07 \t AccHead 89.62 \t AccTail 21.95\n",
      "Epoch: [083] \t Loss 0.3234 \t Acc 89.65 \t AccHead 90.18 \t AccTail 26.67\n",
      "Epoch: [084] \t Loss 0.3172 \t Acc 89.43 \t AccHead 89.85 \t AccTail 38.92\n",
      "Epoch: [085] \t Loss 0.3133 \t Acc 88.53 \t AccHead 88.97 \t AccTail 35.93\n",
      "Epoch: [086] \t Loss 0.3144 \t Acc 89.84 \t AccHead 90.31 \t AccTail 34.13\n",
      "Epoch: [087] \t Loss 0.3068 \t Acc 89.08 \t AccHead 89.54 \t AccTail 34.13\n",
      "Epoch: [088] \t Loss 0.3210 \t Acc 89.47 \t AccHead 89.95 \t AccTail 31.74\n",
      "Epoch: [089] \t Loss 0.3021 \t Acc 90.33 \t AccHead 90.88 \t AccTail 24.10\n",
      "Epoch: [090] \t Loss 0.3108 \t Acc 88.56 \t AccHead 89.08 \t AccTail 27.54\n",
      "Epoch: [091] \t Loss 0.2997 \t Acc 88.58 \t AccHead 89.01 \t AccTail 38.32\n",
      "Epoch: [092] \t Loss 0.3067 \t Acc 87.40 \t AccHead 87.94 \t AccTail 22.89\n",
      "Epoch: [093] \t Loss 0.3000 \t Acc 90.13 \t AccHead 90.63 \t AccTail 29.94\n",
      "Epoch: [094] \t Loss 0.3017 \t Acc 90.90 \t AccHead 91.31 \t AccTail 41.57\n",
      "Epoch: [095] \t Loss 0.2955 \t Acc 90.58 \t AccHead 91.11 \t AccTail 27.11\n",
      "Epoch: [096] \t Loss 0.3105 \t Acc 90.25 \t AccHead 90.63 \t AccTail 44.91\n",
      "Epoch: [097] \t Loss 0.3003 \t Acc 88.20 \t AccHead 88.60 \t AccTail 40.12\n",
      "Epoch: [098] \t Loss 0.2950 \t Acc 90.73 \t AccHead 91.20 \t AccTail 34.73\n",
      "Epoch: [099] \t Loss 0.2914 \t Acc 89.30 \t AccHead 89.82 \t AccTail 26.35\n",
      "Epoch: [100] \t Loss 0.3055 \t Acc 89.39 \t AccHead 89.82 \t AccTail 37.35\n",
      "Epoch: [101] \t Loss 0.2926 \t Acc 90.06 \t AccHead 90.60 \t AccTail 25.90\n",
      "Epoch: [102] \t Loss 0.3019 \t Acc 89.71 \t AccHead 90.21 \t AccTail 30.54\n",
      "Epoch: [103] \t Loss 0.2963 \t Acc 89.70 \t AccHead 90.17 \t AccTail 33.73\n",
      "Epoch: [104] \t Loss 0.2894 \t Acc 89.94 \t AccHead 90.44 \t AccTail 29.70\n",
      "Epoch: [105] \t Loss 0.2956 \t Acc 89.44 \t AccHead 89.93 \t AccTail 31.14\n",
      "Epoch: [106] \t Loss 0.2950 \t Acc 90.48 \t AccHead 90.95 \t AccTail 32.73\n",
      "Epoch: [107] \t Loss 0.2894 \t Acc 90.05 \t AccHead 90.52 \t AccTail 34.13\n",
      "Epoch: [108] \t Loss 0.2796 \t Acc 91.04 \t AccHead 91.39 \t AccTail 49.10\n",
      "Epoch: [109] \t Loss 0.2883 \t Acc 90.64 \t AccHead 91.18 \t AccTail 26.35\n",
      "Epoch: [110] \t Loss 0.2863 \t Acc 90.17 \t AccHead 90.71 \t AccTail 23.78\n",
      "Epoch: [111] \t Loss 0.2835 \t Acc 90.11 \t AccHead 90.61 \t AccTail 30.72\n",
      "Epoch: [112] \t Loss 0.2987 \t Acc 86.67 \t AccHead 87.02 \t AccTail 44.58\n",
      "Epoch: [113] \t Loss 0.2917 \t Acc 87.75 \t AccHead 88.15 \t AccTail 40.12\n",
      "Epoch: [114] \t Loss 0.2901 \t Acc 88.78 \t AccHead 89.27 \t AccTail 31.14\n",
      "Epoch: [115] \t Loss 0.2737 \t Acc 89.39 \t AccHead 89.97 \t AccTail 19.16\n",
      "Epoch: [116] \t Loss 0.2979 \t Acc 86.96 \t AccHead 87.34 \t AccTail 40.61\n",
      "Epoch: [117] \t Loss 0.2881 \t Acc 90.38 \t AccHead 90.84 \t AccTail 34.34\n",
      "Epoch: [118] \t Loss 0.2860 \t Acc 90.39 \t AccHead 90.85 \t AccTail 34.34\n",
      "Epoch: [119] \t Loss 0.2858 \t Acc 90.15 \t AccHead 90.65 \t AccTail 30.54\n",
      "Epoch: [120] \t Loss 0.2760 \t Acc 90.80 \t AccHead 91.26 \t AccTail 35.33\n",
      "Epoch: [121] \t Loss 0.2732 \t Acc 90.84 \t AccHead 91.27 \t AccTail 38.55\n",
      "Epoch: [122] \t Loss 0.2818 \t Acc 91.21 \t AccHead 91.61 \t AccTail 42.68\n",
      "Epoch: [123] \t Loss 0.2841 \t Acc 91.63 \t AccHead 92.01 \t AccTail 45.45\n",
      "Epoch: [124] \t Loss 0.2835 \t Acc 89.77 \t AccHead 90.24 \t AccTail 32.73\n",
      "Epoch: [125] \t Loss 0.2794 \t Acc 88.85 \t AccHead 89.42 \t AccTail 20.48\n",
      "Epoch: [126] \t Loss 0.2722 \t Acc 90.19 \t AccHead 90.57 \t AccTail 43.64\n",
      "Epoch: [127] \t Loss 0.2835 \t Acc 92.35 \t AccHead 92.72 \t AccTail 47.27\n",
      "Epoch: [128] \t Loss 0.2732 \t Acc 90.28 \t AccHead 90.73 \t AccTail 36.53\n",
      "Epoch: [129] \t Loss 0.2722 \t Acc 90.23 \t AccHead 90.71 \t AccTail 33.13\n",
      "Epoch: [130] \t Loss 0.2790 \t Acc 91.22 \t AccHead 91.71 \t AccTail 31.93\n",
      "Epoch: [131] \t Loss 0.2698 \t Acc 90.89 \t AccHead 91.22 \t AccTail 51.50\n",
      "Epoch: [132] \t Loss 0.2696 \t Acc 90.60 \t AccHead 90.93 \t AccTail 50.30\n",
      "Epoch: [133] \t Loss 0.2706 \t Acc 90.06 \t AccHead 90.44 \t AccTail 45.18\n",
      "Epoch: [134] \t Loss 0.2774 \t Acc 90.69 \t AccHead 91.06 \t AccTail 46.11\n",
      "Epoch: [135] \t Loss 0.2672 \t Acc 90.71 \t AccHead 91.08 \t AccTail 47.31\n",
      "Epoch: [136] \t Loss 0.2683 \t Acc 91.16 \t AccHead 91.51 \t AccTail 48.50\n",
      "Epoch: [137] \t Loss 0.2649 \t Acc 91.86 \t AccHead 92.26 \t AccTail 43.98\n",
      "Epoch: [138] \t Loss 0.2717 \t Acc 90.03 \t AccHead 90.40 \t AccTail 46.11\n",
      "Epoch: [139] \t Loss 0.2693 \t Acc 90.14 \t AccHead 90.46 \t AccTail 51.52\n",
      "Epoch: [140] \t Loss 0.2722 \t Acc 91.67 \t AccHead 92.00 \t AccTail 52.41\n",
      "Epoch: [141] \t Loss 0.2661 \t Acc 91.42 \t AccHead 91.87 \t AccTail 37.72\n",
      "Epoch: [142] \t Loss 0.2703 \t Acc 91.78 \t AccHead 92.10 \t AccTail 54.22\n",
      "Epoch: [143] \t Loss 0.2594 \t Acc 91.00 \t AccHead 91.47 \t AccTail 34.13\n",
      "Epoch: [144] \t Loss 0.2671 \t Acc 90.47 \t AccHead 90.81 \t AccTail 49.70\n",
      "Epoch: [145] \t Loss 0.2722 \t Acc 90.05 \t AccHead 90.38 \t AccTail 51.50\n",
      "Epoch: [146] \t Loss 0.2685 \t Acc 88.82 \t AccHead 89.23 \t AccTail 39.76\n",
      "Epoch: [147] \t Loss 0.2692 \t Acc 90.76 \t AccHead 91.16 \t AccTail 43.11\n",
      "Epoch: [148] \t Loss 0.2744 \t Acc 90.95 \t AccHead 91.31 \t AccTail 47.59\n",
      "Epoch: [149] \t Loss 0.2719 \t Acc 88.52 \t AccHead 88.93 \t AccTail 38.55\n",
      "Epoch: [150] \t Loss 0.2737 \t Acc 89.58 \t AccHead 89.92 \t AccTail 47.90\n",
      "Epoch: [151] \t Loss 0.1738 \t Acc 95.91 \t AccHead 96.14 \t AccTail 68.67\n",
      "Epoch: [152] \t Loss 0.1274 \t Acc 96.56 \t AccHead 96.73 \t AccTail 76.05\n",
      "Epoch: [153] \t Loss 0.1136 \t Acc 96.89 \t AccHead 97.04 \t AccTail 79.04\n",
      "Epoch: [154] \t Loss 0.1026 \t Acc 97.15 \t AccHead 97.34 \t AccTail 74.85\n",
      "Epoch: [155] \t Loss 0.0992 \t Acc 97.46 \t AccHead 97.64 \t AccTail 75.90\n",
      "Epoch: [156] \t Loss 0.0900 \t Acc 97.59 \t AccHead 97.70 \t AccTail 84.34\n",
      "Epoch: [157] \t Loss 0.0861 \t Acc 97.83 \t AccHead 97.95 \t AccTail 83.13\n",
      "Epoch: [158] \t Loss 0.0810 \t Acc 97.77 \t AccHead 97.90 \t AccTail 81.33\n",
      "Epoch: [159] \t Loss 0.0748 \t Acc 98.21 \t AccHead 98.29 \t AccTail 88.55\n",
      "Epoch: [160] \t Loss 0.0743 \t Acc 98.15 \t AccHead 98.21 \t AccTail 90.36\n",
      "Epoch: [161] \t Loss 0.0699 \t Acc 98.36 \t AccHead 98.43 \t AccTail 89.22\n",
      "Epoch: [162] \t Loss 0.0625 \t Acc 98.29 \t AccHead 98.38 \t AccTail 87.35\n",
      "Epoch: [163] \t Loss 0.0642 \t Acc 98.30 \t AccHead 98.41 \t AccTail 85.03\n",
      "Epoch: [164] \t Loss 0.0597 \t Acc 98.49 \t AccHead 98.58 \t AccTail 88.55\n",
      "Epoch: [165] \t Loss 0.0581 \t Acc 98.46 \t AccHead 98.52 \t AccTail 91.02\n",
      "Epoch: [166] \t Loss 0.0594 \t Acc 98.50 \t AccHead 98.55 \t AccTail 91.62\n",
      "Epoch: [167] \t Loss 0.0550 \t Acc 98.59 \t AccHead 98.65 \t AccTail 91.62\n",
      "Epoch: [168] \t Loss 0.0529 \t Acc 98.78 \t AccHead 98.84 \t AccTail 92.22\n",
      "Epoch: [169] \t Loss 0.0510 \t Acc 98.72 \t AccHead 98.79 \t AccTail 90.42\n",
      "Epoch: [170] \t Loss 0.0510 \t Acc 98.86 \t AccHead 98.93 \t AccTail 91.02\n",
      "Epoch: [171] \t Loss 0.0461 \t Acc 98.96 \t AccHead 99.01 \t AccTail 92.22\n",
      "Epoch: [172] \t Loss 0.0415 \t Acc 98.84 \t AccHead 98.91 \t AccTail 90.42\n",
      "Epoch: [173] \t Loss 0.0493 \t Acc 98.84 \t AccHead 98.88 \t AccTail 94.01\n",
      "Epoch: [174] \t Loss 0.0432 \t Acc 99.10 \t AccHead 99.17 \t AccTail 90.96\n",
      "Epoch: [175] \t Loss 0.0420 \t Acc 99.15 \t AccHead 99.20 \t AccTail 92.81\n",
      "Epoch: [176] \t Loss 0.0431 \t Acc 98.97 \t AccHead 99.02 \t AccTail 93.41\n",
      "Epoch: [177] \t Loss 0.0379 \t Acc 99.04 \t AccHead 99.12 \t AccTail 90.42\n",
      "Epoch: [178] \t Loss 0.0385 \t Acc 99.10 \t AccHead 99.13 \t AccTail 95.81\n",
      "Epoch: [179] \t Loss 0.0366 \t Acc 99.18 \t AccHead 99.21 \t AccTail 95.21\n",
      "Epoch: [180] \t Loss 0.0346 \t Acc 99.15 \t AccHead 99.17 \t AccTail 96.97\n",
      "Epoch: [181] \t Loss 0.0371 \t Acc 99.11 \t AccHead 99.16 \t AccTail 93.41\n",
      "Epoch: [182] \t Loss 0.0410 \t Acc 99.00 \t AccHead 99.03 \t AccTail 95.81\n",
      "Epoch: [183] \t Loss 0.0385 \t Acc 99.04 \t AccHead 99.08 \t AccTail 94.61\n",
      "Epoch: [184] \t Loss 0.0336 \t Acc 99.25 \t AccHead 99.27 \t AccTail 96.36\n",
      "Epoch: [185] \t Loss 0.0349 \t Acc 99.16 \t AccHead 99.21 \t AccTail 93.37\n",
      "Epoch: [186] \t Loss 0.0334 \t Acc 99.26 \t AccHead 99.30 \t AccTail 94.58\n",
      "Epoch: [187] \t Loss 0.0321 \t Acc 99.26 \t AccHead 99.31 \t AccTail 93.33\n",
      "Epoch: [188] \t Loss 0.0303 \t Acc 99.21 \t AccHead 99.25 \t AccTail 94.01\n",
      "Epoch: [189] \t Loss 0.0300 \t Acc 99.26 \t AccHead 99.30 \t AccTail 94.61\n",
      "Epoch: [190] \t Loss 0.0334 \t Acc 99.12 \t AccHead 99.15 \t AccTail 95.81\n",
      "Epoch: [191] \t Loss 0.0269 \t Acc 99.44 \t AccHead 99.47 \t AccTail 95.21\n",
      "Epoch: [192] \t Loss 0.0311 \t Acc 99.46 \t AccHead 99.47 \t AccTail 98.80\n",
      "Epoch: [193] \t Loss 0.0294 \t Acc 99.33 \t AccHead 99.36 \t AccTail 95.18\n",
      "Epoch: [194] \t Loss 0.0298 \t Acc 99.36 \t AccHead 99.37 \t AccTail 98.20\n",
      "Epoch: [195] \t Loss 0.0308 \t Acc 99.13 \t AccHead 99.17 \t AccTail 94.01\n",
      "Epoch: [196] \t Loss 0.0313 \t Acc 99.30 \t AccHead 99.34 \t AccTail 95.18\n",
      "Epoch: [197] \t Loss 0.0273 \t Acc 99.31 \t AccHead 99.37 \t AccTail 92.22\n",
      "Epoch: [198] \t Loss 0.0253 \t Acc 99.46 \t AccHead 99.50 \t AccTail 94.58\n",
      "Epoch: [199] \t Loss 0.0280 \t Acc 99.36 \t AccHead 99.38 \t AccTail 96.39\n",
      "Epoch: [200] \t Loss 0.0237 \t Acc 99.29 \t AccHead 99.32 \t AccTail 96.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 05:10:07,332]\u001b[0m Trial 1 finished with value: 44.30290222167969 and parameters: {'n_epoch': 200, 'weight_decay': 0.0002573140890326084}. Best is trial 1 with value: 44.30290222167969.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 44.30 \t AccHead 86.34 \t AccTail 1.33\n",
      "Epoch: [001] \t Loss 1.8903 \t Acc 21.80 \t AccHead 21.98 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.2382 \t Acc 44.01 \t AccHead 44.38 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.2314 \t Acc 39.56 \t AccHead 39.88 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.2111 \t Acc 47.85 \t AccHead 48.25 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.2216 \t Acc 47.07 \t AccHead 47.47 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.2095 \t Acc 52.24 \t AccHead 52.68 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 1.2136 \t Acc 47.33 \t AccHead 47.72 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 1.2178 \t Acc 42.83 \t AccHead 43.19 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 1.2048 \t Acc 49.20 \t AccHead 49.62 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 1.2231 \t Acc 43.80 \t AccHead 44.17 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 1.2057 \t Acc 43.08 \t AccHead 43.44 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 1.2242 \t Acc 37.93 \t AccHead 38.25 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 1.2283 \t Acc 40.98 \t AccHead 41.32 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 1.2085 \t Acc 46.35 \t AccHead 46.73 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 1.2050 \t Acc 50.04 \t AccHead 50.46 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 1.2209 \t Acc 37.25 \t AccHead 37.56 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 1.2234 \t Acc 46.65 \t AccHead 47.04 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 1.2173 \t Acc 42.24 \t AccHead 42.59 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 1.2171 \t Acc 38.64 \t AccHead 38.97 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 1.2164 \t Acc 47.52 \t AccHead 47.92 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 1.2398 \t Acc 36.72 \t AccHead 37.03 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 1.2241 \t Acc 45.37 \t AccHead 45.75 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 1.2369 \t Acc 51.44 \t AccHead 51.87 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 1.2380 \t Acc 47.74 \t AccHead 48.14 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 1.2342 \t Acc 41.07 \t AccHead 41.42 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 1.2245 \t Acc 46.11 \t AccHead 46.49 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 1.2517 \t Acc 46.55 \t AccHead 46.94 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 1.2457 \t Acc 42.61 \t AccHead 42.96 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 1.2306 \t Acc 39.20 \t AccHead 39.53 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 1.2342 \t Acc 32.93 \t AccHead 33.20 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 1.2327 \t Acc 39.51 \t AccHead 39.83 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 1.2565 \t Acc 44.61 \t AccHead 44.98 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 1.2382 \t Acc 42.60 \t AccHead 42.95 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 1.2423 \t Acc 43.30 \t AccHead 43.66 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 1.2416 \t Acc 36.41 \t AccHead 36.71 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 1.2437 \t Acc 42.33 \t AccHead 42.69 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 1.2557 \t Acc 44.05 \t AccHead 44.42 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 1.2408 \t Acc 38.69 \t AccHead 39.01 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 1.2528 \t Acc 42.08 \t AccHead 42.43 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 1.2473 \t Acc 39.23 \t AccHead 39.56 \t AccTail 0.00\n",
      "Epoch: [041] \t Loss 1.2395 \t Acc 37.21 \t AccHead 37.52 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 1.2610 \t Acc 40.37 \t AccHead 40.71 \t AccTail 0.00\n",
      "Epoch: [043] \t Loss 1.2650 \t Acc 46.59 \t AccHead 46.98 \t AccTail 0.00\n",
      "Epoch: [044] \t Loss 1.2549 \t Acc 37.64 \t AccHead 37.95 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 1.2522 \t Acc 44.92 \t AccHead 45.30 \t AccTail 0.00\n",
      "Epoch: [046] \t Loss 1.2513 \t Acc 49.28 \t AccHead 49.69 \t AccTail 0.00\n",
      "Epoch: [047] \t Loss 1.2485 \t Acc 45.19 \t AccHead 45.57 \t AccTail 0.00\n",
      "Epoch: [048] \t Loss 1.2562 \t Acc 43.99 \t AccHead 44.36 \t AccTail 0.00\n",
      "Epoch: [049] \t Loss 1.2542 \t Acc 51.02 \t AccHead 51.45 \t AccTail 0.00\n",
      "Epoch: [050] \t Loss 1.2815 \t Acc 31.78 \t AccHead 32.04 \t AccTail 0.00\n",
      "Epoch: [051] \t Loss 1.2924 \t Acc 27.23 \t AccHead 27.46 \t AccTail 0.00\n",
      "Epoch: [052] \t Loss 1.2749 \t Acc 42.36 \t AccHead 42.72 \t AccTail 0.00\n",
      "Epoch: [053] \t Loss 1.2798 \t Acc 30.08 \t AccHead 30.33 \t AccTail 0.00\n",
      "Epoch: [054] \t Loss 1.2837 \t Acc 38.79 \t AccHead 39.12 \t AccTail 0.00\n",
      "Epoch: [055] \t Loss 1.2982 \t Acc 37.63 \t AccHead 37.94 \t AccTail 0.00\n",
      "Epoch: [056] \t Loss 1.2662 \t Acc 43.21 \t AccHead 43.57 \t AccTail 0.00\n",
      "Epoch: [057] \t Loss 1.2867 \t Acc 46.49 \t AccHead 46.87 \t AccTail 0.00\n",
      "Epoch: [058] \t Loss 1.2893 \t Acc 42.48 \t AccHead 42.83 \t AccTail 0.00\n",
      "Epoch: [059] \t Loss 1.2683 \t Acc 37.76 \t AccHead 38.08 \t AccTail 0.00\n",
      "Epoch: [060] \t Loss 1.2837 \t Acc 47.02 \t AccHead 47.41 \t AccTail 0.00\n",
      "Epoch: [061] \t Loss 1.3026 \t Acc 31.12 \t AccHead 31.37 \t AccTail 0.00\n",
      "Epoch: [062] \t Loss 1.3042 \t Acc 33.70 \t AccHead 33.98 \t AccTail 0.00\n",
      "Epoch: [063] \t Loss 1.2895 \t Acc 27.11 \t AccHead 27.34 \t AccTail 0.00\n",
      "Epoch: [064] \t Loss 1.2863 \t Acc 38.66 \t AccHead 38.98 \t AccTail 0.00\n",
      "Epoch: [065] \t Loss 1.2944 \t Acc 39.58 \t AccHead 39.90 \t AccTail 0.00\n",
      "Epoch: [066] \t Loss 1.3095 \t Acc 44.81 \t AccHead 45.18 \t AccTail 0.00\n",
      "Epoch: [067] \t Loss 1.3098 \t Acc 35.75 \t AccHead 36.05 \t AccTail 0.00\n",
      "Epoch: [068] \t Loss 1.3029 \t Acc 36.26 \t AccHead 36.56 \t AccTail 0.00\n",
      "Epoch: [069] \t Loss 1.3114 \t Acc 35.79 \t AccHead 36.09 \t AccTail 0.00\n",
      "Epoch: [070] \t Loss 1.3131 \t Acc 38.13 \t AccHead 38.45 \t AccTail 0.00\n",
      "Epoch: [071] \t Loss 1.2956 \t Acc 37.33 \t AccHead 37.63 \t AccTail 0.00\n",
      "Epoch: [072] \t Loss 1.3074 \t Acc 32.84 \t AccHead 33.12 \t AccTail 0.00\n",
      "Epoch: [073] \t Loss 1.3155 \t Acc 19.95 \t AccHead 20.11 \t AccTail 0.00\n",
      "Epoch: [074] \t Loss 1.3002 \t Acc 20.17 \t AccHead 20.34 \t AccTail 0.00\n",
      "Epoch: [075] \t Loss 1.3124 \t Acc 32.66 \t AccHead 32.94 \t AccTail 0.00\n",
      "Epoch: [076] \t Loss 1.3291 \t Acc 22.39 \t AccHead 22.57 \t AccTail 0.00\n",
      "Epoch: [077] \t Loss 1.3148 \t Acc 42.77 \t AccHead 43.13 \t AccTail 0.00\n",
      "Epoch: [078] \t Loss 1.3232 \t Acc 37.29 \t AccHead 37.60 \t AccTail 0.00\n",
      "Epoch: [079] \t Loss 1.3174 \t Acc 34.03 \t AccHead 34.31 \t AccTail 0.00\n",
      "Epoch: [080] \t Loss 1.3127 \t Acc 41.08 \t AccHead 41.43 \t AccTail 0.00\n",
      "Epoch: [081] \t Loss 1.3020 \t Acc 42.80 \t AccHead 43.16 \t AccTail 0.00\n",
      "Epoch: [082] \t Loss 1.3117 \t Acc 41.46 \t AccHead 41.81 \t AccTail 0.00\n",
      "Epoch: [083] \t Loss 1.3040 \t Acc 37.19 \t AccHead 37.50 \t AccTail 0.00\n",
      "Epoch: [084] \t Loss 1.2976 \t Acc 35.18 \t AccHead 35.48 \t AccTail 0.00\n",
      "Epoch: [085] \t Loss 1.3122 \t Acc 42.54 \t AccHead 42.89 \t AccTail 0.00\n",
      "Epoch: [086] \t Loss 1.3126 \t Acc 30.20 \t AccHead 30.45 \t AccTail 0.00\n",
      "Epoch: [087] \t Loss 1.3194 \t Acc 37.71 \t AccHead 38.03 \t AccTail 0.00\n",
      "Epoch: [088] \t Loss 1.3142 \t Acc 36.43 \t AccHead 36.74 \t AccTail 0.00\n",
      "Epoch: [089] \t Loss 1.3128 \t Acc 42.52 \t AccHead 42.88 \t AccTail 0.00\n",
      "Epoch: [090] \t Loss 1.3080 \t Acc 23.98 \t AccHead 24.18 \t AccTail 0.00\n",
      "Epoch: [091] \t Loss 1.3189 \t Acc 40.32 \t AccHead 40.65 \t AccTail 0.00\n",
      "Epoch: [092] \t Loss 1.3164 \t Acc 40.77 \t AccHead 41.12 \t AccTail 0.00\n",
      "Epoch: [093] \t Loss 1.3145 \t Acc 36.32 \t AccHead 36.62 \t AccTail 0.00\n",
      "Epoch: [094] \t Loss 1.3194 \t Acc 34.19 \t AccHead 34.47 \t AccTail 0.00\n",
      "Epoch: [095] \t Loss 1.3085 \t Acc 40.30 \t AccHead 40.63 \t AccTail 0.00\n",
      "Epoch: [096] \t Loss 1.3207 \t Acc 37.02 \t AccHead 37.33 \t AccTail 0.00\n",
      "Epoch: [097] \t Loss 1.3215 \t Acc 39.14 \t AccHead 39.47 \t AccTail 0.00\n",
      "Epoch: [098] \t Loss 1.3217 \t Acc 36.67 \t AccHead 36.98 \t AccTail 0.00\n",
      "Epoch: [099] \t Loss 1.3194 \t Acc 43.05 \t AccHead 43.41 \t AccTail 0.00\n",
      "Epoch: [100] \t Loss 1.3225 \t Acc 33.32 \t AccHead 33.59 \t AccTail 0.00\n",
      "Epoch: [101] \t Loss 1.3159 \t Acc 30.12 \t AccHead 30.37 \t AccTail 0.00\n",
      "Epoch: [102] \t Loss 1.3245 \t Acc 29.54 \t AccHead 29.78 \t AccTail 0.00\n",
      "Epoch: [103] \t Loss 1.3245 \t Acc 25.91 \t AccHead 26.13 \t AccTail 0.00\n",
      "Epoch: [104] \t Loss 1.3250 \t Acc 32.57 \t AccHead 32.85 \t AccTail 0.00\n",
      "Epoch: [105] \t Loss 1.3185 \t Acc 37.01 \t AccHead 37.32 \t AccTail 0.00\n",
      "Epoch: [106] \t Loss 1.3199 \t Acc 33.84 \t AccHead 34.13 \t AccTail 0.00\n",
      "Epoch: [107] \t Loss 1.3259 \t Acc 34.69 \t AccHead 34.98 \t AccTail 0.00\n",
      "Epoch: [108] \t Loss 1.3176 \t Acc 30.60 \t AccHead 30.86 \t AccTail 0.00\n",
      "Epoch: [109] \t Loss 1.3225 \t Acc 25.89 \t AccHead 26.10 \t AccTail 0.00\n",
      "Epoch: [110] \t Loss 1.3257 \t Acc 26.43 \t AccHead 26.65 \t AccTail 0.00\n",
      "Epoch: [111] \t Loss 1.3154 \t Acc 28.13 \t AccHead 28.37 \t AccTail 0.00\n",
      "Epoch: [112] \t Loss 1.3252 \t Acc 30.52 \t AccHead 30.78 \t AccTail 0.00\n",
      "Epoch: [113] \t Loss 1.3178 \t Acc 31.08 \t AccHead 31.34 \t AccTail 0.00\n",
      "Epoch: [114] \t Loss 1.3181 \t Acc 33.48 \t AccHead 33.76 \t AccTail 0.00\n",
      "Epoch: [115] \t Loss 1.3288 \t Acc 28.50 \t AccHead 28.74 \t AccTail 0.00\n",
      "Epoch: [116] \t Loss 1.3430 \t Acc 40.06 \t AccHead 40.40 \t AccTail 0.00\n",
      "Epoch: [117] \t Loss 1.3167 \t Acc 38.12 \t AccHead 38.44 \t AccTail 0.00\n",
      "Epoch: [118] \t Loss 1.3140 \t Acc 38.90 \t AccHead 39.23 \t AccTail 0.00\n",
      "Epoch: [119] \t Loss 1.3296 \t Acc 28.12 \t AccHead 28.36 \t AccTail 0.00\n",
      "Epoch: [120] \t Loss 1.3237 \t Acc 37.79 \t AccHead 38.11 \t AccTail 0.00\n",
      "Epoch: [121] \t Loss 1.3233 \t Acc 36.82 \t AccHead 37.13 \t AccTail 0.00\n",
      "Epoch: [122] \t Loss 1.3209 \t Acc 42.95 \t AccHead 43.31 \t AccTail 0.00\n",
      "Epoch: [123] \t Loss 1.3213 \t Acc 33.48 \t AccHead 33.76 \t AccTail 0.00\n",
      "Epoch: [124] \t Loss 1.3238 \t Acc 36.43 \t AccHead 36.74 \t AccTail 0.00\n",
      "Epoch: [125] \t Loss 1.3118 \t Acc 30.20 \t AccHead 30.45 \t AccTail 0.00\n",
      "Epoch: [126] \t Loss 1.3257 \t Acc 21.83 \t AccHead 22.01 \t AccTail 0.00\n",
      "Epoch: [127] \t Loss 1.3191 \t Acc 20.75 \t AccHead 20.92 \t AccTail 0.00\n",
      "Epoch: [128] \t Loss 1.3234 \t Acc 35.27 \t AccHead 35.57 \t AccTail 0.00\n",
      "Epoch: [129] \t Loss 1.3247 \t Acc 23.10 \t AccHead 23.30 \t AccTail 0.00\n",
      "Epoch: [130] \t Loss 1.3221 \t Acc 32.55 \t AccHead 32.82 \t AccTail 0.00\n",
      "Epoch: [131] \t Loss 1.3228 \t Acc 36.42 \t AccHead 36.72 \t AccTail 0.00\n",
      "Epoch: [132] \t Loss 1.3205 \t Acc 31.59 \t AccHead 31.85 \t AccTail 0.00\n",
      "Epoch: [133] \t Loss 1.3280 \t Acc 24.37 \t AccHead 24.57 \t AccTail 0.00\n",
      "Epoch: [134] \t Loss 1.3149 \t Acc 31.01 \t AccHead 31.26 \t AccTail 0.00\n",
      "Epoch: [135] \t Loss 1.3223 \t Acc 41.59 \t AccHead 41.93 \t AccTail 0.00\n",
      "Epoch: [136] \t Loss 1.3195 \t Acc 26.62 \t AccHead 26.85 \t AccTail 0.00\n",
      "Epoch: [137] \t Loss 1.3327 \t Acc 30.49 \t AccHead 30.75 \t AccTail 0.00\n",
      "Epoch: [138] \t Loss 1.3244 \t Acc 35.82 \t AccHead 36.12 \t AccTail 0.00\n",
      "Epoch: [139] \t Loss 1.3220 \t Acc 45.42 \t AccHead 45.80 \t AccTail 0.00\n",
      "Epoch: [140] \t Loss 1.3197 \t Acc 37.48 \t AccHead 37.79 \t AccTail 0.00\n",
      "Epoch: [141] \t Loss 1.3240 \t Acc 35.46 \t AccHead 35.76 \t AccTail 0.00\n",
      "Epoch: [142] \t Loss 1.3215 \t Acc 37.42 \t AccHead 37.73 \t AccTail 0.00\n",
      "Epoch: [143] \t Loss 1.3179 \t Acc 26.84 \t AccHead 27.07 \t AccTail 0.00\n",
      "Epoch: [144] \t Loss 1.3280 \t Acc 35.94 \t AccHead 36.24 \t AccTail 0.00\n",
      "Epoch: [145] \t Loss 1.3102 \t Acc 25.55 \t AccHead 25.76 \t AccTail 0.00\n",
      "Epoch: [146] \t Loss 1.3223 \t Acc 31.17 \t AccHead 31.43 \t AccTail 0.00\n",
      "Epoch: [147] \t Loss 1.3064 \t Acc 36.31 \t AccHead 36.61 \t AccTail 0.00\n",
      "Epoch: [148] \t Loss 1.3301 \t Acc 38.14 \t AccHead 38.46 \t AccTail 0.00\n",
      "Epoch: [149] \t Loss 1.3143 \t Acc 36.04 \t AccHead 36.34 \t AccTail 0.00\n",
      "Epoch: [150] \t Loss 1.3252 \t Acc 27.31 \t AccHead 27.54 \t AccTail 0.00\n",
      "Epoch: [151] \t Loss 1.2305 \t Acc 47.83 \t AccHead 48.22 \t AccTail 0.00\n",
      "Epoch: [152] \t Loss 1.2144 \t Acc 45.07 \t AccHead 45.44 \t AccTail 0.00\n",
      "Epoch: [153] \t Loss 1.2240 \t Acc 45.93 \t AccHead 46.31 \t AccTail 0.00\n",
      "Epoch: [154] \t Loss 1.2189 \t Acc 48.74 \t AccHead 49.14 \t AccTail 0.00\n",
      "Epoch: [155] \t Loss 1.2179 \t Acc 49.44 \t AccHead 49.85 \t AccTail 0.00\n",
      "Epoch: [156] \t Loss 1.2214 \t Acc 46.99 \t AccHead 47.39 \t AccTail 0.00\n",
      "Epoch: [157] \t Loss 1.2211 \t Acc 47.39 \t AccHead 47.78 \t AccTail 0.00\n",
      "Epoch: [158] \t Loss 1.2290 \t Acc 46.44 \t AccHead 46.83 \t AccTail 0.00\n",
      "Epoch: [159] \t Loss 1.2122 \t Acc 45.35 \t AccHead 45.73 \t AccTail 0.00\n",
      "Epoch: [160] \t Loss 1.2205 \t Acc 49.99 \t AccHead 50.40 \t AccTail 0.00\n",
      "Epoch: [161] \t Loss 1.2148 \t Acc 47.89 \t AccHead 48.29 \t AccTail 0.00\n",
      "Epoch: [162] \t Loss 1.2180 \t Acc 49.74 \t AccHead 50.16 \t AccTail 0.00\n",
      "Epoch: [163] \t Loss 1.2107 \t Acc 45.86 \t AccHead 46.24 \t AccTail 0.00\n",
      "Epoch: [164] \t Loss 1.2088 \t Acc 48.53 \t AccHead 48.93 \t AccTail 0.00\n",
      "Epoch: [165] \t Loss 1.2155 \t Acc 47.54 \t AccHead 47.94 \t AccTail 0.00\n",
      "Epoch: [166] \t Loss 1.2056 \t Acc 50.26 \t AccHead 50.68 \t AccTail 0.00\n",
      "Epoch: [167] \t Loss 1.2076 \t Acc 47.07 \t AccHead 47.46 \t AccTail 0.00\n",
      "Epoch: [168] \t Loss 1.2069 \t Acc 45.05 \t AccHead 45.43 \t AccTail 0.00\n",
      "Epoch: [169] \t Loss 1.2055 \t Acc 42.08 \t AccHead 42.44 \t AccTail 0.00\n",
      "Epoch: [170] \t Loss 1.2157 \t Acc 45.47 \t AccHead 45.85 \t AccTail 0.00\n",
      "Epoch: [171] \t Loss 1.2150 \t Acc 50.40 \t AccHead 50.83 \t AccTail 0.00\n",
      "Epoch: [172] \t Loss 1.2088 \t Acc 47.68 \t AccHead 48.08 \t AccTail 0.00\n",
      "Epoch: [173] \t Loss 1.2150 \t Acc 44.73 \t AccHead 45.10 \t AccTail 0.00\n",
      "Epoch: [174] \t Loss 1.2212 \t Acc 46.62 \t AccHead 47.01 \t AccTail 0.00\n",
      "Epoch: [175] \t Loss 1.2088 \t Acc 45.07 \t AccHead 45.44 \t AccTail 0.00\n",
      "Epoch: [176] \t Loss 1.2135 \t Acc 47.39 \t AccHead 47.78 \t AccTail 0.00\n",
      "Epoch: [177] \t Loss 1.2119 \t Acc 46.84 \t AccHead 47.23 \t AccTail 0.00\n",
      "Epoch: [178] \t Loss 1.2071 \t Acc 50.59 \t AccHead 51.01 \t AccTail 0.00\n",
      "Epoch: [179] \t Loss 1.2107 \t Acc 46.92 \t AccHead 47.31 \t AccTail 0.00\n",
      "Epoch: [180] \t Loss 1.2135 \t Acc 48.24 \t AccHead 48.65 \t AccTail 0.00\n",
      "Epoch: [181] \t Loss 1.2088 \t Acc 44.55 \t AccHead 44.92 \t AccTail 0.00\n",
      "Epoch: [182] \t Loss 1.2129 \t Acc 47.73 \t AccHead 48.13 \t AccTail 0.00\n",
      "Epoch: [183] \t Loss 1.2040 \t Acc 47.52 \t AccHead 47.92 \t AccTail 0.00\n",
      "Epoch: [184] \t Loss 1.2099 \t Acc 45.46 \t AccHead 45.84 \t AccTail 0.00\n",
      "Epoch: [185] \t Loss 1.2102 \t Acc 43.81 \t AccHead 44.18 \t AccTail 0.00\n",
      "Epoch: [186] \t Loss 1.2122 \t Acc 47.70 \t AccHead 48.09 \t AccTail 0.00\n",
      "Epoch: [187] \t Loss 1.2039 \t Acc 48.28 \t AccHead 48.68 \t AccTail 0.00\n",
      "Epoch: [188] \t Loss 1.2102 \t Acc 50.28 \t AccHead 50.70 \t AccTail 0.00\n",
      "Epoch: [189] \t Loss 1.2071 \t Acc 42.94 \t AccHead 43.30 \t AccTail 0.00\n",
      "Epoch: [190] \t Loss 1.2121 \t Acc 48.93 \t AccHead 49.34 \t AccTail 0.00\n",
      "Epoch: [191] \t Loss 1.2099 \t Acc 46.62 \t AccHead 47.01 \t AccTail 0.00\n",
      "Epoch: [192] \t Loss 1.2114 \t Acc 49.71 \t AccHead 50.13 \t AccTail 0.00\n",
      "Epoch: [193] \t Loss 1.2161 \t Acc 50.53 \t AccHead 50.95 \t AccTail 0.00\n",
      "Epoch: [194] \t Loss 1.2088 \t Acc 46.36 \t AccHead 46.74 \t AccTail 0.00\n",
      "Epoch: [195] \t Loss 1.2050 \t Acc 48.57 \t AccHead 48.97 \t AccTail 0.00\n",
      "Epoch: [196] \t Loss 1.2103 \t Acc 49.25 \t AccHead 49.66 \t AccTail 0.00\n",
      "Epoch: [197] \t Loss 1.2108 \t Acc 46.69 \t AccHead 47.07 \t AccTail 0.00\n",
      "Epoch: [198] \t Loss 1.2072 \t Acc 47.92 \t AccHead 48.32 \t AccTail 0.00\n",
      "Epoch: [199] \t Loss 1.2155 \t Acc 50.18 \t AccHead 50.60 \t AccTail 0.00\n",
      "Epoch: [200] \t Loss 1.2116 \t Acc 49.66 \t AccHead 50.07 \t AccTail 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 05:45:13,749]\u001b[0m Trial 2 finished with value: 24.699222564697266 and parameters: {'n_epoch': 200, 'weight_decay': 0.015852378990145258}. Best is trial 1 with value: 44.30290222167969.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 24.70 \t AccHead 48.86 \t AccTail 0.00\n",
      "Epoch: [001] \t Loss 2.3552 \t Acc 43.05 \t AccHead 43.41 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.3929 \t Acc 50.52 \t AccHead 50.94 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.1806 \t Acc 55.11 \t AccHead 55.57 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.0866 \t Acc 59.67 \t AccHead 60.17 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.0314 \t Acc 60.80 \t AccHead 61.31 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 0.9881 \t Acc 63.85 \t AccHead 64.39 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 0.9402 \t Acc 65.71 \t AccHead 66.27 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 0.9003 \t Acc 67.62 \t AccHead 68.18 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 0.8740 \t Acc 69.85 \t AccHead 70.43 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 0.8346 \t Acc 71.16 \t AccHead 71.75 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 0.8034 \t Acc 71.26 \t AccHead 71.86 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 0.7648 \t Acc 72.82 \t AccHead 73.42 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 0.7430 \t Acc 73.15 \t AccHead 73.76 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 0.7137 \t Acc 75.33 \t AccHead 75.96 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 0.6857 \t Acc 76.99 \t AccHead 77.64 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 0.6619 \t Acc 76.53 \t AccHead 77.17 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 0.6450 \t Acc 77.76 \t AccHead 78.41 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 0.6101 \t Acc 77.47 \t AccHead 78.12 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 0.6113 \t Acc 79.22 \t AccHead 79.88 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 0.6371 \t Acc 77.79 \t AccHead 78.44 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 0.5780 \t Acc 78.72 \t AccHead 79.38 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 0.5664 \t Acc 79.44 \t AccHead 80.11 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 0.5536 \t Acc 79.89 \t AccHead 80.56 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 0.5392 \t Acc 82.66 \t AccHead 83.35 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 0.5229 \t Acc 81.31 \t AccHead 82.00 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 0.5141 \t Acc 83.25 \t AccHead 83.94 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 0.4999 \t Acc 82.71 \t AccHead 83.40 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 0.4857 \t Acc 84.62 \t AccHead 85.33 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 0.4727 \t Acc 83.45 \t AccHead 84.15 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 0.4659 \t Acc 85.17 \t AccHead 85.88 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 0.4501 \t Acc 84.38 \t AccHead 85.08 \t AccTail 0.60\n",
      "Epoch: [032] \t Loss 0.4547 \t Acc 84.62 \t AccHead 85.33 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 0.4360 \t Acc 85.38 \t AccHead 86.08 \t AccTail 1.20\n",
      "Epoch: [034] \t Loss 0.4253 \t Acc 85.50 \t AccHead 86.21 \t AccTail 0.60\n",
      "Epoch: [035] \t Loss 0.4172 \t Acc 86.39 \t AccHead 87.09 \t AccTail 1.81\n",
      "Epoch: [036] \t Loss 0.4034 \t Acc 86.96 \t AccHead 87.67 \t AccTail 1.20\n",
      "Epoch: [037] \t Loss 0.3976 \t Acc 87.16 \t AccHead 87.88 \t AccTail 1.20\n",
      "Epoch: [038] \t Loss 0.3862 \t Acc 87.59 \t AccHead 88.31 \t AccTail 0.60\n",
      "Epoch: [039] \t Loss 0.3866 \t Acc 86.78 \t AccHead 87.49 \t AccTail 1.20\n",
      "Epoch: [040] \t Loss 0.3785 \t Acc 84.00 \t AccHead 84.63 \t AccTail 9.04\n",
      "Epoch: [041] \t Loss 0.3722 \t Acc 88.82 \t AccHead 89.49 \t AccTail 8.98\n",
      "Epoch: [042] \t Loss 0.3557 \t Acc 88.08 \t AccHead 88.72 \t AccTail 11.45\n",
      "Epoch: [043] \t Loss 0.3523 \t Acc 88.78 \t AccHead 89.41 \t AccTail 14.37\n",
      "Epoch: [044] \t Loss 0.3545 \t Acc 88.73 \t AccHead 89.39 \t AccTail 9.64\n",
      "Epoch: [045] \t Loss 0.3418 \t Acc 89.14 \t AccHead 89.80 \t AccTail 9.64\n",
      "Epoch: [046] \t Loss 0.3354 \t Acc 88.72 \t AccHead 89.31 \t AccTail 18.56\n",
      "Epoch: [047] \t Loss 0.3311 \t Acc 89.78 \t AccHead 90.45 \t AccTail 10.24\n",
      "Epoch: [048] \t Loss 0.3188 \t Acc 89.31 \t AccHead 89.89 \t AccTail 19.76\n",
      "Epoch: [049] \t Loss 0.3185 \t Acc 90.56 \t AccHead 91.12 \t AccTail 22.75\n",
      "Epoch: [050] \t Loss 0.3061 \t Acc 89.24 \t AccHead 89.69 \t AccTail 34.34\n",
      "Epoch: [051] \t Loss 0.3053 \t Acc 89.55 \t AccHead 90.11 \t AccTail 21.56\n",
      "Epoch: [052] \t Loss 0.2943 \t Acc 90.80 \t AccHead 91.31 \t AccTail 29.34\n",
      "Epoch: [053] \t Loss 0.2942 \t Acc 91.10 \t AccHead 91.61 \t AccTail 30.72\n",
      "Epoch: [054] \t Loss 0.2837 \t Acc 88.56 \t AccHead 89.04 \t AccTail 32.34\n",
      "Epoch: [055] \t Loss 0.2808 \t Acc 90.04 \t AccHead 90.55 \t AccTail 28.74\n",
      "Epoch: [056] \t Loss 0.2817 \t Acc 90.28 \t AccHead 90.79 \t AccTail 28.74\n",
      "Epoch: [057] \t Loss 0.2771 \t Acc 90.41 \t AccHead 90.87 \t AccTail 34.94\n",
      "Epoch: [058] \t Loss 0.2677 \t Acc 91.48 \t AccHead 91.96 \t AccTail 34.13\n",
      "Epoch: [059] \t Loss 0.2653 \t Acc 90.87 \t AccHead 91.24 \t AccTail 45.73\n",
      "Epoch: [060] \t Loss 0.2576 \t Acc 91.91 \t AccHead 92.34 \t AccTail 41.32\n",
      "Epoch: [061] \t Loss 0.2539 \t Acc 91.93 \t AccHead 92.35 \t AccTail 41.57\n",
      "Epoch: [062] \t Loss 0.2516 \t Acc 91.62 \t AccHead 92.02 \t AccTail 43.37\n",
      "Epoch: [063] \t Loss 0.2483 \t Acc 92.38 \t AccHead 92.78 \t AccTail 44.31\n",
      "Epoch: [064] \t Loss 0.2387 \t Acc 91.34 \t AccHead 91.71 \t AccTail 47.31\n",
      "Epoch: [065] \t Loss 0.2354 \t Acc 92.74 \t AccHead 93.21 \t AccTail 37.72\n",
      "Epoch: [066] \t Loss 0.2306 \t Acc 92.02 \t AccHead 92.35 \t AccTail 53.01\n",
      "Epoch: [067] \t Loss 0.2233 \t Acc 93.44 \t AccHead 93.75 \t AccTail 56.89\n",
      "Epoch: [068] \t Loss 0.2217 \t Acc 92.93 \t AccHead 93.26 \t AccTail 53.29\n",
      "Epoch: [069] \t Loss 0.2169 \t Acc 93.31 \t AccHead 93.57 \t AccTail 62.28\n",
      "Epoch: [070] \t Loss 0.2155 \t Acc 92.65 \t AccHead 92.89 \t AccTail 63.25\n",
      "Epoch: [071] \t Loss 0.2097 \t Acc 93.32 \t AccHead 93.68 \t AccTail 49.70\n",
      "Epoch: [072] \t Loss 0.2001 \t Acc 93.32 \t AccHead 93.52 \t AccTail 69.46\n",
      "Epoch: [073] \t Loss 0.2047 \t Acc 93.15 \t AccHead 93.48 \t AccTail 54.49\n",
      "Epoch: [074] \t Loss 0.2009 \t Acc 93.12 \t AccHead 93.35 \t AccTail 65.87\n",
      "Epoch: [075] \t Loss 0.2031 \t Acc 93.32 \t AccHead 93.58 \t AccTail 61.82\n",
      "Epoch: [076] \t Loss 0.1874 \t Acc 94.42 \t AccHead 94.61 \t AccTail 71.26\n",
      "Epoch: [077] \t Loss 0.1892 \t Acc 94.07 \t AccHead 94.38 \t AccTail 57.23\n",
      "Epoch: [078] \t Loss 0.1847 \t Acc 95.03 \t AccHead 95.28 \t AccTail 64.46\n",
      "Epoch: [079] \t Loss 0.1792 \t Acc 92.98 \t AccHead 93.25 \t AccTail 61.68\n",
      "Epoch: [080] \t Loss 0.1699 \t Acc 93.86 \t AccHead 94.10 \t AccTail 64.67\n",
      "Epoch: [081] \t Loss 0.1763 \t Acc 94.81 \t AccHead 94.99 \t AccTail 72.89\n",
      "Epoch: [082] \t Loss 0.1815 \t Acc 93.62 \t AccHead 93.85 \t AccTail 66.27\n",
      "Epoch: [083] \t Loss 0.1768 \t Acc 94.54 \t AccHead 94.76 \t AccTail 68.86\n",
      "Epoch: [084] \t Loss 0.1735 \t Acc 94.57 \t AccHead 94.81 \t AccTail 65.66\n",
      "Epoch: [085] \t Loss 0.1657 \t Acc 93.87 \t AccHead 94.09 \t AccTail 67.27\n",
      "Epoch: [086] \t Loss 0.1665 \t Acc 94.72 \t AccHead 94.90 \t AccTail 72.89\n",
      "Epoch: [087] \t Loss 0.1637 \t Acc 95.01 \t AccHead 95.19 \t AccTail 74.10\n",
      "Epoch: [088] \t Loss 0.1565 \t Acc 95.36 \t AccHead 95.47 \t AccTail 81.44\n",
      "Epoch: [089] \t Loss 0.1519 \t Acc 94.29 \t AccHead 94.44 \t AccTail 76.51\n",
      "Epoch: [090] \t Loss 0.1540 \t Acc 95.64 \t AccHead 95.78 \t AccTail 78.79\n",
      "Epoch: [091] \t Loss 0.1485 \t Acc 94.84 \t AccHead 95.02 \t AccTail 73.49\n",
      "Epoch: [092] \t Loss 0.1441 \t Acc 96.12 \t AccHead 96.23 \t AccTail 83.73\n",
      "Epoch: [093] \t Loss 0.1532 \t Acc 95.50 \t AccHead 95.68 \t AccTail 73.49\n",
      "Epoch: [094] \t Loss 0.1453 \t Acc 94.32 \t AccHead 94.48 \t AccTail 76.05\n",
      "Epoch: [095] \t Loss 0.1470 \t Acc 95.21 \t AccHead 95.41 \t AccTail 71.26\n",
      "Epoch: [096] \t Loss 0.1385 \t Acc 95.86 \t AccHead 96.01 \t AccTail 79.04\n",
      "Epoch: [097] \t Loss 0.1362 \t Acc 95.62 \t AccHead 95.75 \t AccTail 79.52\n",
      "Epoch: [098] \t Loss 0.1400 \t Acc 95.34 \t AccHead 95.56 \t AccTail 69.46\n",
      "Epoch: [099] \t Loss 0.1346 \t Acc 95.88 \t AccHead 96.08 \t AccTail 71.86\n",
      "Epoch: [100] \t Loss 0.1354 \t Acc 96.19 \t AccHead 96.33 \t AccTail 79.52\n",
      "Epoch: [101] \t Loss 0.1328 \t Acc 96.14 \t AccHead 96.22 \t AccTail 87.35\n",
      "Epoch: [102] \t Loss 0.1324 \t Acc 95.65 \t AccHead 95.78 \t AccTail 79.52\n",
      "Epoch: [103] \t Loss 0.1263 \t Acc 95.99 \t AccHead 96.05 \t AccTail 88.55\n",
      "Epoch: [104] \t Loss 0.1283 \t Acc 96.21 \t AccHead 96.33 \t AccTail 82.04\n",
      "Epoch: [105] \t Loss 0.1264 \t Acc 96.67 \t AccHead 96.82 \t AccTail 78.44\n",
      "Epoch: [106] \t Loss 0.1225 \t Acc 95.84 \t AccHead 95.91 \t AccTail 87.43\n",
      "Epoch: [107] \t Loss 0.1225 \t Acc 96.33 \t AccHead 96.37 \t AccTail 91.57\n",
      "Epoch: [108] \t Loss 0.1205 \t Acc 96.54 \t AccHead 96.63 \t AccTail 85.03\n",
      "Epoch: [109] \t Loss 0.1249 \t Acc 96.14 \t AccHead 96.28 \t AccTail 79.52\n",
      "Epoch: [110] \t Loss 0.1175 \t Acc 96.78 \t AccHead 96.95 \t AccTail 75.90\n",
      "Epoch: [111] \t Loss 0.1158 \t Acc 95.96 \t AccHead 96.06 \t AccTail 85.03\n",
      "Epoch: [112] \t Loss 0.1131 \t Acc 96.42 \t AccHead 96.48 \t AccTail 89.82\n",
      "Epoch: [113] \t Loss 0.1153 \t Acc 96.35 \t AccHead 96.39 \t AccTail 92.22\n",
      "Epoch: [114] \t Loss 0.1126 \t Acc 96.19 \t AccHead 96.29 \t AccTail 84.43\n",
      "Epoch: [115] \t Loss 0.1148 \t Acc 96.27 \t AccHead 96.37 \t AccTail 85.03\n",
      "Epoch: [116] \t Loss 0.1087 \t Acc 96.62 \t AccHead 96.72 \t AccTail 84.43\n",
      "Epoch: [117] \t Loss 0.1059 \t Acc 96.13 \t AccHead 96.19 \t AccTail 89.16\n",
      "Epoch: [118] \t Loss 0.1009 \t Acc 97.00 \t AccHead 97.06 \t AccTail 89.82\n",
      "Epoch: [119] \t Loss 0.1109 \t Acc 96.75 \t AccHead 96.87 \t AccTail 81.93\n",
      "Epoch: [120] \t Loss 0.0987 \t Acc 96.91 \t AccHead 96.97 \t AccTail 89.16\n",
      "Epoch: [121] \t Loss 0.1075 \t Acc 96.92 \t AccHead 96.98 \t AccTail 89.76\n",
      "Epoch: [122] \t Loss 0.0959 \t Acc 97.13 \t AccHead 97.20 \t AccTail 89.22\n",
      "Epoch: [123] \t Loss 0.0973 \t Acc 97.27 \t AccHead 97.40 \t AccTail 81.82\n",
      "Epoch: [124] \t Loss 0.0974 \t Acc 96.62 \t AccHead 96.67 \t AccTail 89.82\n",
      "Epoch: [125] \t Loss 0.1017 \t Acc 97.32 \t AccHead 97.36 \t AccTail 93.33\n",
      "Epoch: [126] \t Loss 0.0975 \t Acc 96.90 \t AccHead 97.02 \t AccTail 82.63\n",
      "Epoch: [127] \t Loss 0.0939 \t Acc 96.36 \t AccHead 96.49 \t AccTail 80.24\n",
      "Epoch: [128] \t Loss 0.0965 \t Acc 97.67 \t AccHead 97.76 \t AccTail 86.14\n",
      "Epoch: [129] \t Loss 0.0902 \t Acc 97.29 \t AccHead 97.38 \t AccTail 86.75\n",
      "Epoch: [130] \t Loss 0.1005 \t Acc 97.17 \t AccHead 97.22 \t AccTail 92.22\n",
      "Epoch: [131] \t Loss 0.0965 \t Acc 97.34 \t AccHead 97.40 \t AccTail 90.42\n",
      "Epoch: [132] \t Loss 0.0930 \t Acc 96.99 \t AccHead 97.07 \t AccTail 87.43\n",
      "Epoch: [133] \t Loss 0.0919 \t Acc 97.66 \t AccHead 97.74 \t AccTail 88.02\n",
      "Epoch: [134] \t Loss 0.0879 \t Acc 96.66 \t AccHead 96.77 \t AccTail 83.83\n",
      "Epoch: [135] \t Loss 0.0894 \t Acc 97.79 \t AccHead 97.82 \t AccTail 93.98\n",
      "Epoch: [136] \t Loss 0.0882 \t Acc 97.22 \t AccHead 97.24 \t AccTail 95.18\n",
      "Epoch: [137] \t Loss 0.0876 \t Acc 97.02 \t AccHead 97.06 \t AccTail 92.22\n",
      "Epoch: [138] \t Loss 0.0867 \t Acc 97.38 \t AccHead 97.44 \t AccTail 91.02\n",
      "Epoch: [139] \t Loss 0.0832 \t Acc 97.03 \t AccHead 97.10 \t AccTail 88.62\n",
      "Epoch: [140] \t Loss 0.0908 \t Acc 97.71 \t AccHead 97.79 \t AccTail 88.62\n",
      "Epoch: [141] \t Loss 0.0819 \t Acc 97.20 \t AccHead 97.27 \t AccTail 89.22\n",
      "Epoch: [142] \t Loss 0.0860 \t Acc 97.58 \t AccHead 97.63 \t AccTail 91.57\n",
      "Epoch: [143] \t Loss 0.0791 \t Acc 97.08 \t AccHead 97.20 \t AccTail 83.23\n",
      "Epoch: [144] \t Loss 0.0892 \t Acc 97.14 \t AccHead 97.24 \t AccTail 86.14\n",
      "Epoch: [145] \t Loss 0.0827 \t Acc 97.19 \t AccHead 97.25 \t AccTail 90.42\n",
      "Epoch: [146] \t Loss 0.0833 \t Acc 97.78 \t AccHead 97.77 \t AccTail 98.20\n",
      "Epoch: [147] \t Loss 0.0796 \t Acc 97.54 \t AccHead 97.58 \t AccTail 92.17\n",
      "Epoch: [148] \t Loss 0.0793 \t Acc 97.33 \t AccHead 97.37 \t AccTail 92.73\n",
      "Epoch: [149] \t Loss 0.0719 \t Acc 96.94 \t AccHead 97.00 \t AccTail 89.70\n",
      "Epoch: [150] \t Loss 0.0789 \t Acc 96.84 \t AccHead 96.94 \t AccTail 84.43\n",
      "Epoch: [151] \t Loss 0.0552 \t Acc 98.93 \t AccHead 98.98 \t AccTail 93.41\n",
      "Epoch: [152] \t Loss 0.0357 \t Acc 99.16 \t AccHead 99.16 \t AccTail 98.80\n",
      "Epoch: [153] \t Loss 0.0340 \t Acc 99.24 \t AccHead 99.29 \t AccTail 93.37\n",
      "Epoch: [154] \t Loss 0.0288 \t Acc 99.21 \t AccHead 99.25 \t AccTail 94.61\n",
      "Epoch: [155] \t Loss 0.0270 \t Acc 99.38 \t AccHead 99.40 \t AccTail 97.58\n",
      "Epoch: [156] \t Loss 0.0245 \t Acc 99.47 \t AccHead 99.48 \t AccTail 98.80\n",
      "Epoch: [157] \t Loss 0.0253 \t Acc 99.53 \t AccHead 99.54 \t AccTail 98.80\n",
      "Epoch: [158] \t Loss 0.0211 \t Acc 99.58 \t AccHead 99.60 \t AccTail 96.99\n",
      "Epoch: [159] \t Loss 0.0212 \t Acc 99.54 \t AccHead 99.55 \t AccTail 98.78\n",
      "Epoch: [160] \t Loss 0.0226 \t Acc 99.44 \t AccHead 99.45 \t AccTail 98.80\n",
      "Epoch: [161] \t Loss 0.0203 \t Acc 99.54 \t AccHead 99.56 \t AccTail 97.01\n",
      "Epoch: [162] \t Loss 0.0192 \t Acc 99.53 \t AccHead 99.55 \t AccTail 97.59\n",
      "Epoch: [163] \t Loss 0.0198 \t Acc 99.56 \t AccHead 99.56 \t AccTail 99.40\n",
      "Epoch: [164] \t Loss 0.0177 \t Acc 99.66 \t AccHead 99.67 \t AccTail 98.20\n",
      "Epoch: [165] \t Loss 0.0155 \t Acc 99.52 \t AccHead 99.53 \t AccTail 97.60\n",
      "Epoch: [166] \t Loss 0.0171 \t Acc 99.64 \t AccHead 99.63 \t AccTail 100.00\n",
      "Epoch: [167] \t Loss 0.0161 \t Acc 99.67 \t AccHead 99.67 \t AccTail 98.80\n",
      "Epoch: [168] \t Loss 0.0146 \t Acc 99.72 \t AccHead 99.73 \t AccTail 98.80\n",
      "Epoch: [169] \t Loss 0.0151 \t Acc 99.69 \t AccHead 99.69 \t AccTail 99.39\n",
      "Epoch: [170] \t Loss 0.0131 \t Acc 99.65 \t AccHead 99.65 \t AccTail 99.40\n",
      "Epoch: [171] \t Loss 0.0140 \t Acc 99.71 \t AccHead 99.71 \t AccTail 98.80\n",
      "Epoch: [172] \t Loss 0.0147 \t Acc 99.72 \t AccHead 99.73 \t AccTail 98.18\n",
      "Epoch: [173] \t Loss 0.0128 \t Acc 99.71 \t AccHead 99.71 \t AccTail 98.80\n",
      "Epoch: [174] \t Loss 0.0136 \t Acc 99.74 \t AccHead 99.73 \t AccTail 100.00\n",
      "Epoch: [175] \t Loss 0.0129 \t Acc 99.74 \t AccHead 99.75 \t AccTail 97.59\n",
      "Epoch: [176] \t Loss 0.0136 \t Acc 99.76 \t AccHead 99.77 \t AccTail 98.80\n",
      "Epoch: [177] \t Loss 0.0131 \t Acc 99.70 \t AccHead 99.70 \t AccTail 99.40\n",
      "Epoch: [178] \t Loss 0.0123 \t Acc 99.77 \t AccHead 99.77 \t AccTail 99.40\n",
      "Epoch: [179] \t Loss 0.0127 \t Acc 99.78 \t AccHead 99.78 \t AccTail 100.00\n",
      "Epoch: [180] \t Loss 0.0143 \t Acc 99.81 \t AccHead 99.81 \t AccTail 99.40\n",
      "Epoch: [181] \t Loss 0.0129 \t Acc 99.78 \t AccHead 99.77 \t AccTail 100.00\n",
      "Epoch: [182] \t Loss 0.0131 \t Acc 99.80 \t AccHead 99.79 \t AccTail 100.00\n",
      "Epoch: [183] \t Loss 0.0109 \t Acc 99.79 \t AccHead 99.79 \t AccTail 100.00\n",
      "Epoch: [184] \t Loss 0.0111 \t Acc 99.83 \t AccHead 99.83 \t AccTail 99.40\n",
      "Epoch: [185] \t Loss 0.0117 \t Acc 99.85 \t AccHead 99.85 \t AccTail 99.40\n",
      "Epoch: [186] \t Loss 0.0097 \t Acc 99.84 \t AccHead 99.84 \t AccTail 98.80\n",
      "Epoch: [187] \t Loss 0.0114 \t Acc 99.77 \t AccHead 99.77 \t AccTail 98.80\n",
      "Epoch: [188] \t Loss 0.0105 \t Acc 99.76 \t AccHead 99.77 \t AccTail 98.80\n",
      "Epoch: [189] \t Loss 0.0101 \t Acc 99.83 \t AccHead 99.83 \t AccTail 99.40\n",
      "Epoch: [190] \t Loss 0.0104 \t Acc 99.80 \t AccHead 99.81 \t AccTail 98.80\n",
      "Epoch: [191] \t Loss 0.0096 \t Acc 99.81 \t AccHead 99.81 \t AccTail 99.40\n",
      "Epoch: [192] \t Loss 0.0107 \t Acc 99.84 \t AccHead 99.83 \t AccTail 100.00\n",
      "Epoch: [193] \t Loss 0.0099 \t Acc 99.86 \t AccHead 99.86 \t AccTail 100.00\n",
      "Epoch: [194] \t Loss 0.0090 \t Acc 99.82 \t AccHead 99.82 \t AccTail 99.39\n",
      "Epoch: [195] \t Loss 0.0093 \t Acc 99.86 \t AccHead 99.86 \t AccTail 100.00\n",
      "Epoch: [196] \t Loss 0.0092 \t Acc 99.83 \t AccHead 99.83 \t AccTail 99.40\n",
      "Epoch: [197] \t Loss 0.0084 \t Acc 99.85 \t AccHead 99.85 \t AccTail 100.00\n",
      "Epoch: [198] \t Loss 0.0084 \t Acc 99.87 \t AccHead 99.88 \t AccTail 98.80\n",
      "Epoch: [199] \t Loss 0.0082 \t Acc 99.81 \t AccHead 99.82 \t AccTail 97.59\n",
      "Epoch: [200] \t Loss 0.0088 \t Acc 99.86 \t AccHead 99.86 \t AccTail 99.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 06:20:11,442]\u001b[0m Trial 3 finished with value: 42.867252349853516 and parameters: {'n_epoch': 200, 'weight_decay': 2.233483397253652e-05}. Best is trial 1 with value: 44.30290222167969.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 42.87 \t AccHead 83.88 \t AccTail 0.94\n",
      "Epoch: [001] \t Loss 2.1952 \t Acc 48.59 \t AccHead 48.99 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.2729 \t Acc 54.37 \t AccHead 54.83 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.1514 \t Acc 57.36 \t AccHead 57.84 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.0705 \t Acc 58.56 \t AccHead 59.05 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.0022 \t Acc 61.75 \t AccHead 62.27 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 0.9575 \t Acc 64.66 \t AccHead 65.20 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 0.8957 \t Acc 68.63 \t AccHead 69.21 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 0.8523 \t Acc 70.27 \t AccHead 70.85 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 0.7970 \t Acc 71.02 \t AccHead 71.61 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 0.7690 \t Acc 73.93 \t AccHead 74.55 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 0.7358 \t Acc 74.90 \t AccHead 75.52 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 0.6943 \t Acc 75.91 \t AccHead 76.54 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 0.6706 \t Acc 77.36 \t AccHead 78.00 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 0.6597 \t Acc 77.10 \t AccHead 77.74 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 0.6388 \t Acc 78.86 \t AccHead 79.51 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 0.6221 \t Acc 79.14 \t AccHead 79.80 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 0.6021 \t Acc 79.75 \t AccHead 80.42 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 0.5829 \t Acc 80.77 \t AccHead 81.44 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 0.5755 \t Acc 81.88 \t AccHead 82.56 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 0.5590 \t Acc 79.65 \t AccHead 80.32 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 0.5484 \t Acc 82.55 \t AccHead 83.24 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 0.5335 \t Acc 82.10 \t AccHead 82.78 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 0.5233 \t Acc 81.97 \t AccHead 82.66 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 0.5118 \t Acc 82.11 \t AccHead 82.80 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 0.5062 \t Acc 81.46 \t AccHead 82.14 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 0.5025 \t Acc 81.67 \t AccHead 82.36 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 0.4838 \t Acc 84.71 \t AccHead 85.42 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 0.4772 \t Acc 84.33 \t AccHead 85.03 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 0.4710 \t Acc 85.20 \t AccHead 85.91 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 0.4652 \t Acc 85.90 \t AccHead 86.62 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 0.4555 \t Acc 84.02 \t AccHead 84.71 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 0.4586 \t Acc 84.67 \t AccHead 85.37 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 0.4422 \t Acc 85.14 \t AccHead 85.85 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 0.4362 \t Acc 85.10 \t AccHead 85.81 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 0.4320 \t Acc 85.72 \t AccHead 86.43 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 0.4271 \t Acc 84.35 \t AccHead 85.05 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 0.4095 \t Acc 85.85 \t AccHead 86.57 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 0.4065 \t Acc 84.94 \t AccHead 85.65 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 0.4052 \t Acc 87.21 \t AccHead 87.94 \t AccTail 0.60\n",
      "Epoch: [040] \t Loss 0.3948 \t Acc 85.83 \t AccHead 86.54 \t AccTail 0.60\n",
      "Epoch: [041] \t Loss 0.4006 \t Acc 87.06 \t AccHead 87.79 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 0.3928 \t Acc 86.57 \t AccHead 87.27 \t AccTail 2.40\n",
      "Epoch: [043] \t Loss 0.3954 \t Acc 86.86 \t AccHead 87.58 \t AccTail 0.00\n",
      "Epoch: [044] \t Loss 0.3794 \t Acc 86.75 \t AccHead 87.48 \t AccTail 0.60\n",
      "Epoch: [045] \t Loss 0.3780 \t Acc 87.26 \t AccHead 87.96 \t AccTail 2.42\n",
      "Epoch: [046] \t Loss 0.3778 \t Acc 86.86 \t AccHead 87.57 \t AccTail 1.80\n",
      "Epoch: [047] \t Loss 0.3689 \t Acc 88.55 \t AccHead 89.20 \t AccTail 10.91\n",
      "Epoch: [048] \t Loss 0.3640 \t Acc 87.63 \t AccHead 88.28 \t AccTail 10.18\n",
      "Epoch: [049] \t Loss 0.3669 \t Acc 86.75 \t AccHead 87.42 \t AccTail 7.19\n",
      "Epoch: [050] \t Loss 0.3632 \t Acc 88.45 \t AccHead 89.09 \t AccTail 10.37\n",
      "Epoch: [051] \t Loss 0.3512 \t Acc 87.53 \t AccHead 88.17 \t AccTail 11.98\n",
      "Epoch: [052] \t Loss 0.3403 \t Acc 87.77 \t AccHead 88.35 \t AccTail 18.56\n",
      "Epoch: [053] \t Loss 0.3450 \t Acc 88.96 \t AccHead 89.53 \t AccTail 21.08\n",
      "Epoch: [054] \t Loss 0.3355 \t Acc 89.30 \t AccHead 89.95 \t AccTail 10.84\n",
      "Epoch: [055] \t Loss 0.3375 \t Acc 88.46 \t AccHead 89.11 \t AccTail 11.38\n",
      "Epoch: [056] \t Loss 0.3334 \t Acc 86.45 \t AccHead 86.98 \t AccTail 22.16\n",
      "Epoch: [057] \t Loss 0.3305 \t Acc 89.78 \t AccHead 90.30 \t AccTail 27.27\n",
      "Epoch: [058] \t Loss 0.3277 \t Acc 88.02 \t AccHead 88.54 \t AccTail 26.06\n",
      "Epoch: [059] \t Loss 0.3133 \t Acc 87.17 \t AccHead 87.73 \t AccTail 20.36\n",
      "Epoch: [060] \t Loss 0.3257 \t Acc 88.66 \t AccHead 89.24 \t AccTail 19.88\n",
      "Epoch: [061] \t Loss 0.3138 \t Acc 89.46 \t AccHead 90.07 \t AccTail 15.76\n",
      "Epoch: [062] \t Loss 0.3281 \t Acc 88.96 \t AccHead 89.45 \t AccTail 31.14\n",
      "Epoch: [063] \t Loss 0.3125 \t Acc 88.68 \t AccHead 89.21 \t AccTail 25.75\n",
      "Epoch: [064] \t Loss 0.3090 \t Acc 89.65 \t AccHead 90.01 \t AccTail 46.99\n",
      "Epoch: [065] \t Loss 0.3037 \t Acc 88.70 \t AccHead 89.21 \t AccTail 27.71\n",
      "Epoch: [066] \t Loss 0.3066 \t Acc 87.82 \t AccHead 88.28 \t AccTail 32.93\n",
      "Epoch: [067] \t Loss 0.3115 \t Acc 90.37 \t AccHead 90.85 \t AccTail 32.93\n",
      "Epoch: [068] \t Loss 0.3042 \t Acc 88.60 \t AccHead 89.09 \t AccTail 30.54\n",
      "Epoch: [069] \t Loss 0.2940 \t Acc 90.72 \t AccHead 91.20 \t AccTail 32.73\n",
      "Epoch: [070] \t Loss 0.2928 \t Acc 90.57 \t AccHead 91.02 \t AccTail 35.93\n",
      "Epoch: [071] \t Loss 0.2943 \t Acc 90.15 \t AccHead 90.49 \t AccTail 50.30\n",
      "Epoch: [072] \t Loss 0.2905 \t Acc 90.53 \t AccHead 90.99 \t AccTail 35.33\n",
      "Epoch: [073] \t Loss 0.2879 \t Acc 91.84 \t AccHead 92.19 \t AccTail 49.70\n",
      "Epoch: [074] \t Loss 0.2892 \t Acc 91.66 \t AccHead 92.02 \t AccTail 48.50\n",
      "Epoch: [075] \t Loss 0.2796 \t Acc 90.37 \t AccHead 90.63 \t AccTail 59.04\n",
      "Epoch: [076] \t Loss 0.2831 \t Acc 91.27 \t AccHead 91.63 \t AccTail 47.27\n",
      "Epoch: [077] \t Loss 0.2823 \t Acc 90.85 \t AccHead 91.32 \t AccTail 33.73\n",
      "Epoch: [078] \t Loss 0.2812 \t Acc 90.55 \t AccHead 90.83 \t AccTail 56.02\n",
      "Epoch: [079] \t Loss 0.2745 \t Acc 91.18 \t AccHead 91.62 \t AccTail 38.18\n",
      "Epoch: [080] \t Loss 0.2749 \t Acc 89.30 \t AccHead 89.57 \t AccTail 56.29\n",
      "Epoch: [081] \t Loss 0.2637 \t Acc 90.93 \t AccHead 91.31 \t AccTail 45.78\n",
      "Epoch: [082] \t Loss 0.2706 \t Acc 88.39 \t AccHead 88.84 \t AccTail 34.73\n",
      "Epoch: [083] \t Loss 0.2686 \t Acc 90.80 \t AccHead 91.16 \t AccTail 48.50\n",
      "Epoch: [084] \t Loss 0.2644 \t Acc 91.88 \t AccHead 92.28 \t AccTail 44.31\n",
      "Epoch: [085] \t Loss 0.2720 \t Acc 91.60 \t AccHead 91.95 \t AccTail 50.00\n",
      "Epoch: [086] \t Loss 0.2653 \t Acc 90.13 \t AccHead 90.49 \t AccTail 46.71\n",
      "Epoch: [087] \t Loss 0.2696 \t Acc 91.61 \t AccHead 92.02 \t AccTail 43.11\n",
      "Epoch: [088] \t Loss 0.2617 \t Acc 89.89 \t AccHead 90.27 \t AccTail 44.24\n",
      "Epoch: [089] \t Loss 0.2583 \t Acc 88.81 \t AccHead 89.14 \t AccTail 49.40\n",
      "Epoch: [090] \t Loss 0.2510 \t Acc 91.65 \t AccHead 92.03 \t AccTail 46.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 06:36:07,840]\u001b[0m Trial 4 finished with value: 41.68436050415039 and parameters: {'n_epoch': 90, 'weight_decay': 0.00015369110702309987}. Best is trial 1 with value: 44.30290222167969.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 41.68 \t AccHead 81.02 \t AccTail 1.47\n",
      "Epoch: [001] \t Loss 1.9948 \t Acc 51.57 \t AccHead 52.00 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.2458 \t Acc 55.53 \t AccHead 56.00 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.1004 \t Acc 58.27 \t AccHead 58.75 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.0364 \t Acc 61.52 \t AccHead 62.04 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 0.9751 \t Acc 65.44 \t AccHead 65.99 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 0.9074 \t Acc 66.86 \t AccHead 67.42 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 0.8696 \t Acc 68.77 \t AccHead 69.34 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 0.8143 \t Acc 72.51 \t AccHead 73.11 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 0.7606 \t Acc 73.68 \t AccHead 74.30 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 0.7255 \t Acc 74.39 \t AccHead 75.02 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 0.7115 \t Acc 75.41 \t AccHead 76.04 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 0.6764 \t Acc 78.85 \t AccHead 79.51 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 0.6614 \t Acc 74.97 \t AccHead 75.59 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 0.6298 \t Acc 77.97 \t AccHead 78.62 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 0.6209 \t Acc 78.93 \t AccHead 79.58 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 0.5929 \t Acc 78.47 \t AccHead 79.12 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 0.5925 \t Acc 80.23 \t AccHead 80.90 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 0.5735 \t Acc 81.64 \t AccHead 82.33 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 0.5665 \t Acc 77.12 \t AccHead 77.77 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 0.5437 \t Acc 80.52 \t AccHead 81.20 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 0.5383 \t Acc 82.07 \t AccHead 82.75 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 0.5261 \t Acc 83.67 \t AccHead 84.36 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 0.5117 \t Acc 81.19 \t AccHead 81.87 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 0.5111 \t Acc 84.05 \t AccHead 84.75 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 0.5051 \t Acc 82.68 \t AccHead 83.37 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 0.4891 \t Acc 80.16 \t AccHead 80.83 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 0.4832 \t Acc 82.98 \t AccHead 83.67 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 0.4804 \t Acc 82.79 \t AccHead 83.48 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 0.4651 \t Acc 84.00 \t AccHead 84.71 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 0.4622 \t Acc 84.42 \t AccHead 85.12 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 0.4672 \t Acc 83.60 \t AccHead 84.30 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 0.4545 \t Acc 84.55 \t AccHead 85.26 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 0.4552 \t Acc 85.33 \t AccHead 86.04 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 0.4495 \t Acc 85.20 \t AccHead 85.91 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 0.4417 \t Acc 83.97 \t AccHead 84.68 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 0.4346 \t Acc 85.89 \t AccHead 86.61 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 0.4362 \t Acc 84.12 \t AccHead 84.83 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 0.4397 \t Acc 84.69 \t AccHead 85.40 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 0.4213 \t Acc 86.99 \t AccHead 87.71 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 0.4222 \t Acc 87.24 \t AccHead 87.96 \t AccTail 0.60\n",
      "Epoch: [041] \t Loss 0.4153 \t Acc 86.25 \t AccHead 86.97 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 0.4115 \t Acc 87.13 \t AccHead 87.85 \t AccTail 0.60\n",
      "Epoch: [043] \t Loss 0.4021 \t Acc 86.43 \t AccHead 87.14 \t AccTail 0.60\n",
      "Epoch: [044] \t Loss 0.4138 \t Acc 85.47 \t AccHead 86.16 \t AccTail 3.59\n",
      "Epoch: [045] \t Loss 0.4021 \t Acc 85.56 \t AccHead 86.27 \t AccTail 0.60\n",
      "Epoch: [046] \t Loss 0.3957 \t Acc 85.45 \t AccHead 86.11 \t AccTail 6.63\n",
      "Epoch: [047] \t Loss 0.3886 \t Acc 85.21 \t AccHead 85.86 \t AccTail 7.23\n",
      "Epoch: [048] \t Loss 0.3926 \t Acc 85.10 \t AccHead 85.76 \t AccTail 5.39\n",
      "Epoch: [049] \t Loss 0.3925 \t Acc 87.64 \t AccHead 88.34 \t AccTail 3.61\n",
      "Epoch: [050] \t Loss 0.3791 \t Acc 86.33 \t AccHead 87.00 \t AccTail 5.39\n",
      "Epoch: [051] \t Loss 0.3851 \t Acc 88.05 \t AccHead 88.74 \t AccTail 6.02\n",
      "Epoch: [052] \t Loss 0.3710 \t Acc 84.90 \t AccHead 85.55 \t AccTail 6.02\n",
      "Epoch: [053] \t Loss 0.3831 \t Acc 87.35 \t AccHead 88.01 \t AccTail 7.83\n",
      "Epoch: [054] \t Loss 0.3767 \t Acc 86.97 \t AccHead 87.68 \t AccTail 2.40\n",
      "Epoch: [055] \t Loss 0.3743 \t Acc 87.59 \t AccHead 88.20 \t AccTail 15.57\n",
      "Epoch: [056] \t Loss 0.3695 \t Acc 88.17 \t AccHead 88.84 \t AccTail 8.43\n",
      "Epoch: [057] \t Loss 0.3692 \t Acc 86.80 \t AccHead 87.50 \t AccTail 2.99\n",
      "Epoch: [058] \t Loss 0.3728 \t Acc 86.60 \t AccHead 87.18 \t AccTail 16.87\n",
      "Epoch: [059] \t Loss 0.3721 \t Acc 86.52 \t AccHead 87.06 \t AccTail 21.34\n",
      "Epoch: [060] \t Loss 0.3569 \t Acc 87.68 \t AccHead 88.35 \t AccTail 7.78\n",
      "Epoch: [061] \t Loss 0.3599 \t Acc 84.06 \t AccHead 84.69 \t AccTail 9.04\n",
      "Epoch: [062] \t Loss 0.3497 \t Acc 88.16 \t AccHead 88.71 \t AccTail 21.56\n",
      "Epoch: [063] \t Loss 0.3637 \t Acc 86.27 \t AccHead 86.86 \t AccTail 14.97\n",
      "Epoch: [064] \t Loss 0.3566 \t Acc 88.90 \t AccHead 89.51 \t AccTail 15.06\n",
      "Epoch: [065] \t Loss 0.3567 \t Acc 86.30 \t AccHead 86.92 \t AccTail 12.57\n",
      "Epoch: [066] \t Loss 0.3534 \t Acc 87.80 \t AccHead 88.34 \t AccTail 22.42\n",
      "Epoch: [067] \t Loss 0.3551 \t Acc 86.51 \t AccHead 87.07 \t AccTail 19.76\n",
      "Epoch: [068] \t Loss 0.3504 \t Acc 88.28 \t AccHead 88.86 \t AccTail 19.16\n",
      "Epoch: [069] \t Loss 0.3475 \t Acc 87.86 \t AccHead 88.39 \t AccTail 23.95\n",
      "Epoch: [070] \t Loss 0.3417 \t Acc 89.04 \t AccHead 89.62 \t AccTail 18.67\n",
      "Epoch: [071] \t Loss 0.3405 \t Acc 89.89 \t AccHead 90.53 \t AccTail 13.17\n",
      "Epoch: [072] \t Loss 0.3337 \t Acc 88.70 \t AccHead 89.29 \t AccTail 17.58\n",
      "Epoch: [073] \t Loss 0.3266 \t Acc 87.15 \t AccHead 87.70 \t AccTail 21.56\n",
      "Epoch: [074] \t Loss 0.3392 \t Acc 85.55 \t AccHead 86.18 \t AccTail 10.78\n",
      "Epoch: [075] \t Loss 0.3368 \t Acc 86.25 \t AccHead 86.82 \t AccTail 17.47\n",
      "Epoch: [076] \t Loss 0.3385 \t Acc 86.42 \t AccHead 86.97 \t AccTail 20.36\n",
      "Epoch: [077] \t Loss 0.3274 \t Acc 89.07 \t AccHead 89.57 \t AccTail 28.74\n",
      "Epoch: [078] \t Loss 0.3361 \t Acc 89.25 \t AccHead 89.79 \t AccTail 24.55\n",
      "Epoch: [079] \t Loss 0.3292 \t Acc 89.67 \t AccHead 90.24 \t AccTail 21.56\n",
      "Epoch: [080] \t Loss 0.3260 \t Acc 89.69 \t AccHead 90.17 \t AccTail 32.93\n",
      "Epoch: [081] \t Loss 0.3321 \t Acc 90.18 \t AccHead 90.71 \t AccTail 26.35\n",
      "Epoch: [082] \t Loss 0.3307 \t Acc 88.01 \t AccHead 88.55 \t AccTail 23.35\n",
      "Epoch: [083] \t Loss 0.3286 \t Acc 84.21 \t AccHead 84.76 \t AccTail 18.67\n",
      "Epoch: [084] \t Loss 0.3238 \t Acc 90.39 \t AccHead 90.98 \t AccTail 19.28\n",
      "Epoch: [085] \t Loss 0.3211 \t Acc 87.29 \t AccHead 87.90 \t AccTail 13.86\n",
      "Epoch: [086] \t Loss 0.3256 \t Acc 89.71 \t AccHead 90.28 \t AccTail 22.29\n",
      "Epoch: [087] \t Loss 0.3145 \t Acc 89.65 \t AccHead 90.16 \t AccTail 28.74\n",
      "Epoch: [088] \t Loss 0.3285 \t Acc 90.58 \t AccHead 91.19 \t AccTail 17.37\n",
      "Epoch: [089] \t Loss 0.3228 \t Acc 87.61 \t AccHead 88.06 \t AccTail 33.73\n",
      "Epoch: [090] \t Loss 0.3201 \t Acc 90.28 \t AccHead 90.82 \t AccTail 24.70\n",
      "Epoch: [091] \t Loss 0.3106 \t Acc 90.32 \t AccHead 90.77 \t AccTail 36.14\n",
      "Epoch: [092] \t Loss 0.3175 \t Acc 88.41 \t AccHead 88.89 \t AccTail 30.30\n",
      "Epoch: [093] \t Loss 0.3103 \t Acc 89.26 \t AccHead 89.69 \t AccTail 38.32\n",
      "Epoch: [094] \t Loss 0.3053 \t Acc 88.86 \t AccHead 89.22 \t AccTail 45.78\n",
      "Epoch: [095] \t Loss 0.3155 \t Acc 88.23 \t AccHead 88.84 \t AccTail 14.55\n",
      "Epoch: [096] \t Loss 0.3196 \t Acc 87.92 \t AccHead 88.38 \t AccTail 31.93\n",
      "Epoch: [097] \t Loss 0.3144 \t Acc 89.28 \t AccHead 89.84 \t AccTail 22.16\n",
      "Epoch: [098] \t Loss 0.3166 \t Acc 89.11 \t AccHead 89.68 \t AccTail 21.56\n",
      "Epoch: [099] \t Loss 0.3115 \t Acc 89.91 \t AccHead 90.45 \t AccTail 25.30\n",
      "Epoch: [100] \t Loss 0.3124 \t Acc 90.08 \t AccHead 90.47 \t AccTail 43.11\n",
      "Epoch: [101] \t Loss 0.3107 \t Acc 89.50 \t AccHead 89.91 \t AccTail 40.12\n",
      "Epoch: [102] \t Loss 0.3135 \t Acc 90.18 \t AccHead 90.68 \t AccTail 30.54\n",
      "Epoch: [103] \t Loss 0.3081 \t Acc 88.71 \t AccHead 89.19 \t AccTail 31.74\n",
      "Epoch: [104] \t Loss 0.3007 \t Acc 88.66 \t AccHead 89.12 \t AccTail 34.73\n",
      "Epoch: [105] \t Loss 0.3006 \t Acc 90.58 \t AccHead 91.14 \t AccTail 23.35\n",
      "Epoch: [106] \t Loss 0.2985 \t Acc 90.37 \t AccHead 90.88 \t AccTail 29.94\n",
      "Epoch: [107] \t Loss 0.2953 \t Acc 88.13 \t AccHead 88.58 \t AccTail 34.73\n",
      "Epoch: [108] \t Loss 0.3007 \t Acc 89.60 \t AccHead 90.04 \t AccTail 37.13\n",
      "Epoch: [109] \t Loss 0.3071 \t Acc 91.58 \t AccHead 92.17 \t AccTail 20.48\n",
      "Epoch: [110] \t Loss 0.3022 \t Acc 90.03 \t AccHead 90.50 \t AccTail 34.73\n",
      "Epoch: [111] \t Loss 0.2986 \t Acc 89.08 \t AccHead 89.62 \t AccTail 24.10\n",
      "Epoch: [112] \t Loss 0.3025 \t Acc 90.60 \t AccHead 91.01 \t AccTail 40.61\n",
      "Epoch: [113] \t Loss 0.3024 \t Acc 89.14 \t AccHead 89.64 \t AccTail 29.34\n",
      "Epoch: [114] \t Loss 0.3009 \t Acc 89.79 \t AccHead 90.23 \t AccTail 38.32\n",
      "Epoch: [115] \t Loss 0.3072 \t Acc 88.49 \t AccHead 88.90 \t AccTail 39.52\n",
      "Epoch: [116] \t Loss 0.3043 \t Acc 89.56 \t AccHead 90.05 \t AccTail 30.12\n",
      "Epoch: [117] \t Loss 0.3004 \t Acc 88.42 \t AccHead 89.03 \t AccTail 16.17\n",
      "Epoch: [118] \t Loss 0.2992 \t Acc 90.09 \t AccHead 90.45 \t AccTail 47.90\n",
      "Epoch: [119] \t Loss 0.2862 \t Acc 90.08 \t AccHead 90.46 \t AccTail 44.24\n",
      "Epoch: [120] \t Loss 0.3024 \t Acc 89.65 \t AccHead 90.06 \t AccTail 40.61\n",
      "Epoch: [121] \t Loss 0.3070 \t Acc 88.94 \t AccHead 89.39 \t AccTail 34.73\n",
      "Epoch: [122] \t Loss 0.2928 \t Acc 88.96 \t AccHead 89.41 \t AccTail 34.73\n",
      "Epoch: [123] \t Loss 0.2929 \t Acc 91.02 \t AccHead 91.47 \t AccTail 37.35\n",
      "Epoch: [124] \t Loss 0.2891 \t Acc 89.79 \t AccHead 90.12 \t AccTail 50.00\n",
      "Epoch: [125] \t Loss 0.2913 \t Acc 89.95 \t AccHead 90.33 \t AccTail 45.18\n",
      "Epoch: [126] \t Loss 0.2867 \t Acc 90.19 \t AccHead 90.57 \t AccTail 44.91\n",
      "Epoch: [127] \t Loss 0.2940 \t Acc 88.85 \t AccHead 89.34 \t AccTail 30.54\n",
      "Epoch: [128] \t Loss 0.2936 \t Acc 90.12 \t AccHead 90.54 \t AccTail 39.52\n",
      "Epoch: [129] \t Loss 0.2904 \t Acc 90.94 \t AccHead 91.37 \t AccTail 39.52\n",
      "Epoch: [130] \t Loss 0.2974 \t Acc 89.97 \t AccHead 90.47 \t AccTail 30.54\n",
      "Epoch: [131] \t Loss 0.2924 \t Acc 89.64 \t AccHead 90.04 \t AccTail 42.51\n",
      "Epoch: [132] \t Loss 0.2881 \t Acc 89.20 \t AccHead 89.75 \t AccTail 22.29\n",
      "Epoch: [133] \t Loss 0.2895 \t Acc 90.65 \t AccHead 90.98 \t AccTail 51.50\n",
      "Epoch: [134] \t Loss 0.2892 \t Acc 89.61 \t AccHead 90.03 \t AccTail 40.12\n",
      "Epoch: [135] \t Loss 0.2885 \t Acc 89.53 \t AccHead 90.00 \t AccTail 33.53\n",
      "Epoch: [136] \t Loss 0.2887 \t Acc 90.21 \t AccHead 90.54 \t AccTail 50.90\n",
      "Epoch: [137] \t Loss 0.2866 \t Acc 88.96 \t AccHead 89.32 \t AccTail 45.18\n",
      "Epoch: [138] \t Loss 0.2919 \t Acc 89.85 \t AccHead 90.24 \t AccTail 43.11\n",
      "Epoch: [139] \t Loss 0.3013 \t Acc 89.30 \t AccHead 89.75 \t AccTail 35.93\n",
      "Epoch: [140] \t Loss 0.2817 \t Acc 88.74 \t AccHead 89.27 \t AccTail 25.75\n",
      "Epoch: [141] \t Loss 0.2830 \t Acc 90.62 \t AccHead 90.97 \t AccTail 49.10\n",
      "Epoch: [142] \t Loss 0.2799 \t Acc 86.99 \t AccHead 87.44 \t AccTail 32.53\n",
      "Epoch: [143] \t Loss 0.2894 \t Acc 88.97 \t AccHead 89.51 \t AccTail 23.95\n",
      "Epoch: [144] \t Loss 0.2818 \t Acc 89.79 \t AccHead 90.29 \t AccTail 29.52\n",
      "Epoch: [145] \t Loss 0.2886 \t Acc 89.77 \t AccHead 90.11 \t AccTail 49.10\n",
      "Epoch: [146] \t Loss 0.2824 \t Acc 90.19 \t AccHead 90.68 \t AccTail 30.91\n",
      "Epoch: [147] \t Loss 0.2834 \t Acc 89.26 \t AccHead 89.63 \t AccTail 44.91\n",
      "Epoch: [148] \t Loss 0.2871 \t Acc 88.59 \t AccHead 89.02 \t AccTail 37.13\n",
      "Epoch: [149] \t Loss 0.2765 \t Acc 90.10 \t AccHead 90.51 \t AccTail 40.61\n",
      "Epoch: [150] \t Loss 0.2883 \t Acc 88.36 \t AccHead 88.79 \t AccTail 37.72\n",
      "Epoch: [151] \t Loss 0.2013 \t Acc 95.31 \t AccHead 95.61 \t AccTail 59.04\n",
      "Epoch: [152] \t Loss 0.1557 \t Acc 96.04 \t AccHead 96.32 \t AccTail 62.42\n",
      "Epoch: [153] \t Loss 0.1289 \t Acc 96.44 \t AccHead 96.61 \t AccTail 75.45\n",
      "Epoch: [154] \t Loss 0.1220 \t Acc 96.79 \t AccHead 96.99 \t AccTail 71.86\n",
      "Epoch: [155] \t Loss 0.1086 \t Acc 97.19 \t AccHead 97.38 \t AccTail 74.85\n",
      "Epoch: [156] \t Loss 0.1035 \t Acc 97.30 \t AccHead 97.48 \t AccTail 76.05\n",
      "Epoch: [157] \t Loss 0.1034 \t Acc 97.35 \t AccHead 97.55 \t AccTail 73.33\n",
      "Epoch: [158] \t Loss 0.0976 \t Acc 97.47 \t AccHead 97.67 \t AccTail 73.49\n",
      "Epoch: [159] \t Loss 0.0908 \t Acc 97.74 \t AccHead 97.92 \t AccTail 76.65\n",
      "Epoch: [160] \t Loss 0.0821 \t Acc 97.69 \t AccHead 97.87 \t AccTail 76.65\n",
      "Epoch: [161] \t Loss 0.0834 \t Acc 97.99 \t AccHead 98.18 \t AccTail 75.15\n",
      "Epoch: [162] \t Loss 0.0762 \t Acc 97.91 \t AccHead 98.06 \t AccTail 79.64\n",
      "Epoch: [163] \t Loss 0.0722 \t Acc 97.92 \t AccHead 98.07 \t AccTail 79.52\n",
      "Epoch: [164] \t Loss 0.0744 \t Acc 98.11 \t AccHead 98.25 \t AccTail 80.84\n",
      "Epoch: [165] \t Loss 0.0681 \t Acc 98.21 \t AccHead 98.35 \t AccTail 82.04\n",
      "Epoch: [166] \t Loss 0.0711 \t Acc 98.36 \t AccHead 98.49 \t AccTail 83.23\n",
      "Epoch: [167] \t Loss 0.0657 \t Acc 98.31 \t AccHead 98.45 \t AccTail 82.04\n",
      "Epoch: [168] \t Loss 0.0604 \t Acc 98.67 \t AccHead 98.82 \t AccTail 80.61\n",
      "Epoch: [169] \t Loss 0.0577 \t Acc 98.58 \t AccHead 98.69 \t AccTail 85.54\n",
      "Epoch: [170] \t Loss 0.0569 \t Acc 98.58 \t AccHead 98.72 \t AccTail 82.04\n",
      "Epoch: [171] \t Loss 0.0538 \t Acc 98.46 \t AccHead 98.56 \t AccTail 85.54\n",
      "Epoch: [172] \t Loss 0.0556 \t Acc 98.66 \t AccHead 98.79 \t AccTail 83.64\n",
      "Epoch: [173] \t Loss 0.0566 \t Acc 98.65 \t AccHead 98.74 \t AccTail 88.55\n",
      "Epoch: [174] \t Loss 0.0542 \t Acc 98.84 \t AccHead 98.93 \t AccTail 88.62\n",
      "Epoch: [175] \t Loss 0.0485 \t Acc 98.84 \t AccHead 98.97 \t AccTail 83.23\n",
      "Epoch: [176] \t Loss 0.0504 \t Acc 98.85 \t AccHead 98.94 \t AccTail 87.35\n",
      "Epoch: [177] \t Loss 0.0466 \t Acc 98.74 \t AccHead 98.82 \t AccTail 89.82\n",
      "Epoch: [178] \t Loss 0.0471 \t Acc 98.79 \t AccHead 98.90 \t AccTail 85.54\n",
      "Epoch: [179] \t Loss 0.0474 \t Acc 98.96 \t AccHead 99.07 \t AccTail 85.03\n",
      "Epoch: [180] \t Loss 0.0430 \t Acc 98.98 \t AccHead 99.10 \t AccTail 85.45\n",
      "Epoch: [181] \t Loss 0.0427 \t Acc 99.01 \t AccHead 99.07 \t AccTail 91.62\n",
      "Epoch: [182] \t Loss 0.0470 \t Acc 98.73 \t AccHead 98.81 \t AccTail 88.48\n",
      "Epoch: [183] \t Loss 0.0382 \t Acc 98.93 \t AccHead 99.01 \t AccTail 89.22\n",
      "Epoch: [184] \t Loss 0.0416 \t Acc 98.99 \t AccHead 99.07 \t AccTail 89.70\n",
      "Epoch: [185] \t Loss 0.0400 \t Acc 99.04 \t AccHead 99.11 \t AccTail 91.02\n",
      "Epoch: [186] \t Loss 0.0414 \t Acc 99.04 \t AccHead 99.09 \t AccTail 93.37\n",
      "Epoch: [187] \t Loss 0.0393 \t Acc 99.09 \t AccHead 99.18 \t AccTail 89.22\n",
      "Epoch: [188] \t Loss 0.0378 \t Acc 98.92 \t AccHead 98.99 \t AccTail 90.42\n",
      "Epoch: [189] \t Loss 0.0375 \t Acc 98.84 \t AccHead 98.90 \t AccTail 91.57\n",
      "Epoch: [190] \t Loss 0.0422 \t Acc 99.16 \t AccHead 99.22 \t AccTail 92.07\n",
      "Epoch: [191] \t Loss 0.0372 \t Acc 98.96 \t AccHead 99.02 \t AccTail 92.22\n",
      "Epoch: [192] \t Loss 0.0328 \t Acc 99.13 \t AccHead 99.19 \t AccTail 92.12\n",
      "Epoch: [193] \t Loss 0.0361 \t Acc 99.01 \t AccHead 99.07 \t AccTail 92.81\n",
      "Epoch: [194] \t Loss 0.0371 \t Acc 99.09 \t AccHead 99.15 \t AccTail 91.62\n",
      "Epoch: [195] \t Loss 0.0334 \t Acc 99.20 \t AccHead 99.27 \t AccTail 91.52\n",
      "Epoch: [196] \t Loss 0.0338 \t Acc 99.01 \t AccHead 99.06 \t AccTail 93.41\n",
      "Epoch: [197] \t Loss 0.0344 \t Acc 98.96 \t AccHead 99.02 \t AccTail 90.96\n",
      "Epoch: [198] \t Loss 0.0330 \t Acc 99.14 \t AccHead 99.18 \t AccTail 95.21\n",
      "Epoch: [199] \t Loss 0.0325 \t Acc 99.21 \t AccHead 99.28 \t AccTail 91.02\n",
      "Epoch: [200] \t Loss 0.0324 \t Acc 99.24 \t AccHead 99.28 \t AccTail 94.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 07:11:17,590]\u001b[0m Trial 5 finished with value: 44.64664840698242 and parameters: {'n_epoch': 200, 'weight_decay': 0.00028816855210490395}. Best is trial 5 with value: 44.64664840698242.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 44.65 \t AccHead 86.46 \t AccTail 1.90\n",
      "Epoch: [001] \t Loss 2.1425 \t Acc 50.25 \t AccHead 50.67 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.2664 \t Acc 49.45 \t AccHead 49.86 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.1136 \t Acc 57.45 \t AccHead 57.93 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.0627 \t Acc 60.17 \t AccHead 60.67 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.0099 \t Acc 61.57 \t AccHead 62.09 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 0.9459 \t Acc 66.21 \t AccHead 66.76 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 0.9016 \t Acc 66.78 \t AccHead 67.34 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 0.8577 \t Acc 69.56 \t AccHead 70.14 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 0.8259 \t Acc 71.77 \t AccHead 72.37 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 0.7729 \t Acc 74.27 \t AccHead 74.89 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 0.7308 \t Acc 75.56 \t AccHead 76.19 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 0.7038 \t Acc 74.19 \t AccHead 74.81 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 0.6928 \t Acc 74.01 \t AccHead 74.63 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 0.6757 \t Acc 78.04 \t AccHead 78.69 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 0.6477 \t Acc 77.12 \t AccHead 77.76 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 0.6260 \t Acc 78.54 \t AccHead 79.19 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 0.6056 \t Acc 80.66 \t AccHead 81.33 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 0.5901 \t Acc 79.56 \t AccHead 80.23 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 0.5747 \t Acc 80.60 \t AccHead 81.27 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 0.5578 \t Acc 79.67 \t AccHead 80.34 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 0.5423 \t Acc 81.61 \t AccHead 82.29 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 0.5349 \t Acc 81.73 \t AccHead 82.41 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 0.5158 \t Acc 81.81 \t AccHead 82.49 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 0.5211 \t Acc 79.99 \t AccHead 80.66 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 0.5040 \t Acc 82.42 \t AccHead 83.12 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 0.4963 \t Acc 82.37 \t AccHead 83.06 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 0.4892 \t Acc 83.88 \t AccHead 84.58 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 0.4704 \t Acc 81.63 \t AccHead 82.31 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 0.4845 \t Acc 81.19 \t AccHead 81.87 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 0.4564 \t Acc 81.21 \t AccHead 81.89 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 0.4648 \t Acc 85.85 \t AccHead 86.57 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 0.4578 \t Acc 84.51 \t AccHead 85.21 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 0.4508 \t Acc 85.40 \t AccHead 86.11 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 0.4464 \t Acc 85.53 \t AccHead 86.25 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 0.4399 \t Acc 84.68 \t AccHead 85.39 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 0.4315 \t Acc 83.99 \t AccHead 84.69 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 0.4319 \t Acc 85.89 \t AccHead 86.60 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 0.4199 \t Acc 84.75 \t AccHead 85.45 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 0.4199 \t Acc 86.26 \t AccHead 86.97 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 0.4157 \t Acc 87.48 \t AccHead 88.21 \t AccTail 0.00\n",
      "Epoch: [041] \t Loss 0.4132 \t Acc 85.19 \t AccHead 85.90 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 0.4050 \t Acc 87.35 \t AccHead 88.07 \t AccTail 0.00\n",
      "Epoch: [043] \t Loss 0.4124 \t Acc 87.32 \t AccHead 88.05 \t AccTail 0.00\n",
      "Epoch: [044] \t Loss 0.4018 \t Acc 87.42 \t AccHead 88.15 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 0.3933 \t Acc 87.55 \t AccHead 88.29 \t AccTail 0.00\n",
      "Epoch: [046] \t Loss 0.3903 \t Acc 86.82 \t AccHead 87.53 \t AccTail 1.81\n",
      "Epoch: [047] \t Loss 0.3841 \t Acc 87.76 \t AccHead 88.47 \t AccTail 2.99\n",
      "Epoch: [048] \t Loss 0.3853 \t Acc 83.38 \t AccHead 84.06 \t AccTail 1.81\n",
      "Epoch: [049] \t Loss 0.3800 \t Acc 88.68 \t AccHead 89.40 \t AccTail 3.59\n",
      "Epoch: [050] \t Loss 0.3641 \t Acc 86.33 \t AccHead 87.02 \t AccTail 4.19\n",
      "Epoch: [051] \t Loss 0.3763 \t Acc 87.30 \t AccHead 87.98 \t AccTail 4.85\n",
      "Epoch: [052] \t Loss 0.3704 \t Acc 86.27 \t AccHead 86.96 \t AccTail 2.44\n",
      "Epoch: [053] \t Loss 0.3712 \t Acc 87.29 \t AccHead 87.99 \t AccTail 3.59\n",
      "Epoch: [054] \t Loss 0.3699 \t Acc 87.45 \t AccHead 88.13 \t AccTail 5.45\n",
      "Epoch: [055] \t Loss 0.3649 \t Acc 87.33 \t AccHead 88.01 \t AccTail 5.39\n",
      "Epoch: [056] \t Loss 0.3646 \t Acc 88.21 \t AccHead 88.87 \t AccTail 9.04\n",
      "Epoch: [057] \t Loss 0.3620 \t Acc 86.39 \t AccHead 87.02 \t AccTail 10.24\n",
      "Epoch: [058] \t Loss 0.3511 \t Acc 89.35 \t AccHead 90.05 \t AccTail 5.42\n",
      "Epoch: [059] \t Loss 0.3653 \t Acc 88.73 \t AccHead 89.36 \t AccTail 12.73\n",
      "Epoch: [060] \t Loss 0.3479 \t Acc 88.73 \t AccHead 89.42 \t AccTail 6.63\n",
      "Epoch: [061] \t Loss 0.3443 \t Acc 87.66 \t AccHead 88.31 \t AccTail 10.18\n",
      "Epoch: [062] \t Loss 0.3447 \t Acc 86.94 \t AccHead 87.60 \t AccTail 8.43\n",
      "Epoch: [063] \t Loss 0.3435 \t Acc 88.86 \t AccHead 89.40 \t AccTail 24.55\n",
      "Epoch: [064] \t Loss 0.3482 \t Acc 87.90 \t AccHead 88.58 \t AccTail 6.63\n",
      "Epoch: [065] \t Loss 0.3362 \t Acc 90.27 \t AccHead 90.83 \t AccTail 22.89\n",
      "Epoch: [066] \t Loss 0.3399 \t Acc 89.73 \t AccHead 90.29 \t AccTail 22.89\n",
      "Epoch: [067] \t Loss 0.3367 \t Acc 89.27 \t AccHead 89.84 \t AccTail 20.48\n",
      "Epoch: [068] \t Loss 0.3376 \t Acc 87.82 \t AccHead 88.35 \t AccTail 24.55\n",
      "Epoch: [069] \t Loss 0.3357 \t Acc 88.32 \t AccHead 88.83 \t AccTail 27.11\n",
      "Epoch: [070] \t Loss 0.3274 \t Acc 89.35 \t AccHead 89.92 \t AccTail 20.96\n",
      "Epoch: [071] \t Loss 0.3232 \t Acc 89.04 \t AccHead 89.62 \t AccTail 19.76\n",
      "Epoch: [072] \t Loss 0.3214 \t Acc 88.22 \t AccHead 88.80 \t AccTail 19.16\n",
      "Epoch: [073] \t Loss 0.3235 \t Acc 88.08 \t AccHead 88.64 \t AccTail 20.96\n",
      "Epoch: [074] \t Loss 0.3219 \t Acc 88.73 \t AccHead 89.22 \t AccTail 29.52\n",
      "Epoch: [075] \t Loss 0.3271 \t Acc 86.35 \t AccHead 86.94 \t AccTail 14.97\n",
      "Epoch: [076] \t Loss 0.3197 \t Acc 88.54 \t AccHead 89.10 \t AccTail 22.75\n",
      "Epoch: [077] \t Loss 0.3221 \t Acc 87.15 \t AccHead 87.72 \t AccTail 18.67\n",
      "Epoch: [078] \t Loss 0.3152 \t Acc 89.40 \t AccHead 89.98 \t AccTail 19.76\n",
      "Epoch: [079] \t Loss 0.3117 \t Acc 90.38 \t AccHead 90.89 \t AccTail 29.52\n",
      "Epoch: [080] \t Loss 0.3173 \t Acc 88.97 \t AccHead 89.51 \t AccTail 24.55\n",
      "Epoch: [081] \t Loss 0.3036 \t Acc 89.04 \t AccHead 89.59 \t AccTail 23.95\n",
      "Epoch: [082] \t Loss 0.3024 \t Acc 89.42 \t AccHead 90.01 \t AccTail 19.16\n",
      "Epoch: [083] \t Loss 0.3129 \t Acc 88.09 \t AccHead 88.54 \t AccTail 34.13\n",
      "Epoch: [084] \t Loss 0.3027 \t Acc 87.93 \t AccHead 88.38 \t AccTail 33.73\n",
      "Epoch: [085] \t Loss 0.3080 \t Acc 89.39 \t AccHead 89.87 \t AccTail 31.14\n",
      "Epoch: [086] \t Loss 0.3110 \t Acc 89.86 \t AccHead 90.36 \t AccTail 30.72\n",
      "Epoch: [087] \t Loss 0.2980 \t Acc 89.73 \t AccHead 90.23 \t AccTail 30.12\n",
      "Epoch: [088] \t Loss 0.3011 \t Acc 88.69 \t AccHead 89.13 \t AccTail 36.14\n",
      "Epoch: [089] \t Loss 0.3039 \t Acc 88.98 \t AccHead 89.48 \t AccTail 29.34\n",
      "Epoch: [090] \t Loss 0.3008 \t Acc 89.32 \t AccHead 89.82 \t AccTail 28.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 07:27:14,101]\u001b[0m Trial 6 finished with value: 41.49226760864258 and parameters: {'n_epoch': 90, 'weight_decay': 0.00023493433660236134}. Best is trial 5 with value: 44.64664840698242.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 41.49 \t AccHead 81.22 \t AccTail 0.88\n",
      "Epoch: [001] \t Loss 1.8728 \t Acc 49.16 \t AccHead 49.58 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.1877 \t Acc 54.46 \t AccHead 54.91 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.0768 \t Acc 57.69 \t AccHead 58.18 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 0.9983 \t Acc 62.49 \t AccHead 63.01 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 0.9539 \t Acc 64.53 \t AccHead 65.06 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 0.9059 \t Acc 61.51 \t AccHead 62.02 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 0.8677 \t Acc 66.30 \t AccHead 66.86 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 0.8613 \t Acc 70.43 \t AccHead 71.02 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 0.8122 \t Acc 67.43 \t AccHead 67.99 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 0.8083 \t Acc 56.36 \t AccHead 56.83 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 0.8056 \t Acc 70.07 \t AccHead 70.66 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 0.8022 \t Acc 65.35 \t AccHead 65.89 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 0.7863 \t Acc 71.22 \t AccHead 71.82 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 0.7738 \t Acc 70.72 \t AccHead 71.31 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 0.7771 \t Acc 72.46 \t AccHead 73.06 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 0.7718 \t Acc 72.05 \t AccHead 72.65 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 0.7568 \t Acc 66.90 \t AccHead 67.46 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 0.7552 \t Acc 70.94 \t AccHead 71.53 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 0.7553 \t Acc 62.02 \t AccHead 62.54 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 0.7500 \t Acc 66.82 \t AccHead 67.38 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 0.7507 \t Acc 71.51 \t AccHead 72.11 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 0.7444 \t Acc 73.79 \t AccHead 74.41 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 0.7411 \t Acc 67.89 \t AccHead 68.46 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 0.7517 \t Acc 63.67 \t AccHead 64.20 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 0.7366 \t Acc 72.74 \t AccHead 73.34 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 0.7484 \t Acc 69.40 \t AccHead 69.97 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 0.7353 \t Acc 68.84 \t AccHead 69.41 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 0.7457 \t Acc 72.42 \t AccHead 73.02 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 0.7410 \t Acc 68.02 \t AccHead 68.59 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 0.7414 \t Acc 70.74 \t AccHead 71.33 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 0.7310 \t Acc 72.21 \t AccHead 72.81 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 0.7282 \t Acc 72.85 \t AccHead 73.46 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 0.7350 \t Acc 59.50 \t AccHead 59.99 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 0.7350 \t Acc 69.10 \t AccHead 69.68 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 0.7242 \t Acc 60.88 \t AccHead 61.38 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 0.7278 \t Acc 67.64 \t AccHead 68.20 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 0.7198 \t Acc 74.37 \t AccHead 74.99 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 0.7430 \t Acc 67.85 \t AccHead 68.42 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 0.7427 \t Acc 72.51 \t AccHead 73.11 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 0.7214 \t Acc 70.94 \t AccHead 71.54 \t AccTail 0.00\n",
      "Epoch: [041] \t Loss 0.7408 \t Acc 68.54 \t AccHead 69.12 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 0.7141 \t Acc 68.13 \t AccHead 68.70 \t AccTail 0.00\n",
      "Epoch: [043] \t Loss 0.7289 \t Acc 74.19 \t AccHead 74.81 \t AccTail 0.00\n",
      "Epoch: [044] \t Loss 0.7141 \t Acc 67.93 \t AccHead 68.50 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 0.7307 \t Acc 73.33 \t AccHead 73.95 \t AccTail 0.00\n",
      "Epoch: [046] \t Loss 0.7446 \t Acc 65.28 \t AccHead 65.83 \t AccTail 0.00\n",
      "Epoch: [047] \t Loss 0.7316 \t Acc 64.45 \t AccHead 64.98 \t AccTail 0.00\n",
      "Epoch: [048] \t Loss 0.7301 \t Acc 69.20 \t AccHead 69.77 \t AccTail 0.00\n",
      "Epoch: [049] \t Loss 0.7290 \t Acc 71.69 \t AccHead 72.28 \t AccTail 0.00\n",
      "Epoch: [050] \t Loss 0.7172 \t Acc 71.95 \t AccHead 72.56 \t AccTail 0.00\n",
      "Epoch: [051] \t Loss 0.7269 \t Acc 70.69 \t AccHead 71.28 \t AccTail 0.00\n",
      "Epoch: [052] \t Loss 0.7488 \t Acc 69.98 \t AccHead 70.56 \t AccTail 0.00\n",
      "Epoch: [053] \t Loss 0.7473 \t Acc 72.86 \t AccHead 73.47 \t AccTail 0.00\n",
      "Epoch: [054] \t Loss 0.7276 \t Acc 71.69 \t AccHead 72.29 \t AccTail 0.00\n",
      "Epoch: [055] \t Loss 0.7329 \t Acc 66.03 \t AccHead 66.59 \t AccTail 0.00\n",
      "Epoch: [056] \t Loss 0.7233 \t Acc 75.45 \t AccHead 76.07 \t AccTail 0.00\n",
      "Epoch: [057] \t Loss 0.7287 \t Acc 71.40 \t AccHead 72.00 \t AccTail 0.00\n",
      "Epoch: [058] \t Loss 0.7056 \t Acc 70.48 \t AccHead 71.06 \t AccTail 0.00\n",
      "Epoch: [059] \t Loss 0.7295 \t Acc 66.86 \t AccHead 67.42 \t AccTail 0.00\n",
      "Epoch: [060] \t Loss 0.7246 \t Acc 73.58 \t AccHead 74.19 \t AccTail 0.00\n",
      "Epoch: [061] \t Loss 0.7132 \t Acc 72.24 \t AccHead 72.85 \t AccTail 0.00\n",
      "Epoch: [062] \t Loss 0.7265 \t Acc 70.81 \t AccHead 71.40 \t AccTail 0.00\n",
      "Epoch: [063] \t Loss 0.7225 \t Acc 70.57 \t AccHead 71.16 \t AccTail 0.00\n",
      "Epoch: [064] \t Loss 0.7291 \t Acc 73.56 \t AccHead 74.17 \t AccTail 0.00\n",
      "Epoch: [065] \t Loss 0.7331 \t Acc 69.83 \t AccHead 70.41 \t AccTail 0.00\n",
      "Epoch: [066] \t Loss 0.7331 \t Acc 73.76 \t AccHead 74.37 \t AccTail 0.00\n",
      "Epoch: [067] \t Loss 0.7272 \t Acc 69.91 \t AccHead 70.50 \t AccTail 0.00\n",
      "Epoch: [068] \t Loss 0.7347 \t Acc 68.80 \t AccHead 69.38 \t AccTail 0.00\n",
      "Epoch: [069] \t Loss 0.7287 \t Acc 71.19 \t AccHead 71.78 \t AccTail 0.00\n",
      "Epoch: [070] \t Loss 0.7189 \t Acc 74.99 \t AccHead 75.61 \t AccTail 0.00\n",
      "Epoch: [071] \t Loss 0.7160 \t Acc 70.45 \t AccHead 71.04 \t AccTail 0.00\n",
      "Epoch: [072] \t Loss 0.7082 \t Acc 54.57 \t AccHead 55.03 \t AccTail 0.00\n",
      "Epoch: [073] \t Loss 0.7301 \t Acc 65.87 \t AccHead 66.42 \t AccTail 0.00\n",
      "Epoch: [074] \t Loss 0.7310 \t Acc 74.16 \t AccHead 74.78 \t AccTail 0.00\n",
      "Epoch: [075] \t Loss 0.7227 \t Acc 70.37 \t AccHead 70.96 \t AccTail 0.00\n",
      "Epoch: [076] \t Loss 0.7261 \t Acc 74.97 \t AccHead 75.59 \t AccTail 0.00\n",
      "Epoch: [077] \t Loss 0.7137 \t Acc 65.87 \t AccHead 66.42 \t AccTail 0.00\n",
      "Epoch: [078] \t Loss 0.7247 \t Acc 69.48 \t AccHead 70.06 \t AccTail 0.00\n",
      "Epoch: [079] \t Loss 0.7192 \t Acc 66.19 \t AccHead 66.75 \t AccTail 0.00\n",
      "Epoch: [080] \t Loss 0.7139 \t Acc 70.01 \t AccHead 70.59 \t AccTail 0.00\n",
      "Epoch: [081] \t Loss 0.7162 \t Acc 70.62 \t AccHead 71.21 \t AccTail 0.00\n",
      "Epoch: [082] \t Loss 0.7233 \t Acc 70.63 \t AccHead 71.22 \t AccTail 0.00\n",
      "Epoch: [083] \t Loss 0.7179 \t Acc 64.60 \t AccHead 65.14 \t AccTail 0.00\n",
      "Epoch: [084] \t Loss 0.7255 \t Acc 73.61 \t AccHead 74.23 \t AccTail 0.00\n",
      "Epoch: [085] \t Loss 0.7248 \t Acc 71.27 \t AccHead 71.86 \t AccTail 0.00\n",
      "Epoch: [086] \t Loss 0.7250 \t Acc 72.25 \t AccHead 72.85 \t AccTail 0.00\n",
      "Epoch: [087] \t Loss 0.7199 \t Acc 71.66 \t AccHead 72.26 \t AccTail 0.00\n",
      "Epoch: [088] \t Loss 0.7176 \t Acc 69.81 \t AccHead 70.39 \t AccTail 0.00\n",
      "Epoch: [089] \t Loss 0.7231 \t Acc 71.06 \t AccHead 71.64 \t AccTail 0.00\n",
      "Epoch: [090] \t Loss 0.7236 \t Acc 68.62 \t AccHead 69.19 \t AccTail 0.00\n",
      "Epoch: [091] \t Loss 0.7371 \t Acc 68.81 \t AccHead 69.39 \t AccTail 0.00\n",
      "Epoch: [092] \t Loss 0.7156 \t Acc 74.90 \t AccHead 75.53 \t AccTail 0.00\n",
      "Epoch: [093] \t Loss 0.7300 \t Acc 69.53 \t AccHead 70.11 \t AccTail 0.00\n",
      "Epoch: [094] \t Loss 0.7236 \t Acc 67.30 \t AccHead 67.86 \t AccTail 0.00\n",
      "Epoch: [095] \t Loss 0.7291 \t Acc 63.55 \t AccHead 64.09 \t AccTail 0.00\n",
      "Epoch: [096] \t Loss 0.7250 \t Acc 65.92 \t AccHead 66.47 \t AccTail 0.00\n",
      "Epoch: [097] \t Loss 0.7327 \t Acc 70.22 \t AccHead 70.81 \t AccTail 0.00\n",
      "Epoch: [098] \t Loss 0.7216 \t Acc 63.77 \t AccHead 64.31 \t AccTail 0.00\n",
      "Epoch: [099] \t Loss 0.7278 \t Acc 68.14 \t AccHead 68.71 \t AccTail 0.00\n",
      "Epoch: [100] \t Loss 0.7203 \t Acc 71.21 \t AccHead 71.80 \t AccTail 0.00\n",
      "Epoch: [101] \t Loss 0.7200 \t Acc 73.51 \t AccHead 74.13 \t AccTail 0.00\n",
      "Epoch: [102] \t Loss 0.7391 \t Acc 70.19 \t AccHead 70.78 \t AccTail 0.00\n",
      "Epoch: [103] \t Loss 0.7141 \t Acc 68.85 \t AccHead 69.43 \t AccTail 0.00\n",
      "Epoch: [104] \t Loss 0.7286 \t Acc 70.50 \t AccHead 71.08 \t AccTail 0.00\n",
      "Epoch: [105] \t Loss 0.7276 \t Acc 71.74 \t AccHead 72.34 \t AccTail 0.00\n",
      "Epoch: [106] \t Loss 0.7258 \t Acc 69.13 \t AccHead 69.70 \t AccTail 0.00\n",
      "Epoch: [107] \t Loss 0.7173 \t Acc 65.90 \t AccHead 66.44 \t AccTail 0.00\n",
      "Epoch: [108] \t Loss 0.7291 \t Acc 76.56 \t AccHead 77.20 \t AccTail 0.00\n",
      "Epoch: [109] \t Loss 0.7312 \t Acc 72.67 \t AccHead 73.28 \t AccTail 0.00\n",
      "Epoch: [110] \t Loss 0.7189 \t Acc 67.24 \t AccHead 67.80 \t AccTail 0.00\n",
      "Epoch: [111] \t Loss 0.7317 \t Acc 73.67 \t AccHead 74.28 \t AccTail 0.00\n",
      "Epoch: [112] \t Loss 0.7270 \t Acc 70.30 \t AccHead 70.89 \t AccTail 0.00\n",
      "Epoch: [113] \t Loss 0.7268 \t Acc 69.95 \t AccHead 70.54 \t AccTail 0.00\n",
      "Epoch: [114] \t Loss 0.7336 \t Acc 66.69 \t AccHead 67.25 \t AccTail 0.00\n",
      "Epoch: [115] \t Loss 0.7327 \t Acc 69.24 \t AccHead 69.82 \t AccTail 0.00\n",
      "Epoch: [116] \t Loss 0.7260 \t Acc 73.66 \t AccHead 74.28 \t AccTail 0.00\n",
      "Epoch: [117] \t Loss 0.7317 \t Acc 74.93 \t AccHead 75.55 \t AccTail 0.00\n",
      "Epoch: [118] \t Loss 0.7271 \t Acc 63.49 \t AccHead 64.02 \t AccTail 0.00\n",
      "Epoch: [119] \t Loss 0.7252 \t Acc 73.78 \t AccHead 74.40 \t AccTail 0.00\n",
      "Epoch: [120] \t Loss 0.7335 \t Acc 61.06 \t AccHead 61.57 \t AccTail 0.00\n",
      "Epoch: [121] \t Loss 0.7439 \t Acc 69.36 \t AccHead 69.94 \t AccTail 0.00\n",
      "Epoch: [122] \t Loss 0.7331 \t Acc 70.99 \t AccHead 71.58 \t AccTail 0.00\n",
      "Epoch: [123] \t Loss 0.7342 \t Acc 69.02 \t AccHead 69.60 \t AccTail 0.00\n",
      "Epoch: [124] \t Loss 0.7391 \t Acc 70.13 \t AccHead 70.72 \t AccTail 0.00\n",
      "Epoch: [125] \t Loss 0.7327 \t Acc 70.70 \t AccHead 71.29 \t AccTail 0.00\n",
      "Epoch: [126] \t Loss 0.7250 \t Acc 70.86 \t AccHead 71.46 \t AccTail 0.00\n",
      "Epoch: [127] \t Loss 0.7281 \t Acc 73.78 \t AccHead 74.39 \t AccTail 0.00\n",
      "Epoch: [128] \t Loss 0.7209 \t Acc 71.68 \t AccHead 72.27 \t AccTail 0.00\n",
      "Epoch: [129] \t Loss 0.7376 \t Acc 71.00 \t AccHead 71.60 \t AccTail 0.00\n",
      "Epoch: [130] \t Loss 0.7391 \t Acc 71.92 \t AccHead 72.52 \t AccTail 0.00\n",
      "Epoch: [131] \t Loss 0.7368 \t Acc 65.89 \t AccHead 66.43 \t AccTail 0.00\n",
      "Epoch: [132] \t Loss 0.7324 \t Acc 71.37 \t AccHead 71.97 \t AccTail 0.00\n",
      "Epoch: [133] \t Loss 0.7272 \t Acc 73.59 \t AccHead 74.21 \t AccTail 0.00\n",
      "Epoch: [134] \t Loss 0.7159 \t Acc 72.98 \t AccHead 73.59 \t AccTail 0.00\n",
      "Epoch: [135] \t Loss 0.7271 \t Acc 70.66 \t AccHead 71.24 \t AccTail 0.00\n",
      "Epoch: [136] \t Loss 0.7307 \t Acc 64.77 \t AccHead 65.31 \t AccTail 0.00\n",
      "Epoch: [137] \t Loss 0.7287 \t Acc 68.75 \t AccHead 69.32 \t AccTail 0.00\n",
      "Epoch: [138] \t Loss 0.7237 \t Acc 73.65 \t AccHead 74.26 \t AccTail 0.00\n",
      "Epoch: [139] \t Loss 0.7272 \t Acc 70.78 \t AccHead 71.36 \t AccTail 0.00\n",
      "Epoch: [140] \t Loss 0.7226 \t Acc 70.02 \t AccHead 70.61 \t AccTail 0.00\n",
      "Epoch: [141] \t Loss 0.7293 \t Acc 61.24 \t AccHead 61.74 \t AccTail 0.00\n",
      "Epoch: [142] \t Loss 0.7135 \t Acc 70.36 \t AccHead 70.95 \t AccTail 0.00\n",
      "Epoch: [143] \t Loss 0.7334 \t Acc 69.43 \t AccHead 70.01 \t AccTail 0.00\n",
      "Epoch: [144] \t Loss 0.7276 \t Acc 70.37 \t AccHead 70.96 \t AccTail 0.00\n",
      "Epoch: [145] \t Loss 0.7303 \t Acc 65.08 \t AccHead 65.62 \t AccTail 0.00\n",
      "Epoch: [146] \t Loss 0.7424 \t Acc 70.69 \t AccHead 71.28 \t AccTail 0.00\n",
      "Epoch: [147] \t Loss 0.7391 \t Acc 73.82 \t AccHead 74.44 \t AccTail 0.00\n",
      "Epoch: [148] \t Loss 0.7302 \t Acc 74.99 \t AccHead 75.61 \t AccTail 0.00\n",
      "Epoch: [149] \t Loss 0.7329 \t Acc 53.03 \t AccHead 53.47 \t AccTail 0.00\n",
      "Epoch: [150] \t Loss 0.7430 \t Acc 72.21 \t AccHead 72.81 \t AccTail 0.00\n",
      "Epoch: [151] \t Loss 0.5754 \t Acc 83.11 \t AccHead 83.80 \t AccTail 0.00\n",
      "Epoch: [152] \t Loss 0.5113 \t Acc 84.09 \t AccHead 84.79 \t AccTail 0.00\n",
      "Epoch: [153] \t Loss 0.4873 \t Acc 84.49 \t AccHead 85.20 \t AccTail 0.00\n",
      "Epoch: [154] \t Loss 0.4796 \t Acc 84.97 \t AccHead 85.68 \t AccTail 0.00\n",
      "Epoch: [155] \t Loss 0.4651 \t Acc 84.97 \t AccHead 85.67 \t AccTail 0.00\n",
      "Epoch: [156] \t Loss 0.4541 \t Acc 85.82 \t AccHead 86.54 \t AccTail 0.00\n",
      "Epoch: [157] \t Loss 0.4493 \t Acc 85.77 \t AccHead 86.49 \t AccTail 0.00\n",
      "Epoch: [158] \t Loss 0.4463 \t Acc 86.40 \t AccHead 87.11 \t AccTail 0.00\n",
      "Epoch: [159] \t Loss 0.4360 \t Acc 85.35 \t AccHead 86.06 \t AccTail 0.00\n",
      "Epoch: [160] \t Loss 0.4304 \t Acc 86.59 \t AccHead 87.31 \t AccTail 0.00\n",
      "Epoch: [161] \t Loss 0.4279 \t Acc 85.73 \t AccHead 86.45 \t AccTail 0.00\n",
      "Epoch: [162] \t Loss 0.4261 \t Acc 85.14 \t AccHead 85.85 \t AccTail 0.00\n",
      "Epoch: [163] \t Loss 0.4267 \t Acc 85.68 \t AccHead 86.40 \t AccTail 0.00\n",
      "Epoch: [164] \t Loss 0.4169 \t Acc 86.42 \t AccHead 87.13 \t AccTail 0.00\n",
      "Epoch: [165] \t Loss 0.4203 \t Acc 85.01 \t AccHead 85.72 \t AccTail 0.00\n",
      "Epoch: [166] \t Loss 0.4229 \t Acc 85.80 \t AccHead 86.52 \t AccTail 0.00\n",
      "Epoch: [167] \t Loss 0.4192 \t Acc 86.55 \t AccHead 87.27 \t AccTail 0.00\n",
      "Epoch: [168] \t Loss 0.4230 \t Acc 86.73 \t AccHead 87.46 \t AccTail 0.00\n",
      "Epoch: [169] \t Loss 0.4163 \t Acc 86.66 \t AccHead 87.38 \t AccTail 0.00\n",
      "Epoch: [170] \t Loss 0.4177 \t Acc 86.58 \t AccHead 87.30 \t AccTail 0.00\n",
      "Epoch: [171] \t Loss 0.4140 \t Acc 87.76 \t AccHead 88.49 \t AccTail 0.00\n",
      "Epoch: [172] \t Loss 0.4060 \t Acc 84.91 \t AccHead 85.62 \t AccTail 0.00\n",
      "Epoch: [173] \t Loss 0.4115 \t Acc 86.76 \t AccHead 87.49 \t AccTail 0.00\n",
      "Epoch: [174] \t Loss 0.4080 \t Acc 86.20 \t AccHead 86.92 \t AccTail 0.00\n",
      "Epoch: [175] \t Loss 0.4051 \t Acc 88.19 \t AccHead 88.92 \t AccTail 0.00\n",
      "Epoch: [176] \t Loss 0.4037 \t Acc 87.36 \t AccHead 88.09 \t AccTail 0.00\n",
      "Epoch: [177] \t Loss 0.4016 \t Acc 87.89 \t AccHead 88.62 \t AccTail 0.00\n",
      "Epoch: [178] \t Loss 0.4005 \t Acc 86.92 \t AccHead 87.64 \t AccTail 0.00\n",
      "Epoch: [179] \t Loss 0.4042 \t Acc 86.26 \t AccHead 86.98 \t AccTail 0.00\n",
      "Epoch: [180] \t Loss 0.4031 \t Acc 87.06 \t AccHead 87.78 \t AccTail 0.00\n",
      "Epoch: [181] \t Loss 0.3993 \t Acc 87.09 \t AccHead 87.82 \t AccTail 0.00\n",
      "Epoch: [182] \t Loss 0.3988 \t Acc 87.26 \t AccHead 87.99 \t AccTail 0.00\n",
      "Epoch: [183] \t Loss 0.3944 \t Acc 88.22 \t AccHead 88.96 \t AccTail 0.00\n",
      "Epoch: [184] \t Loss 0.3879 \t Acc 87.66 \t AccHead 88.38 \t AccTail 0.00\n",
      "Epoch: [185] \t Loss 0.3882 \t Acc 86.77 \t AccHead 87.50 \t AccTail 0.00\n",
      "Epoch: [186] \t Loss 0.3887 \t Acc 86.12 \t AccHead 86.84 \t AccTail 0.00\n",
      "Epoch: [187] \t Loss 0.3849 \t Acc 86.71 \t AccHead 87.44 \t AccTail 0.00\n",
      "Epoch: [188] \t Loss 0.3830 \t Acc 87.08 \t AccHead 87.81 \t AccTail 0.00\n",
      "Epoch: [189] \t Loss 0.3777 \t Acc 86.88 \t AccHead 87.61 \t AccTail 0.00\n",
      "Epoch: [190] \t Loss 0.3840 \t Acc 87.07 \t AccHead 87.79 \t AccTail 0.00\n",
      "Epoch: [191] \t Loss 0.3813 \t Acc 88.53 \t AccHead 89.27 \t AccTail 0.00\n",
      "Epoch: [192] \t Loss 0.3831 \t Acc 88.78 \t AccHead 89.52 \t AccTail 0.00\n",
      "Epoch: [193] \t Loss 0.3823 \t Acc 87.00 \t AccHead 87.72 \t AccTail 0.00\n",
      "Epoch: [194] \t Loss 0.3731 \t Acc 82.86 \t AccHead 83.55 \t AccTail 0.00\n",
      "Epoch: [195] \t Loss 0.3779 \t Acc 88.29 \t AccHead 89.02 \t AccTail 0.00\n",
      "Epoch: [196] \t Loss 0.3731 \t Acc 87.86 \t AccHead 88.59 \t AccTail 0.00\n",
      "Epoch: [197] \t Loss 0.3663 \t Acc 89.04 \t AccHead 89.78 \t AccTail 0.00\n",
      "Epoch: [198] \t Loss 0.3746 \t Acc 87.17 \t AccHead 87.90 \t AccTail 0.00\n",
      "Epoch: [199] \t Loss 0.3726 \t Acc 88.51 \t AccHead 89.25 \t AccTail 0.00\n",
      "Epoch: [200] \t Loss 0.3713 \t Acc 87.47 \t AccHead 88.20 \t AccTail 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 08:02:02,678]\u001b[0m Trial 7 finished with value: 41.0777473449707 and parameters: {'n_epoch': 200, 'weight_decay': 0.002342933527703765}. Best is trial 5 with value: 44.64664840698242.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 41.08 \t AccHead 81.26 \t AccTail 0.00\n",
      "Epoch: [001] \t Loss 2.2487 \t Acc 40.82 \t AccHead 41.16 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.2967 \t Acc 53.07 \t AccHead 53.51 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.1397 \t Acc 57.87 \t AccHead 58.35 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.0464 \t Acc 61.77 \t AccHead 62.29 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 0.9957 \t Acc 61.19 \t AccHead 61.69 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 0.9411 \t Acc 66.09 \t AccHead 66.64 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 0.8934 \t Acc 68.70 \t AccHead 69.27 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 0.8322 \t Acc 70.84 \t AccHead 71.43 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 0.7894 \t Acc 73.12 \t AccHead 73.73 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 0.7598 \t Acc 74.63 \t AccHead 75.25 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 0.7210 \t Acc 74.46 \t AccHead 75.08 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 0.6936 \t Acc 76.14 \t AccHead 76.78 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 0.6819 \t Acc 76.64 \t AccHead 77.28 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 0.6557 \t Acc 74.30 \t AccHead 74.93 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 0.6281 \t Acc 76.21 \t AccHead 76.84 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 0.6166 \t Acc 78.53 \t AccHead 79.19 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 0.6073 \t Acc 77.31 \t AccHead 77.96 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 0.5869 \t Acc 74.65 \t AccHead 75.28 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 0.5731 \t Acc 81.13 \t AccHead 81.81 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 0.5617 \t Acc 80.61 \t AccHead 81.29 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 0.5572 \t Acc 82.10 \t AccHead 82.78 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 0.5445 \t Acc 80.05 \t AccHead 80.72 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 0.5440 \t Acc 80.91 \t AccHead 81.58 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 0.5314 \t Acc 82.47 \t AccHead 83.16 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 0.5172 \t Acc 79.29 \t AccHead 79.95 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 0.5186 \t Acc 82.68 \t AccHead 83.37 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 0.5059 \t Acc 80.40 \t AccHead 81.07 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 0.5046 \t Acc 80.65 \t AccHead 81.32 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 0.4988 \t Acc 82.73 \t AccHead 83.43 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 0.4922 \t Acc 82.87 \t AccHead 83.57 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 0.4810 \t Acc 81.13 \t AccHead 81.80 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 0.4848 \t Acc 84.03 \t AccHead 84.73 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 0.4837 \t Acc 84.42 \t AccHead 85.13 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 0.4740 \t Acc 83.47 \t AccHead 84.17 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 0.4740 \t Acc 83.20 \t AccHead 83.90 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 0.4649 \t Acc 82.83 \t AccHead 83.51 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 0.4573 \t Acc 84.16 \t AccHead 84.86 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 0.4598 \t Acc 82.24 \t AccHead 82.92 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 0.4528 \t Acc 82.99 \t AccHead 83.69 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 0.4489 \t Acc 81.91 \t AccHead 82.58 \t AccTail 1.20\n",
      "Epoch: [041] \t Loss 0.4599 \t Acc 85.63 \t AccHead 86.35 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 0.4548 \t Acc 84.91 \t AccHead 85.61 \t AccTail 0.00\n",
      "Epoch: [043] \t Loss 0.4253 \t Acc 86.68 \t AccHead 87.40 \t AccTail 0.00\n",
      "Epoch: [044] \t Loss 0.4375 \t Acc 82.81 \t AccHead 83.50 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 0.4435 \t Acc 85.46 \t AccHead 86.17 \t AccTail 0.60\n",
      "Epoch: [046] \t Loss 0.4373 \t Acc 84.76 \t AccHead 85.47 \t AccTail 0.00\n",
      "Epoch: [047] \t Loss 0.4339 \t Acc 82.95 \t AccHead 83.65 \t AccTail 0.00\n",
      "Epoch: [048] \t Loss 0.4289 \t Acc 85.65 \t AccHead 86.29 \t AccTail 9.58\n",
      "Epoch: [049] \t Loss 0.4203 \t Acc 86.54 \t AccHead 87.22 \t AccTail 4.79\n",
      "Epoch: [050] \t Loss 0.4269 \t Acc 86.10 \t AccHead 86.81 \t AccTail 1.80\n",
      "Epoch: [051] \t Loss 0.4213 \t Acc 84.47 \t AccHead 85.07 \t AccTail 11.52\n",
      "Epoch: [052] \t Loss 0.4179 \t Acc 84.61 \t AccHead 85.30 \t AccTail 2.41\n",
      "Epoch: [053] \t Loss 0.4200 \t Acc 82.96 \t AccHead 83.64 \t AccTail 1.20\n",
      "Epoch: [054] \t Loss 0.4300 \t Acc 85.61 \t AccHead 86.32 \t AccTail 1.20\n",
      "Epoch: [055] \t Loss 0.4242 \t Acc 83.95 \t AccHead 84.65 \t AccTail 0.60\n",
      "Epoch: [056] \t Loss 0.4029 \t Acc 85.13 \t AccHead 85.79 \t AccTail 6.02\n",
      "Epoch: [057] \t Loss 0.4098 \t Acc 84.75 \t AccHead 85.40 \t AccTail 7.78\n",
      "Epoch: [058] \t Loss 0.4026 \t Acc 86.27 \t AccHead 86.93 \t AccTail 6.63\n",
      "Epoch: [059] \t Loss 0.4093 \t Acc 85.85 \t AccHead 86.51 \t AccTail 7.19\n",
      "Epoch: [060] \t Loss 0.3991 \t Acc 85.72 \t AccHead 86.43 \t AccTail 0.00\n",
      "Epoch: [061] \t Loss 0.4096 \t Acc 81.85 \t AccHead 82.44 \t AccTail 10.78\n",
      "Epoch: [062] \t Loss 0.4057 \t Acc 82.98 \t AccHead 83.57 \t AccTail 12.57\n",
      "Epoch: [063] \t Loss 0.4058 \t Acc 86.95 \t AccHead 87.61 \t AccTail 7.78\n",
      "Epoch: [064] \t Loss 0.3976 \t Acc 86.72 \t AccHead 87.33 \t AccTail 14.46\n",
      "Epoch: [065] \t Loss 0.3933 \t Acc 84.80 \t AccHead 85.47 \t AccTail 5.39\n",
      "Epoch: [066] \t Loss 0.4020 \t Acc 80.15 \t AccHead 80.76 \t AccTail 6.59\n",
      "Epoch: [067] \t Loss 0.3848 \t Acc 86.24 \t AccHead 86.89 \t AccTail 8.38\n",
      "Epoch: [068] \t Loss 0.3972 \t Acc 86.11 \t AccHead 86.74 \t AccTail 11.38\n",
      "Epoch: [069] \t Loss 0.3981 \t Acc 87.28 \t AccHead 87.99 \t AccTail 1.20\n",
      "Epoch: [070] \t Loss 0.3946 \t Acc 88.06 \t AccHead 88.76 \t AccTail 5.39\n",
      "Epoch: [071] \t Loss 0.3936 \t Acc 84.99 \t AccHead 85.63 \t AccTail 7.78\n",
      "Epoch: [072] \t Loss 0.3979 \t Acc 86.56 \t AccHead 87.20 \t AccTail 10.78\n",
      "Epoch: [073] \t Loss 0.3894 \t Acc 84.85 \t AccHead 85.45 \t AccTail 12.65\n",
      "Epoch: [074] \t Loss 0.3901 \t Acc 87.12 \t AccHead 87.79 \t AccTail 7.78\n",
      "Epoch: [075] \t Loss 0.3894 \t Acc 84.88 \t AccHead 85.56 \t AccTail 3.59\n",
      "Epoch: [076] \t Loss 0.3863 \t Acc 87.69 \t AccHead 88.35 \t AccTail 8.98\n",
      "Epoch: [077] \t Loss 0.4004 \t Acc 87.86 \t AccHead 88.50 \t AccTail 11.45\n",
      "Epoch: [078] \t Loss 0.3757 \t Acc 86.87 \t AccHead 87.56 \t AccTail 4.79\n",
      "Epoch: [079] \t Loss 0.3876 \t Acc 87.22 \t AccHead 87.88 \t AccTail 8.98\n",
      "Epoch: [080] \t Loss 0.3903 \t Acc 82.82 \t AccHead 83.49 \t AccTail 2.40\n",
      "Epoch: [081] \t Loss 0.3855 \t Acc 87.52 \t AccHead 88.18 \t AccTail 7.83\n",
      "Epoch: [082] \t Loss 0.3913 \t Acc 87.69 \t AccHead 88.32 \t AccTail 12.57\n",
      "Epoch: [083] \t Loss 0.3713 \t Acc 85.15 \t AccHead 85.75 \t AccTail 13.25\n",
      "Epoch: [084] \t Loss 0.3773 \t Acc 84.71 \t AccHead 85.36 \t AccTail 7.78\n",
      "Epoch: [085] \t Loss 0.3785 \t Acc 85.98 \t AccHead 86.65 \t AccTail 5.39\n",
      "Epoch: [086] \t Loss 0.3727 \t Acc 86.61 \t AccHead 87.27 \t AccTail 7.78\n",
      "Epoch: [087] \t Loss 0.3735 \t Acc 85.31 \t AccHead 85.94 \t AccTail 9.58\n",
      "Epoch: [088] \t Loss 0.3832 \t Acc 87.15 \t AccHead 87.80 \t AccTail 8.98\n",
      "Epoch: [089] \t Loss 0.3736 \t Acc 84.21 \t AccHead 84.81 \t AccTail 12.65\n",
      "Epoch: [090] \t Loss 0.3788 \t Acc 86.39 \t AccHead 87.04 \t AccTail 8.38\n",
      "Epoch: [091] \t Loss 0.3785 \t Acc 86.25 \t AccHead 86.79 \t AccTail 20.00\n",
      "Epoch: [092] \t Loss 0.3758 \t Acc 86.55 \t AccHead 87.20 \t AccTail 8.98\n",
      "Epoch: [093] \t Loss 0.3747 \t Acc 87.42 \t AccHead 88.00 \t AccTail 17.96\n",
      "Epoch: [094] \t Loss 0.3711 \t Acc 85.18 \t AccHead 85.72 \t AccTail 19.51\n",
      "Epoch: [095] \t Loss 0.3726 \t Acc 87.00 \t AccHead 87.62 \t AccTail 13.17\n",
      "Epoch: [096] \t Loss 0.3700 \t Acc 85.13 \t AccHead 85.75 \t AccTail 11.38\n",
      "Epoch: [097] \t Loss 0.3748 \t Acc 84.70 \t AccHead 85.35 \t AccTail 6.02\n",
      "Epoch: [098] \t Loss 0.3786 \t Acc 87.76 \t AccHead 88.43 \t AccTail 7.78\n",
      "Epoch: [099] \t Loss 0.3747 \t Acc 87.98 \t AccHead 88.68 \t AccTail 3.59\n",
      "Epoch: [100] \t Loss 0.3688 \t Acc 87.43 \t AccHead 88.02 \t AccTail 17.37\n",
      "Epoch: [101] \t Loss 0.3678 \t Acc 85.62 \t AccHead 86.29 \t AccTail 5.42\n",
      "Epoch: [102] \t Loss 0.3769 \t Acc 86.68 \t AccHead 87.25 \t AccTail 18.07\n",
      "Epoch: [103] \t Loss 0.3724 \t Acc 88.56 \t AccHead 89.10 \t AccTail 24.10\n",
      "Epoch: [104] \t Loss 0.3605 \t Acc 87.79 \t AccHead 88.43 \t AccTail 10.84\n",
      "Epoch: [105] \t Loss 0.3627 \t Acc 87.70 \t AccHead 88.40 \t AccTail 4.79\n",
      "Epoch: [106] \t Loss 0.3658 \t Acc 87.59 \t AccHead 88.12 \t AccTail 24.10\n",
      "Epoch: [107] \t Loss 0.3685 \t Acc 88.08 \t AccHead 88.72 \t AccTail 10.84\n",
      "Epoch: [108] \t Loss 0.3703 \t Acc 88.69 \t AccHead 89.36 \t AccTail 7.93\n",
      "Epoch: [109] \t Loss 0.3633 \t Acc 88.23 \t AccHead 88.82 \t AccTail 17.96\n",
      "Epoch: [110] \t Loss 0.3622 \t Acc 85.14 \t AccHead 85.80 \t AccTail 6.63\n",
      "Epoch: [111] \t Loss 0.3603 \t Acc 88.37 \t AccHead 89.01 \t AccTail 12.57\n",
      "Epoch: [112] \t Loss 0.3546 \t Acc 86.38 \t AccHead 86.87 \t AccTail 27.44\n",
      "Epoch: [113] \t Loss 0.3644 \t Acc 84.23 \t AccHead 84.78 \t AccTail 17.96\n",
      "Epoch: [114] \t Loss 0.3637 \t Acc 89.89 \t AccHead 90.38 \t AccTail 32.34\n",
      "Epoch: [115] \t Loss 0.3628 \t Acc 87.11 \t AccHead 87.67 \t AccTail 19.88\n",
      "Epoch: [116] \t Loss 0.3599 \t Acc 87.97 \t AccHead 88.61 \t AccTail 10.30\n",
      "Epoch: [117] \t Loss 0.3651 \t Acc 88.51 \t AccHead 89.13 \t AccTail 12.73\n",
      "Epoch: [118] \t Loss 0.3608 \t Acc 88.05 \t AccHead 88.69 \t AccTail 11.45\n",
      "Epoch: [119] \t Loss 0.3626 \t Acc 87.47 \t AccHead 88.08 \t AccTail 14.37\n",
      "Epoch: [120] \t Loss 0.3573 \t Acc 84.47 \t AccHead 85.02 \t AccTail 19.16\n",
      "Epoch: [121] \t Loss 0.3524 \t Acc 83.50 \t AccHead 84.10 \t AccTail 11.98\n",
      "Epoch: [122] \t Loss 0.3593 \t Acc 87.05 \t AccHead 87.60 \t AccTail 21.56\n",
      "Epoch: [123] \t Loss 0.3548 \t Acc 87.49 \t AccHead 88.01 \t AccTail 24.10\n",
      "Epoch: [124] \t Loss 0.3555 \t Acc 84.61 \t AccHead 85.17 \t AccTail 18.56\n",
      "Epoch: [125] \t Loss 0.3562 \t Acc 86.83 \t AccHead 87.46 \t AccTail 11.98\n",
      "Epoch: [126] \t Loss 0.3630 \t Acc 87.75 \t AccHead 88.37 \t AccTail 13.17\n",
      "Epoch: [127] \t Loss 0.3523 \t Acc 87.10 \t AccHead 87.73 \t AccTail 12.05\n",
      "Epoch: [128] \t Loss 0.3509 \t Acc 88.04 \t AccHead 88.57 \t AccTail 24.55\n",
      "Epoch: [129] \t Loss 0.3565 \t Acc 87.47 \t AccHead 88.05 \t AccTail 17.96\n",
      "Epoch: [130] \t Loss 0.3513 \t Acc 86.95 \t AccHead 87.54 \t AccTail 16.77\n",
      "Epoch: [131] \t Loss 0.3594 \t Acc 86.14 \t AccHead 86.80 \t AccTail 7.19\n",
      "Epoch: [132] \t Loss 0.3521 \t Acc 86.24 \t AccHead 86.89 \t AccTail 8.38\n",
      "Epoch: [133] \t Loss 0.3495 \t Acc 87.22 \t AccHead 87.86 \t AccTail 10.78\n",
      "Epoch: [134] \t Loss 0.3620 \t Acc 87.86 \t AccHead 88.50 \t AccTail 10.78\n",
      "Epoch: [135] \t Loss 0.3548 \t Acc 88.10 \t AccHead 88.67 \t AccTail 20.36\n",
      "Epoch: [136] \t Loss 0.3492 \t Acc 88.44 \t AccHead 89.01 \t AccTail 20.36\n",
      "Epoch: [137] \t Loss 0.3444 \t Acc 86.66 \t AccHead 87.23 \t AccTail 19.16\n",
      "Epoch: [138] \t Loss 0.3638 \t Acc 86.74 \t AccHead 87.29 \t AccTail 20.96\n",
      "Epoch: [139] \t Loss 0.3553 \t Acc 86.69 \t AccHead 87.26 \t AccTail 19.16\n",
      "Epoch: [140] \t Loss 0.3521 \t Acc 87.43 \t AccHead 87.85 \t AccTail 36.53\n",
      "Epoch: [141] \t Loss 0.3457 \t Acc 86.89 \t AccHead 87.52 \t AccTail 11.45\n",
      "Epoch: [142] \t Loss 0.3509 \t Acc 81.61 \t AccHead 82.16 \t AccTail 15.57\n",
      "Epoch: [143] \t Loss 0.3522 \t Acc 84.41 \t AccHead 84.95 \t AccTail 19.39\n",
      "Epoch: [144] \t Loss 0.3486 \t Acc 89.31 \t AccHead 90.03 \t AccTail 1.82\n",
      "Epoch: [145] \t Loss 0.3513 \t Acc 88.25 \t AccHead 88.81 \t AccTail 21.56\n",
      "Epoch: [146] \t Loss 0.3542 \t Acc 85.90 \t AccHead 86.47 \t AccTail 17.37\n",
      "Epoch: [147] \t Loss 0.3408 \t Acc 88.11 \t AccHead 88.57 \t AccTail 32.93\n",
      "Epoch: [148] \t Loss 0.3483 \t Acc 87.98 \t AccHead 88.53 \t AccTail 22.75\n",
      "Epoch: [149] \t Loss 0.3541 \t Acc 88.69 \t AccHead 89.16 \t AccTail 31.52\n",
      "Epoch: [150] \t Loss 0.3417 \t Acc 84.82 \t AccHead 85.40 \t AccTail 15.66\n",
      "Epoch: [151] \t Loss 0.2552 \t Acc 93.94 \t AccHead 94.33 \t AccTail 47.31\n",
      "Epoch: [152] \t Loss 0.1949 \t Acc 94.72 \t AccHead 95.08 \t AccTail 50.90\n",
      "Epoch: [153] \t Loss 0.1749 \t Acc 95.25 \t AccHead 95.58 \t AccTail 55.69\n",
      "Epoch: [154] \t Loss 0.1607 \t Acc 95.54 \t AccHead 95.86 \t AccTail 56.89\n",
      "Epoch: [155] \t Loss 0.1528 \t Acc 95.91 \t AccHead 96.20 \t AccTail 61.45\n",
      "Epoch: [156] \t Loss 0.1486 \t Acc 96.08 \t AccHead 96.41 \t AccTail 56.63\n",
      "Epoch: [157] \t Loss 0.1405 \t Acc 96.13 \t AccHead 96.40 \t AccTail 63.86\n",
      "Epoch: [158] \t Loss 0.1309 \t Acc 96.27 \t AccHead 96.54 \t AccTail 63.86\n",
      "Epoch: [159] \t Loss 0.1243 \t Acc 96.97 \t AccHead 97.21 \t AccTail 68.86\n",
      "Epoch: [160] \t Loss 0.1195 \t Acc 96.92 \t AccHead 97.15 \t AccTail 69.88\n",
      "Epoch: [161] \t Loss 0.1165 \t Acc 97.06 \t AccHead 97.30 \t AccTail 68.48\n",
      "Epoch: [162] \t Loss 0.1137 \t Acc 96.57 \t AccHead 96.76 \t AccTail 73.65\n",
      "Epoch: [163] \t Loss 0.1101 \t Acc 96.88 \t AccHead 97.11 \t AccTail 68.67\n",
      "Epoch: [164] \t Loss 0.1069 \t Acc 97.17 \t AccHead 97.34 \t AccTail 76.65\n",
      "Epoch: [165] \t Loss 0.1048 \t Acc 97.54 \t AccHead 97.74 \t AccTail 73.49\n",
      "Epoch: [166] \t Loss 0.0983 \t Acc 97.27 \t AccHead 97.50 \t AccTail 69.88\n",
      "Epoch: [167] \t Loss 0.0910 \t Acc 97.63 \t AccHead 97.77 \t AccTail 80.84\n",
      "Epoch: [168] \t Loss 0.0908 \t Acc 97.66 \t AccHead 97.84 \t AccTail 76.05\n",
      "Epoch: [169] \t Loss 0.0917 \t Acc 97.63 \t AccHead 97.79 \t AccTail 78.44\n",
      "Epoch: [170] \t Loss 0.0902 \t Acc 97.74 \t AccHead 97.88 \t AccTail 80.24\n",
      "Epoch: [171] \t Loss 0.0868 \t Acc 97.85 \t AccHead 98.02 \t AccTail 77.71\n",
      "Epoch: [172] \t Loss 0.0814 \t Acc 98.01 \t AccHead 98.20 \t AccTail 75.15\n",
      "Epoch: [173] \t Loss 0.0835 \t Acc 98.10 \t AccHead 98.23 \t AccTail 82.04\n",
      "Epoch: [174] \t Loss 0.0843 \t Acc 97.70 \t AccHead 97.85 \t AccTail 79.64\n",
      "Epoch: [175] \t Loss 0.0785 \t Acc 97.98 \t AccHead 98.15 \t AccTail 77.71\n",
      "Epoch: [176] \t Loss 0.0748 \t Acc 98.06 \t AccHead 98.21 \t AccTail 80.24\n",
      "Epoch: [177] \t Loss 0.0794 \t Acc 98.11 \t AccHead 98.30 \t AccTail 75.90\n",
      "Epoch: [178] \t Loss 0.0732 \t Acc 98.23 \t AccHead 98.35 \t AccTail 83.83\n",
      "Epoch: [179] \t Loss 0.0763 \t Acc 98.13 \t AccHead 98.27 \t AccTail 81.21\n",
      "Epoch: [180] \t Loss 0.0662 \t Acc 98.26 \t AccHead 98.40 \t AccTail 82.04\n",
      "Epoch: [181] \t Loss 0.0683 \t Acc 98.23 \t AccHead 98.37 \t AccTail 81.33\n",
      "Epoch: [182] \t Loss 0.0683 \t Acc 97.73 \t AccHead 97.87 \t AccTail 81.33\n",
      "Epoch: [183] \t Loss 0.0715 \t Acc 97.97 \t AccHead 98.07 \t AccTail 86.23\n",
      "Epoch: [184] \t Loss 0.0711 \t Acc 98.41 \t AccHead 98.57 \t AccTail 79.64\n",
      "Epoch: [185] \t Loss 0.0648 \t Acc 98.28 \t AccHead 98.39 \t AccTail 84.43\n",
      "Epoch: [186] \t Loss 0.0673 \t Acc 98.16 \t AccHead 98.27 \t AccTail 84.94\n",
      "Epoch: [187] \t Loss 0.0667 \t Acc 98.12 \t AccHead 98.28 \t AccTail 79.64\n",
      "Epoch: [188] \t Loss 0.0670 \t Acc 98.27 \t AccHead 98.39 \t AccTail 83.83\n",
      "Epoch: [189] \t Loss 0.0660 \t Acc 98.41 \t AccHead 98.51 \t AccTail 86.14\n",
      "Epoch: [190] \t Loss 0.0579 \t Acc 98.43 \t AccHead 98.54 \t AccTail 84.94\n",
      "Epoch: [191] \t Loss 0.0628 \t Acc 98.51 \t AccHead 98.61 \t AccTail 86.75\n",
      "Epoch: [192] \t Loss 0.0571 \t Acc 98.26 \t AccHead 98.36 \t AccTail 85.63\n",
      "Epoch: [193] \t Loss 0.0630 \t Acc 98.22 \t AccHead 98.31 \t AccTail 87.27\n",
      "Epoch: [194] \t Loss 0.0649 \t Acc 98.13 \t AccHead 98.24 \t AccTail 84.85\n",
      "Epoch: [195] \t Loss 0.0621 \t Acc 98.47 \t AccHead 98.58 \t AccTail 84.43\n",
      "Epoch: [196] \t Loss 0.0557 \t Acc 98.37 \t AccHead 98.45 \t AccTail 88.62\n",
      "Epoch: [197] \t Loss 0.0604 \t Acc 98.17 \t AccHead 98.27 \t AccTail 86.23\n",
      "Epoch: [198] \t Loss 0.0625 \t Acc 98.33 \t AccHead 98.44 \t AccTail 85.54\n",
      "Epoch: [199] \t Loss 0.0609 \t Acc 98.44 \t AccHead 98.51 \t AccTail 89.82\n",
      "Epoch: [200] \t Loss 0.0638 \t Acc 98.20 \t AccHead 98.35 \t AccTail 80.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 08:37:05,035]\u001b[0m Trial 8 finished with value: 44.211910247802734 and parameters: {'n_epoch': 200, 'weight_decay': 0.00042076599546542876}. Best is trial 5 with value: 44.64664840698242.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 44.21 \t AccHead 85.84 \t AccTail 1.66\n",
      "Epoch: [001] \t Loss 2.0754 \t Acc 49.81 \t AccHead 50.23 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.2273 \t Acc 54.96 \t AccHead 55.42 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.1072 \t Acc 58.76 \t AccHead 59.25 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.0273 \t Acc 62.23 \t AccHead 62.75 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 0.9749 \t Acc 63.44 \t AccHead 63.96 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 0.9142 \t Acc 66.25 \t AccHead 66.80 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 0.8645 \t Acc 68.02 \t AccHead 68.59 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 0.8205 \t Acc 69.86 \t AccHead 70.45 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 0.7815 \t Acc 68.79 \t AccHead 69.36 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 0.7631 \t Acc 72.74 \t AccHead 73.35 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 0.7253 \t Acc 73.27 \t AccHead 73.89 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 0.7195 \t Acc 71.73 \t AccHead 72.33 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 0.6996 \t Acc 74.25 \t AccHead 74.87 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 0.6754 \t Acc 74.71 \t AccHead 75.33 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 0.6664 \t Acc 75.97 \t AccHead 76.61 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 0.6564 \t Acc 73.80 \t AccHead 74.42 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 0.6439 \t Acc 74.66 \t AccHead 75.28 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 0.6426 \t Acc 78.23 \t AccHead 78.89 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 0.6332 \t Acc 74.66 \t AccHead 75.28 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 0.6097 \t Acc 74.58 \t AccHead 75.20 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 0.6106 \t Acc 77.72 \t AccHead 78.36 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 0.6141 \t Acc 76.75 \t AccHead 77.39 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 0.5930 \t Acc 78.39 \t AccHead 79.05 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 0.6010 \t Acc 78.96 \t AccHead 79.62 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 0.6028 \t Acc 79.41 \t AccHead 80.07 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 0.5930 \t Acc 79.73 \t AccHead 80.40 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 0.5898 \t Acc 78.00 \t AccHead 78.65 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 0.5795 \t Acc 80.31 \t AccHead 80.98 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 0.5734 \t Acc 79.47 \t AccHead 80.14 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 0.5713 \t Acc 80.68 \t AccHead 81.35 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 0.5729 \t Acc 78.50 \t AccHead 79.15 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 0.5727 \t Acc 77.00 \t AccHead 77.64 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 0.5646 \t Acc 76.85 \t AccHead 77.49 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 0.5658 \t Acc 80.43 \t AccHead 81.10 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 0.5560 \t Acc 78.40 \t AccHead 79.06 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 0.5579 \t Acc 79.44 \t AccHead 80.10 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 0.5657 \t Acc 77.76 \t AccHead 78.41 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 0.5589 \t Acc 81.23 \t AccHead 81.91 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 0.5575 \t Acc 75.93 \t AccHead 76.56 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 0.5540 \t Acc 80.15 \t AccHead 80.82 \t AccTail 0.00\n",
      "Epoch: [041] \t Loss 0.5613 \t Acc 77.47 \t AccHead 78.12 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 0.5484 \t Acc 77.22 \t AccHead 77.87 \t AccTail 0.00\n",
      "Epoch: [043] \t Loss 0.5487 \t Acc 80.60 \t AccHead 81.28 \t AccTail 0.00\n",
      "Epoch: [044] \t Loss 0.5602 \t Acc 80.72 \t AccHead 81.39 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 0.5458 \t Acc 79.01 \t AccHead 79.66 \t AccTail 0.00\n",
      "Epoch: [046] \t Loss 0.5523 \t Acc 80.27 \t AccHead 80.94 \t AccTail 0.00\n",
      "Epoch: [047] \t Loss 0.5503 \t Acc 81.59 \t AccHead 82.27 \t AccTail 0.00\n",
      "Epoch: [048] \t Loss 0.5519 \t Acc 81.82 \t AccHead 82.51 \t AccTail 0.00\n",
      "Epoch: [049] \t Loss 0.5472 \t Acc 75.33 \t AccHead 75.95 \t AccTail 0.00\n",
      "Epoch: [050] \t Loss 0.5626 \t Acc 82.37 \t AccHead 83.06 \t AccTail 0.00\n",
      "Epoch: [051] \t Loss 0.5348 \t Acc 78.91 \t AccHead 79.57 \t AccTail 0.00\n",
      "Epoch: [052] \t Loss 0.5638 \t Acc 81.20 \t AccHead 81.88 \t AccTail 0.00\n",
      "Epoch: [053] \t Loss 0.5334 \t Acc 78.43 \t AccHead 79.09 \t AccTail 0.00\n",
      "Epoch: [054] \t Loss 0.5392 \t Acc 80.57 \t AccHead 81.24 \t AccTail 0.00\n",
      "Epoch: [055] \t Loss 0.5525 \t Acc 81.11 \t AccHead 81.79 \t AccTail 0.00\n",
      "Epoch: [056] \t Loss 0.5477 \t Acc 76.75 \t AccHead 77.39 \t AccTail 0.00\n",
      "Epoch: [057] \t Loss 0.5398 \t Acc 81.29 \t AccHead 81.98 \t AccTail 0.00\n",
      "Epoch: [058] \t Loss 0.5370 \t Acc 81.49 \t AccHead 82.17 \t AccTail 0.00\n",
      "Epoch: [059] \t Loss 0.5351 \t Acc 80.84 \t AccHead 81.52 \t AccTail 0.00\n",
      "Epoch: [060] \t Loss 0.5410 \t Acc 77.83 \t AccHead 78.47 \t AccTail 0.00\n",
      "Epoch: [061] \t Loss 0.5361 \t Acc 79.78 \t AccHead 80.44 \t AccTail 0.00\n",
      "Epoch: [062] \t Loss 0.5409 \t Acc 77.18 \t AccHead 77.82 \t AccTail 0.00\n",
      "Epoch: [063] \t Loss 0.5392 \t Acc 81.05 \t AccHead 81.73 \t AccTail 0.00\n",
      "Epoch: [064] \t Loss 0.5277 \t Acc 76.94 \t AccHead 77.58 \t AccTail 0.00\n",
      "Epoch: [065] \t Loss 0.5347 \t Acc 78.71 \t AccHead 79.35 \t AccTail 0.00\n",
      "Epoch: [066] \t Loss 0.5406 \t Acc 82.60 \t AccHead 83.30 \t AccTail 0.00\n",
      "Epoch: [067] \t Loss 0.5329 \t Acc 78.92 \t AccHead 79.58 \t AccTail 0.00\n",
      "Epoch: [068] \t Loss 0.5458 \t Acc 81.24 \t AccHead 81.92 \t AccTail 0.00\n",
      "Epoch: [069] \t Loss 0.5300 \t Acc 80.88 \t AccHead 81.56 \t AccTail 0.00\n",
      "Epoch: [070] \t Loss 0.5402 \t Acc 76.61 \t AccHead 77.25 \t AccTail 0.00\n",
      "Epoch: [071] \t Loss 0.5364 \t Acc 82.00 \t AccHead 82.67 \t AccTail 0.00\n",
      "Epoch: [072] \t Loss 0.5330 \t Acc 79.80 \t AccHead 80.47 \t AccTail 0.00\n",
      "Epoch: [073] \t Loss 0.5313 \t Acc 81.50 \t AccHead 82.19 \t AccTail 0.00\n",
      "Epoch: [074] \t Loss 0.5305 \t Acc 74.69 \t AccHead 75.31 \t AccTail 0.00\n",
      "Epoch: [075] \t Loss 0.5348 \t Acc 75.37 \t AccHead 76.00 \t AccTail 0.00\n",
      "Epoch: [076] \t Loss 0.5352 \t Acc 76.83 \t AccHead 77.47 \t AccTail 0.00\n",
      "Epoch: [077] \t Loss 0.5254 \t Acc 80.58 \t AccHead 81.25 \t AccTail 0.00\n",
      "Epoch: [078] \t Loss 0.5340 \t Acc 79.51 \t AccHead 80.18 \t AccTail 0.00\n",
      "Epoch: [079] \t Loss 0.5345 \t Acc 81.64 \t AccHead 82.33 \t AccTail 0.00\n",
      "Epoch: [080] \t Loss 0.5184 \t Acc 79.91 \t AccHead 80.58 \t AccTail 0.00\n",
      "Epoch: [081] \t Loss 0.5299 \t Acc 78.43 \t AccHead 79.09 \t AccTail 0.00\n",
      "Epoch: [082] \t Loss 0.5258 \t Acc 78.29 \t AccHead 78.94 \t AccTail 0.00\n",
      "Epoch: [083] \t Loss 0.5364 \t Acc 79.11 \t AccHead 79.77 \t AccTail 0.00\n",
      "Epoch: [084] \t Loss 0.5294 \t Acc 81.31 \t AccHead 82.00 \t AccTail 0.00\n",
      "Epoch: [085] \t Loss 0.5420 \t Acc 80.38 \t AccHead 81.05 \t AccTail 0.00\n",
      "Epoch: [086] \t Loss 0.5372 \t Acc 81.46 \t AccHead 82.14 \t AccTail 0.00\n",
      "Epoch: [087] \t Loss 0.5331 \t Acc 83.51 \t AccHead 84.21 \t AccTail 0.00\n",
      "Epoch: [088] \t Loss 0.5192 \t Acc 79.24 \t AccHead 79.90 \t AccTail 0.00\n",
      "Epoch: [089] \t Loss 0.5287 \t Acc 81.87 \t AccHead 82.55 \t AccTail 0.00\n",
      "Epoch: [090] \t Loss 0.5322 \t Acc 79.06 \t AccHead 79.71 \t AccTail 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 08:52:49,126]\u001b[0m Trial 9 finished with value: 38.23678207397461 and parameters: {'n_epoch': 90, 'weight_decay': 0.000978981977376328}. Best is trial 5 with value: 44.64664840698242.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 38.24 \t AccHead 75.64 \t AccTail 0.00\n",
      "Epoch: [001] \t Loss 1.7342 \t Acc 27.69 \t AccHead 27.92 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.5466 \t Acc 19.71 \t AccHead 19.88 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.5703 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.5483 \t Acc 23.27 \t AccHead 23.47 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.5847 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.5899 \t Acc 19.82 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 1.6144 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 1.6514 \t Acc 19.86 \t AccHead 20.03 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 1.6539 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 1.7305 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 1.7311 \t Acc 19.81 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 1.7334 \t Acc 19.82 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 1.7354 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 1.7341 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 1.7332 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 1.7374 \t Acc 19.80 \t AccHead 19.96 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 1.7322 \t Acc 19.84 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 1.7301 \t Acc 19.83 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 1.7324 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 1.7323 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 1.7340 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 1.7319 \t Acc 19.81 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 1.7359 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 1.7313 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 1.7303 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 1.7316 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 1.7318 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 1.7388 \t Acc 19.86 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 1.7316 \t Acc 19.82 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 1.7336 \t Acc 19.85 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 1.7309 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 1.7362 \t Acc 19.88 \t AccHead 20.05 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 1.7346 \t Acc 19.86 \t AccHead 20.03 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 1.7299 \t Acc 19.83 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 1.7309 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 1.7306 \t Acc 19.81 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 1.7349 \t Acc 19.82 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 1.7300 \t Acc 19.81 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 1.7321 \t Acc 19.83 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 1.7352 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [041] \t Loss 1.7311 \t Acc 19.86 \t AccHead 20.03 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 1.7347 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [043] \t Loss 1.7350 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [044] \t Loss 1.7324 \t Acc 19.81 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 1.7345 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [046] \t Loss 1.7352 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [047] \t Loss 1.7307 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [048] \t Loss 1.7326 \t Acc 19.83 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [049] \t Loss 1.7336 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [050] \t Loss 1.7292 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [051] \t Loss 1.7396 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [052] \t Loss 1.7299 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [053] \t Loss 1.7322 \t Acc 19.83 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [054] \t Loss 1.7355 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [055] \t Loss 1.7359 \t Acc 19.81 \t AccHead 19.97 \t AccTail 0.00\n",
      "Epoch: [056] \t Loss 1.7341 \t Acc 19.81 \t AccHead 19.97 \t AccTail 0.00\n",
      "Epoch: [057] \t Loss 1.7274 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [058] \t Loss 1.7331 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [059] \t Loss 1.7309 \t Acc 19.83 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [060] \t Loss 1.7342 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [061] \t Loss 1.7339 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [062] \t Loss 1.7336 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [063] \t Loss 1.7339 \t Acc 19.84 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [064] \t Loss 1.7312 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [065] \t Loss 1.7287 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [066] \t Loss 1.7316 \t Acc 19.82 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [067] \t Loss 1.7298 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [068] \t Loss 1.7334 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [069] \t Loss 1.7288 \t Acc 19.84 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [070] \t Loss 1.7313 \t Acc 19.89 \t AccHead 20.06 \t AccTail 0.00\n",
      "Epoch: [071] \t Loss 1.7298 \t Acc 19.82 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [072] \t Loss 1.7329 \t Acc 19.87 \t AccHead 20.04 \t AccTail 0.00\n",
      "Epoch: [073] \t Loss 1.7305 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [074] \t Loss 1.7321 \t Acc 19.86 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [075] \t Loss 1.7301 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [076] \t Loss 1.7282 \t Acc 19.83 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [077] \t Loss 1.7325 \t Acc 19.86 \t AccHead 20.03 \t AccTail 0.00\n",
      "Epoch: [078] \t Loss 1.7315 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [079] \t Loss 1.7299 \t Acc 19.80 \t AccHead 19.97 \t AccTail 0.00\n",
      "Epoch: [080] \t Loss 1.7345 \t Acc 19.80 \t AccHead 19.97 \t AccTail 0.00\n",
      "Epoch: [081] \t Loss 1.7314 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [082] \t Loss 1.7334 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [083] \t Loss 1.7336 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [084] \t Loss 1.7302 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [085] \t Loss 1.7334 \t Acc 19.81 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [086] \t Loss 1.7357 \t Acc 19.81 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [087] \t Loss 1.7343 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [088] \t Loss 1.7327 \t Acc 19.83 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [089] \t Loss 1.7297 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [090] \t Loss 1.7353 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [091] \t Loss 1.7370 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [092] \t Loss 1.7299 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [093] \t Loss 1.7288 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [094] \t Loss 1.7293 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [095] \t Loss 1.7313 \t Acc 19.80 \t AccHead 19.97 \t AccTail 0.00\n",
      "Epoch: [096] \t Loss 1.7364 \t Acc 19.83 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [097] \t Loss 1.7316 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [098] \t Loss 1.7333 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [099] \t Loss 1.7353 \t Acc 19.84 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [100] \t Loss 1.7334 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [101] \t Loss 1.7290 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [102] \t Loss 1.7361 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [103] \t Loss 1.7283 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [104] \t Loss 1.7341 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [105] \t Loss 1.7312 \t Acc 19.81 \t AccHead 19.97 \t AccTail 0.00\n",
      "Epoch: [106] \t Loss 1.7389 \t Acc 19.81 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [107] \t Loss 1.7309 \t Acc 19.81 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [108] \t Loss 1.7280 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [109] \t Loss 1.7301 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [110] \t Loss 1.7334 \t Acc 19.80 \t AccHead 19.97 \t AccTail 0.00\n",
      "Epoch: [111] \t Loss 1.7324 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [112] \t Loss 1.7297 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [113] \t Loss 1.7367 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [114] \t Loss 1.7283 \t Acc 19.80 \t AccHead 19.97 \t AccTail 0.00\n",
      "Epoch: [115] \t Loss 1.7320 \t Acc 19.81 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [116] \t Loss 1.7314 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [117] \t Loss 1.7327 \t Acc 19.84 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [118] \t Loss 1.7346 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [119] \t Loss 1.7329 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [120] \t Loss 1.7305 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [121] \t Loss 1.7304 \t Acc 19.81 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [122] \t Loss 1.7301 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [123] \t Loss 1.7292 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [124] \t Loss 1.7317 \t Acc 19.80 \t AccHead 19.97 \t AccTail 0.00\n",
      "Epoch: [125] \t Loss 1.7338 \t Acc 19.81 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [126] \t Loss 1.7331 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [127] \t Loss 1.7329 \t Acc 19.81 \t AccHead 19.97 \t AccTail 0.00\n",
      "Epoch: [128] \t Loss 1.7309 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [129] \t Loss 1.7324 \t Acc 19.83 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [130] \t Loss 1.7341 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [131] \t Loss 1.7277 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [132] \t Loss 1.7321 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [133] \t Loss 1.7329 \t Acc 19.81 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [134] \t Loss 1.7302 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [135] \t Loss 1.7367 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [136] \t Loss 1.7361 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [137] \t Loss 1.7289 \t Acc 19.80 \t AccHead 19.97 \t AccTail 0.00\n",
      "Epoch: [138] \t Loss 1.7378 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [139] \t Loss 1.7319 \t Acc 19.80 \t AccHead 19.97 \t AccTail 0.00\n",
      "Epoch: [140] \t Loss 1.7301 \t Acc 19.81 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [141] \t Loss 1.7309 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [142] \t Loss 1.7286 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [143] \t Loss 1.7318 \t Acc 19.86 \t AccHead 20.03 \t AccTail 0.00\n",
      "Epoch: [144] \t Loss 1.7300 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [145] \t Loss 1.7300 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [146] \t Loss 1.7306 \t Acc 19.82 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [147] \t Loss 1.7299 \t Acc 19.83 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [148] \t Loss 1.7284 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [149] \t Loss 1.7334 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [150] \t Loss 1.7319 \t Acc 19.81 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [151] \t Loss 1.7215 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [152] \t Loss 1.7202 \t Acc 19.81 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [153] \t Loss 1.7193 \t Acc 19.84 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [154] \t Loss 1.7201 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [155] \t Loss 1.7200 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [156] \t Loss 1.7201 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [157] \t Loss 1.7195 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [158] \t Loss 1.7194 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [159] \t Loss 1.7194 \t Acc 19.84 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [160] \t Loss 1.7201 \t Acc 19.82 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [161] \t Loss 1.7195 \t Acc 19.82 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [162] \t Loss 1.7207 \t Acc 19.83 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [163] \t Loss 1.7195 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [164] \t Loss 1.7197 \t Acc 19.82 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [165] \t Loss 1.7199 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [166] \t Loss 1.7203 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [167] \t Loss 1.7204 \t Acc 19.81 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [168] \t Loss 1.7197 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [169] \t Loss 1.7199 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [170] \t Loss 1.7198 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [171] \t Loss 1.7199 \t Acc 19.81 \t AccHead 19.97 \t AccTail 0.00\n",
      "Epoch: [172] \t Loss 1.7198 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [173] \t Loss 1.7197 \t Acc 19.81 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [174] \t Loss 1.7199 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [175] \t Loss 1.7200 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [176] \t Loss 1.7194 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [177] \t Loss 1.7207 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [178] \t Loss 1.7195 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [179] \t Loss 1.7191 \t Acc 19.82 \t AccHead 19.98 \t AccTail 0.00\n",
      "Epoch: [180] \t Loss 1.7207 \t Acc 19.85 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [181] \t Loss 1.7195 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [182] \t Loss 1.7200 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [183] \t Loss 1.7199 \t Acc 19.83 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [184] \t Loss 1.7192 \t Acc 19.83 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [185] \t Loss 1.7195 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [186] \t Loss 1.7199 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [187] \t Loss 1.7201 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [188] \t Loss 1.7197 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [189] \t Loss 1.7201 \t Acc 19.85 \t AccHead 20.02 \t AccTail 0.00\n",
      "Epoch: [190] \t Loss 1.7200 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [191] \t Loss 1.7198 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [192] \t Loss 1.7202 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [193] \t Loss 1.7192 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n",
      "Epoch: [194] \t Loss 1.7205 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [195] \t Loss 1.7198 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [196] \t Loss 1.7192 \t Acc 19.82 \t AccHead 19.99 \t AccTail 0.00\n",
      "Epoch: [197] \t Loss 1.7198 \t Acc 19.87 \t AccHead 20.04 \t AccTail 0.00\n",
      "Epoch: [198] \t Loss 1.7196 \t Acc 19.83 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [199] \t Loss 1.7198 \t Acc 19.86 \t AccHead 20.03 \t AccTail 0.00\n",
      "Epoch: [200] \t Loss 1.7199 \t Acc 19.84 \t AccHead 20.01 \t AccTail 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 09:28:00,041]\u001b[0m Trial 10 finished with value: 10.110200881958008 and parameters: {'n_epoch': 200, 'weight_decay': 0.08451228520498819}. Best is trial 5 with value: 44.64664840698242.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 10.11 \t AccHead 20.00 \t AccTail 0.00\n",
      "Epoch: [001] \t Loss 2.1324 \t Acc 48.99 \t AccHead 49.40 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 1.4165 \t Acc 52.67 \t AccHead 53.11 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 1.1909 \t Acc 56.27 \t AccHead 56.74 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 1.1202 \t Acc 51.12 \t AccHead 51.55 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 1.0559 \t Acc 55.81 \t AccHead 56.28 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 1.0189 \t Acc 63.68 \t AccHead 64.22 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 0.9492 \t Acc 65.56 \t AccHead 66.11 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 0.9123 \t Acc 67.53 \t AccHead 68.09 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 0.8742 \t Acc 66.50 \t AccHead 67.05 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 0.8273 \t Acc 68.97 \t AccHead 69.54 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 0.7817 \t Acc 72.39 \t AccHead 72.99 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 0.7559 \t Acc 69.58 \t AccHead 70.16 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 0.7289 \t Acc 75.95 \t AccHead 76.58 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 0.6914 \t Acc 74.76 \t AccHead 75.38 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 0.6689 \t Acc 78.23 \t AccHead 78.89 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 0.6476 \t Acc 78.83 \t AccHead 79.48 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 0.6234 \t Acc 78.01 \t AccHead 78.66 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 0.6094 \t Acc 78.22 \t AccHead 78.88 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 0.5975 \t Acc 79.65 \t AccHead 80.32 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 0.5748 \t Acc 79.37 \t AccHead 80.03 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 0.5627 \t Acc 80.04 \t AccHead 80.71 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 0.5476 \t Acc 81.98 \t AccHead 82.66 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 0.5355 \t Acc 82.16 \t AccHead 82.84 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 0.5146 \t Acc 82.58 \t AccHead 83.28 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 0.5227 \t Acc 81.86 \t AccHead 82.54 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 0.5119 \t Acc 82.80 \t AccHead 83.49 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 0.4857 \t Acc 84.52 \t AccHead 85.23 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 0.4768 \t Acc 84.01 \t AccHead 84.71 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 0.4703 \t Acc 85.89 \t AccHead 86.61 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 0.4633 \t Acc 83.26 \t AccHead 83.96 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 0.4529 \t Acc 85.59 \t AccHead 86.31 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 0.4533 \t Acc 85.56 \t AccHead 86.28 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 0.4295 \t Acc 86.48 \t AccHead 87.21 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 0.4252 \t Acc 86.66 \t AccHead 87.38 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 0.4132 \t Acc 87.56 \t AccHead 88.29 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 0.4090 \t Acc 86.82 \t AccHead 87.55 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 0.4022 \t Acc 87.18 \t AccHead 87.90 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 0.3927 \t Acc 86.75 \t AccHead 87.48 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 0.3828 \t Acc 87.56 \t AccHead 88.29 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 0.3769 \t Acc 88.81 \t AccHead 89.56 \t AccTail 0.00\n",
      "Epoch: [041] \t Loss 0.3694 \t Acc 87.21 \t AccHead 87.94 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 0.3661 \t Acc 87.22 \t AccHead 87.94 \t AccTail 1.20\n",
      "Epoch: [043] \t Loss 0.3597 \t Acc 88.29 \t AccHead 89.02 \t AccTail 1.20\n",
      "Epoch: [044] \t Loss 0.3501 \t Acc 87.56 \t AccHead 88.22 \t AccTail 7.88\n",
      "Epoch: [045] \t Loss 0.3493 \t Acc 89.86 \t AccHead 90.60 \t AccTail 1.80\n",
      "Epoch: [046] \t Loss 0.3470 \t Acc 90.27 \t AccHead 90.99 \t AccTail 3.59\n",
      "Epoch: [047] \t Loss 0.3290 \t Acc 88.71 \t AccHead 89.35 \t AccTail 11.45\n",
      "Epoch: [048] \t Loss 0.3351 \t Acc 90.39 \t AccHead 91.10 \t AccTail 5.39\n",
      "Epoch: [049] \t Loss 0.3263 \t Acc 88.54 \t AccHead 89.20 \t AccTail 9.04\n",
      "Epoch: [050] \t Loss 0.3193 \t Acc 89.93 \t AccHead 90.61 \t AccTail 9.58\n",
      "Epoch: [051] \t Loss 0.3019 \t Acc 89.46 \t AccHead 90.09 \t AccTail 13.77\n",
      "Epoch: [052] \t Loss 0.3098 \t Acc 91.00 \t AccHead 91.69 \t AccTail 8.43\n",
      "Epoch: [053] \t Loss 0.2984 \t Acc 90.73 \t AccHead 91.40 \t AccTail 10.18\n",
      "Epoch: [054] \t Loss 0.3005 \t Acc 89.47 \t AccHead 90.07 \t AccTail 17.47\n",
      "Epoch: [055] \t Loss 0.2916 \t Acc 90.83 \t AccHead 91.39 \t AccTail 23.95\n",
      "Epoch: [056] \t Loss 0.2853 \t Acc 91.25 \t AccHead 91.86 \t AccTail 18.67\n",
      "Epoch: [057] \t Loss 0.2797 \t Acc 91.15 \t AccHead 91.79 \t AccTail 13.94\n",
      "Epoch: [058] \t Loss 0.2817 \t Acc 89.38 \t AccHead 90.02 \t AccTail 12.65\n",
      "Epoch: [059] \t Loss 0.2733 \t Acc 89.04 \t AccHead 89.69 \t AccTail 11.98\n",
      "Epoch: [060] \t Loss 0.2735 \t Acc 89.98 \t AccHead 90.65 \t AccTail 10.18\n",
      "Epoch: [061] \t Loss 0.2640 \t Acc 92.14 \t AccHead 92.71 \t AccTail 23.95\n",
      "Epoch: [062] \t Loss 0.2567 \t Acc 91.26 \t AccHead 91.75 \t AccTail 32.34\n",
      "Epoch: [063] \t Loss 0.2603 \t Acc 90.10 \t AccHead 90.64 \t AccTail 25.30\n",
      "Epoch: [064] \t Loss 0.2590 \t Acc 91.67 \t AccHead 92.25 \t AccTail 22.29\n",
      "Epoch: [065] \t Loss 0.2521 \t Acc 92.63 \t AccHead 93.20 \t AccTail 24.70\n",
      "Epoch: [066] \t Loss 0.2413 \t Acc 92.29 \t AccHead 92.81 \t AccTail 29.70\n",
      "Epoch: [067] \t Loss 0.2425 \t Acc 91.96 \t AccHead 92.45 \t AccTail 33.53\n",
      "Epoch: [068] \t Loss 0.2325 \t Acc 92.61 \t AccHead 93.01 \t AccTail 43.29\n",
      "Epoch: [069] \t Loss 0.2351 \t Acc 92.71 \t AccHead 93.15 \t AccTail 40.36\n",
      "Epoch: [070] \t Loss 0.2331 \t Acc 93.01 \t AccHead 93.44 \t AccTail 41.57\n",
      "Epoch: [071] \t Loss 0.2249 \t Acc 93.56 \t AccHead 94.02 \t AccTail 37.20\n",
      "Epoch: [072] \t Loss 0.2240 \t Acc 93.30 \t AccHead 93.71 \t AccTail 43.37\n",
      "Epoch: [073] \t Loss 0.2149 \t Acc 93.03 \t AccHead 93.44 \t AccTail 44.31\n",
      "Epoch: [074] \t Loss 0.2199 \t Acc 90.97 \t AccHead 91.38 \t AccTail 41.32\n",
      "Epoch: [075] \t Loss 0.2142 \t Acc 93.01 \t AccHead 93.33 \t AccTail 55.69\n",
      "Epoch: [076] \t Loss 0.2063 \t Acc 92.40 \t AccHead 92.80 \t AccTail 44.58\n",
      "Epoch: [077] \t Loss 0.2169 \t Acc 93.87 \t AccHead 94.16 \t AccTail 58.68\n",
      "Epoch: [078] \t Loss 0.2070 \t Acc 93.64 \t AccHead 93.90 \t AccTail 62.05\n",
      "Epoch: [079] \t Loss 0.1908 \t Acc 92.82 \t AccHead 93.14 \t AccTail 55.09\n",
      "Epoch: [080] \t Loss 0.1964 \t Acc 93.79 \t AccHead 94.02 \t AccTail 66.27\n",
      "Epoch: [081] \t Loss 0.1951 \t Acc 93.80 \t AccHead 94.13 \t AccTail 54.22\n",
      "Epoch: [082] \t Loss 0.1881 \t Acc 93.67 \t AccHead 93.99 \t AccTail 55.09\n",
      "Epoch: [083] \t Loss 0.1906 \t Acc 94.52 \t AccHead 94.81 \t AccTail 59.28\n",
      "Epoch: [084] \t Loss 0.1795 \t Acc 93.94 \t AccHead 94.22 \t AccTail 60.24\n",
      "Epoch: [085] \t Loss 0.1868 \t Acc 93.90 \t AccHead 94.23 \t AccTail 54.82\n",
      "Epoch: [086] \t Loss 0.1842 \t Acc 94.57 \t AccHead 94.84 \t AccTail 62.28\n",
      "Epoch: [087] \t Loss 0.1744 \t Acc 93.56 \t AccHead 93.86 \t AccTail 57.49\n",
      "Epoch: [088] \t Loss 0.1788 \t Acc 94.53 \t AccHead 94.78 \t AccTail 64.67\n",
      "Epoch: [089] \t Loss 0.1659 \t Acc 94.14 \t AccHead 94.39 \t AccTail 64.46\n",
      "Epoch: [090] \t Loss 0.1726 \t Acc 93.68 \t AccHead 93.89 \t AccTail 67.88\n",
      "Epoch: [091] \t Loss 0.1760 \t Acc 94.47 \t AccHead 94.69 \t AccTail 68.07\n",
      "Epoch: [092] \t Loss 0.1741 \t Acc 94.57 \t AccHead 94.72 \t AccTail 76.51\n",
      "Epoch: [093] \t Loss 0.1663 \t Acc 95.09 \t AccHead 95.34 \t AccTail 65.87\n",
      "Epoch: [094] \t Loss 0.1622 \t Acc 95.62 \t AccHead 95.83 \t AccTail 70.06\n",
      "Epoch: [095] \t Loss 0.1539 \t Acc 94.65 \t AccHead 94.86 \t AccTail 69.88\n",
      "Epoch: [096] \t Loss 0.1614 \t Acc 95.47 \t AccHead 95.67 \t AccTail 70.55\n",
      "Epoch: [097] \t Loss 0.1526 \t Acc 95.31 \t AccHead 95.46 \t AccTail 76.51\n",
      "Epoch: [098] \t Loss 0.1532 \t Acc 95.19 \t AccHead 95.50 \t AccTail 57.83\n",
      "Epoch: [099] \t Loss 0.1586 \t Acc 94.25 \t AccHead 94.42 \t AccTail 73.49\n",
      "Epoch: [100] \t Loss 0.1538 \t Acc 95.18 \t AccHead 95.42 \t AccTail 66.27\n",
      "Epoch: [101] \t Loss 0.1414 \t Acc 95.52 \t AccHead 95.68 \t AccTail 75.90\n",
      "Epoch: [102] \t Loss 0.1567 \t Acc 95.15 \t AccHead 95.36 \t AccTail 69.46\n",
      "Epoch: [103] \t Loss 0.1568 \t Acc 95.62 \t AccHead 95.85 \t AccTail 68.26\n",
      "Epoch: [104] \t Loss 0.1374 \t Acc 96.02 \t AccHead 96.20 \t AccTail 74.85\n",
      "Epoch: [105] \t Loss 0.1518 \t Acc 95.85 \t AccHead 96.04 \t AccTail 73.65\n",
      "Epoch: [106] \t Loss 0.1491 \t Acc 95.69 \t AccHead 95.79 \t AccTail 83.73\n",
      "Epoch: [107] \t Loss 0.1395 \t Acc 94.68 \t AccHead 94.90 \t AccTail 68.26\n",
      "Epoch: [108] \t Loss 0.1429 \t Acc 95.38 \t AccHead 95.57 \t AccTail 72.29\n",
      "Epoch: [109] \t Loss 0.1421 \t Acc 94.97 \t AccHead 95.12 \t AccTail 77.71\n",
      "Epoch: [110] \t Loss 0.1435 \t Acc 95.15 \t AccHead 95.35 \t AccTail 71.08\n",
      "Epoch: [111] \t Loss 0.1358 \t Acc 95.83 \t AccHead 96.05 \t AccTail 69.28\n",
      "Epoch: [112] \t Loss 0.1349 \t Acc 94.79 \t AccHead 95.00 \t AccTail 69.70\n",
      "Epoch: [113] \t Loss 0.1273 \t Acc 96.18 \t AccHead 96.28 \t AccTail 84.43\n",
      "Epoch: [114] \t Loss 0.1301 \t Acc 94.72 \t AccHead 94.87 \t AccTail 76.51\n",
      "Epoch: [115] \t Loss 0.1254 \t Acc 96.19 \t AccHead 96.30 \t AccTail 82.63\n",
      "Epoch: [116] \t Loss 0.1314 \t Acc 96.29 \t AccHead 96.40 \t AccTail 82.63\n",
      "Epoch: [117] \t Loss 0.1241 \t Acc 95.27 \t AccHead 95.42 \t AccTail 77.84\n",
      "Epoch: [118] \t Loss 0.1237 \t Acc 95.56 \t AccHead 95.66 \t AccTail 83.83\n",
      "Epoch: [119] \t Loss 0.1290 \t Acc 95.81 \t AccHead 95.88 \t AccTail 87.35\n",
      "Epoch: [120] \t Loss 0.1292 \t Acc 95.46 \t AccHead 95.56 \t AccTail 82.53\n",
      "Epoch: [121] \t Loss 0.1185 \t Acc 95.88 \t AccHead 96.02 \t AccTail 79.04\n",
      "Epoch: [122] \t Loss 0.1183 \t Acc 96.51 \t AccHead 96.63 \t AccTail 81.33\n",
      "Epoch: [123] \t Loss 0.1194 \t Acc 95.68 \t AccHead 95.83 \t AccTail 77.58\n",
      "Epoch: [124] \t Loss 0.1216 \t Acc 96.60 \t AccHead 96.66 \t AccTail 89.82\n",
      "Epoch: [125] \t Loss 0.1194 \t Acc 96.88 \t AccHead 96.99 \t AccTail 83.83\n",
      "Epoch: [126] \t Loss 0.1202 \t Acc 96.04 \t AccHead 96.22 \t AccTail 75.45\n",
      "Epoch: [127] \t Loss 0.1058 \t Acc 96.23 \t AccHead 96.31 \t AccTail 86.59\n",
      "Epoch: [128] \t Loss 0.1157 \t Acc 96.53 \t AccHead 96.64 \t AccTail 83.23\n",
      "Epoch: [129] \t Loss 0.1217 \t Acc 96.45 \t AccHead 96.56 \t AccTail 83.03\n",
      "Epoch: [130] \t Loss 0.1041 \t Acc 96.93 \t AccHead 97.02 \t AccTail 86.83\n",
      "Epoch: [131] \t Loss 0.1156 \t Acc 96.80 \t AccHead 96.89 \t AccTail 85.45\n",
      "Epoch: [132] \t Loss 0.1156 \t Acc 96.89 \t AccHead 96.97 \t AccTail 87.43\n",
      "Epoch: [133] \t Loss 0.1098 \t Acc 96.35 \t AccHead 96.48 \t AccTail 80.24\n",
      "Epoch: [134] \t Loss 0.1110 \t Acc 96.33 \t AccHead 96.43 \t AccTail 84.34\n",
      "Epoch: [135] \t Loss 0.1074 \t Acc 96.53 \t AccHead 96.63 \t AccTail 84.34\n",
      "Epoch: [136] \t Loss 0.1098 \t Acc 96.43 \t AccHead 96.51 \t AccTail 86.67\n",
      "Epoch: [137] \t Loss 0.1058 \t Acc 96.90 \t AccHead 96.97 \t AccTail 87.95\n",
      "Epoch: [138] \t Loss 0.1053 \t Acc 96.62 \t AccHead 96.72 \t AccTail 84.24\n",
      "Epoch: [139] \t Loss 0.1105 \t Acc 97.04 \t AccHead 97.17 \t AccTail 81.44\n",
      "Epoch: [140] \t Loss 0.1026 \t Acc 96.60 \t AccHead 96.69 \t AccTail 86.23\n",
      "Epoch: [141] \t Loss 0.1067 \t Acc 97.00 \t AccHead 97.04 \t AccTail 91.62\n",
      "Epoch: [142] \t Loss 0.1009 \t Acc 96.84 \t AccHead 96.98 \t AccTail 79.64\n",
      "Epoch: [143] \t Loss 0.0997 \t Acc 97.25 \t AccHead 97.32 \t AccTail 89.22\n",
      "Epoch: [144] \t Loss 0.0988 \t Acc 95.83 \t AccHead 95.88 \t AccTail 90.96\n",
      "Epoch: [145] \t Loss 0.0986 \t Acc 96.52 \t AccHead 96.61 \t AccTail 85.45\n",
      "Epoch: [146] \t Loss 0.1017 \t Acc 97.23 \t AccHead 97.32 \t AccTail 87.35\n",
      "Epoch: [147] \t Loss 0.0986 \t Acc 96.87 \t AccHead 96.98 \t AccTail 83.64\n",
      "Epoch: [148] \t Loss 0.0933 \t Acc 97.31 \t AccHead 97.40 \t AccTail 86.14\n",
      "Epoch: [149] \t Loss 0.0937 \t Acc 96.76 \t AccHead 96.87 \t AccTail 83.23\n",
      "Epoch: [150] \t Loss 0.0926 \t Acc 96.59 \t AccHead 96.73 \t AccTail 79.52\n",
      "Epoch: [151] \t Loss 0.0651 \t Acc 98.62 \t AccHead 98.66 \t AccTail 94.01\n",
      "Epoch: [152] \t Loss 0.0472 \t Acc 99.03 \t AccHead 99.09 \t AccTail 92.73\n",
      "Epoch: [153] \t Loss 0.0393 \t Acc 99.13 \t AccHead 99.16 \t AccTail 95.18\n",
      "Epoch: [154] \t Loss 0.0340 \t Acc 99.19 \t AccHead 99.23 \t AccTail 95.18\n",
      "Epoch: [155] \t Loss 0.0317 \t Acc 99.25 \t AccHead 99.28 \t AccTail 95.78\n",
      "Epoch: [156] \t Loss 0.0295 \t Acc 99.34 \t AccHead 99.35 \t AccTail 97.59\n",
      "Epoch: [157] \t Loss 0.0278 \t Acc 99.24 \t AccHead 99.27 \t AccTail 95.78\n",
      "Epoch: [158] \t Loss 0.0281 \t Acc 99.39 \t AccHead 99.42 \t AccTail 96.34\n",
      "Epoch: [159] \t Loss 0.0235 \t Acc 99.38 \t AccHead 99.41 \t AccTail 95.81\n",
      "Epoch: [160] \t Loss 0.0248 \t Acc 99.43 \t AccHead 99.45 \t AccTail 96.36\n",
      "Epoch: [161] \t Loss 0.0213 \t Acc 99.56 \t AccHead 99.57 \t AccTail 98.20\n",
      "Epoch: [162] \t Loss 0.0223 \t Acc 99.51 \t AccHead 99.51 \t AccTail 99.40\n",
      "Epoch: [163] \t Loss 0.0206 \t Acc 99.53 \t AccHead 99.53 \t AccTail 98.80\n",
      "Epoch: [164] \t Loss 0.0214 \t Acc 99.61 \t AccHead 99.62 \t AccTail 97.59\n",
      "Epoch: [165] \t Loss 0.0193 \t Acc 99.61 \t AccHead 99.61 \t AccTail 99.40\n",
      "Epoch: [166] \t Loss 0.0190 \t Acc 99.61 \t AccHead 99.62 \t AccTail 98.20\n",
      "Epoch: [167] \t Loss 0.0202 \t Acc 99.68 \t AccHead 99.69 \t AccTail 98.18\n",
      "Epoch: [168] \t Loss 0.0174 \t Acc 99.64 \t AccHead 99.65 \t AccTail 97.59\n",
      "Epoch: [169] \t Loss 0.0171 \t Acc 99.67 \t AccHead 99.67 \t AccTail 98.80\n",
      "Epoch: [170] \t Loss 0.0164 \t Acc 99.69 \t AccHead 99.70 \t AccTail 98.17\n",
      "Epoch: [171] \t Loss 0.0145 \t Acc 99.63 \t AccHead 99.63 \t AccTail 98.80\n",
      "Epoch: [172] \t Loss 0.0158 \t Acc 99.66 \t AccHead 99.67 \t AccTail 97.60\n",
      "Epoch: [173] \t Loss 0.0143 \t Acc 99.67 \t AccHead 99.68 \t AccTail 98.80\n",
      "Epoch: [174] \t Loss 0.0176 \t Acc 99.66 \t AccHead 99.68 \t AccTail 97.59\n",
      "Epoch: [175] \t Loss 0.0156 \t Acc 99.71 \t AccHead 99.71 \t AccTail 99.40\n",
      "Epoch: [176] \t Loss 0.0139 \t Acc 99.66 \t AccHead 99.67 \t AccTail 98.19\n",
      "Epoch: [177] \t Loss 0.0151 \t Acc 99.75 \t AccHead 99.75 \t AccTail 99.40\n",
      "Epoch: [178] \t Loss 0.0134 \t Acc 99.74 \t AccHead 99.74 \t AccTail 98.80\n",
      "Epoch: [179] \t Loss 0.0138 \t Acc 99.75 \t AccHead 99.77 \t AccTail 96.99\n",
      "Epoch: [180] \t Loss 0.0127 \t Acc 99.73 \t AccHead 99.73 \t AccTail 100.00\n",
      "Epoch: [181] \t Loss 0.0135 \t Acc 99.72 \t AccHead 99.73 \t AccTail 98.20\n",
      "Epoch: [182] \t Loss 0.0119 \t Acc 99.76 \t AccHead 99.76 \t AccTail 99.40\n",
      "Epoch: [183] \t Loss 0.0123 \t Acc 99.65 \t AccHead 99.65 \t AccTail 99.40\n",
      "Epoch: [184] \t Loss 0.0119 \t Acc 99.76 \t AccHead 99.76 \t AccTail 98.80\n",
      "Epoch: [185] \t Loss 0.0135 \t Acc 99.74 \t AccHead 99.74 \t AccTail 98.80\n",
      "Epoch: [186] \t Loss 0.0120 \t Acc 99.73 \t AccHead 99.73 \t AccTail 98.80\n",
      "Epoch: [187] \t Loss 0.0143 \t Acc 99.73 \t AccHead 99.73 \t AccTail 99.39\n",
      "Epoch: [188] \t Loss 0.0123 \t Acc 99.76 \t AccHead 99.75 \t AccTail 100.00\n",
      "Epoch: [189] \t Loss 0.0134 \t Acc 99.73 \t AccHead 99.74 \t AccTail 98.18\n",
      "Epoch: [190] \t Loss 0.0112 \t Acc 99.77 \t AccHead 99.76 \t AccTail 100.00\n",
      "Epoch: [191] \t Loss 0.0121 \t Acc 99.79 \t AccHead 99.78 \t AccTail 100.00\n",
      "Epoch: [192] \t Loss 0.0120 \t Acc 99.80 \t AccHead 99.80 \t AccTail 100.00\n",
      "Epoch: [193] \t Loss 0.0104 \t Acc 99.81 \t AccHead 99.81 \t AccTail 99.40\n",
      "Epoch: [194] \t Loss 0.0121 \t Acc 99.78 \t AccHead 99.78 \t AccTail 99.40\n",
      "Epoch: [195] \t Loss 0.0112 \t Acc 99.82 \t AccHead 99.82 \t AccTail 98.80\n",
      "Epoch: [196] \t Loss 0.0121 \t Acc 99.75 \t AccHead 99.75 \t AccTail 99.40\n",
      "Epoch: [197] \t Loss 0.0088 \t Acc 99.81 \t AccHead 99.81 \t AccTail 100.00\n",
      "Epoch: [198] \t Loss 0.0103 \t Acc 99.84 \t AccHead 99.84 \t AccTail 98.80\n",
      "Epoch: [199] \t Loss 0.0101 \t Acc 99.80 \t AccHead 99.80 \t AccTail 99.40\n",
      "Epoch: [200] \t Loss 0.0106 \t Acc 99.85 \t AccHead 99.86 \t AccTail 98.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 10:03:08,031]\u001b[0m Trial 11 finished with value: 43.49408721923828 and parameters: {'n_epoch': 200, 'weight_decay': 3.566967303889489e-05}. Best is trial 5 with value: 44.64664840698242.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 43.49 \t AccHead 84.76 \t AccTail 1.31\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'CIFAR10' #['CIFAR10', 'CIFAR100']\n",
    "IMB_TYPE = 'step' #['exp', 'step']\n",
    "IMB_FACTOR = 0.01 #[0.1, 0.01]\n",
    "train_loader, test_loader, num_classes = get_loaders()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sampler = optuna.samplers.TPESampler()\n",
    "    study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "    study.optimize(func=train_model, n_trials=12)\n",
    "    joblib.dump(study, 'set_10_step_01.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87f8809a-c6e9-4661-b931-01ea780bc6ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T10:03:08.094565Z",
     "iopub.status.busy": "2022-06-17T10:03:08.094357Z",
     "iopub.status.idle": "2022-06-17T10:03:08.116689Z",
     "shell.execute_reply": "2022-06-17T10:03:08.116088Z",
     "shell.execute_reply.started": "2022-06-17T10:03:08.094541Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_n_epoch</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35.335155</td>\n",
       "      <td>0 days 00:35:15.375066</td>\n",
       "      <td>200</td>\n",
       "      <td>0.007382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>44.302902</td>\n",
       "      <td>0 days 00:34:58.414487</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>24.699223</td>\n",
       "      <td>0 days 00:35:06.414250</td>\n",
       "      <td>200</td>\n",
       "      <td>0.015852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>42.867252</td>\n",
       "      <td>0 days 00:34:57.689213</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>41.684361</td>\n",
       "      <td>0 days 00:15:56.394683</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>44.646648</td>\n",
       "      <td>0 days 00:35:09.745846</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>41.492268</td>\n",
       "      <td>0 days 00:15:56.506590</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>41.077747</td>\n",
       "      <td>0 days 00:34:48.574028</td>\n",
       "      <td>200</td>\n",
       "      <td>0.002343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>44.211910</td>\n",
       "      <td>0 days 00:35:02.353758</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>38.236782</td>\n",
       "      <td>0 days 00:15:44.087744</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number      value               duration  params_n_epoch  \\\n",
       "0       0  35.335155 0 days 00:35:15.375066             200   \n",
       "1       1  44.302902 0 days 00:34:58.414487             200   \n",
       "2       2  24.699223 0 days 00:35:06.414250             200   \n",
       "3       3  42.867252 0 days 00:34:57.689213             200   \n",
       "4       4  41.684361 0 days 00:15:56.394683              90   \n",
       "5       5  44.646648 0 days 00:35:09.745846             200   \n",
       "6       6  41.492268 0 days 00:15:56.506590              90   \n",
       "7       7  41.077747 0 days 00:34:48.574028             200   \n",
       "8       8  44.211910 0 days 00:35:02.353758             200   \n",
       "9       9  38.236782 0 days 00:15:44.087744              90   \n",
       "\n",
       "   params_weight_decay  \n",
       "0             0.007382  \n",
       "1             0.000257  \n",
       "2             0.015852  \n",
       "3             0.000022  \n",
       "4             0.000154  \n",
       "5             0.000288  \n",
       "6             0.000235  \n",
       "7             0.002343  \n",
       "8             0.000421  \n",
       "9             0.000979  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = joblib.load('set_10_step_01.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa80b8bd-70c4-4a62-8fad-922427468953",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T10:03:08.118138Z",
     "iopub.status.busy": "2022-06-17T10:03:08.117907Z",
     "iopub.status.idle": "2022-06-17T14:28:40.650427Z",
     "shell.execute_reply": "2022-06-17T14:28:40.649537Z",
     "shell.execute_reply.started": "2022-06-17T10:03:08.118118Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 10:03:45,637]\u001b[0m A new study created in memory with name: no-name-12208c39-adbe-4b0d-a0b0-ce6e64049729\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls num list(train_dataset):\n",
      "[400, 390, 381, 373, 364, 356, 347, 339, 332, 324, 316, 309, 302, 295, 288, 282, 275, 269, 263, 257, 251, 245, 239, 234, 228, 223, 218, 213, 208, 203, 199, 194, 190, 185, 181, 177, 173, 169, 165, 161, 157, 154, 150, 147, 143, 140, 137, 134, 130, 127, 125, 122, 119, 116, 113, 111, 108, 106, 103, 101, 99, 96, 94, 92, 90, 88, 86, 84, 82, 80, 78, 76, 74, 73, 71, 69, 68, 66, 65, 63, 62, 60, 59, 58, 56, 55, 54, 52, 51, 50, 49, 48, 47, 45, 44, 43, 42, 41, 40, 40]\n",
      "cls num list(val_dataset):\n",
      "[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
      "Epoch: [001] \t Loss 4.3720 \t Acc 5.16 \t AccHead 6.76 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 4.2287 \t Acc 4.79 \t AccHead 6.28 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 4.2174 \t Acc 4.03 \t AccHead 5.28 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 4.2091 \t Acc 6.01 \t AccHead 7.88 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 4.2146 \t Acc 5.07 \t AccHead 6.64 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 4.2077 \t Acc 5.83 \t AccHead 7.64 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 4.2172 \t Acc 6.13 \t AccHead 8.03 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 4.2051 \t Acc 4.86 \t AccHead 6.37 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 4.2125 \t Acc 4.60 \t AccHead 6.04 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 4.2279 \t Acc 4.78 \t AccHead 6.26 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 4.2154 \t Acc 5.11 \t AccHead 6.70 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 4.2196 \t Acc 5.61 \t AccHead 7.35 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 4.2094 \t Acc 5.89 \t AccHead 7.72 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 4.2197 \t Acc 3.92 \t AccHead 5.14 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 4.2199 \t Acc 5.77 \t AccHead 7.56 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 4.3554 \t Acc 1.93 \t AccHead 2.53 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 4.3525 \t Acc 4.54 \t AccHead 5.95 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 4.3331 \t Acc 4.02 \t AccHead 5.26 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 4.3746 \t Acc 1.49 \t AccHead 1.95 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 4.4007 \t Acc 3.32 \t AccHead 4.36 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 4.3551 \t Acc 3.39 \t AccHead 4.44 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 4.3662 \t Acc 2.39 \t AccHead 3.13 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 4.3989 \t Acc 2.11 \t AccHead 2.77 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 4.3690 \t Acc 2.12 \t AccHead 2.78 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 4.3685 \t Acc 2.95 \t AccHead 3.86 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 4.3451 \t Acc 2.82 \t AccHead 3.69 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 4.3558 \t Acc 2.47 \t AccHead 3.23 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 4.3499 \t Acc 2.69 \t AccHead 3.53 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 4.3477 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 4.3554 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 4.3488 \t Acc 4.17 \t AccHead 5.46 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 4.3496 \t Acc 2.38 \t AccHead 3.11 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 4.3503 \t Acc 3.34 \t AccHead 4.38 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 4.3535 \t Acc 2.55 \t AccHead 3.34 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 4.3550 \t Acc 2.40 \t AccHead 3.15 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 4.3473 \t Acc 3.09 \t AccHead 4.04 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 4.3589 \t Acc 3.91 \t AccHead 5.13 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 4.3606 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 4.3558 \t Acc 1.93 \t AccHead 2.53 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 4.3509 \t Acc 3.21 \t AccHead 4.21 \t AccTail 0.00\n",
      "Epoch: [041] \t Loss 4.3498 \t Acc 2.54 \t AccHead 3.33 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 4.3581 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [043] \t Loss 4.3530 \t Acc 4.29 \t AccHead 5.62 \t AccTail 0.00\n",
      "Epoch: [044] \t Loss 4.3618 \t Acc 2.39 \t AccHead 3.14 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 4.3505 \t Acc 2.22 \t AccHead 2.90 \t AccTail 0.00\n",
      "Epoch: [046] \t Loss 4.3509 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [047] \t Loss 4.3530 \t Acc 4.25 \t AccHead 5.57 \t AccTail 0.00\n",
      "Epoch: [048] \t Loss 4.3614 \t Acc 2.54 \t AccHead 3.32 \t AccTail 0.00\n",
      "Epoch: [049] \t Loss 4.3661 \t Acc 2.43 \t AccHead 3.19 \t AccTail 0.00\n",
      "Epoch: [050] \t Loss 4.3552 \t Acc 4.35 \t AccHead 5.70 \t AccTail 0.00\n",
      "Epoch: [051] \t Loss 4.3552 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [052] \t Loss 4.3569 \t Acc 3.56 \t AccHead 4.67 \t AccTail 0.00\n",
      "Epoch: [053] \t Loss 4.3638 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [054] \t Loss 4.3683 \t Acc 2.39 \t AccHead 3.13 \t AccTail 0.00\n",
      "Epoch: [055] \t Loss 4.4377 \t Acc 2.43 \t AccHead 3.19 \t AccTail 0.00\n",
      "Epoch: [056] \t Loss 4.4480 \t Acc 2.55 \t AccHead 3.34 \t AccTail 0.00\n",
      "Epoch: [057] \t Loss 4.4471 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [058] \t Loss 4.4461 \t Acc 2.39 \t AccHead 3.13 \t AccTail 0.00\n",
      "Epoch: [059] \t Loss 4.4487 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [060] \t Loss 4.4474 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [061] \t Loss 4.4464 \t Acc 2.43 \t AccHead 3.19 \t AccTail 0.00\n",
      "Epoch: [062] \t Loss 4.4482 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [063] \t Loss 4.4473 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [064] \t Loss 4.4477 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [065] \t Loss 4.4458 \t Acc 2.28 \t AccHead 2.99 \t AccTail 0.00\n",
      "Epoch: [066] \t Loss 4.4459 \t Acc 2.22 \t AccHead 2.91 \t AccTail 0.00\n",
      "Epoch: [067] \t Loss 4.4476 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [068] \t Loss 4.4468 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [069] \t Loss 4.4472 \t Acc 2.39 \t AccHead 3.13 \t AccTail 0.00\n",
      "Epoch: [070] \t Loss 4.4478 \t Acc 2.38 \t AccHead 3.12 \t AccTail 0.00\n",
      "Epoch: [071] \t Loss 4.4476 \t Acc 2.49 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [072] \t Loss 4.4481 \t Acc 2.39 \t AccHead 3.13 \t AccTail 0.00\n",
      "Epoch: [073] \t Loss 4.4470 \t Acc 2.39 \t AccHead 3.13 \t AccTail 0.00\n",
      "Epoch: [074] \t Loss 4.4475 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [075] \t Loss 4.4482 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [076] \t Loss 4.4475 \t Acc 2.22 \t AccHead 2.91 \t AccTail 0.00\n",
      "Epoch: [077] \t Loss 4.4496 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [078] \t Loss 4.4470 \t Acc 2.28 \t AccHead 2.99 \t AccTail 0.00\n",
      "Epoch: [079] \t Loss 4.4482 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [080] \t Loss 4.4474 \t Acc 1.97 \t AccHead 2.58 \t AccTail 0.00\n",
      "Epoch: [081] \t Loss 4.4472 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [082] \t Loss 4.4469 \t Acc 2.55 \t AccHead 3.34 \t AccTail 0.00\n",
      "Epoch: [083] \t Loss 4.4485 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [084] \t Loss 4.4494 \t Acc 2.28 \t AccHead 2.99 \t AccTail 0.00\n",
      "Epoch: [085] \t Loss 4.4470 \t Acc 2.43 \t AccHead 3.18 \t AccTail 0.00\n",
      "Epoch: [086] \t Loss 4.4460 \t Acc 2.48 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [087] \t Loss 4.4483 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [088] \t Loss 4.4485 \t Acc 2.22 \t AccHead 2.91 \t AccTail 0.00\n",
      "Epoch: [089] \t Loss 4.4482 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [090] \t Loss 4.4465 \t Acc 2.38 \t AccHead 3.12 \t AccTail 0.00\n",
      "Epoch: [091] \t Loss 4.4466 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [092] \t Loss 4.4471 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [093] \t Loss 4.4484 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [094] \t Loss 4.4456 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [095] \t Loss 4.4488 \t Acc 2.16 \t AccHead 2.84 \t AccTail 0.00\n",
      "Epoch: [096] \t Loss 4.4467 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [097] \t Loss 4.4475 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [098] \t Loss 4.4478 \t Acc 2.27 \t AccHead 2.98 \t AccTail 0.00\n",
      "Epoch: [099] \t Loss 4.4485 \t Acc 2.54 \t AccHead 3.33 \t AccTail 0.00\n",
      "Epoch: [100] \t Loss 4.4461 \t Acc 2.28 \t AccHead 2.99 \t AccTail 0.00\n",
      "Epoch: [101] \t Loss 4.4478 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [102] \t Loss 4.4485 \t Acc 2.22 \t AccHead 2.91 \t AccTail 0.00\n",
      "Epoch: [103] \t Loss 4.4475 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [104] \t Loss 4.4483 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [105] \t Loss 4.4452 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [106] \t Loss 4.4495 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [107] \t Loss 4.4454 \t Acc 2.49 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [108] \t Loss 4.4480 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [109] \t Loss 4.4476 \t Acc 2.39 \t AccHead 3.13 \t AccTail 0.00\n",
      "Epoch: [110] \t Loss 4.4464 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [111] \t Loss 4.4471 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [112] \t Loss 4.4466 \t Acc 2.49 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [113] \t Loss 4.4487 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [114] \t Loss 4.4469 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [115] \t Loss 4.4470 \t Acc 2.22 \t AccHead 2.91 \t AccTail 0.00\n",
      "Epoch: [116] \t Loss 4.4474 \t Acc 2.16 \t AccHead 2.84 \t AccTail 0.00\n",
      "Epoch: [117] \t Loss 4.4463 \t Acc 2.27 \t AccHead 2.98 \t AccTail 0.00\n",
      "Epoch: [118] \t Loss 4.4498 \t Acc 2.28 \t AccHead 2.99 \t AccTail 0.00\n",
      "Epoch: [119] \t Loss 4.4463 \t Acc 2.43 \t AccHead 3.19 \t AccTail 0.00\n",
      "Epoch: [120] \t Loss 4.4464 \t Acc 2.32 \t AccHead 3.04 \t AccTail 0.00\n",
      "Epoch: [121] \t Loss 4.4474 \t Acc 2.07 \t AccHead 2.72 \t AccTail 0.00\n",
      "Epoch: [122] \t Loss 4.4459 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [123] \t Loss 4.4451 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [124] \t Loss 4.4468 \t Acc 2.17 \t AccHead 2.85 \t AccTail 0.00\n",
      "Epoch: [125] \t Loss 4.4474 \t Acc 2.38 \t AccHead 3.12 \t AccTail 0.00\n",
      "Epoch: [126] \t Loss 4.4463 \t Acc 2.32 \t AccHead 3.05 \t AccTail 0.00\n",
      "Epoch: [127] \t Loss 4.4468 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [128] \t Loss 4.4468 \t Acc 2.22 \t AccHead 2.91 \t AccTail 0.00\n",
      "Epoch: [129] \t Loss 4.4460 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [130] \t Loss 4.4471 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [131] \t Loss 4.4469 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [132] \t Loss 4.4469 \t Acc 2.39 \t AccHead 3.13 \t AccTail 0.00\n",
      "Epoch: [133] \t Loss 4.4465 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [134] \t Loss 4.4467 \t Acc 2.43 \t AccHead 3.18 \t AccTail 0.00\n",
      "Epoch: [135] \t Loss 4.4480 \t Acc 2.43 \t AccHead 3.19 \t AccTail 0.00\n",
      "Epoch: [136] \t Loss 4.4488 \t Acc 2.43 \t AccHead 3.18 \t AccTail 0.00\n",
      "Epoch: [137] \t Loss 4.4461 \t Acc 2.49 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [138] \t Loss 4.4494 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [139] \t Loss 4.4454 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [140] \t Loss 4.4476 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [141] \t Loss 4.4451 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [142] \t Loss 4.4462 \t Acc 2.33 \t AccHead 3.05 \t AccTail 0.00\n",
      "Epoch: [143] \t Loss 4.4483 \t Acc 2.43 \t AccHead 3.18 \t AccTail 0.00\n",
      "Epoch: [144] \t Loss 4.4467 \t Acc 2.15 \t AccHead 2.82 \t AccTail 0.00\n",
      "Epoch: [145] \t Loss 4.4479 \t Acc 2.17 \t AccHead 2.85 \t AccTail 0.00\n",
      "Epoch: [146] \t Loss 4.4455 \t Acc 2.48 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [147] \t Loss 4.4467 \t Acc 2.22 \t AccHead 2.90 \t AccTail 0.00\n",
      "Epoch: [148] \t Loss 4.4475 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [149] \t Loss 4.4456 \t Acc 2.38 \t AccHead 3.12 \t AccTail 0.00\n",
      "Epoch: [150] \t Loss 4.4469 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [151] \t Loss 4.4400 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [152] \t Loss 4.4348 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [153] \t Loss 4.4355 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [154] \t Loss 4.4339 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [155] \t Loss 4.4352 \t Acc 2.55 \t AccHead 3.34 \t AccTail 0.00\n",
      "Epoch: [156] \t Loss 4.4340 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [157] \t Loss 4.4352 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [158] \t Loss 4.4333 \t Acc 2.55 \t AccHead 3.34 \t AccTail 0.00\n",
      "Epoch: [159] \t Loss 4.4350 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [160] \t Loss 4.4345 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [161] \t Loss 4.4334 \t Acc 2.55 \t AccHead 3.34 \t AccTail 0.00\n",
      "Epoch: [162] \t Loss 4.4350 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [163] \t Loss 4.4342 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [164] \t Loss 4.4339 \t Acc 2.42 \t AccHead 3.17 \t AccTail 0.00\n",
      "Epoch: [165] \t Loss 4.4347 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [166] \t Loss 4.4337 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [167] \t Loss 4.4357 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [168] \t Loss 4.4345 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [169] \t Loss 4.4340 \t Acc 2.55 \t AccHead 3.34 \t AccTail 0.00\n",
      "Epoch: [170] \t Loss 4.4340 \t Acc 2.48 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [171] \t Loss 4.4339 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [172] \t Loss 4.4347 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [173] \t Loss 4.4334 \t Acc 2.55 \t AccHead 3.34 \t AccTail 0.00\n",
      "Epoch: [174] \t Loss 4.4344 \t Acc 2.55 \t AccHead 3.34 \t AccTail 0.00\n",
      "Epoch: [175] \t Loss 4.4338 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [176] \t Loss 4.4339 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [177] \t Loss 4.4338 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [178] \t Loss 4.4347 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [179] \t Loss 4.4340 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [180] \t Loss 4.4345 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [181] \t Loss 4.4346 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [182] \t Loss 4.4337 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [183] \t Loss 4.4336 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [184] \t Loss 4.4350 \t Acc 2.42 \t AccHead 3.17 \t AccTail 0.00\n",
      "Epoch: [185] \t Loss 4.4344 \t Acc 2.48 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [186] \t Loss 4.4340 \t Acc 2.49 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [187] \t Loss 4.4348 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [188] \t Loss 4.4339 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [189] \t Loss 4.4348 \t Acc 2.43 \t AccHead 3.19 \t AccTail 0.00\n",
      "Epoch: [190] \t Loss 4.4344 \t Acc 2.48 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [191] \t Loss 4.4335 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [192] \t Loss 4.4350 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [193] \t Loss 4.4344 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [194] \t Loss 4.4341 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [195] \t Loss 4.4347 \t Acc 2.55 \t AccHead 3.34 \t AccTail 0.00\n",
      "Epoch: [196] \t Loss 4.4343 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [197] \t Loss 4.4341 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [198] \t Loss 4.4347 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [199] \t Loss 4.4340 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [200] \t Loss 4.4346 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 10:34:46,028]\u001b[0m Trial 0 finished with value: 1.033484935760498 and parameters: {'n_epoch': 200, 'weight_decay': 0.037809461247346354}. Best is trial 0 with value: 1.033484935760498.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 1.03 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [001] \t Loss 4.5252 \t Acc 8.66 \t AccHead 10.98 \t AccTail 1.21\n",
      "Epoch: [002] \t Loss 3.8960 \t Acc 13.99 \t AccHead 16.83 \t AccTail 4.83\n",
      "Epoch: [003] \t Loss 3.6699 \t Acc 15.16 \t AccHead 19.31 \t AccTail 1.76\n",
      "Epoch: [004] \t Loss 3.4873 \t Acc 18.99 \t AccHead 22.56 \t AccTail 7.48\n",
      "Epoch: [005] \t Loss 3.3559 \t Acc 22.41 \t AccHead 27.19 \t AccTail 7.02\n",
      "Epoch: [006] \t Loss 3.2266 \t Acc 23.74 \t AccHead 28.25 \t AccTail 9.21\n",
      "Epoch: [007] \t Loss 3.1152 \t Acc 25.83 \t AccHead 29.51 \t AccTail 13.96\n",
      "Epoch: [008] \t Loss 3.0290 \t Acc 28.98 \t AccHead 34.35 \t AccTail 11.69\n",
      "Epoch: [009] \t Loss 2.9343 \t Acc 28.11 \t AccHead 32.41 \t AccTail 14.29\n",
      "Epoch: [010] \t Loss 2.8684 \t Acc 26.05 \t AccHead 30.67 \t AccTail 11.16\n",
      "Epoch: [011] \t Loss 2.7854 \t Acc 33.47 \t AccHead 39.25 \t AccTail 14.86\n",
      "Epoch: [012] \t Loss 2.6962 \t Acc 32.82 \t AccHead 37.68 \t AccTail 17.15\n",
      "Epoch: [013] \t Loss 2.6257 \t Acc 33.72 \t AccHead 38.65 \t AccTail 17.81\n",
      "Epoch: [014] \t Loss 2.5832 \t Acc 35.80 \t AccHead 40.62 \t AccTail 20.29\n",
      "Epoch: [015] \t Loss 2.5273 \t Acc 37.47 \t AccHead 42.73 \t AccTail 20.54\n",
      "Epoch: [016] \t Loss 2.4673 \t Acc 37.75 \t AccHead 43.15 \t AccTail 20.39\n",
      "Epoch: [017] \t Loss 2.4094 \t Acc 39.43 \t AccHead 45.02 \t AccTail 21.44\n",
      "Epoch: [018] \t Loss 2.3786 \t Acc 41.86 \t AccHead 46.42 \t AccTail 27.18\n",
      "Epoch: [019] \t Loss 2.3313 \t Acc 42.87 \t AccHead 48.26 \t AccTail 25.55\n",
      "Epoch: [020] \t Loss 2.2859 \t Acc 38.97 \t AccHead 44.65 \t AccTail 20.70\n",
      "Epoch: [021] \t Loss 2.2534 \t Acc 39.89 \t AccHead 45.29 \t AccTail 22.50\n",
      "Epoch: [022] \t Loss 2.2265 \t Acc 39.92 \t AccHead 44.70 \t AccTail 24.53\n",
      "Epoch: [023] \t Loss 2.1897 \t Acc 44.16 \t AccHead 49.74 \t AccTail 26.21\n",
      "Epoch: [024] \t Loss 2.1438 \t Acc 44.29 \t AccHead 49.50 \t AccTail 27.53\n",
      "Epoch: [025] \t Loss 2.1160 \t Acc 47.47 \t AccHead 53.40 \t AccTail 28.39\n",
      "Epoch: [026] \t Loss 2.1016 \t Acc 46.23 \t AccHead 50.91 \t AccTail 31.19\n",
      "Epoch: [027] \t Loss 2.0523 \t Acc 45.02 \t AccHead 50.21 \t AccTail 28.30\n",
      "Epoch: [028] \t Loss 2.0483 \t Acc 45.76 \t AccHead 50.53 \t AccTail 30.38\n",
      "Epoch: [029] \t Loss 1.9799 \t Acc 42.05 \t AccHead 46.76 \t AccTail 26.90\n",
      "Epoch: [030] \t Loss 1.9599 \t Acc 46.60 \t AccHead 51.57 \t AccTail 30.58\n",
      "Epoch: [031] \t Loss 1.9456 \t Acc 48.77 \t AccHead 53.28 \t AccTail 34.26\n",
      "Epoch: [032] \t Loss 1.9359 \t Acc 46.20 \t AccHead 50.76 \t AccTail 31.53\n",
      "Epoch: [033] \t Loss 1.8916 \t Acc 47.11 \t AccHead 51.60 \t AccTail 32.66\n",
      "Epoch: [034] \t Loss 1.8966 \t Acc 52.43 \t AccHead 57.00 \t AccTail 37.70\n",
      "Epoch: [035] \t Loss 1.8312 \t Acc 49.74 \t AccHead 53.17 \t AccTail 38.73\n",
      "Epoch: [036] \t Loss 1.8093 \t Acc 52.22 \t AccHead 56.48 \t AccTail 38.51\n",
      "Epoch: [037] \t Loss 1.7791 \t Acc 51.75 \t AccHead 56.94 \t AccTail 35.05\n",
      "Epoch: [038] \t Loss 1.7774 \t Acc 51.06 \t AccHead 55.25 \t AccTail 37.59\n",
      "Epoch: [039] \t Loss 1.7522 \t Acc 50.67 \t AccHead 54.56 \t AccTail 38.13\n",
      "Epoch: [040] \t Loss 1.7473 \t Acc 50.80 \t AccHead 56.13 \t AccTail 33.64\n",
      "Epoch: [041] \t Loss 1.7215 \t Acc 53.59 \t AccHead 58.47 \t AccTail 37.89\n",
      "Epoch: [042] \t Loss 1.7049 \t Acc 53.87 \t AccHead 58.58 \t AccTail 38.72\n",
      "Epoch: [043] \t Loss 1.6628 \t Acc 53.96 \t AccHead 58.18 \t AccTail 40.39\n",
      "Epoch: [044] \t Loss 1.6558 \t Acc 54.00 \t AccHead 57.77 \t AccTail 41.88\n",
      "Epoch: [045] \t Loss 1.6330 \t Acc 56.96 \t AccHead 61.45 \t AccTail 42.52\n",
      "Epoch: [046] \t Loss 1.6294 \t Acc 53.28 \t AccHead 56.56 \t AccTail 42.72\n",
      "Epoch: [047] \t Loss 1.6007 \t Acc 55.34 \t AccHead 59.11 \t AccTail 43.22\n",
      "Epoch: [048] \t Loss 1.5810 \t Acc 57.84 \t AccHead 62.06 \t AccTail 44.24\n",
      "Epoch: [049] \t Loss 1.5558 \t Acc 55.00 \t AccHead 58.61 \t AccTail 43.40\n",
      "Epoch: [050] \t Loss 1.5375 \t Acc 59.07 \t AccHead 62.91 \t AccTail 46.73\n",
      "Epoch: [051] \t Loss 1.5414 \t Acc 60.82 \t AccHead 64.60 \t AccTail 48.64\n",
      "Epoch: [052] \t Loss 1.5059 \t Acc 57.73 \t AccHead 61.37 \t AccTail 46.00\n",
      "Epoch: [053] \t Loss 1.4835 \t Acc 58.53 \t AccHead 60.99 \t AccTail 50.60\n",
      "Epoch: [054] \t Loss 1.4697 \t Acc 62.28 \t AccHead 66.60 \t AccTail 48.34\n",
      "Epoch: [055] \t Loss 1.4454 \t Acc 55.44 \t AccHead 58.52 \t AccTail 45.53\n",
      "Epoch: [056] \t Loss 1.4368 \t Acc 61.84 \t AccHead 65.18 \t AccTail 51.09\n",
      "Epoch: [057] \t Loss 1.4402 \t Acc 62.39 \t AccHead 66.08 \t AccTail 50.53\n",
      "Epoch: [058] \t Loss 1.3961 \t Acc 59.64 \t AccHead 63.28 \t AccTail 47.92\n",
      "Epoch: [059] \t Loss 1.4072 \t Acc 63.48 \t AccHead 66.52 \t AccTail 53.70\n",
      "Epoch: [060] \t Loss 1.3471 \t Acc 60.23 \t AccHead 64.12 \t AccTail 47.70\n",
      "Epoch: [061] \t Loss 1.3915 \t Acc 57.79 \t AccHead 60.86 \t AccTail 47.92\n",
      "Epoch: [062] \t Loss 1.3344 \t Acc 58.06 \t AccHead 61.37 \t AccTail 47.41\n",
      "Epoch: [063] \t Loss 1.3558 \t Acc 61.81 \t AccHead 64.97 \t AccTail 51.62\n",
      "Epoch: [064] \t Loss 1.3229 \t Acc 63.10 \t AccHead 67.43 \t AccTail 49.12\n",
      "Epoch: [065] \t Loss 1.3140 \t Acc 60.90 \t AccHead 63.42 \t AccTail 52.78\n",
      "Epoch: [066] \t Loss 1.3022 \t Acc 64.09 \t AccHead 68.05 \t AccTail 51.34\n",
      "Epoch: [067] \t Loss 1.2780 \t Acc 63.20 \t AccHead 65.73 \t AccTail 55.08\n",
      "Epoch: [068] \t Loss 1.2827 \t Acc 63.01 \t AccHead 65.29 \t AccTail 55.69\n",
      "Epoch: [069] \t Loss 1.2562 \t Acc 59.87 \t AccHead 62.71 \t AccTail 50.72\n",
      "Epoch: [070] \t Loss 1.2620 \t Acc 65.77 \t AccHead 68.30 \t AccTail 57.59\n",
      "Epoch: [071] \t Loss 1.2416 \t Acc 64.66 \t AccHead 67.72 \t AccTail 54.78\n",
      "Epoch: [072] \t Loss 1.2337 \t Acc 63.34 \t AccHead 65.39 \t AccTail 56.74\n",
      "Epoch: [073] \t Loss 1.2259 \t Acc 60.98 \t AccHead 63.88 \t AccTail 51.65\n",
      "Epoch: [074] \t Loss 1.2136 \t Acc 61.76 \t AccHead 64.92 \t AccTail 51.57\n",
      "Epoch: [075] \t Loss 1.1957 \t Acc 65.95 \t AccHead 68.20 \t AccTail 58.71\n",
      "Epoch: [076] \t Loss 1.1888 \t Acc 62.17 \t AccHead 65.07 \t AccTail 52.82\n",
      "Epoch: [077] \t Loss 1.1986 \t Acc 64.37 \t AccHead 66.93 \t AccTail 56.13\n",
      "Epoch: [078] \t Loss 1.1875 \t Acc 67.04 \t AccHead 69.82 \t AccTail 58.07\n",
      "Epoch: [079] \t Loss 1.1590 \t Acc 64.81 \t AccHead 68.26 \t AccTail 53.72\n",
      "Epoch: [080] \t Loss 1.1723 \t Acc 61.91 \t AccHead 64.32 \t AccTail 54.16\n",
      "Epoch: [081] \t Loss 1.1496 \t Acc 66.23 \t AccHead 67.84 \t AccTail 61.05\n",
      "Epoch: [082] \t Loss 1.1343 \t Acc 63.90 \t AccHead 67.17 \t AccTail 53.37\n",
      "Epoch: [083] \t Loss 1.1071 \t Acc 66.45 \t AccHead 69.63 \t AccTail 56.22\n",
      "Epoch: [084] \t Loss 1.1305 \t Acc 65.00 \t AccHead 67.49 \t AccTail 56.98\n",
      "Epoch: [085] \t Loss 1.1400 \t Acc 66.60 \t AccHead 68.89 \t AccTail 59.22\n",
      "Epoch: [086] \t Loss 1.1108 \t Acc 70.81 \t AccHead 72.78 \t AccTail 64.46\n",
      "Epoch: [087] \t Loss 1.1258 \t Acc 67.00 \t AccHead 69.36 \t AccTail 59.37\n",
      "Epoch: [088] \t Loss 1.1092 \t Acc 70.70 \t AccHead 72.21 \t AccTail 65.82\n",
      "Epoch: [089] \t Loss 1.1005 \t Acc 69.36 \t AccHead 71.45 \t AccTail 62.65\n",
      "Epoch: [090] \t Loss 1.0821 \t Acc 61.85 \t AccHead 65.42 \t AccTail 50.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 10:48:41,584]\u001b[0m Trial 1 finished with value: 8.34022331237793 and parameters: {'n_epoch': 90, 'weight_decay': 0.0006824735356722844}. Best is trial 1 with value: 8.34022331237793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 8.34 \t AccHead 16.50 \t AccTail 0.31\n",
      "Epoch: [001] \t Loss 4.4650 \t Acc 9.89 \t AccHead 11.72 \t AccTail 4.03\n",
      "Epoch: [002] \t Loss 3.8940 \t Acc 13.37 \t AccHead 16.75 \t AccTail 2.51\n",
      "Epoch: [003] \t Loss 3.6723 \t Acc 17.29 \t AccHead 21.00 \t AccTail 5.35\n",
      "Epoch: [004] \t Loss 3.4842 \t Acc 19.97 \t AccHead 24.16 \t AccTail 6.44\n",
      "Epoch: [005] \t Loss 3.3438 \t Acc 22.27 \t AccHead 26.80 \t AccTail 7.69\n",
      "Epoch: [006] \t Loss 3.2264 \t Acc 24.44 \t AccHead 28.63 \t AccTail 10.95\n",
      "Epoch: [007] \t Loss 3.1056 \t Acc 26.80 \t AccHead 30.94 \t AccTail 13.48\n",
      "Epoch: [008] \t Loss 3.0143 \t Acc 28.48 \t AccHead 32.72 \t AccTail 14.83\n",
      "Epoch: [009] \t Loss 2.9281 \t Acc 25.33 \t AccHead 29.54 \t AccTail 11.76\n",
      "Epoch: [010] \t Loss 2.8407 \t Acc 32.40 \t AccHead 37.61 \t AccTail 15.64\n",
      "Epoch: [011] \t Loss 2.7371 \t Acc 33.64 \t AccHead 38.24 \t AccTail 18.84\n",
      "Epoch: [012] \t Loss 2.6550 \t Acc 35.64 \t AccHead 40.42 \t AccTail 20.26\n",
      "Epoch: [013] \t Loss 2.5771 \t Acc 25.22 \t AccHead 28.05 \t AccTail 16.13\n",
      "Epoch: [014] \t Loss 2.5716 \t Acc 39.02 \t AccHead 43.36 \t AccTail 25.05\n",
      "Epoch: [015] \t Loss 2.4552 \t Acc 40.91 \t AccHead 46.06 \t AccTail 24.37\n",
      "Epoch: [016] \t Loss 2.3603 \t Acc 41.31 \t AccHead 46.09 \t AccTail 25.92\n",
      "Epoch: [017] \t Loss 2.2659 \t Acc 44.39 \t AccHead 48.80 \t AccTail 30.17\n",
      "Epoch: [018] \t Loss 2.2003 \t Acc 47.62 \t AccHead 52.69 \t AccTail 31.30\n",
      "Epoch: [019] \t Loss 2.1433 \t Acc 47.36 \t AccHead 52.55 \t AccTail 30.62\n",
      "Epoch: [020] \t Loss 2.1005 \t Acc 37.93 \t AccHead 42.46 \t AccTail 23.35\n",
      "Epoch: [021] \t Loss 2.0932 \t Acc 50.10 \t AccHead 54.74 \t AccTail 35.16\n",
      "Epoch: [022] \t Loss 1.9475 \t Acc 53.00 \t AccHead 56.53 \t AccTail 41.63\n",
      "Epoch: [023] \t Loss 1.8595 \t Acc 53.87 \t AccHead 58.67 \t AccTail 38.37\n",
      "Epoch: [024] \t Loss 1.7757 \t Acc 57.10 \t AccHead 61.39 \t AccTail 43.26\n",
      "Epoch: [025] \t Loss 1.7240 \t Acc 59.39 \t AccHead 63.51 \t AccTail 46.13\n",
      "Epoch: [026] \t Loss 1.6136 \t Acc 58.89 \t AccHead 63.23 \t AccTail 44.91\n",
      "Epoch: [027] \t Loss 1.5461 \t Acc 61.04 \t AccHead 64.66 \t AccTail 49.39\n",
      "Epoch: [028] \t Loss 1.4834 \t Acc 63.93 \t AccHead 66.95 \t AccTail 54.21\n",
      "Epoch: [029] \t Loss 1.3991 \t Acc 67.28 \t AccHead 69.85 \t AccTail 58.99\n",
      "Epoch: [030] \t Loss 1.3198 \t Acc 67.80 \t AccHead 71.02 \t AccTail 57.44\n",
      "Epoch: [031] \t Loss 1.2534 \t Acc 71.32 \t AccHead 74.34 \t AccTail 61.59\n",
      "Epoch: [032] \t Loss 1.1770 \t Acc 68.81 \t AccHead 71.83 \t AccTail 59.08\n",
      "Epoch: [033] \t Loss 1.1202 \t Acc 69.87 \t AccHead 72.80 \t AccTail 60.42\n",
      "Epoch: [034] \t Loss 1.0559 \t Acc 74.61 \t AccHead 76.94 \t AccTail 67.09\n",
      "Epoch: [035] \t Loss 0.9817 \t Acc 76.56 \t AccHead 78.94 \t AccTail 68.89\n",
      "Epoch: [036] \t Loss 0.8962 \t Acc 77.27 \t AccHead 78.16 \t AccTail 74.41\n",
      "Epoch: [037] \t Loss 0.8455 \t Acc 77.09 \t AccHead 78.16 \t AccTail 73.65\n",
      "Epoch: [038] \t Loss 0.8246 \t Acc 80.05 \t AccHead 80.93 \t AccTail 77.20\n",
      "Epoch: [039] \t Loss 0.7706 \t Acc 81.93 \t AccHead 82.89 \t AccTail 78.82\n",
      "Epoch: [040] \t Loss 0.6709 \t Acc 83.02 \t AccHead 84.28 \t AccTail 78.98\n",
      "Epoch: [041] \t Loss 0.6172 \t Acc 83.63 \t AccHead 84.16 \t AccTail 81.92\n",
      "Epoch: [042] \t Loss 0.6064 \t Acc 84.05 \t AccHead 84.83 \t AccTail 81.57\n",
      "Epoch: [043] \t Loss 0.5814 \t Acc 86.90 \t AccHead 87.47 \t AccTail 85.05\n",
      "Epoch: [044] \t Loss 0.5246 \t Acc 89.44 \t AccHead 89.88 \t AccTail 88.03\n",
      "Epoch: [045] \t Loss 0.4574 \t Acc 89.61 \t AccHead 90.62 \t AccTail 86.37\n",
      "Epoch: [046] \t Loss 0.4724 \t Acc 91.09 \t AccHead 91.29 \t AccTail 90.46\n",
      "Epoch: [047] \t Loss 0.4296 \t Acc 90.06 \t AccHead 90.20 \t AccTail 89.60\n",
      "Epoch: [048] \t Loss 0.3755 \t Acc 90.50 \t AccHead 90.66 \t AccTail 90.00\n",
      "Epoch: [049] \t Loss 0.3617 \t Acc 91.68 \t AccHead 92.02 \t AccTail 90.60\n",
      "Epoch: [050] \t Loss 0.3445 \t Acc 92.73 \t AccHead 92.96 \t AccTail 91.99\n",
      "Epoch: [051] \t Loss 0.3262 \t Acc 92.35 \t AccHead 92.61 \t AccTail 91.52\n",
      "Epoch: [052] \t Loss 0.3104 \t Acc 93.84 \t AccHead 94.07 \t AccTail 93.11\n",
      "Epoch: [053] \t Loss 0.2654 \t Acc 93.53 \t AccHead 93.80 \t AccTail 92.65\n",
      "Epoch: [054] \t Loss 0.2914 \t Acc 93.64 \t AccHead 93.71 \t AccTail 93.41\n",
      "Epoch: [055] \t Loss 0.2654 \t Acc 94.28 \t AccHead 94.44 \t AccTail 93.76\n",
      "Epoch: [056] \t Loss 0.2432 \t Acc 94.67 \t AccHead 95.18 \t AccTail 93.03\n",
      "Epoch: [057] \t Loss 0.2214 \t Acc 94.70 \t AccHead 94.77 \t AccTail 94.46\n",
      "Epoch: [058] \t Loss 0.2202 \t Acc 95.71 \t AccHead 95.75 \t AccTail 95.59\n",
      "Epoch: [059] \t Loss 0.1924 \t Acc 95.45 \t AccHead 95.51 \t AccTail 95.25\n",
      "Epoch: [060] \t Loss 0.2113 \t Acc 95.11 \t AccHead 94.83 \t AccTail 96.03\n",
      "Epoch: [061] \t Loss 0.1981 \t Acc 95.99 \t AccHead 96.02 \t AccTail 95.89\n",
      "Epoch: [062] \t Loss 0.1804 \t Acc 96.83 \t AccHead 96.78 \t AccTail 97.00\n",
      "Epoch: [063] \t Loss 0.1735 \t Acc 96.31 \t AccHead 96.54 \t AccTail 95.54\n",
      "Epoch: [064] \t Loss 0.1793 \t Acc 96.14 \t AccHead 96.31 \t AccTail 95.60\n",
      "Epoch: [065] \t Loss 0.1606 \t Acc 96.77 \t AccHead 96.75 \t AccTail 96.81\n",
      "Epoch: [066] \t Loss 0.1589 \t Acc 97.17 \t AccHead 97.26 \t AccTail 96.89\n",
      "Epoch: [067] \t Loss 0.1480 \t Acc 96.97 \t AccHead 97.23 \t AccTail 96.13\n",
      "Epoch: [068] \t Loss 0.1454 \t Acc 97.17 \t AccHead 97.35 \t AccTail 96.60\n",
      "Epoch: [069] \t Loss 0.1434 \t Acc 96.57 \t AccHead 96.83 \t AccTail 95.75\n",
      "Epoch: [070] \t Loss 0.1447 \t Acc 97.25 \t AccHead 97.35 \t AccTail 96.94\n",
      "Epoch: [071] \t Loss 0.1257 \t Acc 97.81 \t AccHead 97.79 \t AccTail 97.86\n",
      "Epoch: [072] \t Loss 0.1192 \t Acc 97.54 \t AccHead 97.52 \t AccTail 97.59\n",
      "Epoch: [073] \t Loss 0.1193 \t Acc 98.06 \t AccHead 98.10 \t AccTail 97.92\n",
      "Epoch: [074] \t Loss 0.1107 \t Acc 97.86 \t AccHead 97.77 \t AccTail 98.14\n",
      "Epoch: [075] \t Loss 0.1105 \t Acc 98.29 \t AccHead 98.37 \t AccTail 98.03\n",
      "Epoch: [076] \t Loss 0.0973 \t Acc 97.73 \t AccHead 97.73 \t AccTail 97.76\n",
      "Epoch: [077] \t Loss 0.1109 \t Acc 97.91 \t AccHead 97.72 \t AccTail 98.52\n",
      "Epoch: [078] \t Loss 0.1161 \t Acc 97.80 \t AccHead 97.78 \t AccTail 97.86\n",
      "Epoch: [079] \t Loss 0.1091 \t Acc 97.85 \t AccHead 97.86 \t AccTail 97.81\n",
      "Epoch: [080] \t Loss 0.1009 \t Acc 97.62 \t AccHead 97.54 \t AccTail 97.87\n",
      "Epoch: [081] \t Loss 0.1041 \t Acc 97.99 \t AccHead 97.93 \t AccTail 98.19\n",
      "Epoch: [082] \t Loss 0.0968 \t Acc 98.09 \t AccHead 98.31 \t AccTail 97.38\n",
      "Epoch: [083] \t Loss 0.0929 \t Acc 98.60 \t AccHead 98.71 \t AccTail 98.27\n",
      "Epoch: [084] \t Loss 0.0974 \t Acc 98.32 \t AccHead 98.25 \t AccTail 98.57\n",
      "Epoch: [085] \t Loss 0.1026 \t Acc 98.05 \t AccHead 98.01 \t AccTail 98.19\n",
      "Epoch: [086] \t Loss 0.0988 \t Acc 98.40 \t AccHead 98.34 \t AccTail 98.60\n",
      "Epoch: [087] \t Loss 0.0852 \t Acc 98.41 \t AccHead 98.50 \t AccTail 98.14\n",
      "Epoch: [088] \t Loss 0.0838 \t Acc 98.78 \t AccHead 98.82 \t AccTail 98.65\n",
      "Epoch: [089] \t Loss 0.0782 \t Acc 98.74 \t AccHead 98.79 \t AccTail 98.59\n",
      "Epoch: [090] \t Loss 0.0808 \t Acc 98.87 \t AccHead 98.93 \t AccTail 98.65\n",
      "Epoch: [091] \t Loss 0.0779 \t Acc 98.74 \t AccHead 98.75 \t AccTail 98.73\n",
      "Epoch: [092] \t Loss 0.0713 \t Acc 98.34 \t AccHead 98.37 \t AccTail 98.22\n",
      "Epoch: [093] \t Loss 0.0669 \t Acc 98.94 \t AccHead 99.01 \t AccTail 98.73\n",
      "Epoch: [094] \t Loss 0.0586 \t Acc 98.98 \t AccHead 99.02 \t AccTail 98.86\n",
      "Epoch: [095] \t Loss 0.0549 \t Acc 98.80 \t AccHead 98.87 \t AccTail 98.59\n",
      "Epoch: [096] \t Loss 0.0600 \t Acc 98.83 \t AccHead 98.89 \t AccTail 98.65\n",
      "Epoch: [097] \t Loss 0.0656 \t Acc 98.98 \t AccHead 98.98 \t AccTail 98.97\n",
      "Epoch: [098] \t Loss 0.0628 \t Acc 98.76 \t AccHead 98.76 \t AccTail 98.76\n",
      "Epoch: [099] \t Loss 0.0729 \t Acc 98.85 \t AccHead 98.85 \t AccTail 98.84\n",
      "Epoch: [100] \t Loss 0.0635 \t Acc 98.89 \t AccHead 99.03 \t AccTail 98.43\n",
      "Epoch: [101] \t Loss 0.0550 \t Acc 98.94 \t AccHead 98.88 \t AccTail 99.11\n",
      "Epoch: [102] \t Loss 0.0522 \t Acc 99.42 \t AccHead 99.43 \t AccTail 99.41\n",
      "Epoch: [103] \t Loss 0.0654 \t Acc 98.98 \t AccHead 98.94 \t AccTail 99.11\n",
      "Epoch: [104] \t Loss 0.0651 \t Acc 99.05 \t AccHead 99.06 \t AccTail 99.03\n",
      "Epoch: [105] \t Loss 0.0578 \t Acc 98.96 \t AccHead 98.99 \t AccTail 98.84\n",
      "Epoch: [106] \t Loss 0.0531 \t Acc 99.15 \t AccHead 99.22 \t AccTail 98.92\n",
      "Epoch: [107] \t Loss 0.0561 \t Acc 98.89 \t AccHead 98.78 \t AccTail 99.24\n",
      "Epoch: [108] \t Loss 0.0489 \t Acc 99.37 \t AccHead 99.40 \t AccTail 99.27\n",
      "Epoch: [109] \t Loss 0.0494 \t Acc 99.12 \t AccHead 99.14 \t AccTail 99.05\n",
      "Epoch: [110] \t Loss 0.0441 \t Acc 99.17 \t AccHead 99.10 \t AccTail 99.38\n",
      "Epoch: [111] \t Loss 0.0511 \t Acc 99.08 \t AccHead 99.06 \t AccTail 99.16\n",
      "Epoch: [112] \t Loss 0.0476 \t Acc 99.44 \t AccHead 99.50 \t AccTail 99.24\n",
      "Epoch: [113] \t Loss 0.0501 \t Acc 99.27 \t AccHead 99.19 \t AccTail 99.51\n",
      "Epoch: [114] \t Loss 0.0548 \t Acc 99.15 \t AccHead 99.04 \t AccTail 99.51\n",
      "Epoch: [115] \t Loss 0.0442 \t Acc 99.38 \t AccHead 99.40 \t AccTail 99.32\n",
      "Epoch: [116] \t Loss 0.0406 \t Acc 99.39 \t AccHead 99.45 \t AccTail 99.19\n",
      "Epoch: [117] \t Loss 0.0414 \t Acc 99.46 \t AccHead 99.49 \t AccTail 99.38\n",
      "Epoch: [118] \t Loss 0.0411 \t Acc 99.44 \t AccHead 99.40 \t AccTail 99.57\n",
      "Epoch: [119] \t Loss 0.0354 \t Acc 99.47 \t AccHead 99.49 \t AccTail 99.43\n",
      "Epoch: [120] \t Loss 0.0387 \t Acc 99.44 \t AccHead 99.42 \t AccTail 99.51\n",
      "Epoch: [121] \t Loss 0.0353 \t Acc 99.46 \t AccHead 99.49 \t AccTail 99.38\n",
      "Epoch: [122] \t Loss 0.0295 \t Acc 99.51 \t AccHead 99.50 \t AccTail 99.51\n",
      "Epoch: [123] \t Loss 0.0396 \t Acc 99.33 \t AccHead 99.30 \t AccTail 99.41\n",
      "Epoch: [124] \t Loss 0.0435 \t Acc 99.31 \t AccHead 99.33 \t AccTail 99.27\n",
      "Epoch: [125] \t Loss 0.0440 \t Acc 99.31 \t AccHead 99.29 \t AccTail 99.38\n",
      "Epoch: [126] \t Loss 0.0463 \t Acc 99.19 \t AccHead 99.26 \t AccTail 98.95\n",
      "Epoch: [127] \t Loss 0.0461 \t Acc 99.30 \t AccHead 99.35 \t AccTail 99.16\n",
      "Epoch: [128] \t Loss 0.0462 \t Acc 99.06 \t AccHead 99.03 \t AccTail 99.16\n",
      "Epoch: [129] \t Loss 0.0420 \t Acc 99.56 \t AccHead 99.53 \t AccTail 99.65\n",
      "Epoch: [130] \t Loss 0.0387 \t Acc 99.31 \t AccHead 99.24 \t AccTail 99.54\n",
      "Epoch: [131] \t Loss 0.0383 \t Acc 99.52 \t AccHead 99.56 \t AccTail 99.40\n",
      "Epoch: [132] \t Loss 0.0368 \t Acc 99.46 \t AccHead 99.41 \t AccTail 99.59\n",
      "Epoch: [133] \t Loss 0.0363 \t Acc 99.17 \t AccHead 99.15 \t AccTail 99.24\n",
      "Epoch: [134] \t Loss 0.0374 \t Acc 99.29 \t AccHead 99.23 \t AccTail 99.49\n",
      "Epoch: [135] \t Loss 0.0403 \t Acc 99.15 \t AccHead 99.14 \t AccTail 99.16\n",
      "Epoch: [136] \t Loss 0.0375 \t Acc 99.46 \t AccHead 99.47 \t AccTail 99.43\n",
      "Epoch: [137] \t Loss 0.0315 \t Acc 99.42 \t AccHead 99.46 \t AccTail 99.30\n",
      "Epoch: [138] \t Loss 0.0415 \t Acc 99.53 \t AccHead 99.50 \t AccTail 99.62\n",
      "Epoch: [139] \t Loss 0.0335 \t Acc 99.54 \t AccHead 99.62 \t AccTail 99.27\n",
      "Epoch: [140] \t Loss 0.0406 \t Acc 99.24 \t AccHead 99.27 \t AccTail 99.14\n",
      "Epoch: [141] \t Loss 0.0450 \t Acc 99.50 \t AccHead 99.55 \t AccTail 99.35\n",
      "Epoch: [142] \t Loss 0.0394 \t Acc 99.51 \t AccHead 99.56 \t AccTail 99.35\n",
      "Epoch: [143] \t Loss 0.0386 \t Acc 99.49 \t AccHead 99.50 \t AccTail 99.43\n",
      "Epoch: [144] \t Loss 0.0392 \t Acc 99.35 \t AccHead 99.35 \t AccTail 99.35\n",
      "Epoch: [145] \t Loss 0.0350 \t Acc 99.54 \t AccHead 99.56 \t AccTail 99.49\n",
      "Epoch: [146] \t Loss 0.0368 \t Acc 99.38 \t AccHead 99.33 \t AccTail 99.54\n",
      "Epoch: [147] \t Loss 0.0404 \t Acc 99.42 \t AccHead 99.40 \t AccTail 99.49\n",
      "Epoch: [148] \t Loss 0.0357 \t Acc 99.47 \t AccHead 99.49 \t AccTail 99.41\n",
      "Epoch: [149] \t Loss 0.0356 \t Acc 99.57 \t AccHead 99.59 \t AccTail 99.51\n",
      "Epoch: [150] \t Loss 0.0307 \t Acc 99.54 \t AccHead 99.55 \t AccTail 99.51\n",
      "Epoch: [151] \t Loss 0.0238 \t Acc 99.82 \t AccHead 99.82 \t AccTail 99.81\n",
      "Epoch: [152] \t Loss 0.0145 \t Acc 99.88 \t AccHead 99.87 \t AccTail 99.95\n",
      "Epoch: [153] \t Loss 0.0108 \t Acc 99.88 \t AccHead 99.87 \t AccTail 99.92\n",
      "Epoch: [154] \t Loss 0.0108 \t Acc 99.90 \t AccHead 99.89 \t AccTail 99.95\n",
      "Epoch: [155] \t Loss 0.0092 \t Acc 99.96 \t AccHead 99.95 \t AccTail 99.97\n",
      "Epoch: [156] \t Loss 0.0083 \t Acc 99.92 \t AccHead 99.92 \t AccTail 99.92\n",
      "Epoch: [157] \t Loss 0.0090 \t Acc 99.89 \t AccHead 99.88 \t AccTail 99.92\n",
      "Epoch: [158] \t Loss 0.0070 \t Acc 99.93 \t AccHead 99.93 \t AccTail 99.92\n",
      "Epoch: [159] \t Loss 0.0076 \t Acc 99.92 \t AccHead 99.91 \t AccTail 99.95\n",
      "Epoch: [160] \t Loss 0.0070 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [161] \t Loss 0.0062 \t Acc 99.96 \t AccHead 99.97 \t AccTail 99.92\n",
      "Epoch: [162] \t Loss 0.0069 \t Acc 99.91 \t AccHead 99.90 \t AccTail 99.95\n",
      "Epoch: [163] \t Loss 0.0057 \t Acc 99.96 \t AccHead 99.96 \t AccTail 99.97\n",
      "Epoch: [164] \t Loss 0.0054 \t Acc 99.96 \t AccHead 99.94 \t AccTail 100.00\n",
      "Epoch: [165] \t Loss 0.0057 \t Acc 99.95 \t AccHead 99.94 \t AccTail 99.97\n",
      "Epoch: [166] \t Loss 0.0055 \t Acc 99.97 \t AccHead 99.97 \t AccTail 99.97\n",
      "Epoch: [167] \t Loss 0.0058 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [168] \t Loss 0.0046 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [169] \t Loss 0.0046 \t Acc 99.95 \t AccHead 99.94 \t AccTail 99.97\n",
      "Epoch: [170] \t Loss 0.0047 \t Acc 99.96 \t AccHead 99.95 \t AccTail 99.97\n",
      "Epoch: [171] \t Loss 0.0047 \t Acc 99.96 \t AccHead 99.95 \t AccTail 99.97\n",
      "Epoch: [172] \t Loss 0.0039 \t Acc 99.97 \t AccHead 99.97 \t AccTail 99.97\n",
      "Epoch: [173] \t Loss 0.0045 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [174] \t Loss 0.0047 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [175] \t Loss 0.0039 \t Acc 99.96 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [176] \t Loss 0.0042 \t Acc 99.96 \t AccHead 99.95 \t AccTail 99.97\n",
      "Epoch: [177] \t Loss 0.0037 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [178] \t Loss 0.0034 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [179] \t Loss 0.0036 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [180] \t Loss 0.0039 \t Acc 99.97 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [181] \t Loss 0.0036 \t Acc 99.93 \t AccHead 99.92 \t AccTail 99.97\n",
      "Epoch: [182] \t Loss 0.0037 \t Acc 99.97 \t AccHead 99.97 \t AccTail 99.97\n",
      "Epoch: [183] \t Loss 0.0032 \t Acc 99.99 \t AccHead 99.99 \t AccTail 99.97\n",
      "Epoch: [184] \t Loss 0.0039 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [185] \t Loss 0.0034 \t Acc 99.96 \t AccHead 99.95 \t AccTail 99.97\n",
      "Epoch: [186] \t Loss 0.0029 \t Acc 99.96 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [187] \t Loss 0.0041 \t Acc 99.96 \t AccHead 99.97 \t AccTail 99.95\n",
      "Epoch: [188] \t Loss 0.0039 \t Acc 99.95 \t AccHead 99.95 \t AccTail 99.95\n",
      "Epoch: [189] \t Loss 0.0031 \t Acc 99.97 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [190] \t Loss 0.0029 \t Acc 99.95 \t AccHead 99.94 \t AccTail 99.97\n",
      "Epoch: [191] \t Loss 0.0032 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [192] \t Loss 0.0032 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [193] \t Loss 0.0034 \t Acc 99.96 \t AccHead 99.96 \t AccTail 99.97\n",
      "Epoch: [194] \t Loss 0.0031 \t Acc 99.97 \t AccHead 99.97 \t AccTail 99.97\n",
      "Epoch: [195] \t Loss 0.0034 \t Acc 99.96 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [196] \t Loss 0.0032 \t Acc 99.99 \t AccHead 99.98 \t AccTail 100.00\n",
      "Epoch: [197] \t Loss 0.0031 \t Acc 99.95 \t AccHead 99.94 \t AccTail 99.97\n",
      "Epoch: [198] \t Loss 0.0029 \t Acc 99.97 \t AccHead 99.97 \t AccTail 99.97\n",
      "Epoch: [199] \t Loss 0.0028 \t Acc 99.96 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [200] \t Loss 0.0031 \t Acc 99.96 \t AccHead 99.94 \t AccTail 100.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 11:19:34,723]\u001b[0m Trial 2 finished with value: 9.270359992980957 and parameters: {'n_epoch': 200, 'weight_decay': 1.3107781275726209e-05}. Best is trial 2 with value: 9.270359992980957.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 9.27 \t AccHead 18.35 \t AccTail 0.33\n",
      "Epoch: [001] \t Loss 4.4504 \t Acc 8.02 \t AccHead 9.39 \t AccTail 3.62\n",
      "Epoch: [002] \t Loss 3.9131 \t Acc 13.96 \t AccHead 17.58 \t AccTail 2.30\n",
      "Epoch: [003] \t Loss 3.6903 \t Acc 16.39 \t AccHead 20.30 \t AccTail 3.81\n",
      "Epoch: [004] \t Loss 3.5495 \t Acc 18.57 \t AccHead 22.31 \t AccTail 6.56\n",
      "Epoch: [005] \t Loss 3.3922 \t Acc 22.11 \t AccHead 26.56 \t AccTail 7.78\n",
      "Epoch: [006] \t Loss 3.2652 \t Acc 25.59 \t AccHead 30.28 \t AccTail 10.49\n",
      "Epoch: [007] \t Loss 3.1356 \t Acc 26.10 \t AccHead 31.36 \t AccTail 9.13\n",
      "Epoch: [008] \t Loss 3.0344 \t Acc 28.73 \t AccHead 33.45 \t AccTail 13.50\n",
      "Epoch: [009] \t Loss 2.9499 \t Acc 27.64 \t AccHead 31.96 \t AccTail 13.75\n",
      "Epoch: [010] \t Loss 2.8555 \t Acc 31.42 \t AccHead 36.23 \t AccTail 15.93\n",
      "Epoch: [011] \t Loss 2.7585 \t Acc 34.42 \t AccHead 39.58 \t AccTail 17.80\n",
      "Epoch: [012] \t Loss 2.6640 \t Acc 34.23 \t AccHead 39.19 \t AccTail 18.28\n",
      "Epoch: [013] \t Loss 2.5882 \t Acc 37.01 \t AccHead 42.14 \t AccTail 20.51\n",
      "Epoch: [014] \t Loss 2.5252 \t Acc 38.43 \t AccHead 43.68 \t AccTail 21.50\n",
      "Epoch: [015] \t Loss 2.4531 \t Acc 38.68 \t AccHead 43.85 \t AccTail 22.02\n",
      "Epoch: [016] \t Loss 2.3711 \t Acc 41.73 \t AccHead 46.66 \t AccTail 25.81\n",
      "Epoch: [017] \t Loss 2.2766 \t Acc 43.97 \t AccHead 48.66 \t AccTail 28.90\n",
      "Epoch: [018] \t Loss 2.2119 \t Acc 46.00 \t AccHead 51.55 \t AccTail 28.11\n",
      "Epoch: [019] \t Loss 2.1487 \t Acc 47.33 \t AccHead 52.25 \t AccTail 31.51\n",
      "Epoch: [020] \t Loss 2.0699 \t Acc 48.32 \t AccHead 52.60 \t AccTail 34.54\n",
      "Epoch: [021] \t Loss 2.0006 \t Acc 45.93 \t AccHead 49.53 \t AccTail 34.31\n",
      "Epoch: [022] \t Loss 1.9407 \t Acc 52.77 \t AccHead 57.74 \t AccTail 36.75\n",
      "Epoch: [023] \t Loss 1.8543 \t Acc 52.65 \t AccHead 56.05 \t AccTail 41.71\n",
      "Epoch: [024] \t Loss 1.7747 \t Acc 55.05 \t AccHead 59.42 \t AccTail 40.96\n",
      "Epoch: [025] \t Loss 1.7334 \t Acc 57.61 \t AccHead 61.74 \t AccTail 44.34\n",
      "Epoch: [026] \t Loss 1.6420 \t Acc 58.13 \t AccHead 62.12 \t AccTail 45.26\n",
      "Epoch: [027] \t Loss 1.5731 \t Acc 62.91 \t AccHead 66.05 \t AccTail 52.81\n",
      "Epoch: [028] \t Loss 1.4994 \t Acc 64.16 \t AccHead 68.22 \t AccTail 51.09\n",
      "Epoch: [029] \t Loss 1.4007 \t Acc 65.15 \t AccHead 68.34 \t AccTail 54.90\n",
      "Epoch: [030] \t Loss 1.3523 \t Acc 67.09 \t AccHead 69.99 \t AccTail 57.73\n",
      "Epoch: [031] \t Loss 1.2856 \t Acc 68.34 \t AccHead 71.12 \t AccTail 59.37\n",
      "Epoch: [032] \t Loss 1.2147 \t Acc 68.31 \t AccHead 71.24 \t AccTail 58.90\n",
      "Epoch: [033] \t Loss 1.1605 \t Acc 71.27 \t AccHead 74.35 \t AccTail 61.36\n",
      "Epoch: [034] \t Loss 1.0908 \t Acc 73.53 \t AccHead 75.09 \t AccTail 68.53\n",
      "Epoch: [035] \t Loss 1.0218 \t Acc 74.85 \t AccHead 76.20 \t AccTail 70.48\n",
      "Epoch: [036] \t Loss 0.9931 \t Acc 77.86 \t AccHead 78.50 \t AccTail 75.82\n",
      "Epoch: [037] \t Loss 0.8873 \t Acc 76.99 \t AccHead 79.76 \t AccTail 68.09\n",
      "Epoch: [038] \t Loss 0.8265 \t Acc 80.42 \t AccHead 82.21 \t AccTail 74.63\n",
      "Epoch: [039] \t Loss 0.7888 \t Acc 80.71 \t AccHead 82.16 \t AccTail 76.05\n",
      "Epoch: [040] \t Loss 0.7506 \t Acc 81.29 \t AccHead 83.06 \t AccTail 75.59\n",
      "Epoch: [041] \t Loss 0.7145 \t Acc 82.67 \t AccHead 83.52 \t AccTail 79.96\n",
      "Epoch: [042] \t Loss 0.6730 \t Acc 82.46 \t AccHead 83.61 \t AccTail 78.75\n",
      "Epoch: [043] \t Loss 0.6467 \t Acc 83.57 \t AccHead 84.18 \t AccTail 81.60\n",
      "Epoch: [044] \t Loss 0.5734 \t Acc 86.67 \t AccHead 87.60 \t AccTail 83.69\n",
      "Epoch: [045] \t Loss 0.5594 \t Acc 87.47 \t AccHead 88.23 \t AccTail 85.03\n",
      "Epoch: [046] \t Loss 0.5314 \t Acc 86.47 \t AccHead 87.37 \t AccTail 83.57\n",
      "Epoch: [047] \t Loss 0.5183 \t Acc 88.11 \t AccHead 88.96 \t AccTail 85.35\n",
      "Epoch: [048] \t Loss 0.4498 \t Acc 89.52 \t AccHead 89.84 \t AccTail 88.46\n",
      "Epoch: [049] \t Loss 0.4249 \t Acc 88.34 \t AccHead 89.00 \t AccTail 86.21\n",
      "Epoch: [050] \t Loss 0.4232 \t Acc 90.09 \t AccHead 90.70 \t AccTail 88.13\n",
      "Epoch: [051] \t Loss 0.3830 \t Acc 90.11 \t AccHead 90.30 \t AccTail 89.50\n",
      "Epoch: [052] \t Loss 0.3984 \t Acc 90.14 \t AccHead 90.75 \t AccTail 88.19\n",
      "Epoch: [053] \t Loss 0.3789 \t Acc 90.59 \t AccHead 91.24 \t AccTail 88.49\n",
      "Epoch: [054] \t Loss 0.3444 \t Acc 90.82 \t AccHead 90.94 \t AccTail 90.43\n",
      "Epoch: [055] \t Loss 0.3138 \t Acc 92.66 \t AccHead 92.98 \t AccTail 91.63\n",
      "Epoch: [056] \t Loss 0.3135 \t Acc 92.33 \t AccHead 93.01 \t AccTail 90.15\n",
      "Epoch: [057] \t Loss 0.2994 \t Acc 92.83 \t AccHead 92.82 \t AccTail 92.89\n",
      "Epoch: [058] \t Loss 0.3027 \t Acc 93.28 \t AccHead 93.72 \t AccTail 91.84\n",
      "Epoch: [059] \t Loss 0.3034 \t Acc 93.19 \t AccHead 93.47 \t AccTail 92.30\n",
      "Epoch: [060] \t Loss 0.2487 \t Acc 93.72 \t AccHead 93.92 \t AccTail 93.08\n",
      "Epoch: [061] \t Loss 0.2634 \t Acc 94.09 \t AccHead 94.11 \t AccTail 94.03\n",
      "Epoch: [062] \t Loss 0.2640 \t Acc 94.08 \t AccHead 94.62 \t AccTail 92.35\n",
      "Epoch: [063] \t Loss 0.2448 \t Acc 93.68 \t AccHead 93.80 \t AccTail 93.30\n",
      "Epoch: [064] \t Loss 0.2208 \t Acc 94.90 \t AccHead 94.92 \t AccTail 94.81\n",
      "Epoch: [065] \t Loss 0.2442 \t Acc 94.38 \t AccHead 94.21 \t AccTail 94.92\n",
      "Epoch: [066] \t Loss 0.2091 \t Acc 94.77 \t AccHead 94.73 \t AccTail 94.89\n",
      "Epoch: [067] \t Loss 0.2134 \t Acc 95.75 \t AccHead 96.18 \t AccTail 94.37\n",
      "Epoch: [068] \t Loss 0.2042 \t Acc 95.81 \t AccHead 96.05 \t AccTail 95.03\n",
      "Epoch: [069] \t Loss 0.1938 \t Acc 96.29 \t AccHead 96.36 \t AccTail 96.06\n",
      "Epoch: [070] \t Loss 0.1849 \t Acc 94.63 \t AccHead 94.49 \t AccTail 95.06\n",
      "Epoch: [071] \t Loss 0.2083 \t Acc 94.93 \t AccHead 95.08 \t AccTail 94.43\n",
      "Epoch: [072] \t Loss 0.1943 \t Acc 95.95 \t AccHead 96.31 \t AccTail 94.79\n",
      "Epoch: [073] \t Loss 0.1761 \t Acc 96.57 \t AccHead 96.96 \t AccTail 95.32\n",
      "Epoch: [074] \t Loss 0.1697 \t Acc 95.04 \t AccHead 95.13 \t AccTail 94.76\n",
      "Epoch: [075] \t Loss 0.1816 \t Acc 95.93 \t AccHead 95.82 \t AccTail 96.30\n",
      "Epoch: [076] \t Loss 0.1759 \t Acc 96.71 \t AccHead 97.09 \t AccTail 95.49\n",
      "Epoch: [077] \t Loss 0.1691 \t Acc 96.44 \t AccHead 96.44 \t AccTail 96.44\n",
      "Epoch: [078] \t Loss 0.1763 \t Acc 96.09 \t AccHead 96.18 \t AccTail 95.79\n",
      "Epoch: [079] \t Loss 0.1699 \t Acc 95.87 \t AccHead 95.88 \t AccTail 95.84\n",
      "Epoch: [080] \t Loss 0.1624 \t Acc 96.78 \t AccHead 96.79 \t AccTail 96.73\n",
      "Epoch: [081] \t Loss 0.1531 \t Acc 96.48 \t AccHead 96.50 \t AccTail 96.41\n",
      "Epoch: [082] \t Loss 0.1691 \t Acc 95.74 \t AccHead 95.81 \t AccTail 95.48\n",
      "Epoch: [083] \t Loss 0.1583 \t Acc 96.13 \t AccHead 96.31 \t AccTail 95.57\n",
      "Epoch: [084] \t Loss 0.1699 \t Acc 95.80 \t AccHead 95.82 \t AccTail 95.73\n",
      "Epoch: [085] \t Loss 0.1445 \t Acc 97.43 \t AccHead 97.42 \t AccTail 97.46\n",
      "Epoch: [086] \t Loss 0.1353 \t Acc 97.30 \t AccHead 97.34 \t AccTail 97.19\n",
      "Epoch: [087] \t Loss 0.1348 \t Acc 96.26 \t AccHead 96.56 \t AccTail 95.30\n",
      "Epoch: [088] \t Loss 0.1373 \t Acc 97.21 \t AccHead 97.47 \t AccTail 96.41\n",
      "Epoch: [089] \t Loss 0.1577 \t Acc 96.38 \t AccHead 96.47 \t AccTail 96.11\n",
      "Epoch: [090] \t Loss 0.1728 \t Acc 96.33 \t AccHead 96.80 \t AccTail 94.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 11:33:35,319]\u001b[0m Trial 3 finished with value: 8.691608428955078 and parameters: {'n_epoch': 90, 'weight_decay': 7.287079544890574e-05}. Best is trial 2 with value: 9.270359992980957.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 8.69 \t AccHead 17.27 \t AccTail 0.25\n",
      "Epoch: [001] \t Loss 4.5454 \t Acc 8.93 \t AccHead 11.45 \t AccTail 0.81\n",
      "Epoch: [002] \t Loss 3.9025 \t Acc 13.89 \t AccHead 17.10 \t AccTail 3.57\n",
      "Epoch: [003] \t Loss 3.6805 \t Acc 16.94 \t AccHead 21.09 \t AccTail 3.59\n",
      "Epoch: [004] \t Loss 3.5114 \t Acc 19.05 \t AccHead 22.72 \t AccTail 7.26\n",
      "Epoch: [005] \t Loss 3.3782 \t Acc 21.88 \t AccHead 25.52 \t AccTail 10.13\n",
      "Epoch: [006] \t Loss 3.2365 \t Acc 24.60 \t AccHead 29.05 \t AccTail 10.29\n",
      "Epoch: [007] \t Loss 3.1218 \t Acc 26.35 \t AccHead 31.09 \t AccTail 11.08\n",
      "Epoch: [008] \t Loss 3.0158 \t Acc 27.66 \t AccHead 32.42 \t AccTail 12.35\n",
      "Epoch: [009] \t Loss 2.9204 \t Acc 30.23 \t AccHead 34.98 \t AccTail 14.96\n",
      "Epoch: [010] \t Loss 2.8374 \t Acc 31.69 \t AccHead 36.43 \t AccTail 16.41\n",
      "Epoch: [011] \t Loss 2.7314 \t Acc 33.79 \t AccHead 38.47 \t AccTail 18.74\n",
      "Epoch: [012] \t Loss 2.6431 \t Acc 36.21 \t AccHead 40.90 \t AccTail 21.11\n",
      "Epoch: [013] \t Loss 2.5629 \t Acc 38.00 \t AccHead 42.90 \t AccTail 22.20\n",
      "Epoch: [014] \t Loss 2.4714 \t Acc 38.54 \t AccHead 43.19 \t AccTail 23.57\n",
      "Epoch: [015] \t Loss 2.4236 \t Acc 40.59 \t AccHead 44.76 \t AccTail 27.14\n",
      "Epoch: [016] \t Loss 2.3266 \t Acc 42.76 \t AccHead 48.43 \t AccTail 24.51\n",
      "Epoch: [017] \t Loss 2.2650 \t Acc 41.95 \t AccHead 47.02 \t AccTail 25.63\n",
      "Epoch: [018] \t Loss 2.1899 \t Acc 46.80 \t AccHead 51.72 \t AccTail 30.98\n",
      "Epoch: [019] \t Loss 2.1276 \t Acc 47.78 \t AccHead 53.18 \t AccTail 30.38\n",
      "Epoch: [020] \t Loss 2.0335 \t Acc 50.18 \t AccHead 55.60 \t AccTail 32.70\n",
      "Epoch: [021] \t Loss 1.9553 \t Acc 51.93 \t AccHead 56.74 \t AccTail 36.42\n",
      "Epoch: [022] \t Loss 1.8798 \t Acc 54.10 \t AccHead 59.08 \t AccTail 38.07\n",
      "Epoch: [023] \t Loss 1.7988 \t Acc 55.60 \t AccHead 60.56 \t AccTail 39.64\n",
      "Epoch: [024] \t Loss 1.7454 \t Acc 57.42 \t AccHead 61.76 \t AccTail 43.47\n",
      "Epoch: [025] \t Loss 1.6595 \t Acc 58.47 \t AccHead 62.38 \t AccTail 45.87\n",
      "Epoch: [026] \t Loss 1.5979 \t Acc 60.07 \t AccHead 64.33 \t AccTail 46.37\n",
      "Epoch: [027] \t Loss 1.5250 \t Acc 61.90 \t AccHead 64.56 \t AccTail 53.35\n",
      "Epoch: [028] \t Loss 1.4651 \t Acc 62.27 \t AccHead 65.89 \t AccTail 50.61\n",
      "Epoch: [029] \t Loss 1.3869 \t Acc 66.95 \t AccHead 70.15 \t AccTail 56.66\n",
      "Epoch: [030] \t Loss 1.2998 \t Acc 67.90 \t AccHead 70.86 \t AccTail 58.39\n",
      "Epoch: [031] \t Loss 1.2317 \t Acc 69.74 \t AccHead 72.26 \t AccTail 61.59\n",
      "Epoch: [032] \t Loss 1.1856 \t Acc 70.07 \t AccHead 72.54 \t AccTail 62.14\n",
      "Epoch: [033] \t Loss 1.1032 \t Acc 73.18 \t AccHead 76.27 \t AccTail 63.27\n",
      "Epoch: [034] \t Loss 1.0692 \t Acc 71.57 \t AccHead 73.51 \t AccTail 65.33\n",
      "Epoch: [035] \t Loss 1.0079 \t Acc 75.37 \t AccHead 77.14 \t AccTail 69.64\n",
      "Epoch: [036] \t Loss 0.9169 \t Acc 76.34 \t AccHead 78.83 \t AccTail 68.33\n",
      "Epoch: [037] \t Loss 0.9035 \t Acc 75.49 \t AccHead 78.02 \t AccTail 67.34\n",
      "Epoch: [038] \t Loss 0.8351 \t Acc 79.36 \t AccHead 81.96 \t AccTail 70.99\n",
      "Epoch: [039] \t Loss 0.7814 \t Acc 80.91 \t AccHead 82.74 \t AccTail 75.02\n",
      "Epoch: [040] \t Loss 0.7579 \t Acc 82.77 \t AccHead 83.77 \t AccTail 79.58\n",
      "Epoch: [041] \t Loss 0.6897 \t Acc 83.15 \t AccHead 84.35 \t AccTail 79.25\n",
      "Epoch: [042] \t Loss 0.6720 \t Acc 83.52 \t AccHead 84.45 \t AccTail 80.52\n",
      "Epoch: [043] \t Loss 0.6227 \t Acc 84.98 \t AccHead 85.70 \t AccTail 82.68\n",
      "Epoch: [044] \t Loss 0.5533 \t Acc 85.37 \t AccHead 86.61 \t AccTail 81.35\n",
      "Epoch: [045] \t Loss 0.5603 \t Acc 85.48 \t AccHead 85.67 \t AccTail 84.84\n",
      "Epoch: [046] \t Loss 0.4936 \t Acc 88.00 \t AccHead 88.43 \t AccTail 86.60\n",
      "Epoch: [047] \t Loss 0.4672 \t Acc 88.04 \t AccHead 88.66 \t AccTail 86.02\n",
      "Epoch: [048] \t Loss 0.4626 \t Acc 88.88 \t AccHead 89.80 \t AccTail 85.90\n",
      "Epoch: [049] \t Loss 0.4285 \t Acc 89.81 \t AccHead 89.91 \t AccTail 89.48\n",
      "Epoch: [050] \t Loss 0.4103 \t Acc 89.86 \t AccHead 90.43 \t AccTail 88.02\n",
      "Epoch: [051] \t Loss 0.3617 \t Acc 92.03 \t AccHead 92.73 \t AccTail 89.77\n",
      "Epoch: [052] \t Loss 0.3428 \t Acc 92.13 \t AccHead 92.61 \t AccTail 90.57\n",
      "Epoch: [053] \t Loss 0.3436 \t Acc 91.08 \t AccHead 91.36 \t AccTail 90.16\n",
      "Epoch: [054] \t Loss 0.3463 \t Acc 92.32 \t AccHead 92.42 \t AccTail 91.98\n",
      "Epoch: [055] \t Loss 0.3034 \t Acc 93.46 \t AccHead 93.53 \t AccTail 93.24\n",
      "Epoch: [056] \t Loss 0.3143 \t Acc 92.39 \t AccHead 92.36 \t AccTail 92.48\n",
      "Epoch: [057] \t Loss 0.2952 \t Acc 92.09 \t AccHead 92.43 \t AccTail 90.98\n",
      "Epoch: [058] \t Loss 0.2767 \t Acc 94.01 \t AccHead 94.29 \t AccTail 93.11\n",
      "Epoch: [059] \t Loss 0.2894 \t Acc 92.92 \t AccHead 93.32 \t AccTail 91.65\n",
      "Epoch: [060] \t Loss 0.2788 \t Acc 93.55 \t AccHead 94.07 \t AccTail 91.87\n",
      "Epoch: [061] \t Loss 0.2635 \t Acc 94.74 \t AccHead 94.90 \t AccTail 94.25\n",
      "Epoch: [062] \t Loss 0.2422 \t Acc 95.15 \t AccHead 95.41 \t AccTail 94.32\n",
      "Epoch: [063] \t Loss 0.2371 \t Acc 94.77 \t AccHead 94.96 \t AccTail 94.17\n",
      "Epoch: [064] \t Loss 0.2272 \t Acc 95.06 \t AccHead 95.25 \t AccTail 94.47\n",
      "Epoch: [065] \t Loss 0.2147 \t Acc 94.88 \t AccHead 94.93 \t AccTail 94.73\n",
      "Epoch: [066] \t Loss 0.2011 \t Acc 94.23 \t AccHead 94.74 \t AccTail 92.59\n",
      "Epoch: [067] \t Loss 0.1982 \t Acc 95.75 \t AccHead 96.05 \t AccTail 94.79\n",
      "Epoch: [068] \t Loss 0.2066 \t Acc 94.82 \t AccHead 94.96 \t AccTail 94.35\n",
      "Epoch: [069] \t Loss 0.1944 \t Acc 95.13 \t AccHead 95.29 \t AccTail 94.63\n",
      "Epoch: [070] \t Loss 0.2055 \t Acc 94.85 \t AccHead 95.03 \t AccTail 94.25\n",
      "Epoch: [071] \t Loss 0.2103 \t Acc 96.03 \t AccHead 96.11 \t AccTail 95.79\n",
      "Epoch: [072] \t Loss 0.1892 \t Acc 96.09 \t AccHead 96.06 \t AccTail 96.17\n",
      "Epoch: [073] \t Loss 0.1928 \t Acc 95.82 \t AccHead 95.92 \t AccTail 95.51\n",
      "Epoch: [074] \t Loss 0.1785 \t Acc 96.42 \t AccHead 96.58 \t AccTail 95.92\n",
      "Epoch: [075] \t Loss 0.1744 \t Acc 96.80 \t AccHead 96.89 \t AccTail 96.54\n",
      "Epoch: [076] \t Loss 0.1523 \t Acc 97.08 \t AccHead 97.20 \t AccTail 96.70\n",
      "Epoch: [077] \t Loss 0.1747 \t Acc 95.70 \t AccHead 95.81 \t AccTail 95.35\n",
      "Epoch: [078] \t Loss 0.1762 \t Acc 96.77 \t AccHead 96.86 \t AccTail 96.46\n",
      "Epoch: [079] \t Loss 0.1465 \t Acc 97.07 \t AccHead 97.04 \t AccTail 97.19\n",
      "Epoch: [080] \t Loss 0.1625 \t Acc 96.63 \t AccHead 96.92 \t AccTail 95.68\n",
      "Epoch: [081] \t Loss 0.1581 \t Acc 96.01 \t AccHead 96.06 \t AccTail 95.84\n",
      "Epoch: [082] \t Loss 0.1668 \t Acc 96.47 \t AccHead 96.64 \t AccTail 95.90\n",
      "Epoch: [083] \t Loss 0.1605 \t Acc 96.56 \t AccHead 96.66 \t AccTail 96.24\n",
      "Epoch: [084] \t Loss 0.1643 \t Acc 96.18 \t AccHead 96.35 \t AccTail 95.65\n",
      "Epoch: [085] \t Loss 0.1582 \t Acc 96.96 \t AccHead 97.06 \t AccTail 96.65\n",
      "Epoch: [086] \t Loss 0.1462 \t Acc 97.14 \t AccHead 97.40 \t AccTail 96.30\n",
      "Epoch: [087] \t Loss 0.1294 \t Acc 97.92 \t AccHead 98.00 \t AccTail 97.65\n",
      "Epoch: [088] \t Loss 0.1309 \t Acc 97.57 \t AccHead 97.79 \t AccTail 96.84\n",
      "Epoch: [089] \t Loss 0.1381 \t Acc 96.76 \t AccHead 96.87 \t AccTail 96.40\n",
      "Epoch: [090] \t Loss 0.1358 \t Acc 97.43 \t AccHead 97.53 \t AccTail 97.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 11:47:29,421]\u001b[0m Trial 4 finished with value: 9.125672340393066 and parameters: {'n_epoch': 90, 'weight_decay': 7.31151648240591e-05}. Best is trial 2 with value: 9.270359992980957.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 9.13 \t AccHead 17.96 \t AccTail 0.43\n",
      "Epoch: [001] \t Loss 4.4569 \t Acc 10.35 \t AccHead 13.19 \t AccTail 1.24\n",
      "Epoch: [002] \t Loss 3.8684 \t Acc 14.57 \t AccHead 18.04 \t AccTail 3.40\n",
      "Epoch: [003] \t Loss 3.6694 \t Acc 16.29 \t AccHead 20.22 \t AccTail 3.65\n",
      "Epoch: [004] \t Loss 3.5241 \t Acc 18.85 \t AccHead 23.04 \t AccTail 5.32\n",
      "Epoch: [005] \t Loss 3.3921 \t Acc 21.45 \t AccHead 25.93 \t AccTail 7.03\n",
      "Epoch: [006] \t Loss 3.2511 \t Acc 23.80 \t AccHead 28.03 \t AccTail 10.19\n",
      "Epoch: [007] \t Loss 3.1435 \t Acc 25.12 \t AccHead 29.29 \t AccTail 11.68\n",
      "Epoch: [008] \t Loss 3.0400 \t Acc 26.99 \t AccHead 32.13 \t AccTail 10.46\n",
      "Epoch: [009] \t Loss 2.9382 \t Acc 28.12 \t AccHead 32.12 \t AccTail 15.28\n",
      "Epoch: [010] \t Loss 2.8343 \t Acc 30.94 \t AccHead 35.34 \t AccTail 16.78\n",
      "Epoch: [011] \t Loss 2.7325 \t Acc 32.74 \t AccHead 36.85 \t AccTail 19.50\n",
      "Epoch: [012] \t Loss 2.6555 \t Acc 34.95 \t AccHead 39.71 \t AccTail 19.64\n",
      "Epoch: [013] \t Loss 2.5779 \t Acc 36.28 \t AccHead 41.27 \t AccTail 20.22\n",
      "Epoch: [014] \t Loss 2.4923 \t Acc 39.25 \t AccHead 44.11 \t AccTail 23.62\n",
      "Epoch: [015] \t Loss 2.4173 \t Acc 38.84 \t AccHead 44.26 \t AccTail 21.40\n",
      "Epoch: [016] \t Loss 2.3573 \t Acc 41.66 \t AccHead 46.63 \t AccTail 25.68\n",
      "Epoch: [017] \t Loss 2.2906 \t Acc 42.46 \t AccHead 46.58 \t AccTail 29.19\n",
      "Epoch: [018] \t Loss 2.2015 \t Acc 43.68 \t AccHead 49.72 \t AccTail 24.24\n",
      "Epoch: [019] \t Loss 2.1476 \t Acc 48.35 \t AccHead 54.21 \t AccTail 29.51\n",
      "Epoch: [020] \t Loss 2.0789 \t Acc 48.56 \t AccHead 53.47 \t AccTail 32.73\n",
      "Epoch: [021] \t Loss 2.0159 \t Acc 46.65 \t AccHead 51.25 \t AccTail 31.87\n",
      "Epoch: [022] \t Loss 1.9679 \t Acc 50.74 \t AccHead 56.08 \t AccTail 33.54\n",
      "Epoch: [023] \t Loss 1.8953 \t Acc 52.15 \t AccHead 56.97 \t AccTail 36.63\n",
      "Epoch: [024] \t Loss 1.8463 \t Acc 49.56 \t AccHead 53.50 \t AccTail 36.91\n",
      "Epoch: [025] \t Loss 1.7772 \t Acc 53.00 \t AccHead 57.70 \t AccTail 37.89\n",
      "Epoch: [026] \t Loss 1.7427 \t Acc 55.20 \t AccHead 59.51 \t AccTail 41.34\n",
      "Epoch: [027] \t Loss 1.6767 \t Acc 53.65 \t AccHead 58.11 \t AccTail 39.28\n",
      "Epoch: [028] \t Loss 1.6300 \t Acc 55.70 \t AccHead 60.35 \t AccTail 40.73\n",
      "Epoch: [029] \t Loss 1.5752 \t Acc 55.97 \t AccHead 61.14 \t AccTail 39.32\n",
      "Epoch: [030] \t Loss 1.5305 \t Acc 61.57 \t AccHead 66.75 \t AccTail 44.87\n",
      "Epoch: [031] \t Loss 1.4808 \t Acc 61.76 \t AccHead 65.94 \t AccTail 48.31\n",
      "Epoch: [032] \t Loss 1.4190 \t Acc 63.26 \t AccHead 68.03 \t AccTail 47.92\n",
      "Epoch: [033] \t Loss 1.4025 \t Acc 64.52 \t AccHead 68.92 \t AccTail 50.35\n",
      "Epoch: [034] \t Loss 1.3244 \t Acc 66.95 \t AccHead 70.41 \t AccTail 55.80\n",
      "Epoch: [035] \t Loss 1.2930 \t Acc 63.09 \t AccHead 66.47 \t AccTail 52.20\n",
      "Epoch: [036] \t Loss 1.2527 \t Acc 67.35 \t AccHead 70.33 \t AccTail 57.75\n",
      "Epoch: [037] \t Loss 1.1750 \t Acc 65.77 \t AccHead 68.70 \t AccTail 56.33\n",
      "Epoch: [038] \t Loss 1.1690 \t Acc 69.46 \t AccHead 72.69 \t AccTail 59.06\n",
      "Epoch: [039] \t Loss 1.1113 \t Acc 71.84 \t AccHead 74.27 \t AccTail 64.01\n",
      "Epoch: [040] \t Loss 1.0484 \t Acc 69.42 \t AccHead 71.42 \t AccTail 62.97\n",
      "Epoch: [041] \t Loss 1.0077 \t Acc 72.34 \t AccHead 76.30 \t AccTail 59.57\n",
      "Epoch: [042] \t Loss 0.9844 \t Acc 72.91 \t AccHead 75.27 \t AccTail 65.28\n",
      "Epoch: [043] \t Loss 0.9829 \t Acc 72.23 \t AccHead 74.11 \t AccTail 66.18\n",
      "Epoch: [044] \t Loss 0.9228 \t Acc 74.19 \t AccHead 76.40 \t AccTail 67.06\n",
      "Epoch: [045] \t Loss 0.8864 \t Acc 78.38 \t AccHead 80.78 \t AccTail 70.66\n",
      "Epoch: [046] \t Loss 0.8392 \t Acc 77.25 \t AccHead 79.15 \t AccTail 71.11\n",
      "Epoch: [047] \t Loss 0.8172 \t Acc 77.41 \t AccHead 79.11 \t AccTail 71.94\n",
      "Epoch: [048] \t Loss 0.7831 \t Acc 78.16 \t AccHead 79.37 \t AccTail 74.28\n",
      "Epoch: [049] \t Loss 0.7801 \t Acc 78.64 \t AccHead 80.32 \t AccTail 73.26\n",
      "Epoch: [050] \t Loss 0.7185 \t Acc 78.97 \t AccHead 80.30 \t AccTail 74.68\n",
      "Epoch: [051] \t Loss 0.7298 \t Acc 81.87 \t AccHead 83.40 \t AccTail 76.96\n",
      "Epoch: [052] \t Loss 0.6890 \t Acc 80.27 \t AccHead 81.93 \t AccTail 74.93\n",
      "Epoch: [053] \t Loss 0.6820 \t Acc 81.05 \t AccHead 82.33 \t AccTail 76.90\n",
      "Epoch: [054] \t Loss 0.6415 \t Acc 80.64 \t AccHead 81.88 \t AccTail 76.62\n",
      "Epoch: [055] \t Loss 0.6344 \t Acc 82.12 \t AccHead 83.86 \t AccTail 76.53\n",
      "Epoch: [056] \t Loss 0.6103 \t Acc 81.46 \t AccHead 82.46 \t AccTail 78.24\n",
      "Epoch: [057] \t Loss 0.6303 \t Acc 82.22 \t AccHead 82.81 \t AccTail 80.31\n",
      "Epoch: [058] \t Loss 0.5921 \t Acc 86.87 \t AccHead 87.15 \t AccTail 85.94\n",
      "Epoch: [059] \t Loss 0.5509 \t Acc 84.67 \t AccHead 85.52 \t AccTail 81.95\n",
      "Epoch: [060] \t Loss 0.5838 \t Acc 83.92 \t AccHead 84.72 \t AccTail 81.34\n",
      "Epoch: [061] \t Loss 0.5592 \t Acc 85.53 \t AccHead 86.25 \t AccTail 83.20\n",
      "Epoch: [062] \t Loss 0.5475 \t Acc 84.06 \t AccHead 84.44 \t AccTail 82.86\n",
      "Epoch: [063] \t Loss 0.5090 \t Acc 85.71 \t AccHead 86.35 \t AccTail 83.68\n",
      "Epoch: [064] \t Loss 0.5134 \t Acc 85.90 \t AccHead 86.11 \t AccTail 85.22\n",
      "Epoch: [065] \t Loss 0.4902 \t Acc 85.87 \t AccHead 86.48 \t AccTail 83.90\n",
      "Epoch: [066] \t Loss 0.5015 \t Acc 86.30 \t AccHead 86.10 \t AccTail 86.96\n",
      "Epoch: [067] \t Loss 0.4951 \t Acc 88.30 \t AccHead 88.93 \t AccTail 86.27\n",
      "Epoch: [068] \t Loss 0.4787 \t Acc 84.99 \t AccHead 86.14 \t AccTail 81.29\n",
      "Epoch: [069] \t Loss 0.5007 \t Acc 83.97 \t AccHead 84.07 \t AccTail 83.65\n",
      "Epoch: [070] \t Loss 0.4525 \t Acc 89.67 \t AccHead 90.19 \t AccTail 88.01\n",
      "Epoch: [071] \t Loss 0.4917 \t Acc 86.64 \t AccHead 87.31 \t AccTail 84.46\n",
      "Epoch: [072] \t Loss 0.4883 \t Acc 82.29 \t AccHead 82.92 \t AccTail 80.25\n",
      "Epoch: [073] \t Loss 0.4708 \t Acc 87.65 \t AccHead 87.83 \t AccTail 87.05\n",
      "Epoch: [074] \t Loss 0.4543 \t Acc 85.46 \t AccHead 86.76 \t AccTail 81.25\n",
      "Epoch: [075] \t Loss 0.4633 \t Acc 87.48 \t AccHead 88.14 \t AccTail 85.36\n",
      "Epoch: [076] \t Loss 0.4381 \t Acc 90.39 \t AccHead 90.51 \t AccTail 90.01\n",
      "Epoch: [077] \t Loss 0.4275 \t Acc 85.99 \t AccHead 86.22 \t AccTail 85.25\n",
      "Epoch: [078] \t Loss 0.4246 \t Acc 84.93 \t AccHead 85.08 \t AccTail 84.45\n",
      "Epoch: [079] \t Loss 0.4093 \t Acc 87.87 \t AccHead 89.15 \t AccTail 83.76\n",
      "Epoch: [080] \t Loss 0.4314 \t Acc 86.55 \t AccHead 87.32 \t AccTail 84.07\n",
      "Epoch: [081] \t Loss 0.4317 \t Acc 84.20 \t AccHead 85.30 \t AccTail 80.63\n",
      "Epoch: [082] \t Loss 0.4517 \t Acc 86.52 \t AccHead 87.24 \t AccTail 84.21\n",
      "Epoch: [083] \t Loss 0.3981 \t Acc 88.51 \t AccHead 89.02 \t AccTail 86.88\n",
      "Epoch: [084] \t Loss 0.4030 \t Acc 88.51 \t AccHead 88.91 \t AccTail 87.19\n",
      "Epoch: [085] \t Loss 0.4110 \t Acc 86.58 \t AccHead 87.34 \t AccTail 84.16\n",
      "Epoch: [086] \t Loss 0.4060 \t Acc 89.19 \t AccHead 89.90 \t AccTail 86.92\n",
      "Epoch: [087] \t Loss 0.4139 \t Acc 89.54 \t AccHead 90.23 \t AccTail 87.32\n",
      "Epoch: [088] \t Loss 0.4089 \t Acc 89.40 \t AccHead 90.02 \t AccTail 87.37\n",
      "Epoch: [089] \t Loss 0.4112 \t Acc 86.01 \t AccHead 86.11 \t AccTail 85.70\n",
      "Epoch: [090] \t Loss 0.3888 \t Acc 89.32 \t AccHead 89.34 \t AccTail 89.26\n",
      "Epoch: [091] \t Loss 0.3864 \t Acc 88.31 \t AccHead 88.95 \t AccTail 86.27\n",
      "Epoch: [092] \t Loss 0.4167 \t Acc 89.40 \t AccHead 90.04 \t AccTail 87.36\n",
      "Epoch: [093] \t Loss 0.4143 \t Acc 88.04 \t AccHead 87.99 \t AccTail 88.23\n",
      "Epoch: [094] \t Loss 0.3902 \t Acc 87.92 \t AccHead 88.41 \t AccTail 86.36\n",
      "Epoch: [095] \t Loss 0.3876 \t Acc 91.38 \t AccHead 91.66 \t AccTail 90.48\n",
      "Epoch: [096] \t Loss 0.3479 \t Acc 88.10 \t AccHead 89.07 \t AccTail 84.97\n",
      "Epoch: [097] \t Loss 0.3792 \t Acc 89.79 \t AccHead 89.86 \t AccTail 89.56\n",
      "Epoch: [098] \t Loss 0.3876 \t Acc 88.54 \t AccHead 88.95 \t AccTail 87.23\n",
      "Epoch: [099] \t Loss 0.3643 \t Acc 88.83 \t AccHead 89.58 \t AccTail 86.44\n",
      "Epoch: [100] \t Loss 0.3872 \t Acc 89.94 \t AccHead 89.96 \t AccTail 89.86\n",
      "Epoch: [101] \t Loss 0.3802 \t Acc 89.94 \t AccHead 90.35 \t AccTail 88.63\n",
      "Epoch: [102] \t Loss 0.4041 \t Acc 85.64 \t AccHead 86.19 \t AccTail 83.88\n",
      "Epoch: [103] \t Loss 0.4137 \t Acc 89.22 \t AccHead 89.61 \t AccTail 87.95\n",
      "Epoch: [104] \t Loss 0.3581 \t Acc 90.14 \t AccHead 90.39 \t AccTail 89.36\n",
      "Epoch: [105] \t Loss 0.3426 \t Acc 91.39 \t AccHead 91.98 \t AccTail 89.47\n",
      "Epoch: [106] \t Loss 0.3468 \t Acc 91.81 \t AccHead 92.05 \t AccTail 91.03\n",
      "Epoch: [107] \t Loss 0.3531 \t Acc 89.43 \t AccHead 89.84 \t AccTail 88.10\n",
      "Epoch: [108] \t Loss 0.3854 \t Acc 89.19 \t AccHead 89.37 \t AccTail 88.60\n",
      "Epoch: [109] \t Loss 0.3836 \t Acc 89.34 \t AccHead 89.70 \t AccTail 88.20\n",
      "Epoch: [110] \t Loss 0.3645 \t Acc 89.59 \t AccHead 90.15 \t AccTail 87.77\n",
      "Epoch: [111] \t Loss 0.3484 \t Acc 91.68 \t AccHead 92.29 \t AccTail 89.74\n",
      "Epoch: [112] \t Loss 0.3381 \t Acc 90.07 \t AccHead 90.28 \t AccTail 89.41\n",
      "Epoch: [113] \t Loss 0.3421 \t Acc 90.50 \t AccHead 90.66 \t AccTail 90.00\n",
      "Epoch: [114] \t Loss 0.3636 \t Acc 90.45 \t AccHead 90.61 \t AccTail 89.92\n",
      "Epoch: [115] \t Loss 0.3691 \t Acc 90.43 \t AccHead 90.46 \t AccTail 90.34\n",
      "Epoch: [116] \t Loss 0.3972 \t Acc 88.67 \t AccHead 89.38 \t AccTail 86.37\n",
      "Epoch: [117] \t Loss 0.3573 \t Acc 90.09 \t AccHead 90.59 \t AccTail 88.46\n",
      "Epoch: [118] \t Loss 0.3352 \t Acc 90.50 \t AccHead 90.63 \t AccTail 90.05\n",
      "Epoch: [119] \t Loss 0.3561 \t Acc 91.39 \t AccHead 91.98 \t AccTail 89.49\n",
      "Epoch: [120] \t Loss 0.3471 \t Acc 90.66 \t AccHead 91.20 \t AccTail 88.90\n",
      "Epoch: [121] \t Loss 0.3250 \t Acc 89.48 \t AccHead 89.04 \t AccTail 90.91\n",
      "Epoch: [122] \t Loss 0.3455 \t Acc 90.22 \t AccHead 90.85 \t AccTail 88.19\n",
      "Epoch: [123] \t Loss 0.3428 \t Acc 91.09 \t AccHead 91.37 \t AccTail 90.21\n",
      "Epoch: [124] \t Loss 0.3406 \t Acc 90.52 \t AccHead 91.09 \t AccTail 88.66\n",
      "Epoch: [125] \t Loss 0.3314 \t Acc 89.18 \t AccHead 89.39 \t AccTail 88.52\n",
      "Epoch: [126] \t Loss 0.3613 \t Acc 88.20 \t AccHead 89.00 \t AccTail 85.60\n",
      "Epoch: [127] \t Loss 0.3520 \t Acc 90.06 \t AccHead 90.85 \t AccTail 87.54\n",
      "Epoch: [128] \t Loss 0.3657 \t Acc 89.54 \t AccHead 89.67 \t AccTail 89.11\n",
      "Epoch: [129] \t Loss 0.3512 \t Acc 90.50 \t AccHead 91.32 \t AccTail 87.84\n",
      "Epoch: [130] \t Loss 0.3322 \t Acc 90.39 \t AccHead 91.10 \t AccTail 88.11\n",
      "Epoch: [131] \t Loss 0.3285 \t Acc 92.14 \t AccHead 92.42 \t AccTail 91.25\n",
      "Epoch: [132] \t Loss 0.3523 \t Acc 90.22 \t AccHead 90.54 \t AccTail 89.20\n",
      "Epoch: [133] \t Loss 0.3657 \t Acc 89.67 \t AccHead 89.74 \t AccTail 89.44\n",
      "Epoch: [134] \t Loss 0.3500 \t Acc 90.76 \t AccHead 91.43 \t AccTail 88.60\n",
      "Epoch: [135] \t Loss 0.3374 \t Acc 89.81 \t AccHead 90.47 \t AccTail 87.67\n",
      "Epoch: [136] \t Loss 0.3455 \t Acc 90.05 \t AccHead 90.80 \t AccTail 87.62\n",
      "Epoch: [137] \t Loss 0.3575 \t Acc 92.08 \t AccHead 92.42 \t AccTail 90.97\n",
      "Epoch: [138] \t Loss 0.3102 \t Acc 91.52 \t AccHead 91.95 \t AccTail 90.14\n",
      "Epoch: [139] \t Loss 0.3262 \t Acc 91.37 \t AccHead 91.61 \t AccTail 90.62\n",
      "Epoch: [140] \t Loss 0.3426 \t Acc 89.81 \t AccHead 90.61 \t AccTail 87.21\n",
      "Epoch: [141] \t Loss 0.3260 \t Acc 90.89 \t AccHead 90.99 \t AccTail 90.56\n",
      "Epoch: [142] \t Loss 0.3511 \t Acc 90.70 \t AccHead 91.68 \t AccTail 87.54\n",
      "Epoch: [143] \t Loss 0.3183 \t Acc 90.07 \t AccHead 90.36 \t AccTail 89.14\n",
      "Epoch: [144] \t Loss 0.3408 \t Acc 89.99 \t AccHead 90.42 \t AccTail 88.59\n",
      "Epoch: [145] \t Loss 0.3281 \t Acc 92.40 \t AccHead 93.05 \t AccTail 90.29\n",
      "Epoch: [146] \t Loss 0.3126 \t Acc 91.52 \t AccHead 91.87 \t AccTail 90.41\n",
      "Epoch: [147] \t Loss 0.3549 \t Acc 91.13 \t AccHead 91.76 \t AccTail 89.12\n",
      "Epoch: [148] \t Loss 0.3373 \t Acc 92.10 \t AccHead 92.34 \t AccTail 91.35\n",
      "Epoch: [149] \t Loss 0.3372 \t Acc 92.86 \t AccHead 93.33 \t AccTail 91.33\n",
      "Epoch: [150] \t Loss 0.3055 \t Acc 91.20 \t AccHead 92.37 \t AccTail 87.44\n",
      "Epoch: [151] \t Loss 0.1397 \t Acc 99.16 \t AccHead 99.27 \t AccTail 98.81\n",
      "Epoch: [152] \t Loss 0.0586 \t Acc 99.57 \t AccHead 99.59 \t AccTail 99.51\n",
      "Epoch: [153] \t Loss 0.0407 \t Acc 99.77 \t AccHead 99.81 \t AccTail 99.65\n",
      "Epoch: [154] \t Loss 0.0330 \t Acc 99.80 \t AccHead 99.82 \t AccTail 99.70\n",
      "Epoch: [155] \t Loss 0.0282 \t Acc 99.82 \t AccHead 99.83 \t AccTail 99.78\n",
      "Epoch: [156] \t Loss 0.0241 \t Acc 99.87 \t AccHead 99.87 \t AccTail 99.86\n",
      "Epoch: [157] \t Loss 0.0224 \t Acc 99.88 \t AccHead 99.90 \t AccTail 99.84\n",
      "Epoch: [158] \t Loss 0.0200 \t Acc 99.89 \t AccHead 99.91 \t AccTail 99.84\n",
      "Epoch: [159] \t Loss 0.0199 \t Acc 99.90 \t AccHead 99.90 \t AccTail 99.89\n",
      "Epoch: [160] \t Loss 0.0174 \t Acc 99.89 \t AccHead 99.88 \t AccTail 99.92\n",
      "Epoch: [161] \t Loss 0.0151 \t Acc 99.90 \t AccHead 99.90 \t AccTail 99.92\n",
      "Epoch: [162] \t Loss 0.0150 \t Acc 99.90 \t AccHead 99.89 \t AccTail 99.95\n",
      "Epoch: [163] \t Loss 0.0145 \t Acc 99.92 \t AccHead 99.92 \t AccTail 99.92\n",
      "Epoch: [164] \t Loss 0.0145 \t Acc 99.99 \t AccHead 99.98 \t AccTail 100.00\n",
      "Epoch: [165] \t Loss 0.0136 \t Acc 99.92 \t AccHead 99.92 \t AccTail 99.92\n",
      "Epoch: [166] \t Loss 0.0133 \t Acc 99.95 \t AccHead 99.96 \t AccTail 99.92\n",
      "Epoch: [167] \t Loss 0.0135 \t Acc 99.96 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [168] \t Loss 0.0117 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [169] \t Loss 0.0107 \t Acc 99.94 \t AccHead 99.94 \t AccTail 99.95\n",
      "Epoch: [170] \t Loss 0.0122 \t Acc 99.93 \t AccHead 99.92 \t AccTail 99.95\n",
      "Epoch: [171] \t Loss 0.0108 \t Acc 99.93 \t AccHead 99.92 \t AccTail 99.95\n",
      "Epoch: [172] \t Loss 0.0113 \t Acc 99.96 \t AccHead 99.95 \t AccTail 99.97\n",
      "Epoch: [173] \t Loss 0.0105 \t Acc 99.94 \t AccHead 99.93 \t AccTail 99.97\n",
      "Epoch: [174] \t Loss 0.0111 \t Acc 99.96 \t AccHead 99.97 \t AccTail 99.92\n",
      "Epoch: [175] \t Loss 0.0109 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [176] \t Loss 0.0106 \t Acc 99.96 \t AccHead 99.94 \t AccTail 100.00\n",
      "Epoch: [177] \t Loss 0.0098 \t Acc 99.96 \t AccHead 99.96 \t AccTail 99.95\n",
      "Epoch: [178] \t Loss 0.0100 \t Acc 99.97 \t AccHead 99.97 \t AccTail 99.97\n",
      "Epoch: [179] \t Loss 0.0096 \t Acc 99.97 \t AccHead 99.97 \t AccTail 99.97\n",
      "Epoch: [180] \t Loss 0.0098 \t Acc 99.96 \t AccHead 99.95 \t AccTail 99.97\n",
      "Epoch: [181] \t Loss 0.0091 \t Acc 99.96 \t AccHead 99.96 \t AccTail 99.97\n",
      "Epoch: [182] \t Loss 0.0090 \t Acc 99.96 \t AccHead 99.96 \t AccTail 99.97\n",
      "Epoch: [183] \t Loss 0.0090 \t Acc 99.97 \t AccHead 99.97 \t AccTail 99.97\n",
      "Epoch: [184] \t Loss 0.0094 \t Acc 99.96 \t AccHead 99.96 \t AccTail 99.97\n",
      "Epoch: [185] \t Loss 0.0089 \t Acc 99.97 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [186] \t Loss 0.0090 \t Acc 99.97 \t AccHead 99.97 \t AccTail 99.97\n",
      "Epoch: [187] \t Loss 0.0086 \t Acc 99.96 \t AccHead 99.96 \t AccTail 99.97\n",
      "Epoch: [188] \t Loss 0.0085 \t Acc 99.96 \t AccHead 99.96 \t AccTail 99.95\n",
      "Epoch: [189] \t Loss 0.0086 \t Acc 99.96 \t AccHead 99.95 \t AccTail 99.97\n",
      "Epoch: [190] \t Loss 0.0083 \t Acc 99.97 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [191] \t Loss 0.0081 \t Acc 99.99 \t AccHead 99.98 \t AccTail 100.00\n",
      "Epoch: [192] \t Loss 0.0078 \t Acc 99.97 \t AccHead 99.97 \t AccTail 99.95\n",
      "Epoch: [193] \t Loss 0.0084 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [194] \t Loss 0.0086 \t Acc 99.96 \t AccHead 99.96 \t AccTail 99.97\n",
      "Epoch: [195] \t Loss 0.0087 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [196] \t Loss 0.0081 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [197] \t Loss 0.0079 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [198] \t Loss 0.0083 \t Acc 99.97 \t AccHead 99.97 \t AccTail 99.97\n",
      "Epoch: [199] \t Loss 0.0085 \t Acc 99.97 \t AccHead 99.97 \t AccTail 99.97\n",
      "Epoch: [200] \t Loss 0.0078 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 12:17:57,289]\u001b[0m Trial 5 finished with value: 10.27284049987793 and parameters: {'n_epoch': 200, 'weight_decay': 0.00025667322460149426}. Best is trial 5 with value: 10.27284049987793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 10.27 \t AccHead 20.50 \t AccTail 0.21\n",
      "Epoch: [001] \t Loss 4.4983 \t Acc 8.14 \t AccHead 10.22 \t AccTail 1.43\n",
      "Epoch: [002] \t Loss 3.9196 \t Acc 12.15 \t AccHead 15.11 \t AccTail 2.62\n",
      "Epoch: [003] \t Loss 3.7357 \t Acc 14.54 \t AccHead 18.64 \t AccTail 1.32\n",
      "Epoch: [004] \t Loss 3.6046 \t Acc 16.12 \t AccHead 19.67 \t AccTail 4.67\n",
      "Epoch: [005] \t Loss 3.4724 \t Acc 17.89 \t AccHead 21.15 \t AccTail 7.40\n",
      "Epoch: [006] \t Loss 3.3811 \t Acc 20.27 \t AccHead 24.29 \t AccTail 7.32\n",
      "Epoch: [007] \t Loss 3.2756 \t Acc 21.00 \t AccHead 25.52 \t AccTail 6.43\n",
      "Epoch: [008] \t Loss 3.1982 \t Acc 23.65 \t AccHead 28.38 \t AccTail 8.43\n",
      "Epoch: [009] \t Loss 3.1090 \t Acc 24.23 \t AccHead 27.60 \t AccTail 13.35\n",
      "Epoch: [010] \t Loss 3.0412 \t Acc 25.95 \t AccHead 29.99 \t AccTail 12.95\n",
      "Epoch: [011] \t Loss 2.9790 \t Acc 26.15 \t AccHead 30.66 \t AccTail 11.64\n",
      "Epoch: [012] \t Loss 2.9149 \t Acc 27.39 \t AccHead 31.44 \t AccTail 14.35\n",
      "Epoch: [013] \t Loss 2.8724 \t Acc 28.07 \t AccHead 32.48 \t AccTail 13.87\n",
      "Epoch: [014] \t Loss 2.8445 \t Acc 30.26 \t AccHead 35.10 \t AccTail 14.71\n",
      "Epoch: [015] \t Loss 2.7938 \t Acc 29.22 \t AccHead 34.32 \t AccTail 12.78\n",
      "Epoch: [016] \t Loss 2.7725 \t Acc 29.98 \t AccHead 34.25 \t AccTail 16.22\n",
      "Epoch: [017] \t Loss 2.7174 \t Acc 32.69 \t AccHead 38.24 \t AccTail 14.83\n",
      "Epoch: [018] \t Loss 2.6976 \t Acc 32.38 \t AccHead 36.62 \t AccTail 18.70\n",
      "Epoch: [019] \t Loss 2.6661 \t Acc 31.09 \t AccHead 36.50 \t AccTail 13.67\n",
      "Epoch: [020] \t Loss 2.6495 \t Acc 33.69 \t AccHead 38.61 \t AccTail 17.87\n",
      "Epoch: [021] \t Loss 2.6221 \t Acc 33.95 \t AccHead 39.38 \t AccTail 16.44\n",
      "Epoch: [022] \t Loss 2.5877 \t Acc 35.66 \t AccHead 40.97 \t AccTail 18.56\n",
      "Epoch: [023] \t Loss 2.5601 \t Acc 35.07 \t AccHead 40.47 \t AccTail 17.67\n",
      "Epoch: [024] \t Loss 2.5687 \t Acc 34.64 \t AccHead 39.86 \t AccTail 17.82\n",
      "Epoch: [025] \t Loss 2.5358 \t Acc 34.96 \t AccHead 40.08 \t AccTail 18.48\n",
      "Epoch: [026] \t Loss 2.5097 \t Acc 34.07 \t AccHead 39.63 \t AccTail 16.17\n",
      "Epoch: [027] \t Loss 2.4867 \t Acc 37.64 \t AccHead 43.20 \t AccTail 19.74\n",
      "Epoch: [028] \t Loss 2.4840 \t Acc 35.37 \t AccHead 40.17 \t AccTail 19.93\n",
      "Epoch: [029] \t Loss 2.4764 \t Acc 36.73 \t AccHead 41.99 \t AccTail 19.77\n",
      "Epoch: [030] \t Loss 2.4622 \t Acc 35.60 \t AccHead 41.04 \t AccTail 18.04\n",
      "Epoch: [031] \t Loss 2.4400 \t Acc 35.88 \t AccHead 40.76 \t AccTail 20.15\n",
      "Epoch: [032] \t Loss 2.4376 \t Acc 35.81 \t AccHead 40.87 \t AccTail 19.54\n",
      "Epoch: [033] \t Loss 2.4298 \t Acc 33.22 \t AccHead 37.10 \t AccTail 20.70\n",
      "Epoch: [034] \t Loss 2.4262 \t Acc 37.35 \t AccHead 41.73 \t AccTail 23.21\n",
      "Epoch: [035] \t Loss 2.4058 \t Acc 40.27 \t AccHead 46.43 \t AccTail 20.42\n",
      "Epoch: [036] \t Loss 2.3568 \t Acc 39.65 \t AccHead 46.84 \t AccTail 16.46\n",
      "Epoch: [037] \t Loss 2.3697 \t Acc 35.68 \t AccHead 40.33 \t AccTail 20.74\n",
      "Epoch: [038] \t Loss 2.3744 \t Acc 32.60 \t AccHead 37.36 \t AccTail 17.27\n",
      "Epoch: [039] \t Loss 2.3621 \t Acc 38.68 \t AccHead 43.12 \t AccTail 24.36\n",
      "Epoch: [040] \t Loss 2.3513 \t Acc 40.69 \t AccHead 45.80 \t AccTail 24.24\n",
      "Epoch: [041] \t Loss 2.3474 \t Acc 39.13 \t AccHead 44.43 \t AccTail 22.10\n",
      "Epoch: [042] \t Loss 2.3164 \t Acc 41.82 \t AccHead 47.93 \t AccTail 22.14\n",
      "Epoch: [043] \t Loss 2.3236 \t Acc 38.90 \t AccHead 44.60 \t AccTail 20.55\n",
      "Epoch: [044] \t Loss 2.2955 \t Acc 40.02 \t AccHead 44.38 \t AccTail 26.01\n",
      "Epoch: [045] \t Loss 2.2931 \t Acc 37.21 \t AccHead 41.79 \t AccTail 22.48\n",
      "Epoch: [046] \t Loss 2.3149 \t Acc 36.01 \t AccHead 40.43 \t AccTail 21.79\n",
      "Epoch: [047] \t Loss 2.2879 \t Acc 39.86 \t AccHead 44.16 \t AccTail 25.99\n",
      "Epoch: [048] \t Loss 2.3108 \t Acc 42.88 \t AccHead 48.30 \t AccTail 25.44\n",
      "Epoch: [049] \t Loss 2.2756 \t Acc 39.41 \t AccHead 45.01 \t AccTail 21.38\n",
      "Epoch: [050] \t Loss 2.2886 \t Acc 40.29 \t AccHead 44.86 \t AccTail 25.57\n",
      "Epoch: [051] \t Loss 2.2623 \t Acc 38.79 \t AccHead 44.47 \t AccTail 20.53\n",
      "Epoch: [052] \t Loss 2.2391 \t Acc 36.94 \t AccHead 41.59 \t AccTail 21.95\n",
      "Epoch: [053] \t Loss 2.2698 \t Acc 42.41 \t AccHead 46.90 \t AccTail 27.97\n",
      "Epoch: [054] \t Loss 2.2680 \t Acc 42.32 \t AccHead 47.88 \t AccTail 24.40\n",
      "Epoch: [055] \t Loss 2.2491 \t Acc 40.14 \t AccHead 44.99 \t AccTail 24.52\n",
      "Epoch: [056] \t Loss 2.2446 \t Acc 35.35 \t AccHead 40.39 \t AccTail 19.15\n",
      "Epoch: [057] \t Loss 2.2536 \t Acc 42.79 \t AccHead 48.31 \t AccTail 24.99\n",
      "Epoch: [058] \t Loss 2.2398 \t Acc 42.71 \t AccHead 47.47 \t AccTail 27.41\n",
      "Epoch: [059] \t Loss 2.2300 \t Acc 40.36 \t AccHead 44.49 \t AccTail 27.06\n",
      "Epoch: [060] \t Loss 2.2322 \t Acc 36.37 \t AccHead 41.25 \t AccTail 20.63\n",
      "Epoch: [061] \t Loss 2.2435 \t Acc 41.88 \t AccHead 46.60 \t AccTail 26.71\n",
      "Epoch: [062] \t Loss 2.2089 \t Acc 43.28 \t AccHead 47.92 \t AccTail 28.33\n",
      "Epoch: [063] \t Loss 2.2061 \t Acc 40.25 \t AccHead 45.19 \t AccTail 24.38\n",
      "Epoch: [064] \t Loss 2.2090 \t Acc 40.06 \t AccHead 45.74 \t AccTail 21.78\n",
      "Epoch: [065] \t Loss 2.1914 \t Acc 40.74 \t AccHead 46.33 \t AccTail 22.75\n",
      "Epoch: [066] \t Loss 2.2401 \t Acc 38.51 \t AccHead 42.97 \t AccTail 24.13\n",
      "Epoch: [067] \t Loss 2.2050 \t Acc 40.25 \t AccHead 45.22 \t AccTail 24.26\n",
      "Epoch: [068] \t Loss 2.1879 \t Acc 41.03 \t AccHead 45.57 \t AccTail 26.41\n",
      "Epoch: [069] \t Loss 2.2019 \t Acc 40.56 \t AccHead 45.98 \t AccTail 23.11\n",
      "Epoch: [070] \t Loss 2.1899 \t Acc 40.72 \t AccHead 45.50 \t AccTail 25.34\n",
      "Epoch: [071] \t Loss 2.1809 \t Acc 42.65 \t AccHead 47.67 \t AccTail 26.51\n",
      "Epoch: [072] \t Loss 2.1756 \t Acc 40.39 \t AccHead 46.19 \t AccTail 21.74\n",
      "Epoch: [073] \t Loss 2.1744 \t Acc 43.28 \t AccHead 49.48 \t AccTail 23.37\n",
      "Epoch: [074] \t Loss 2.1686 \t Acc 36.03 \t AccHead 39.42 \t AccTail 25.11\n",
      "Epoch: [075] \t Loss 2.1933 \t Acc 40.74 \t AccHead 46.18 \t AccTail 23.22\n",
      "Epoch: [076] \t Loss 2.2007 \t Acc 40.05 \t AccHead 44.56 \t AccTail 25.51\n",
      "Epoch: [077] \t Loss 2.1754 \t Acc 44.42 \t AccHead 50.35 \t AccTail 25.34\n",
      "Epoch: [078] \t Loss 2.1552 \t Acc 40.58 \t AccHead 44.57 \t AccTail 27.71\n",
      "Epoch: [079] \t Loss 2.1641 \t Acc 37.34 \t AccHead 42.28 \t AccTail 21.42\n",
      "Epoch: [080] \t Loss 2.1742 \t Acc 35.93 \t AccHead 40.17 \t AccTail 22.31\n",
      "Epoch: [081] \t Loss 2.1970 \t Acc 43.79 \t AccHead 49.35 \t AccTail 25.90\n",
      "Epoch: [082] \t Loss 2.1368 \t Acc 39.06 \t AccHead 43.38 \t AccTail 25.11\n",
      "Epoch: [083] \t Loss 2.1736 \t Acc 43.70 \t AccHead 48.67 \t AccTail 27.70\n",
      "Epoch: [084] \t Loss 2.1494 \t Acc 39.95 \t AccHead 44.89 \t AccTail 24.03\n",
      "Epoch: [085] \t Loss 2.1629 \t Acc 41.31 \t AccHead 46.72 \t AccTail 23.90\n",
      "Epoch: [086] \t Loss 2.1713 \t Acc 42.67 \t AccHead 47.10 \t AccTail 28.41\n",
      "Epoch: [087] \t Loss 2.1671 \t Acc 42.80 \t AccHead 47.30 \t AccTail 28.30\n",
      "Epoch: [088] \t Loss 2.1542 \t Acc 41.66 \t AccHead 46.35 \t AccTail 26.55\n",
      "Epoch: [089] \t Loss 2.1631 \t Acc 39.88 \t AccHead 44.49 \t AccTail 25.01\n",
      "Epoch: [090] \t Loss 2.1531 \t Acc 46.29 \t AccHead 52.35 \t AccTail 26.76\n",
      "Epoch: [091] \t Loss 2.1222 \t Acc 40.70 \t AccHead 45.73 \t AccTail 24.48\n",
      "Epoch: [092] \t Loss 2.1329 \t Acc 43.59 \t AccHead 48.14 \t AccTail 28.96\n",
      "Epoch: [093] \t Loss 2.1362 \t Acc 37.25 \t AccHead 40.75 \t AccTail 25.97\n",
      "Epoch: [094] \t Loss 2.1662 \t Acc 39.79 \t AccHead 44.42 \t AccTail 24.90\n",
      "Epoch: [095] \t Loss 2.1301 \t Acc 42.01 \t AccHead 45.61 \t AccTail 30.42\n",
      "Epoch: [096] \t Loss 2.1300 \t Acc 40.72 \t AccHead 45.46 \t AccTail 25.47\n",
      "Epoch: [097] \t Loss 2.1157 \t Acc 42.36 \t AccHead 46.99 \t AccTail 27.48\n",
      "Epoch: [098] \t Loss 2.1435 \t Acc 42.05 \t AccHead 46.76 \t AccTail 26.89\n",
      "Epoch: [099] \t Loss 2.1185 \t Acc 46.11 \t AccHead 52.22 \t AccTail 26.43\n",
      "Epoch: [100] \t Loss 2.1448 \t Acc 42.98 \t AccHead 46.90 \t AccTail 30.33\n",
      "Epoch: [101] \t Loss 2.1219 \t Acc 40.48 \t AccHead 45.25 \t AccTail 25.14\n",
      "Epoch: [102] \t Loss 2.1254 \t Acc 39.89 \t AccHead 44.84 \t AccTail 23.94\n",
      "Epoch: [103] \t Loss 2.1353 \t Acc 39.44 \t AccHead 43.62 \t AccTail 26.00\n",
      "Epoch: [104] \t Loss 2.1188 \t Acc 41.27 \t AccHead 46.78 \t AccTail 23.52\n",
      "Epoch: [105] \t Loss 2.1177 \t Acc 46.57 \t AccHead 51.55 \t AccTail 30.56\n",
      "Epoch: [106] \t Loss 2.1427 \t Acc 42.81 \t AccHead 47.16 \t AccTail 28.80\n",
      "Epoch: [107] \t Loss 2.1043 \t Acc 45.35 \t AccHead 50.72 \t AccTail 28.07\n",
      "Epoch: [108] \t Loss 2.1239 \t Acc 46.49 \t AccHead 52.44 \t AccTail 27.34\n",
      "Epoch: [109] \t Loss 2.1162 \t Acc 42.58 \t AccHead 47.98 \t AccTail 25.23\n",
      "Epoch: [110] \t Loss 2.1024 \t Acc 41.80 \t AccHead 46.98 \t AccTail 25.12\n",
      "Epoch: [111] \t Loss 2.1065 \t Acc 39.70 \t AccHead 44.06 \t AccTail 25.65\n",
      "Epoch: [112] \t Loss 2.1290 \t Acc 44.53 \t AccHead 49.48 \t AccTail 28.59\n",
      "Epoch: [113] \t Loss 2.1099 \t Acc 41.85 \t AccHead 47.45 \t AccTail 23.88\n",
      "Epoch: [114] \t Loss 2.1092 \t Acc 42.57 \t AccHead 48.42 \t AccTail 23.73\n",
      "Epoch: [115] \t Loss 2.1121 \t Acc 43.55 \t AccHead 48.73 \t AccTail 26.88\n",
      "Epoch: [116] \t Loss 2.1024 \t Acc 44.13 \t AccHead 48.45 \t AccTail 30.24\n",
      "Epoch: [117] \t Loss 2.1120 \t Acc 44.76 \t AccHead 49.41 \t AccTail 29.79\n",
      "Epoch: [118] \t Loss 2.0879 \t Acc 43.90 \t AccHead 48.42 \t AccTail 29.35\n",
      "Epoch: [119] \t Loss 2.1118 \t Acc 38.99 \t AccHead 42.78 \t AccTail 26.79\n",
      "Epoch: [120] \t Loss 2.1256 \t Acc 45.81 \t AccHead 51.17 \t AccTail 28.55\n",
      "Epoch: [121] \t Loss 2.1137 \t Acc 43.87 \t AccHead 48.94 \t AccTail 27.50\n",
      "Epoch: [122] \t Loss 2.1203 \t Acc 44.81 \t AccHead 50.74 \t AccTail 25.74\n",
      "Epoch: [123] \t Loss 2.1082 \t Acc 41.78 \t AccHead 46.01 \t AccTail 28.16\n",
      "Epoch: [124] \t Loss 2.1159 \t Acc 39.33 \t AccHead 44.30 \t AccTail 23.36\n",
      "Epoch: [125] \t Loss 2.1033 \t Acc 47.23 \t AccHead 52.04 \t AccTail 31.72\n",
      "Epoch: [126] \t Loss 2.1098 \t Acc 42.76 \t AccHead 47.63 \t AccTail 27.09\n",
      "Epoch: [127] \t Loss 2.0866 \t Acc 45.76 \t AccHead 51.07 \t AccTail 28.68\n",
      "Epoch: [128] \t Loss 2.0689 \t Acc 41.76 \t AccHead 45.95 \t AccTail 28.27\n",
      "Epoch: [129] \t Loss 2.1107 \t Acc 43.22 \t AccHead 47.85 \t AccTail 28.31\n",
      "Epoch: [130] \t Loss 2.0976 \t Acc 42.93 \t AccHead 47.17 \t AccTail 29.29\n",
      "Epoch: [131] \t Loss 2.0971 \t Acc 43.32 \t AccHead 48.88 \t AccTail 25.40\n",
      "Epoch: [132] \t Loss 2.0949 \t Acc 44.97 \t AccHead 50.14 \t AccTail 28.34\n",
      "Epoch: [133] \t Loss 2.0942 \t Acc 37.54 \t AccHead 41.95 \t AccTail 23.36\n",
      "Epoch: [134] \t Loss 2.0881 \t Acc 41.46 \t AccHead 47.28 \t AccTail 22.75\n",
      "Epoch: [135] \t Loss 2.1082 \t Acc 42.32 \t AccHead 47.08 \t AccTail 27.01\n",
      "Epoch: [136] \t Loss 2.0965 \t Acc 42.55 \t AccHead 47.19 \t AccTail 27.58\n",
      "Epoch: [137] \t Loss 2.0931 \t Acc 43.38 \t AccHead 48.72 \t AccTail 26.16\n",
      "Epoch: [138] \t Loss 2.0978 \t Acc 44.23 \t AccHead 48.80 \t AccTail 29.50\n",
      "Epoch: [139] \t Loss 2.0958 \t Acc 43.31 \t AccHead 47.21 \t AccTail 30.78\n",
      "Epoch: [140] \t Loss 2.1013 \t Acc 44.76 \t AccHead 49.69 \t AccTail 28.87\n",
      "Epoch: [141] \t Loss 2.0945 \t Acc 42.92 \t AccHead 49.40 \t AccTail 22.08\n",
      "Epoch: [142] \t Loss 2.0832 \t Acc 44.15 \t AccHead 48.76 \t AccTail 29.28\n",
      "Epoch: [143] \t Loss 2.0891 \t Acc 46.20 \t AccHead 52.61 \t AccTail 25.63\n",
      "Epoch: [144] \t Loss 2.1386 \t Acc 42.32 \t AccHead 45.32 \t AccTail 32.69\n",
      "Epoch: [145] \t Loss 2.0961 \t Acc 45.97 \t AccHead 52.28 \t AccTail 25.62\n",
      "Epoch: [146] \t Loss 2.0638 \t Acc 41.94 \t AccHead 47.52 \t AccTail 23.97\n",
      "Epoch: [147] \t Loss 2.0862 \t Acc 44.36 \t AccHead 48.71 \t AccTail 30.42\n",
      "Epoch: [148] \t Loss 2.0916 \t Acc 43.91 \t AccHead 47.55 \t AccTail 32.18\n",
      "Epoch: [149] \t Loss 2.0895 \t Acc 44.23 \t AccHead 48.09 \t AccTail 31.79\n",
      "Epoch: [150] \t Loss 2.0917 \t Acc 45.84 \t AccHead 50.96 \t AccTail 29.34\n",
      "Epoch: [151] \t Loss 1.5909 \t Acc 65.36 \t AccHead 71.19 \t AccTail 46.63\n",
      "Epoch: [152] \t Loss 1.3344 \t Acc 68.47 \t AccHead 73.93 \t AccTail 50.88\n",
      "Epoch: [153] \t Loss 1.2175 \t Acc 71.25 \t AccHead 76.05 \t AccTail 55.82\n",
      "Epoch: [154] \t Loss 1.1265 \t Acc 73.72 \t AccHead 78.42 \t AccTail 58.58\n",
      "Epoch: [155] \t Loss 1.0479 \t Acc 75.33 \t AccHead 79.63 \t AccTail 61.51\n",
      "Epoch: [156] \t Loss 0.9816 \t Acc 77.14 \t AccHead 81.80 \t AccTail 62.14\n",
      "Epoch: [157] \t Loss 0.9164 \t Acc 78.90 \t AccHead 82.96 \t AccTail 65.84\n",
      "Epoch: [158] \t Loss 0.8621 \t Acc 80.56 \t AccHead 84.16 \t AccTail 68.99\n",
      "Epoch: [159] \t Loss 0.8198 \t Acc 81.65 \t AccHead 84.84 \t AccTail 71.40\n",
      "Epoch: [160] \t Loss 0.7644 \t Acc 83.34 \t AccHead 86.85 \t AccTail 72.08\n",
      "Epoch: [161] \t Loss 0.7225 \t Acc 84.56 \t AccHead 87.61 \t AccTail 74.76\n",
      "Epoch: [162] \t Loss 0.6833 \t Acc 85.12 \t AccHead 88.01 \t AccTail 75.82\n",
      "Epoch: [163] \t Loss 0.6388 \t Acc 85.91 \t AccHead 88.65 \t AccTail 77.09\n",
      "Epoch: [164] \t Loss 0.6036 \t Acc 86.92 \t AccHead 89.27 \t AccTail 79.35\n",
      "Epoch: [165] \t Loss 0.5543 \t Acc 88.04 \t AccHead 90.53 \t AccTail 80.05\n",
      "Epoch: [166] \t Loss 0.5358 \t Acc 88.81 \t AccHead 91.23 \t AccTail 81.01\n",
      "Epoch: [167] \t Loss 0.5054 \t Acc 89.54 \t AccHead 91.85 \t AccTail 82.12\n",
      "Epoch: [168] \t Loss 0.4861 \t Acc 89.37 \t AccHead 91.36 \t AccTail 82.97\n",
      "Epoch: [169] \t Loss 0.4584 \t Acc 90.78 \t AccHead 92.23 \t AccTail 86.10\n",
      "Epoch: [170] \t Loss 0.4476 \t Acc 90.28 \t AccHead 91.89 \t AccTail 85.09\n",
      "Epoch: [171] \t Loss 0.4287 \t Acc 91.30 \t AccHead 92.94 \t AccTail 86.00\n",
      "Epoch: [172] \t Loss 0.4111 \t Acc 91.83 \t AccHead 93.22 \t AccTail 87.37\n",
      "Epoch: [173] \t Loss 0.3885 \t Acc 91.55 \t AccHead 92.94 \t AccTail 87.07\n",
      "Epoch: [174] \t Loss 0.3901 \t Acc 90.88 \t AccHead 92.09 \t AccTail 86.99\n",
      "Epoch: [175] \t Loss 0.3854 \t Acc 91.69 \t AccHead 92.67 \t AccTail 88.52\n",
      "Epoch: [176] \t Loss 0.3806 \t Acc 90.77 \t AccHead 92.18 \t AccTail 86.23\n",
      "Epoch: [177] \t Loss 0.3631 \t Acc 90.93 \t AccHead 92.19 \t AccTail 86.85\n",
      "Epoch: [178] \t Loss 0.3629 \t Acc 92.58 \t AccHead 93.67 \t AccTail 89.06\n",
      "Epoch: [179] \t Loss 0.3489 \t Acc 92.15 \t AccHead 92.90 \t AccTail 89.73\n",
      "Epoch: [180] \t Loss 0.3546 \t Acc 92.15 \t AccHead 93.13 \t AccTail 88.99\n",
      "Epoch: [181] \t Loss 0.3436 \t Acc 92.67 \t AccHead 93.92 \t AccTail 88.63\n",
      "Epoch: [182] \t Loss 0.3356 \t Acc 93.89 \t AccHead 94.33 \t AccTail 92.47\n",
      "Epoch: [183] \t Loss 0.3166 \t Acc 93.37 \t AccHead 94.02 \t AccTail 91.27\n",
      "Epoch: [184] \t Loss 0.3167 \t Acc 93.72 \t AccHead 94.43 \t AccTail 91.43\n",
      "Epoch: [185] \t Loss 0.2937 \t Acc 93.34 \t AccHead 94.17 \t AccTail 90.65\n",
      "Epoch: [186] \t Loss 0.3020 \t Acc 92.99 \t AccHead 93.82 \t AccTail 90.32\n",
      "Epoch: [187] \t Loss 0.3077 \t Acc 93.99 \t AccHead 94.72 \t AccTail 91.66\n",
      "Epoch: [188] \t Loss 0.2940 \t Acc 92.43 \t AccHead 92.83 \t AccTail 91.14\n",
      "Epoch: [189] \t Loss 0.2911 \t Acc 93.57 \t AccHead 94.01 \t AccTail 92.17\n",
      "Epoch: [190] \t Loss 0.2935 \t Acc 93.98 \t AccHead 94.64 \t AccTail 91.86\n",
      "Epoch: [191] \t Loss 0.2924 \t Acc 91.09 \t AccHead 91.46 \t AccTail 89.90\n",
      "Epoch: [192] \t Loss 0.2951 \t Acc 92.99 \t AccHead 93.42 \t AccTail 91.59\n",
      "Epoch: [193] \t Loss 0.3086 \t Acc 92.37 \t AccHead 92.59 \t AccTail 91.66\n",
      "Epoch: [194] \t Loss 0.3081 \t Acc 93.48 \t AccHead 94.01 \t AccTail 91.76\n",
      "Epoch: [195] \t Loss 0.2821 \t Acc 94.66 \t AccHead 95.39 \t AccTail 92.30\n",
      "Epoch: [196] \t Loss 0.2610 \t Acc 92.94 \t AccHead 93.16 \t AccTail 92.22\n",
      "Epoch: [197] \t Loss 0.2902 \t Acc 94.84 \t AccHead 95.37 \t AccTail 93.14\n",
      "Epoch: [198] \t Loss 0.2922 \t Acc 93.53 \t AccHead 94.14 \t AccTail 91.58\n",
      "Epoch: [199] \t Loss 0.2903 \t Acc 93.33 \t AccHead 93.99 \t AccTail 91.22\n",
      "Epoch: [200] \t Loss 0.2888 \t Acc 93.65 \t AccHead 93.68 \t AccTail 93.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 12:48:30,297]\u001b[0m Trial 6 finished with value: 10.572550773620605 and parameters: {'n_epoch': 200, 'weight_decay': 0.0014050162062201677}. Best is trial 6 with value: 10.572550773620605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 10.57 \t AccHead 21.02 \t AccTail 0.29\n",
      "Epoch: [001] \t Loss 4.5308 \t Acc 10.16 \t AccHead 12.91 \t AccTail 1.30\n",
      "Epoch: [002] \t Loss 3.8862 \t Acc 13.17 \t AccHead 16.51 \t AccTail 2.43\n",
      "Epoch: [003] \t Loss 3.6547 \t Acc 16.96 \t AccHead 20.82 \t AccTail 4.49\n",
      "Epoch: [004] \t Loss 3.4839 \t Acc 19.17 \t AccHead 23.29 \t AccTail 5.89\n",
      "Epoch: [005] \t Loss 3.3465 \t Acc 20.92 \t AccHead 25.14 \t AccTail 7.32\n",
      "Epoch: [006] \t Loss 3.2300 \t Acc 23.44 \t AccHead 27.41 \t AccTail 10.67\n",
      "Epoch: [007] \t Loss 3.1029 \t Acc 25.81 \t AccHead 30.52 \t AccTail 10.66\n",
      "Epoch: [008] \t Loss 2.9984 \t Acc 25.76 \t AccHead 29.98 \t AccTail 12.19\n",
      "Epoch: [009] \t Loss 2.9113 \t Acc 30.23 \t AccHead 35.21 \t AccTail 14.20\n",
      "Epoch: [010] \t Loss 2.8068 \t Acc 32.25 \t AccHead 37.94 \t AccTail 13.96\n",
      "Epoch: [011] \t Loss 2.7192 \t Acc 32.72 \t AccHead 37.94 \t AccTail 15.94\n",
      "Epoch: [012] \t Loss 2.6421 \t Acc 33.68 \t AccHead 38.68 \t AccTail 17.58\n",
      "Epoch: [013] \t Loss 2.5660 \t Acc 34.19 \t AccHead 38.89 \t AccTail 19.03\n",
      "Epoch: [014] \t Loss 2.5093 \t Acc 37.71 \t AccHead 42.97 \t AccTail 20.77\n",
      "Epoch: [015] \t Loss 2.4411 \t Acc 39.01 \t AccHead 44.34 \t AccTail 21.87\n",
      "Epoch: [016] \t Loss 2.3581 \t Acc 39.49 \t AccHead 44.93 \t AccTail 21.96\n",
      "Epoch: [017] \t Loss 2.3250 \t Acc 42.79 \t AccHead 48.29 \t AccTail 25.09\n",
      "Epoch: [018] \t Loss 2.2609 \t Acc 42.43 \t AccHead 47.48 \t AccTail 26.16\n",
      "Epoch: [019] \t Loss 2.1981 \t Acc 42.21 \t AccHead 46.76 \t AccTail 27.58\n",
      "Epoch: [020] \t Loss 2.1671 \t Acc 45.49 \t AccHead 50.16 \t AccTail 30.46\n",
      "Epoch: [021] \t Loss 2.1486 \t Acc 45.52 \t AccHead 50.75 \t AccTail 28.69\n",
      "Epoch: [022] \t Loss 2.1115 \t Acc 46.32 \t AccHead 51.39 \t AccTail 29.96\n",
      "Epoch: [023] \t Loss 2.0485 \t Acc 46.55 \t AccHead 52.91 \t AccTail 26.08\n",
      "Epoch: [024] \t Loss 2.0027 \t Acc 43.55 \t AccHead 49.09 \t AccTail 25.71\n",
      "Epoch: [025] \t Loss 2.0045 \t Acc 47.99 \t AccHead 52.89 \t AccTail 32.22\n",
      "Epoch: [026] \t Loss 1.9334 \t Acc 47.80 \t AccHead 51.68 \t AccTail 35.29\n",
      "Epoch: [027] \t Loss 1.9114 \t Acc 51.54 \t AccHead 57.12 \t AccTail 33.56\n",
      "Epoch: [028] \t Loss 1.8762 \t Acc 50.29 \t AccHead 55.53 \t AccTail 33.41\n",
      "Epoch: [029] \t Loss 1.8276 \t Acc 54.14 \t AccHead 58.84 \t AccTail 38.98\n",
      "Epoch: [030] \t Loss 1.8041 \t Acc 51.84 \t AccHead 56.19 \t AccTail 37.84\n",
      "Epoch: [031] \t Loss 1.7681 \t Acc 53.38 \t AccHead 58.04 \t AccTail 38.37\n",
      "Epoch: [032] \t Loss 1.7286 \t Acc 53.35 \t AccHead 58.43 \t AccTail 36.97\n",
      "Epoch: [033] \t Loss 1.6982 \t Acc 56.05 \t AccHead 59.93 \t AccTail 43.59\n",
      "Epoch: [034] \t Loss 1.6753 \t Acc 55.47 \t AccHead 59.47 \t AccTail 42.59\n",
      "Epoch: [035] \t Loss 1.6493 \t Acc 53.48 \t AccHead 57.37 \t AccTail 40.93\n",
      "Epoch: [036] \t Loss 1.6221 \t Acc 56.67 \t AccHead 60.92 \t AccTail 42.98\n",
      "Epoch: [037] \t Loss 1.5578 \t Acc 58.03 \t AccHead 61.98 \t AccTail 45.33\n",
      "Epoch: [038] \t Loss 1.5768 \t Acc 59.19 \t AccHead 63.91 \t AccTail 43.97\n",
      "Epoch: [039] \t Loss 1.5011 \t Acc 57.71 \t AccHead 61.49 \t AccTail 45.54\n",
      "Epoch: [040] \t Loss 1.5069 \t Acc 60.57 \t AccHead 64.74 \t AccTail 47.12\n",
      "Epoch: [041] \t Loss 1.5077 \t Acc 62.26 \t AccHead 65.11 \t AccTail 53.12\n",
      "Epoch: [042] \t Loss 1.4231 \t Acc 61.62 \t AccHead 65.89 \t AccTail 47.88\n",
      "Epoch: [043] \t Loss 1.4189 \t Acc 60.31 \t AccHead 65.02 \t AccTail 45.15\n",
      "Epoch: [044] \t Loss 1.3770 \t Acc 61.59 \t AccHead 65.77 \t AccTail 48.12\n",
      "Epoch: [045] \t Loss 1.3623 \t Acc 61.66 \t AccHead 64.75 \t AccTail 51.72\n",
      "Epoch: [046] \t Loss 1.3256 \t Acc 60.02 \t AccHead 63.82 \t AccTail 47.80\n",
      "Epoch: [047] \t Loss 1.3214 \t Acc 61.08 \t AccHead 63.88 \t AccTail 52.08\n",
      "Epoch: [048] \t Loss 1.2874 \t Acc 62.39 \t AccHead 64.90 \t AccTail 54.32\n",
      "Epoch: [049] \t Loss 1.2984 \t Acc 65.44 \t AccHead 70.10 \t AccTail 50.45\n",
      "Epoch: [050] \t Loss 1.2535 \t Acc 66.34 \t AccHead 68.69 \t AccTail 58.76\n",
      "Epoch: [051] \t Loss 1.2289 \t Acc 65.77 \t AccHead 67.74 \t AccTail 59.43\n",
      "Epoch: [052] \t Loss 1.2143 \t Acc 65.19 \t AccHead 67.33 \t AccTail 58.32\n",
      "Epoch: [053] \t Loss 1.1866 \t Acc 66.96 \t AccHead 69.66 \t AccTail 58.24\n",
      "Epoch: [054] \t Loss 1.1517 \t Acc 64.34 \t AccHead 67.19 \t AccTail 55.16\n",
      "Epoch: [055] \t Loss 1.1577 \t Acc 68.73 \t AccHead 72.67 \t AccTail 56.06\n",
      "Epoch: [056] \t Loss 1.1275 \t Acc 68.91 \t AccHead 72.11 \t AccTail 58.60\n",
      "Epoch: [057] \t Loss 1.0966 \t Acc 70.33 \t AccHead 73.52 \t AccTail 60.04\n",
      "Epoch: [058] \t Loss 1.0770 \t Acc 68.51 \t AccHead 70.85 \t AccTail 60.94\n",
      "Epoch: [059] \t Loss 1.1024 \t Acc 63.72 \t AccHead 65.60 \t AccTail 57.65\n",
      "Epoch: [060] \t Loss 1.0851 \t Acc 67.50 \t AccHead 70.23 \t AccTail 58.71\n",
      "Epoch: [061] \t Loss 1.0515 \t Acc 68.45 \t AccHead 71.47 \t AccTail 58.75\n",
      "Epoch: [062] \t Loss 1.0489 \t Acc 70.64 \t AccHead 72.66 \t AccTail 64.14\n",
      "Epoch: [063] \t Loss 1.0261 \t Acc 73.46 \t AccHead 75.38 \t AccTail 67.31\n",
      "Epoch: [064] \t Loss 0.9895 \t Acc 66.60 \t AccHead 68.84 \t AccTail 59.38\n",
      "Epoch: [065] \t Loss 0.9905 \t Acc 72.19 \t AccHead 73.40 \t AccTail 68.28\n",
      "Epoch: [066] \t Loss 0.9783 \t Acc 67.62 \t AccHead 67.79 \t AccTail 67.07\n",
      "Epoch: [067] \t Loss 0.9974 \t Acc 67.89 \t AccHead 69.84 \t AccTail 61.60\n",
      "Epoch: [068] \t Loss 1.0130 \t Acc 67.76 \t AccHead 70.14 \t AccTail 60.10\n",
      "Epoch: [069] \t Loss 0.9452 \t Acc 73.91 \t AccHead 76.52 \t AccTail 65.52\n",
      "Epoch: [070] \t Loss 0.9386 \t Acc 67.77 \t AccHead 69.84 \t AccTail 61.11\n",
      "Epoch: [071] \t Loss 0.8993 \t Acc 72.65 \t AccHead 74.68 \t AccTail 66.12\n",
      "Epoch: [072] \t Loss 0.9424 \t Acc 71.02 \t AccHead 73.39 \t AccTail 63.36\n",
      "Epoch: [073] \t Loss 0.9165 \t Acc 76.14 \t AccHead 77.96 \t AccTail 70.29\n",
      "Epoch: [074] \t Loss 0.8893 \t Acc 74.14 \t AccHead 76.16 \t AccTail 67.65\n",
      "Epoch: [075] \t Loss 0.9247 \t Acc 73.53 \t AccHead 74.80 \t AccTail 69.42\n",
      "Epoch: [076] \t Loss 0.8704 \t Acc 72.50 \t AccHead 73.74 \t AccTail 68.50\n",
      "Epoch: [077] \t Loss 0.8912 \t Acc 72.94 \t AccHead 73.85 \t AccTail 70.03\n",
      "Epoch: [078] \t Loss 0.8787 \t Acc 74.78 \t AccHead 75.95 \t AccTail 71.02\n",
      "Epoch: [079] \t Loss 0.8761 \t Acc 70.57 \t AccHead 72.19 \t AccTail 65.34\n",
      "Epoch: [080] \t Loss 0.8462 \t Acc 76.80 \t AccHead 78.81 \t AccTail 70.32\n",
      "Epoch: [081] \t Loss 0.8322 \t Acc 76.26 \t AccHead 78.02 \t AccTail 70.58\n",
      "Epoch: [082] \t Loss 0.8384 \t Acc 74.34 \t AccHead 77.08 \t AccTail 65.54\n",
      "Epoch: [083] \t Loss 0.8286 \t Acc 76.36 \t AccHead 77.71 \t AccTail 72.04\n",
      "Epoch: [084] \t Loss 0.8624 \t Acc 73.36 \t AccHead 75.35 \t AccTail 66.96\n",
      "Epoch: [085] \t Loss 0.8353 \t Acc 74.40 \t AccHead 76.20 \t AccTail 68.64\n",
      "Epoch: [086] \t Loss 0.8321 \t Acc 74.84 \t AccHead 76.89 \t AccTail 68.23\n",
      "Epoch: [087] \t Loss 0.8141 \t Acc 76.04 \t AccHead 78.67 \t AccTail 67.59\n",
      "Epoch: [088] \t Loss 0.8209 \t Acc 74.66 \t AccHead 76.32 \t AccTail 69.33\n",
      "Epoch: [089] \t Loss 0.7906 \t Acc 76.34 \t AccHead 77.64 \t AccTail 72.14\n",
      "Epoch: [090] \t Loss 0.8369 \t Acc 72.59 \t AccHead 74.01 \t AccTail 67.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 13:02:13,236]\u001b[0m Trial 7 finished with value: 8.360893249511719 and parameters: {'n_epoch': 90, 'weight_decay': 0.0005261355135797675}. Best is trial 6 with value: 10.572550773620605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 8.36 \t AccHead 16.60 \t AccTail 0.25\n",
      "Epoch: [001] \t Loss 4.5089 \t Acc 2.43 \t AccHead 3.19 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 4.4838 \t Acc 1.93 \t AccHead 2.53 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 4.4948 \t Acc 2.43 \t AccHead 3.18 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 4.4922 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 4.4934 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 4.4941 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 4.4944 \t Acc 2.22 \t AccHead 2.90 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 4.4930 \t Acc 2.33 \t AccHead 3.05 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 4.4929 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 4.4942 \t Acc 2.17 \t AccHead 2.84 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 4.4934 \t Acc 2.49 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 4.4938 \t Acc 2.38 \t AccHead 3.12 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 4.4939 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 4.4938 \t Acc 2.43 \t AccHead 3.19 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 4.4919 \t Acc 2.33 \t AccHead 3.06 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 4.4939 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 4.4943 \t Acc 2.38 \t AccHead 3.12 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 4.4927 \t Acc 2.48 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 4.4952 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 4.4937 \t Acc 2.12 \t AccHead 2.78 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 4.4933 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 4.4934 \t Acc 2.38 \t AccHead 3.12 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 4.4931 \t Acc 2.39 \t AccHead 3.13 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 4.4964 \t Acc 2.38 \t AccHead 3.11 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 4.4940 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 4.4933 \t Acc 2.43 \t AccHead 3.18 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 4.4934 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 4.4939 \t Acc 2.28 \t AccHead 2.99 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 4.4925 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 4.4931 \t Acc 2.49 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 4.4931 \t Acc 2.49 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 4.4937 \t Acc 2.48 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 4.4924 \t Acc 2.17 \t AccHead 2.85 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 4.4931 \t Acc 2.49 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 4.4950 \t Acc 2.49 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 4.4940 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 4.4919 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 4.4943 \t Acc 2.43 \t AccHead 3.19 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 4.4947 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 4.4932 \t Acc 2.38 \t AccHead 3.12 \t AccTail 0.00\n",
      "Epoch: [041] \t Loss 4.4934 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 4.4929 \t Acc 2.22 \t AccHead 2.90 \t AccTail 0.00\n",
      "Epoch: [043] \t Loss 4.4943 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [044] \t Loss 4.4914 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 4.4944 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [046] \t Loss 4.4933 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [047] \t Loss 4.4940 \t Acc 2.12 \t AccHead 2.78 \t AccTail 0.00\n",
      "Epoch: [048] \t Loss 4.4916 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [049] \t Loss 4.4941 \t Acc 2.17 \t AccHead 2.85 \t AccTail 0.00\n",
      "Epoch: [050] \t Loss 4.4926 \t Acc 2.27 \t AccHead 2.98 \t AccTail 0.00\n",
      "Epoch: [051] \t Loss 4.4948 \t Acc 2.22 \t AccHead 2.91 \t AccTail 0.00\n",
      "Epoch: [052] \t Loss 4.4926 \t Acc 2.06 \t AccHead 2.70 \t AccTail 0.00\n",
      "Epoch: [053] \t Loss 4.4941 \t Acc 2.55 \t AccHead 3.34 \t AccTail 0.00\n",
      "Epoch: [054] \t Loss 4.4936 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [055] \t Loss 4.4932 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [056] \t Loss 4.4923 \t Acc 2.32 \t AccHead 3.05 \t AccTail 0.00\n",
      "Epoch: [057] \t Loss 4.4945 \t Acc 2.39 \t AccHead 3.13 \t AccTail 0.00\n",
      "Epoch: [058] \t Loss 4.4938 \t Acc 2.49 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [059] \t Loss 4.4948 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [060] \t Loss 4.4911 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [061] \t Loss 4.4941 \t Acc 2.49 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [062] \t Loss 4.4930 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [063] \t Loss 4.4924 \t Acc 2.39 \t AccHead 3.13 \t AccTail 0.00\n",
      "Epoch: [064] \t Loss 4.4936 \t Acc 2.38 \t AccHead 3.11 \t AccTail 0.00\n",
      "Epoch: [065] \t Loss 4.4940 \t Acc 2.39 \t AccHead 3.13 \t AccTail 0.00\n",
      "Epoch: [066] \t Loss 4.4923 \t Acc 2.43 \t AccHead 3.19 \t AccTail 0.00\n",
      "Epoch: [067] \t Loss 4.4943 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [068] \t Loss 4.4909 \t Acc 2.27 \t AccHead 2.98 \t AccTail 0.00\n",
      "Epoch: [069] \t Loss 4.4953 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [070] \t Loss 4.4940 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [071] \t Loss 4.4946 \t Acc 2.38 \t AccHead 3.12 \t AccTail 0.00\n",
      "Epoch: [072] \t Loss 4.4918 \t Acc 2.38 \t AccHead 3.12 \t AccTail 0.00\n",
      "Epoch: [073] \t Loss 4.4945 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [074] \t Loss 4.4938 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [075] \t Loss 4.4932 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [076] \t Loss 4.4939 \t Acc 2.07 \t AccHead 2.71 \t AccTail 0.00\n",
      "Epoch: [077] \t Loss 4.4929 \t Acc 2.13 \t AccHead 2.79 \t AccTail 0.00\n",
      "Epoch: [078] \t Loss 4.4906 \t Acc 2.55 \t AccHead 3.34 \t AccTail 0.00\n",
      "Epoch: [079] \t Loss 4.4948 \t Acc 2.07 \t AccHead 2.72 \t AccTail 0.00\n",
      "Epoch: [080] \t Loss 4.4933 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [081] \t Loss 4.4921 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [082] \t Loss 4.4950 \t Acc 2.38 \t AccHead 3.11 \t AccTail 0.00\n",
      "Epoch: [083] \t Loss 4.4936 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [084] \t Loss 4.4940 \t Acc 2.28 \t AccHead 2.99 \t AccTail 0.00\n",
      "Epoch: [085] \t Loss 4.4938 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [086] \t Loss 4.4927 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [087] \t Loss 4.4924 \t Acc 2.49 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [088] \t Loss 4.4947 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [089] \t Loss 4.4957 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [090] \t Loss 4.4922 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 13:15:31,796]\u001b[0m Trial 8 finished with value: 1.033484935760498 and parameters: {'n_epoch': 90, 'weight_decay': 0.06876963291919139}. Best is trial 6 with value: 10.572550773620605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 1.03 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [001] \t Loss 4.4808 \t Acc 3.97 \t AccHead 5.20 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 4.3686 \t Acc 3.16 \t AccHead 4.14 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 4.3456 \t Acc 4.12 \t AccHead 5.40 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 4.3492 \t Acc 3.13 \t AccHead 4.10 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 4.3780 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 4.4572 \t Acc 1.72 \t AccHead 2.26 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 4.4593 \t Acc 2.38 \t AccHead 3.11 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 4.4589 \t Acc 2.49 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 4.4586 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 4.4602 \t Acc 2.49 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 4.4581 \t Acc 2.02 \t AccHead 2.65 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 4.4573 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 4.4592 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 4.4591 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 4.4595 \t Acc 2.12 \t AccHead 2.78 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 4.4585 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 4.4568 \t Acc 2.07 \t AccHead 2.72 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 4.4596 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 4.4571 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 4.4584 \t Acc 2.49 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 4.4588 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 4.4588 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 4.4583 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 4.4593 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 4.4596 \t Acc 2.39 \t AccHead 3.13 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 4.4596 \t Acc 2.33 \t AccHead 3.05 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 4.4592 \t Acc 2.02 \t AccHead 2.64 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 4.4580 \t Acc 2.38 \t AccHead 3.11 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 4.4576 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 4.4595 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 4.4576 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 4.4574 \t Acc 2.28 \t AccHead 2.99 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 4.4581 \t Acc 2.21 \t AccHead 2.90 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 4.4591 \t Acc 2.28 \t AccHead 2.99 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 4.4582 \t Acc 2.02 \t AccHead 2.65 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 4.4581 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 4.4595 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 4.4578 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 4.4587 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 4.4575 \t Acc 2.43 \t AccHead 3.19 \t AccTail 0.00\n",
      "Epoch: [041] \t Loss 4.4600 \t Acc 2.49 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 4.4573 \t Acc 2.38 \t AccHead 3.11 \t AccTail 0.00\n",
      "Epoch: [043] \t Loss 4.4591 \t Acc 2.43 \t AccHead 3.19 \t AccTail 0.00\n",
      "Epoch: [044] \t Loss 4.4589 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 4.4588 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [046] \t Loss 4.4597 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [047] \t Loss 4.4578 \t Acc 2.32 \t AccHead 3.04 \t AccTail 0.00\n",
      "Epoch: [048] \t Loss 4.4604 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [049] \t Loss 4.4592 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [050] \t Loss 4.4591 \t Acc 2.22 \t AccHead 2.90 \t AccTail 0.00\n",
      "Epoch: [051] \t Loss 4.4592 \t Acc 2.28 \t AccHead 2.99 \t AccTail 0.00\n",
      "Epoch: [052] \t Loss 4.4573 \t Acc 2.43 \t AccHead 3.19 \t AccTail 0.00\n",
      "Epoch: [053] \t Loss 4.4589 \t Acc 1.93 \t AccHead 2.53 \t AccTail 0.00\n",
      "Epoch: [054] \t Loss 4.4580 \t Acc 2.48 \t AccHead 3.26 \t AccTail 0.00\n",
      "Epoch: [055] \t Loss 4.4579 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [056] \t Loss 4.4583 \t Acc 2.13 \t AccHead 2.79 \t AccTail 0.00\n",
      "Epoch: [057] \t Loss 4.4590 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [058] \t Loss 4.4575 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [059] \t Loss 4.4592 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [060] \t Loss 4.4580 \t Acc 2.33 \t AccHead 3.06 \t AccTail 0.00\n",
      "Epoch: [061] \t Loss 4.4590 \t Acc 2.33 \t AccHead 3.06 \t AccTail 0.00\n",
      "Epoch: [062] \t Loss 4.4585 \t Acc 2.16 \t AccHead 2.83 \t AccTail 0.00\n",
      "Epoch: [063] \t Loss 4.4582 \t Acc 2.17 \t AccHead 2.85 \t AccTail 0.00\n",
      "Epoch: [064] \t Loss 4.4581 \t Acc 1.89 \t AccHead 2.48 \t AccTail 0.00\n",
      "Epoch: [065] \t Loss 4.4617 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [066] \t Loss 4.4568 \t Acc 2.13 \t AccHead 2.79 \t AccTail 0.00\n",
      "Epoch: [067] \t Loss 4.4576 \t Acc 2.55 \t AccHead 3.34 \t AccTail 0.00\n",
      "Epoch: [068] \t Loss 4.4581 \t Acc 2.44 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [069] \t Loss 4.4590 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [070] \t Loss 4.4580 \t Acc 2.55 \t AccHead 3.34 \t AccTail 0.00\n",
      "Epoch: [071] \t Loss 4.4585 \t Acc 2.55 \t AccHead 3.34 \t AccTail 0.00\n",
      "Epoch: [072] \t Loss 4.4598 \t Acc 2.48 \t AccHead 3.25 \t AccTail 0.00\n",
      "Epoch: [073] \t Loss 4.4580 \t Acc 2.43 \t AccHead 3.19 \t AccTail 0.00\n",
      "Epoch: [074] \t Loss 4.4586 \t Acc 2.16 \t AccHead 2.84 \t AccTail 0.00\n",
      "Epoch: [075] \t Loss 4.4585 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [076] \t Loss 4.4579 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [077] \t Loss 4.4600 \t Acc 2.49 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [078] \t Loss 4.4583 \t Acc 2.28 \t AccHead 2.99 \t AccTail 0.00\n",
      "Epoch: [079] \t Loss 4.4603 \t Acc 2.21 \t AccHead 2.90 \t AccTail 0.00\n",
      "Epoch: [080] \t Loss 4.4575 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [081] \t Loss 4.4592 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [082] \t Loss 4.4606 \t Acc 2.12 \t AccHead 2.78 \t AccTail 0.00\n",
      "Epoch: [083] \t Loss 4.4575 \t Acc 2.33 \t AccHead 3.05 \t AccTail 0.00\n",
      "Epoch: [084] \t Loss 4.4585 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [085] \t Loss 4.4572 \t Acc 2.56 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [086] \t Loss 4.4587 \t Acc 2.22 \t AccHead 2.91 \t AccTail 0.00\n",
      "Epoch: [087] \t Loss 4.4610 \t Acc 2.39 \t AccHead 3.13 \t AccTail 0.00\n",
      "Epoch: [088] \t Loss 4.4577 \t Acc 2.56 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [089] \t Loss 4.4588 \t Acc 2.50 \t AccHead 3.27 \t AccTail 0.00\n",
      "Epoch: [090] \t Loss 4.4593 \t Acc 2.49 \t AccHead 3.26 \t AccTail 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 13:28:58,097]\u001b[0m Trial 9 finished with value: 1.033484935760498 and parameters: {'n_epoch': 90, 'weight_decay': 0.04724606778291743}. Best is trial 6 with value: 10.572550773620605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 1.03 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [001] \t Loss 4.4310 \t Acc 7.08 \t AccHead 9.27 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 3.8907 \t Acc 9.80 \t AccHead 12.49 \t AccTail 1.16\n",
      "Epoch: [003] \t Loss 3.7296 \t Acc 14.23 \t AccHead 18.05 \t AccTail 1.92\n",
      "Epoch: [004] \t Loss 3.5949 \t Acc 13.70 \t AccHead 16.90 \t AccTail 3.40\n",
      "Epoch: [005] \t Loss 3.5274 \t Acc 16.57 \t AccHead 20.31 \t AccTail 4.47\n",
      "Epoch: [006] \t Loss 3.4742 \t Acc 15.36 \t AccHead 18.24 \t AccTail 6.08\n",
      "Epoch: [007] \t Loss 3.4299 \t Acc 16.66 \t AccHead 20.87 \t AccTail 3.11\n",
      "Epoch: [008] \t Loss 3.3988 \t Acc 17.61 \t AccHead 21.56 \t AccTail 4.89\n",
      "Epoch: [009] \t Loss 3.3701 \t Acc 14.95 \t AccHead 17.63 \t AccTail 6.30\n",
      "Epoch: [010] \t Loss 3.3081 \t Acc 21.30 \t AccHead 25.75 \t AccTail 6.97\n",
      "Epoch: [011] \t Loss 3.2978 \t Acc 19.12 \t AccHead 22.56 \t AccTail 8.07\n",
      "Epoch: [012] \t Loss 3.2578 \t Acc 21.04 \t AccHead 24.34 \t AccTail 10.40\n",
      "Epoch: [013] \t Loss 3.2281 \t Acc 18.02 \t AccHead 21.23 \t AccTail 7.70\n",
      "Epoch: [014] \t Loss 3.2037 \t Acc 19.95 \t AccHead 23.22 \t AccTail 9.43\n",
      "Epoch: [015] \t Loss 3.1902 \t Acc 21.29 \t AccHead 26.01 \t AccTail 6.08\n",
      "Epoch: [016] \t Loss 3.1823 \t Acc 24.31 \t AccHead 28.88 \t AccTail 9.60\n",
      "Epoch: [017] \t Loss 3.1680 \t Acc 21.71 \t AccHead 25.76 \t AccTail 8.65\n",
      "Epoch: [018] \t Loss 3.1683 \t Acc 19.90 \t AccHead 23.95 \t AccTail 6.86\n",
      "Epoch: [019] \t Loss 3.1513 \t Acc 19.29 \t AccHead 23.38 \t AccTail 6.16\n",
      "Epoch: [020] \t Loss 3.1358 \t Acc 21.26 \t AccHead 25.27 \t AccTail 8.35\n",
      "Epoch: [021] \t Loss 3.1300 \t Acc 18.01 \t AccHead 21.92 \t AccTail 5.40\n",
      "Epoch: [022] \t Loss 3.1388 \t Acc 19.21 \t AccHead 22.81 \t AccTail 7.62\n",
      "Epoch: [023] \t Loss 3.1210 \t Acc 20.63 \t AccHead 24.17 \t AccTail 9.26\n",
      "Epoch: [024] \t Loss 3.1011 \t Acc 21.92 \t AccHead 26.88 \t AccTail 5.94\n",
      "Epoch: [025] \t Loss 3.0928 \t Acc 20.70 \t AccHead 24.04 \t AccTail 9.91\n",
      "Epoch: [026] \t Loss 3.1099 \t Acc 24.12 \t AccHead 29.00 \t AccTail 8.36\n",
      "Epoch: [027] \t Loss 3.1079 \t Acc 20.76 \t AccHead 25.87 \t AccTail 4.32\n",
      "Epoch: [028] \t Loss 3.0963 \t Acc 20.54 \t AccHead 24.85 \t AccTail 6.66\n",
      "Epoch: [029] \t Loss 3.0883 \t Acc 18.10 \t AccHead 21.25 \t AccTail 7.95\n",
      "Epoch: [030] \t Loss 3.0929 \t Acc 21.27 \t AccHead 25.43 \t AccTail 7.93\n",
      "Epoch: [031] \t Loss 3.0658 \t Acc 24.71 \t AccHead 28.70 \t AccTail 11.84\n",
      "Epoch: [032] \t Loss 3.1066 \t Acc 13.36 \t AccHead 16.35 \t AccTail 3.76\n",
      "Epoch: [033] \t Loss 3.0848 \t Acc 21.63 \t AccHead 25.20 \t AccTail 10.12\n",
      "Epoch: [034] \t Loss 3.0848 \t Acc 23.66 \t AccHead 28.25 \t AccTail 8.84\n",
      "Epoch: [035] \t Loss 3.0747 \t Acc 18.25 \t AccHead 21.03 \t AccTail 9.30\n",
      "Epoch: [036] \t Loss 3.0894 \t Acc 20.16 \t AccHead 24.41 \t AccTail 6.48\n",
      "Epoch: [037] \t Loss 3.0791 \t Acc 22.51 \t AccHead 26.02 \t AccTail 11.19\n",
      "Epoch: [038] \t Loss 3.0850 \t Acc 22.15 \t AccHead 26.38 \t AccTail 8.52\n",
      "Epoch: [039] \t Loss 3.0833 \t Acc 23.13 \t AccHead 28.10 \t AccTail 7.11\n",
      "Epoch: [040] \t Loss 3.0722 \t Acc 19.01 \t AccHead 22.16 \t AccTail 8.84\n",
      "Epoch: [041] \t Loss 3.0772 \t Acc 18.14 \t AccHead 21.75 \t AccTail 6.51\n",
      "Epoch: [042] \t Loss 3.0721 \t Acc 22.13 \t AccHead 26.70 \t AccTail 7.45\n",
      "Epoch: [043] \t Loss 3.0772 \t Acc 25.40 \t AccHead 30.41 \t AccTail 9.28\n",
      "Epoch: [044] \t Loss 3.0601 \t Acc 23.40 \t AccHead 27.76 \t AccTail 9.35\n",
      "Epoch: [045] \t Loss 3.0587 \t Acc 19.18 \t AccHead 23.14 \t AccTail 6.43\n",
      "Epoch: [046] \t Loss 3.0837 \t Acc 23.62 \t AccHead 28.69 \t AccTail 7.29\n",
      "Epoch: [047] \t Loss 3.0519 \t Acc 21.98 \t AccHead 26.46 \t AccTail 7.56\n",
      "Epoch: [048] \t Loss 3.0636 \t Acc 21.84 \t AccHead 25.69 \t AccTail 9.45\n",
      "Epoch: [049] \t Loss 3.0870 \t Acc 18.53 \t AccHead 22.16 \t AccTail 6.86\n",
      "Epoch: [050] \t Loss 3.0824 \t Acc 20.59 \t AccHead 24.68 \t AccTail 7.42\n",
      "Epoch: [051] \t Loss 3.0748 \t Acc 19.50 \t AccHead 22.73 \t AccTail 9.10\n",
      "Epoch: [052] \t Loss 3.0603 \t Acc 18.70 \t AccHead 22.31 \t AccTail 7.08\n",
      "Epoch: [053] \t Loss 3.0563 \t Acc 19.58 \t AccHead 23.50 \t AccTail 6.95\n",
      "Epoch: [054] \t Loss 3.0689 \t Acc 24.71 \t AccHead 29.96 \t AccTail 7.80\n",
      "Epoch: [055] \t Loss 3.0698 \t Acc 21.28 \t AccHead 24.03 \t AccTail 12.43\n",
      "Epoch: [056] \t Loss 3.0471 \t Acc 22.27 \t AccHead 26.28 \t AccTail 9.37\n",
      "Epoch: [057] \t Loss 3.0695 \t Acc 19.44 \t AccHead 22.75 \t AccTail 8.77\n",
      "Epoch: [058] \t Loss 3.0782 \t Acc 21.52 \t AccHead 24.98 \t AccTail 10.37\n",
      "Epoch: [059] \t Loss 3.0695 \t Acc 23.30 \t AccHead 27.76 \t AccTail 8.97\n",
      "Epoch: [060] \t Loss 3.0669 \t Acc 20.31 \t AccHead 25.25 \t AccTail 4.40\n",
      "Epoch: [061] \t Loss 3.0525 \t Acc 19.33 \t AccHead 23.54 \t AccTail 5.76\n",
      "Epoch: [062] \t Loss 3.0644 \t Acc 21.96 \t AccHead 26.88 \t AccTail 6.13\n",
      "Epoch: [063] \t Loss 3.0435 \t Acc 17.89 \t AccHead 22.00 \t AccTail 4.65\n",
      "Epoch: [064] \t Loss 3.0626 \t Acc 17.24 \t AccHead 20.20 \t AccTail 7.68\n",
      "Epoch: [065] \t Loss 3.0580 \t Acc 22.41 \t AccHead 27.11 \t AccTail 7.27\n",
      "Epoch: [066] \t Loss 3.0591 \t Acc 20.09 \t AccHead 23.22 \t AccTail 10.03\n",
      "Epoch: [067] \t Loss 3.0762 \t Acc 21.71 \t AccHead 26.53 \t AccTail 6.17\n",
      "Epoch: [068] \t Loss 3.0695 \t Acc 20.59 \t AccHead 24.07 \t AccTail 9.38\n",
      "Epoch: [069] \t Loss 3.0585 \t Acc 22.22 \t AccHead 26.10 \t AccTail 9.72\n",
      "Epoch: [070] \t Loss 3.0629 \t Acc 17.47 \t AccHead 19.94 \t AccTail 9.49\n",
      "Epoch: [071] \t Loss 3.0783 \t Acc 23.20 \t AccHead 28.36 \t AccTail 6.61\n",
      "Epoch: [072] \t Loss 3.0488 \t Acc 25.77 \t AccHead 31.13 \t AccTail 8.53\n",
      "Epoch: [073] \t Loss 3.0609 \t Acc 24.80 \t AccHead 29.71 \t AccTail 8.99\n",
      "Epoch: [074] \t Loss 3.0756 \t Acc 20.74 \t AccHead 25.17 \t AccTail 6.48\n",
      "Epoch: [075] \t Loss 3.0793 \t Acc 22.53 \t AccHead 26.97 \t AccTail 8.24\n",
      "Epoch: [076] \t Loss 3.0624 \t Acc 23.34 \t AccHead 27.57 \t AccTail 9.72\n",
      "Epoch: [077] \t Loss 3.0628 \t Acc 21.64 \t AccHead 25.80 \t AccTail 8.26\n",
      "Epoch: [078] \t Loss 3.0869 \t Acc 22.53 \t AccHead 27.03 \t AccTail 8.03\n",
      "Epoch: [079] \t Loss 3.0828 \t Acc 20.01 \t AccHead 23.02 \t AccTail 10.30\n",
      "Epoch: [080] \t Loss 3.0671 \t Acc 22.10 \t AccHead 26.87 \t AccTail 6.75\n",
      "Epoch: [081] \t Loss 3.0656 \t Acc 15.31 \t AccHead 17.65 \t AccTail 7.78\n",
      "Epoch: [082] \t Loss 3.0482 \t Acc 23.94 \t AccHead 28.56 \t AccTail 9.06\n",
      "Epoch: [083] \t Loss 3.0716 \t Acc 22.16 \t AccHead 25.23 \t AccTail 12.26\n",
      "Epoch: [084] \t Loss 3.0675 \t Acc 22.05 \t AccHead 27.41 \t AccTail 4.78\n",
      "Epoch: [085] \t Loss 3.0498 \t Acc 23.19 \t AccHead 28.05 \t AccTail 7.54\n",
      "Epoch: [086] \t Loss 3.0661 \t Acc 18.24 \t AccHead 21.68 \t AccTail 7.19\n",
      "Epoch: [087] \t Loss 3.0542 \t Acc 23.33 \t AccHead 28.06 \t AccTail 8.10\n",
      "Epoch: [088] \t Loss 3.0675 \t Acc 25.11 \t AccHead 28.61 \t AccTail 13.81\n",
      "Epoch: [089] \t Loss 3.0712 \t Acc 16.44 \t AccHead 19.98 \t AccTail 5.06\n",
      "Epoch: [090] \t Loss 3.0688 \t Acc 19.24 \t AccHead 23.05 \t AccTail 6.97\n",
      "Epoch: [091] \t Loss 3.0605 \t Acc 20.68 \t AccHead 24.20 \t AccTail 9.35\n",
      "Epoch: [092] \t Loss 3.0689 \t Acc 20.34 \t AccHead 23.95 \t AccTail 8.71\n",
      "Epoch: [093] \t Loss 3.0542 \t Acc 20.15 \t AccHead 22.64 \t AccTail 12.16\n",
      "Epoch: [094] \t Loss 3.0620 \t Acc 25.63 \t AccHead 30.13 \t AccTail 11.16\n",
      "Epoch: [095] \t Loss 3.0674 \t Acc 23.13 \t AccHead 26.96 \t AccTail 10.80\n",
      "Epoch: [096] \t Loss 3.0768 \t Acc 20.17 \t AccHead 24.69 \t AccTail 5.59\n",
      "Epoch: [097] \t Loss 3.0687 \t Acc 24.74 \t AccHead 28.69 \t AccTail 12.02\n",
      "Epoch: [098] \t Loss 3.0804 \t Acc 17.35 \t AccHead 20.82 \t AccTail 6.19\n",
      "Epoch: [099] \t Loss 3.0747 \t Acc 23.41 \t AccHead 27.68 \t AccTail 9.65\n",
      "Epoch: [100] \t Loss 3.0852 \t Acc 22.16 \t AccHead 26.67 \t AccTail 7.65\n",
      "Epoch: [101] \t Loss 3.0860 \t Acc 23.33 \t AccHead 28.30 \t AccTail 7.33\n",
      "Epoch: [102] \t Loss 3.0706 \t Acc 23.59 \t AccHead 28.24 \t AccTail 8.62\n",
      "Epoch: [103] \t Loss 3.0525 \t Acc 21.59 \t AccHead 25.91 \t AccTail 7.65\n",
      "Epoch: [104] \t Loss 3.0636 \t Acc 23.72 \t AccHead 28.52 \t AccTail 8.27\n",
      "Epoch: [105] \t Loss 3.0686 \t Acc 21.42 \t AccHead 25.74 \t AccTail 7.51\n",
      "Epoch: [106] \t Loss 3.0800 \t Acc 20.17 \t AccHead 23.29 \t AccTail 10.15\n",
      "Epoch: [107] \t Loss 3.0787 \t Acc 21.11 \t AccHead 24.63 \t AccTail 9.75\n",
      "Epoch: [108] \t Loss 3.0512 \t Acc 23.44 \t AccHead 28.08 \t AccTail 8.49\n",
      "Epoch: [109] \t Loss 3.0747 \t Acc 22.95 \t AccHead 27.09 \t AccTail 9.64\n",
      "Epoch: [110] \t Loss 3.0653 \t Acc 15.33 \t AccHead 18.99 \t AccTail 3.57\n",
      "Epoch: [111] \t Loss 3.0728 \t Acc 22.45 \t AccHead 26.61 \t AccTail 9.05\n",
      "Epoch: [112] \t Loss 3.0607 \t Acc 19.58 \t AccHead 22.75 \t AccTail 9.35\n",
      "Epoch: [113] \t Loss 3.0611 \t Acc 24.17 \t AccHead 28.65 \t AccTail 9.73\n",
      "Epoch: [114] \t Loss 3.0664 \t Acc 24.93 \t AccHead 30.06 \t AccTail 8.41\n",
      "Epoch: [115] \t Loss 3.0663 \t Acc 24.88 \t AccHead 29.30 \t AccTail 10.65\n",
      "Epoch: [116] \t Loss 3.0814 \t Acc 24.41 \t AccHead 29.13 \t AccTail 9.24\n",
      "Epoch: [117] \t Loss 3.0640 \t Acc 22.55 \t AccHead 26.16 \t AccTail 10.90\n",
      "Epoch: [118] \t Loss 3.0777 \t Acc 18.65 \t AccHead 21.37 \t AccTail 9.89\n",
      "Epoch: [119] \t Loss 3.0439 \t Acc 23.38 \t AccHead 27.02 \t AccTail 11.67\n",
      "Epoch: [120] \t Loss 3.0825 \t Acc 22.16 \t AccHead 26.75 \t AccTail 7.42\n",
      "Epoch: [121] \t Loss 3.0549 \t Acc 20.08 \t AccHead 24.24 \t AccTail 6.67\n",
      "Epoch: [122] \t Loss 3.0778 \t Acc 21.98 \t AccHead 25.57 \t AccTail 10.45\n",
      "Epoch: [123] \t Loss 3.0557 \t Acc 21.99 \t AccHead 26.13 \t AccTail 8.67\n",
      "Epoch: [124] \t Loss 3.0702 \t Acc 24.62 \t AccHead 29.66 \t AccTail 8.38\n",
      "Epoch: [125] \t Loss 3.0806 \t Acc 25.17 \t AccHead 30.11 \t AccTail 9.25\n",
      "Epoch: [126] \t Loss 3.0734 \t Acc 24.69 \t AccHead 29.18 \t AccTail 10.24\n",
      "Epoch: [127] \t Loss 3.0580 \t Acc 23.16 \t AccHead 27.82 \t AccTail 8.18\n",
      "Epoch: [128] \t Loss 3.0818 \t Acc 19.90 \t AccHead 23.14 \t AccTail 9.46\n",
      "Epoch: [129] \t Loss 3.0799 \t Acc 22.27 \t AccHead 25.60 \t AccTail 11.53\n",
      "Epoch: [130] \t Loss 3.0639 \t Acc 22.21 \t AccHead 26.15 \t AccTail 9.52\n",
      "Epoch: [131] \t Loss 3.0788 \t Acc 22.09 \t AccHead 26.56 \t AccTail 7.72\n",
      "Epoch: [132] \t Loss 3.0664 \t Acc 24.33 \t AccHead 27.99 \t AccTail 12.52\n",
      "Epoch: [133] \t Loss 3.0814 \t Acc 22.57 \t AccHead 26.57 \t AccTail 9.68\n",
      "Epoch: [134] \t Loss 3.0974 \t Acc 22.04 \t AccHead 26.45 \t AccTail 7.83\n",
      "Epoch: [135] \t Loss 3.0480 \t Acc 19.24 \t AccHead 23.25 \t AccTail 6.32\n",
      "Epoch: [136] \t Loss 3.0858 \t Acc 18.60 \t AccHead 22.79 \t AccTail 5.11\n",
      "Epoch: [137] \t Loss 3.0549 \t Acc 25.46 \t AccHead 30.14 \t AccTail 10.40\n",
      "Epoch: [138] \t Loss 3.0649 \t Acc 18.12 \t AccHead 21.13 \t AccTail 8.43\n",
      "Epoch: [139] \t Loss 3.0711 \t Acc 23.57 \t AccHead 28.66 \t AccTail 7.14\n",
      "Epoch: [140] \t Loss 3.0568 \t Acc 20.93 \t AccHead 24.90 \t AccTail 8.11\n",
      "Epoch: [141] \t Loss 3.0849 \t Acc 21.41 \t AccHead 25.44 \t AccTail 8.41\n",
      "Epoch: [142] \t Loss 3.0922 \t Acc 20.31 \t AccHead 24.90 \t AccTail 5.51\n",
      "Epoch: [143] \t Loss 3.0776 \t Acc 18.89 \t AccHead 23.16 \t AccTail 5.14\n",
      "Epoch: [144] \t Loss 3.0825 \t Acc 23.82 \t AccHead 28.42 \t AccTail 9.02\n",
      "Epoch: [145] \t Loss 3.0563 \t Acc 17.98 \t AccHead 20.93 \t AccTail 8.49\n",
      "Epoch: [146] \t Loss 3.0799 \t Acc 19.83 \t AccHead 23.95 \t AccTail 6.57\n",
      "Epoch: [147] \t Loss 3.0861 \t Acc 20.62 \t AccHead 24.67 \t AccTail 7.57\n",
      "Epoch: [148] \t Loss 3.1015 \t Acc 23.34 \t AccHead 27.81 \t AccTail 8.92\n",
      "Epoch: [149] \t Loss 3.0661 \t Acc 12.31 \t AccHead 14.12 \t AccTail 6.51\n",
      "Epoch: [150] \t Loss 3.0785 \t Acc 22.96 \t AccHead 26.50 \t AccTail 11.59\n",
      "Epoch: [151] \t Loss 2.6909 \t Acc 38.76 \t AccHead 45.25 \t AccTail 17.86\n",
      "Epoch: [152] \t Loss 2.4870 \t Acc 40.68 \t AccHead 47.26 \t AccTail 19.49\n",
      "Epoch: [153] \t Loss 2.4083 \t Acc 42.83 \t AccHead 49.72 \t AccTail 20.65\n",
      "Epoch: [154] \t Loss 2.3509 \t Acc 41.17 \t AccHead 47.69 \t AccTail 20.16\n",
      "Epoch: [155] \t Loss 2.3073 \t Acc 43.88 \t AccHead 50.86 \t AccTail 21.42\n",
      "Epoch: [156] \t Loss 2.2722 \t Acc 43.50 \t AccHead 49.55 \t AccTail 24.03\n",
      "Epoch: [157] \t Loss 2.2354 \t Acc 44.76 \t AccHead 52.17 \t AccTail 20.90\n",
      "Epoch: [158] \t Loss 2.2211 \t Acc 45.38 \t AccHead 51.51 \t AccTail 25.66\n",
      "Epoch: [159] \t Loss 2.1832 \t Acc 45.72 \t AccHead 52.53 \t AccTail 23.77\n",
      "Epoch: [160] \t Loss 2.1769 \t Acc 45.86 \t AccHead 52.23 \t AccTail 25.35\n",
      "Epoch: [161] \t Loss 2.1514 \t Acc 47.00 \t AccHead 53.11 \t AccTail 27.31\n",
      "Epoch: [162] \t Loss 2.1349 \t Acc 47.69 \t AccHead 54.01 \t AccTail 27.34\n",
      "Epoch: [163] \t Loss 2.1075 \t Acc 43.93 \t AccHead 50.65 \t AccTail 22.25\n",
      "Epoch: [164] \t Loss 2.1000 \t Acc 46.70 \t AccHead 53.64 \t AccTail 24.34\n",
      "Epoch: [165] \t Loss 2.0693 \t Acc 50.04 \t AccHead 56.24 \t AccTail 30.06\n",
      "Epoch: [166] \t Loss 2.0547 \t Acc 48.54 \t AccHead 54.92 \t AccTail 28.00\n",
      "Epoch: [167] \t Loss 2.0327 \t Acc 47.06 \t AccHead 53.40 \t AccTail 26.68\n",
      "Epoch: [168] \t Loss 2.0135 \t Acc 45.99 \t AccHead 51.69 \t AccTail 27.67\n",
      "Epoch: [169] \t Loss 2.0094 \t Acc 49.10 \t AccHead 56.22 \t AccTail 26.16\n",
      "Epoch: [170] \t Loss 1.9734 \t Acc 51.93 \t AccHead 58.57 \t AccTail 30.51\n",
      "Epoch: [171] \t Loss 1.9676 \t Acc 51.49 \t AccHead 58.27 \t AccTail 29.61\n",
      "Epoch: [172] \t Loss 1.9186 \t Acc 49.26 \t AccHead 55.73 \t AccTail 28.44\n",
      "Epoch: [173] \t Loss 1.9096 \t Acc 51.72 \t AccHead 57.79 \t AccTail 32.17\n",
      "Epoch: [174] \t Loss 1.9152 \t Acc 50.74 \t AccHead 57.21 \t AccTail 29.93\n",
      "Epoch: [175] \t Loss 1.8624 \t Acc 51.14 \t AccHead 57.15 \t AccTail 31.80\n",
      "Epoch: [176] \t Loss 1.8534 \t Acc 52.24 \t AccHead 58.59 \t AccTail 31.79\n",
      "Epoch: [177] \t Loss 1.8322 \t Acc 51.58 \t AccHead 57.74 \t AccTail 31.76\n",
      "Epoch: [178] \t Loss 1.8321 \t Acc 52.37 \t AccHead 59.03 \t AccTail 30.89\n",
      "Epoch: [179] \t Loss 1.8060 \t Acc 52.39 \t AccHead 58.91 \t AccTail 31.41\n",
      "Epoch: [180] \t Loss 1.8106 \t Acc 51.46 \t AccHead 58.07 \t AccTail 30.17\n",
      "Epoch: [181] \t Loss 1.7634 \t Acc 51.66 \t AccHead 58.20 \t AccTail 30.62\n",
      "Epoch: [182] \t Loss 1.7664 \t Acc 54.15 \t AccHead 59.39 \t AccTail 37.31\n",
      "Epoch: [183] \t Loss 1.7367 \t Acc 54.83 \t AccHead 61.20 \t AccTail 34.32\n",
      "Epoch: [184] \t Loss 1.7311 \t Acc 53.78 \t AccHead 59.37 \t AccTail 35.80\n",
      "Epoch: [185] \t Loss 1.7205 \t Acc 56.55 \t AccHead 63.51 \t AccTail 34.17\n",
      "Epoch: [186] \t Loss 1.6913 \t Acc 56.17 \t AccHead 61.48 \t AccTail 39.08\n",
      "Epoch: [187] \t Loss 1.6590 \t Acc 55.34 \t AccHead 61.63 \t AccTail 35.12\n",
      "Epoch: [188] \t Loss 1.6543 \t Acc 54.89 \t AccHead 61.25 \t AccTail 34.44\n",
      "Epoch: [189] \t Loss 1.6515 \t Acc 57.87 \t AccHead 64.01 \t AccTail 38.10\n",
      "Epoch: [190] \t Loss 1.6152 \t Acc 59.98 \t AccHead 66.76 \t AccTail 38.17\n",
      "Epoch: [191] \t Loss 1.6022 \t Acc 56.90 \t AccHead 62.90 \t AccTail 37.60\n",
      "Epoch: [192] \t Loss 1.6037 \t Acc 57.49 \t AccHead 63.54 \t AccTail 37.99\n",
      "Epoch: [193] \t Loss 1.5717 \t Acc 57.69 \t AccHead 63.29 \t AccTail 39.68\n",
      "Epoch: [194] \t Loss 1.5687 \t Acc 60.07 \t AccHead 66.33 \t AccTail 39.90\n",
      "Epoch: [195] \t Loss 1.5638 \t Acc 59.60 \t AccHead 64.90 \t AccTail 42.49\n",
      "Epoch: [196] \t Loss 1.5503 \t Acc 58.93 \t AccHead 65.45 \t AccTail 37.93\n",
      "Epoch: [197] \t Loss 1.5177 \t Acc 59.94 \t AccHead 66.40 \t AccTail 39.19\n",
      "Epoch: [198] \t Loss 1.5264 \t Acc 58.64 \t AccHead 64.85 \t AccTail 38.68\n",
      "Epoch: [199] \t Loss 1.5059 \t Acc 61.05 \t AccHead 66.78 \t AccTail 42.58\n",
      "Epoch: [200] \t Loss 1.4958 \t Acc 58.58 \t AccHead 63.80 \t AccTail 41.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 13:58:48,934]\u001b[0m Trial 10 finished with value: 9.394377708435059 and parameters: {'n_epoch': 200, 'weight_decay': 0.003728674914045116}. Best is trial 6 with value: 10.572550773620605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 9.39 \t AccHead 18.67 \t AccTail 0.27\n",
      "Epoch: [001] \t Loss 4.4140 \t Acc 6.04 \t AccHead 7.90 \t AccTail 0.03\n",
      "Epoch: [002] \t Loss 3.8572 \t Acc 10.98 \t AccHead 14.37 \t AccTail 0.03\n",
      "Epoch: [003] \t Loss 3.7204 \t Acc 13.85 \t AccHead 17.28 \t AccTail 2.79\n",
      "Epoch: [004] \t Loss 3.6362 \t Acc 12.48 \t AccHead 15.80 \t AccTail 1.81\n",
      "Epoch: [005] \t Loss 3.5678 \t Acc 16.06 \t AccHead 19.79 \t AccTail 4.03\n",
      "Epoch: [006] \t Loss 3.5016 \t Acc 15.18 \t AccHead 18.09 \t AccTail 5.81\n",
      "Epoch: [007] \t Loss 3.4561 \t Acc 16.49 \t AccHead 19.75 \t AccTail 6.00\n",
      "Epoch: [008] \t Loss 3.4502 \t Acc 18.69 \t AccHead 23.51 \t AccTail 3.16\n",
      "Epoch: [009] \t Loss 3.3886 \t Acc 16.41 \t AccHead 19.12 \t AccTail 7.70\n",
      "Epoch: [010] \t Loss 3.3644 \t Acc 16.28 \t AccHead 19.84 \t AccTail 4.83\n",
      "Epoch: [011] \t Loss 3.3679 \t Acc 17.85 \t AccHead 21.87 \t AccTail 4.89\n",
      "Epoch: [012] \t Loss 3.3404 \t Acc 18.36 \t AccHead 21.79 \t AccTail 7.32\n",
      "Epoch: [013] \t Loss 3.3113 \t Acc 16.50 \t AccHead 20.25 \t AccTail 4.43\n",
      "Epoch: [014] \t Loss 3.2895 \t Acc 20.59 \t AccHead 24.75 \t AccTail 7.19\n",
      "Epoch: [015] \t Loss 3.2800 \t Acc 17.76 \t AccHead 22.69 \t AccTail 1.86\n",
      "Epoch: [016] \t Loss 3.2489 \t Acc 19.36 \t AccHead 23.95 \t AccTail 4.59\n",
      "Epoch: [017] \t Loss 3.2207 \t Acc 18.90 \t AccHead 22.32 \t AccTail 7.89\n",
      "Epoch: [018] \t Loss 3.2478 \t Acc 19.60 \t AccHead 23.18 \t AccTail 8.08\n",
      "Epoch: [019] \t Loss 3.2285 \t Acc 21.77 \t AccHead 26.54 \t AccTail 6.45\n",
      "Epoch: [020] \t Loss 3.2216 \t Acc 20.82 \t AccHead 24.77 \t AccTail 8.11\n",
      "Epoch: [021] \t Loss 3.2183 \t Acc 21.03 \t AccHead 25.56 \t AccTail 6.45\n",
      "Epoch: [022] \t Loss 3.2157 \t Acc 20.07 \t AccHead 23.73 \t AccTail 8.27\n",
      "Epoch: [023] \t Loss 3.1990 \t Acc 18.55 \t AccHead 21.17 \t AccTail 10.08\n",
      "Epoch: [024] \t Loss 3.2107 \t Acc 17.42 \t AccHead 21.13 \t AccTail 5.48\n",
      "Epoch: [025] \t Loss 3.1821 \t Acc 21.55 \t AccHead 25.28 \t AccTail 9.54\n",
      "Epoch: [026] \t Loss 3.1879 \t Acc 20.97 \t AccHead 24.91 \t AccTail 8.27\n",
      "Epoch: [027] \t Loss 3.1732 \t Acc 20.22 \t AccHead 23.97 \t AccTail 8.12\n",
      "Epoch: [028] \t Loss 3.1848 \t Acc 19.59 \t AccHead 23.51 \t AccTail 6.97\n",
      "Epoch: [029] \t Loss 3.1978 \t Acc 21.73 \t AccHead 26.10 \t AccTail 7.70\n",
      "Epoch: [030] \t Loss 3.1805 \t Acc 20.61 \t AccHead 24.62 \t AccTail 7.70\n",
      "Epoch: [031] \t Loss 3.1731 \t Acc 9.33 \t AccHead 10.98 \t AccTail 4.02\n",
      "Epoch: [032] \t Loss 3.1739 \t Acc 18.88 \t AccHead 22.97 \t AccTail 5.73\n",
      "Epoch: [033] \t Loss 3.1704 \t Acc 19.13 \t AccHead 23.27 \t AccTail 5.83\n",
      "Epoch: [034] \t Loss 3.1603 \t Acc 19.55 \t AccHead 22.48 \t AccTail 10.13\n",
      "Epoch: [035] \t Loss 3.1500 \t Acc 20.61 \t AccHead 25.05 \t AccTail 6.32\n",
      "Epoch: [036] \t Loss 3.1688 \t Acc 21.34 \t AccHead 25.38 \t AccTail 8.32\n",
      "Epoch: [037] \t Loss 3.1715 \t Acc 19.43 \t AccHead 23.48 \t AccTail 6.36\n",
      "Epoch: [038] \t Loss 3.1684 \t Acc 22.02 \t AccHead 26.09 \t AccTail 8.93\n",
      "Epoch: [039] \t Loss 3.1694 \t Acc 18.71 \t AccHead 22.52 \t AccTail 6.46\n",
      "Epoch: [040] \t Loss 3.1623 \t Acc 24.26 \t AccHead 29.96 \t AccTail 5.91\n",
      "Epoch: [041] \t Loss 3.1592 \t Acc 15.46 \t AccHead 17.41 \t AccTail 9.21\n",
      "Epoch: [042] \t Loss 3.1615 \t Acc 21.87 \t AccHead 26.57 \t AccTail 6.73\n",
      "Epoch: [043] \t Loss 3.1630 \t Acc 21.71 \t AccHead 26.24 \t AccTail 7.16\n",
      "Epoch: [044] \t Loss 3.1658 \t Acc 15.36 \t AccHead 18.70 \t AccTail 4.64\n",
      "Epoch: [045] \t Loss 3.1549 \t Acc 20.98 \t AccHead 24.93 \t AccTail 8.30\n",
      "Epoch: [046] \t Loss 3.1527 \t Acc 21.48 \t AccHead 26.07 \t AccTail 6.72\n",
      "Epoch: [047] \t Loss 3.1738 \t Acc 19.90 \t AccHead 23.46 \t AccTail 8.43\n",
      "Epoch: [048] \t Loss 3.1664 \t Acc 20.46 \t AccHead 23.94 \t AccTail 9.25\n",
      "Epoch: [049] \t Loss 3.1681 \t Acc 21.61 \t AccHead 25.68 \t AccTail 8.51\n",
      "Epoch: [050] \t Loss 3.1614 \t Acc 18.80 \t AccHead 22.45 \t AccTail 7.05\n",
      "Epoch: [051] \t Loss 3.1366 \t Acc 22.50 \t AccHead 27.35 \t AccTail 6.86\n",
      "Epoch: [052] \t Loss 3.1534 \t Acc 21.41 \t AccHead 26.55 \t AccTail 4.84\n",
      "Epoch: [053] \t Loss 3.1714 \t Acc 18.37 \t AccHead 21.73 \t AccTail 7.54\n",
      "Epoch: [054] \t Loss 3.1675 \t Acc 21.06 \t AccHead 25.59 \t AccTail 6.48\n",
      "Epoch: [055] \t Loss 3.1631 \t Acc 21.71 \t AccHead 26.36 \t AccTail 6.74\n",
      "Epoch: [056] \t Loss 3.1509 \t Acc 20.29 \t AccHead 24.11 \t AccTail 7.97\n",
      "Epoch: [057] \t Loss 3.1885 \t Acc 22.69 \t AccHead 26.94 \t AccTail 9.00\n",
      "Epoch: [058] \t Loss 3.1468 \t Acc 22.04 \t AccHead 26.86 \t AccTail 6.56\n",
      "Epoch: [059] \t Loss 3.1463 \t Acc 23.09 \t AccHead 28.27 \t AccTail 6.38\n",
      "Epoch: [060] \t Loss 3.1533 \t Acc 20.36 \t AccHead 24.65 \t AccTail 6.54\n",
      "Epoch: [061] \t Loss 3.1531 \t Acc 19.89 \t AccHead 24.34 \t AccTail 5.57\n",
      "Epoch: [062] \t Loss 3.1623 \t Acc 22.47 \t AccHead 27.74 \t AccTail 5.47\n",
      "Epoch: [063] \t Loss 3.1876 \t Acc 20.09 \t AccHead 23.68 \t AccTail 8.54\n",
      "Epoch: [064] \t Loss 3.1678 \t Acc 20.53 \t AccHead 24.76 \t AccTail 6.91\n",
      "Epoch: [065] \t Loss 3.1624 \t Acc 20.82 \t AccHead 25.35 \t AccTail 6.27\n",
      "Epoch: [066] \t Loss 3.1614 \t Acc 20.88 \t AccHead 24.73 \t AccTail 8.51\n",
      "Epoch: [067] \t Loss 3.1491 \t Acc 20.58 \t AccHead 24.43 \t AccTail 8.21\n",
      "Epoch: [068] \t Loss 3.1701 \t Acc 20.08 \t AccHead 23.64 \t AccTail 8.60\n",
      "Epoch: [069] \t Loss 3.1432 \t Acc 16.49 \t AccHead 19.88 \t AccTail 5.59\n",
      "Epoch: [070] \t Loss 3.1775 \t Acc 20.98 \t AccHead 24.28 \t AccTail 10.39\n",
      "Epoch: [071] \t Loss 3.1846 \t Acc 19.45 \t AccHead 23.10 \t AccTail 7.72\n",
      "Epoch: [072] \t Loss 3.1682 \t Acc 18.95 \t AccHead 23.16 \t AccTail 5.41\n",
      "Epoch: [073] \t Loss 3.1463 \t Acc 22.45 \t AccHead 27.90 \t AccTail 4.89\n",
      "Epoch: [074] \t Loss 3.1682 \t Acc 19.86 \t AccHead 24.24 \t AccTail 5.75\n",
      "Epoch: [075] \t Loss 3.1724 \t Acc 19.97 \t AccHead 24.36 \t AccTail 5.84\n",
      "Epoch: [076] \t Loss 3.1658 \t Acc 21.91 \t AccHead 26.42 \t AccTail 7.37\n",
      "Epoch: [077] \t Loss 3.1622 \t Acc 19.50 \t AccHead 24.14 \t AccTail 4.57\n",
      "Epoch: [078] \t Loss 3.1581 \t Acc 24.28 \t AccHead 30.03 \t AccTail 5.76\n",
      "Epoch: [079] \t Loss 3.1682 \t Acc 22.28 \t AccHead 27.15 \t AccTail 6.60\n",
      "Epoch: [080] \t Loss 3.1759 \t Acc 11.58 \t AccHead 13.55 \t AccTail 5.22\n",
      "Epoch: [081] \t Loss 3.1734 \t Acc 24.12 \t AccHead 28.29 \t AccTail 10.69\n",
      "Epoch: [082] \t Loss 3.1541 \t Acc 22.86 \t AccHead 26.92 \t AccTail 9.80\n",
      "Epoch: [083] \t Loss 3.1537 \t Acc 21.31 \t AccHead 26.01 \t AccTail 6.16\n",
      "Epoch: [084] \t Loss 3.1375 \t Acc 15.66 \t AccHead 18.19 \t AccTail 7.51\n",
      "Epoch: [085] \t Loss 3.1563 \t Acc 19.45 \t AccHead 23.11 \t AccTail 7.69\n",
      "Epoch: [086] \t Loss 3.1525 \t Acc 18.96 \t AccHead 22.61 \t AccTail 7.21\n",
      "Epoch: [087] \t Loss 3.1710 \t Acc 20.04 \t AccHead 24.74 \t AccTail 4.94\n",
      "Epoch: [088] \t Loss 3.1658 \t Acc 22.26 \t AccHead 26.64 \t AccTail 8.16\n",
      "Epoch: [089] \t Loss 3.1747 \t Acc 18.91 \t AccHead 22.60 \t AccTail 7.05\n",
      "Epoch: [090] \t Loss 3.1687 \t Acc 17.83 \t AccHead 21.41 \t AccTail 6.32\n",
      "Epoch: [091] \t Loss 3.1725 \t Acc 20.22 \t AccHead 24.22 \t AccTail 7.35\n",
      "Epoch: [092] \t Loss 3.1546 \t Acc 20.79 \t AccHead 24.09 \t AccTail 10.14\n",
      "Epoch: [093] \t Loss 3.1638 \t Acc 22.08 \t AccHead 27.33 \t AccTail 5.16\n",
      "Epoch: [094] \t Loss 3.1632 \t Acc 22.97 \t AccHead 28.10 \t AccTail 6.46\n",
      "Epoch: [095] \t Loss 3.1958 \t Acc 22.25 \t AccHead 26.72 \t AccTail 7.86\n",
      "Epoch: [096] \t Loss 3.1512 \t Acc 19.11 \t AccHead 22.36 \t AccTail 8.64\n",
      "Epoch: [097] \t Loss 3.1847 \t Acc 19.97 \t AccHead 23.58 \t AccTail 8.35\n",
      "Epoch: [098] \t Loss 3.1840 \t Acc 14.61 \t AccHead 16.78 \t AccTail 7.62\n",
      "Epoch: [099] \t Loss 3.1782 \t Acc 18.03 \t AccHead 20.86 \t AccTail 8.92\n",
      "Epoch: [100] \t Loss 3.1722 \t Acc 18.19 \t AccHead 22.56 \t AccTail 4.11\n",
      "Epoch: [101] \t Loss 3.1674 \t Acc 18.12 \t AccHead 21.43 \t AccTail 7.48\n",
      "Epoch: [102] \t Loss 3.1666 \t Acc 19.40 \t AccHead 23.55 \t AccTail 6.08\n",
      "Epoch: [103] \t Loss 3.1810 \t Acc 18.90 \t AccHead 23.02 \t AccTail 5.67\n",
      "Epoch: [104] \t Loss 3.1458 \t Acc 21.80 \t AccHead 25.61 \t AccTail 9.51\n",
      "Epoch: [105] \t Loss 3.1752 \t Acc 21.94 \t AccHead 25.39 \t AccTail 10.83\n",
      "Epoch: [106] \t Loss 3.1772 \t Acc 15.45 \t AccHead 19.22 \t AccTail 3.27\n",
      "Epoch: [107] \t Loss 3.1690 \t Acc 21.01 \t AccHead 25.36 \t AccTail 7.00\n",
      "Epoch: [108] \t Loss 3.1672 \t Acc 21.98 \t AccHead 26.17 \t AccTail 8.51\n",
      "Epoch: [109] \t Loss 3.1751 \t Acc 21.31 \t AccHead 26.15 \t AccTail 5.71\n",
      "Epoch: [110] \t Loss 3.1710 \t Acc 21.24 \t AccHead 24.98 \t AccTail 9.19\n",
      "Epoch: [111] \t Loss 3.1776 \t Acc 21.31 \t AccHead 25.72 \t AccTail 7.11\n",
      "Epoch: [112] \t Loss 3.1671 \t Acc 21.00 \t AccHead 24.76 \t AccTail 8.91\n",
      "Epoch: [113] \t Loss 3.1934 \t Acc 20.73 \t AccHead 24.67 \t AccTail 8.01\n",
      "Epoch: [114] \t Loss 3.1591 \t Acc 14.29 \t AccHead 16.79 \t AccTail 6.27\n",
      "Epoch: [115] \t Loss 3.1644 \t Acc 20.48 \t AccHead 24.24 \t AccTail 8.38\n",
      "Epoch: [116] \t Loss 3.1779 \t Acc 21.66 \t AccHead 26.72 \t AccTail 5.38\n",
      "Epoch: [117] \t Loss 3.1569 \t Acc 23.81 \t AccHead 27.62 \t AccTail 11.56\n",
      "Epoch: [118] \t Loss 3.1734 \t Acc 19.19 \t AccHead 22.21 \t AccTail 9.45\n",
      "Epoch: [119] \t Loss 3.1432 \t Acc 19.08 \t AccHead 22.56 \t AccTail 7.89\n",
      "Epoch: [120] \t Loss 3.1705 \t Acc 21.63 \t AccHead 25.80 \t AccTail 8.19\n",
      "Epoch: [121] \t Loss 3.1830 \t Acc 20.55 \t AccHead 25.38 \t AccTail 5.00\n",
      "Epoch: [122] \t Loss 3.1745 \t Acc 19.13 \t AccHead 22.67 \t AccTail 7.73\n",
      "Epoch: [123] \t Loss 3.1658 \t Acc 17.14 \t AccHead 21.24 \t AccTail 3.94\n",
      "Epoch: [124] \t Loss 3.1563 \t Acc 16.92 \t AccHead 19.87 \t AccTail 7.43\n",
      "Epoch: [125] \t Loss 3.1798 \t Acc 23.48 \t AccHead 26.95 \t AccTail 12.27\n",
      "Epoch: [126] \t Loss 3.1652 \t Acc 21.36 \t AccHead 26.17 \t AccTail 5.86\n",
      "Epoch: [127] \t Loss 3.1689 \t Acc 21.35 \t AccHead 26.31 \t AccTail 5.40\n",
      "Epoch: [128] \t Loss 3.1808 \t Acc 18.99 \t AccHead 22.63 \t AccTail 7.29\n",
      "Epoch: [129] \t Loss 3.1795 \t Acc 17.93 \t AccHead 21.64 \t AccTail 6.00\n",
      "Epoch: [130] \t Loss 3.1888 \t Acc 20.88 \t AccHead 24.21 \t AccTail 10.13\n",
      "Epoch: [131] \t Loss 3.1689 \t Acc 21.21 \t AccHead 25.13 \t AccTail 8.59\n",
      "Epoch: [132] \t Loss 3.1773 \t Acc 16.70 \t AccHead 20.22 \t AccTail 5.35\n",
      "Epoch: [133] \t Loss 3.1832 \t Acc 20.98 \t AccHead 24.87 \t AccTail 8.46\n",
      "Epoch: [134] \t Loss 3.1551 \t Acc 16.94 \t AccHead 20.44 \t AccTail 5.67\n",
      "Epoch: [135] \t Loss 3.1789 \t Acc 20.77 \t AccHead 24.48 \t AccTail 8.83\n",
      "Epoch: [136] \t Loss 3.1504 \t Acc 22.52 \t AccHead 27.18 \t AccTail 7.49\n",
      "Epoch: [137] \t Loss 3.1840 \t Acc 22.94 \t AccHead 28.11 \t AccTail 6.32\n",
      "Epoch: [138] \t Loss 3.1883 \t Acc 18.96 \t AccHead 22.95 \t AccTail 6.11\n",
      "Epoch: [139] \t Loss 3.1700 \t Acc 19.85 \t AccHead 23.63 \t AccTail 7.67\n",
      "Epoch: [140] \t Loss 3.1637 \t Acc 19.10 \t AccHead 22.49 \t AccTail 8.16\n",
      "Epoch: [141] \t Loss 3.1836 \t Acc 20.88 \t AccHead 25.54 \t AccTail 5.86\n",
      "Epoch: [142] \t Loss 3.1846 \t Acc 16.83 \t AccHead 19.70 \t AccTail 7.59\n",
      "Epoch: [143] \t Loss 3.1633 \t Acc 17.91 \t AccHead 21.57 \t AccTail 6.16\n",
      "Epoch: [144] \t Loss 3.1855 \t Acc 23.27 \t AccHead 27.04 \t AccTail 11.13\n",
      "Epoch: [145] \t Loss 3.1771 \t Acc 21.74 \t AccHead 25.91 \t AccTail 8.32\n",
      "Epoch: [146] \t Loss 3.1776 \t Acc 16.30 \t AccHead 19.19 \t AccTail 7.02\n",
      "Epoch: [147] \t Loss 3.1902 \t Acc 18.42 \t AccHead 21.31 \t AccTail 9.10\n",
      "Epoch: [148] \t Loss 3.1805 \t Acc 19.69 \t AccHead 23.03 \t AccTail 8.95\n",
      "Epoch: [149] \t Loss 3.1625 \t Acc 17.64 \t AccHead 20.91 \t AccTail 7.11\n",
      "Epoch: [150] \t Loss 3.1561 \t Acc 19.50 \t AccHead 22.71 \t AccTail 9.16\n",
      "Epoch: [151] \t Loss 2.8030 \t Acc 35.67 \t AccHead 42.11 \t AccTail 14.92\n",
      "Epoch: [152] \t Loss 2.6081 \t Acc 38.11 \t AccHead 44.66 \t AccTail 17.04\n",
      "Epoch: [153] \t Loss 2.5213 \t Acc 38.38 \t AccHead 44.99 \t AccTail 17.08\n",
      "Epoch: [154] \t Loss 2.4635 \t Acc 40.14 \t AccHead 46.68 \t AccTail 19.08\n",
      "Epoch: [155] \t Loss 2.4307 \t Acc 40.89 \t AccHead 47.65 \t AccTail 19.16\n",
      "Epoch: [156] \t Loss 2.3986 \t Acc 41.53 \t AccHead 48.10 \t AccTail 20.42\n",
      "Epoch: [157] \t Loss 2.3645 \t Acc 39.58 \t AccHead 46.67 \t AccTail 16.79\n",
      "Epoch: [158] \t Loss 2.3561 \t Acc 41.63 \t AccHead 48.18 \t AccTail 20.56\n",
      "Epoch: [159] \t Loss 2.3237 \t Acc 42.62 \t AccHead 49.26 \t AccTail 21.21\n",
      "Epoch: [160] \t Loss 2.2955 \t Acc 40.77 \t AccHead 46.59 \t AccTail 22.03\n",
      "Epoch: [161] \t Loss 2.2817 \t Acc 42.49 \t AccHead 48.90 \t AccTail 21.84\n",
      "Epoch: [162] \t Loss 2.2694 \t Acc 43.49 \t AccHead 50.13 \t AccTail 22.17\n",
      "Epoch: [163] \t Loss 2.2453 \t Acc 44.40 \t AccHead 50.52 \t AccTail 24.68\n",
      "Epoch: [164] \t Loss 2.2203 \t Acc 44.39 \t AccHead 50.54 \t AccTail 24.61\n",
      "Epoch: [165] \t Loss 2.2012 \t Acc 44.50 \t AccHead 50.58 \t AccTail 24.94\n",
      "Epoch: [166] \t Loss 2.2133 \t Acc 44.54 \t AccHead 50.86 \t AccTail 24.19\n",
      "Epoch: [167] \t Loss 2.1796 \t Acc 45.18 \t AccHead 51.94 \t AccTail 23.45\n",
      "Epoch: [168] \t Loss 2.1567 \t Acc 45.27 \t AccHead 52.31 \t AccTail 22.65\n",
      "Epoch: [169] \t Loss 2.1413 \t Acc 44.22 \t AccHead 50.50 \t AccTail 24.00\n",
      "Epoch: [170] \t Loss 2.1071 \t Acc 46.64 \t AccHead 53.39 \t AccTail 24.93\n",
      "Epoch: [171] \t Loss 2.1256 \t Acc 46.80 \t AccHead 53.99 \t AccTail 23.67\n",
      "Epoch: [172] \t Loss 2.0883 \t Acc 46.02 \t AccHead 52.76 \t AccTail 24.33\n",
      "Epoch: [173] \t Loss 2.0731 \t Acc 46.37 \t AccHead 53.08 \t AccTail 24.76\n",
      "Epoch: [174] \t Loss 2.0453 \t Acc 48.08 \t AccHead 54.48 \t AccTail 27.46\n",
      "Epoch: [175] \t Loss 2.0375 \t Acc 44.81 \t AccHead 50.96 \t AccTail 25.01\n",
      "Epoch: [176] \t Loss 2.0250 \t Acc 46.38 \t AccHead 52.54 \t AccTail 26.54\n",
      "Epoch: [177] \t Loss 1.9888 \t Acc 46.68 \t AccHead 52.64 \t AccTail 27.50\n",
      "Epoch: [178] \t Loss 1.9875 \t Acc 47.71 \t AccHead 53.03 \t AccTail 30.55\n",
      "Epoch: [179] \t Loss 1.9799 \t Acc 47.72 \t AccHead 53.20 \t AccTail 30.09\n",
      "Epoch: [180] \t Loss 1.9559 \t Acc 47.68 \t AccHead 54.45 \t AccTail 25.86\n",
      "Epoch: [181] \t Loss 1.9445 \t Acc 46.17 \t AccHead 52.05 \t AccTail 27.26\n",
      "Epoch: [182] \t Loss 1.9367 \t Acc 51.77 \t AccHead 58.86 \t AccTail 28.93\n",
      "Epoch: [183] \t Loss 1.9285 \t Acc 51.74 \t AccHead 57.70 \t AccTail 32.54\n",
      "Epoch: [184] \t Loss 1.9012 \t Acc 49.33 \t AccHead 54.91 \t AccTail 31.33\n",
      "Epoch: [185] \t Loss 1.8951 \t Acc 51.40 \t AccHead 58.08 \t AccTail 29.88\n",
      "Epoch: [186] \t Loss 1.8784 \t Acc 52.63 \t AccHead 59.58 \t AccTail 30.25\n",
      "Epoch: [187] \t Loss 1.8852 \t Acc 50.51 \t AccHead 56.64 \t AccTail 30.75\n",
      "Epoch: [188] \t Loss 1.8460 \t Acc 52.65 \t AccHead 59.40 \t AccTail 30.94\n",
      "Epoch: [189] \t Loss 1.8205 \t Acc 53.70 \t AccHead 60.27 \t AccTail 32.55\n",
      "Epoch: [190] \t Loss 1.8179 \t Acc 54.57 \t AccHead 60.65 \t AccTail 34.97\n",
      "Epoch: [191] \t Loss 1.8191 \t Acc 47.16 \t AccHead 52.32 \t AccTail 30.57\n",
      "Epoch: [192] \t Loss 1.8126 \t Acc 51.61 \t AccHead 58.07 \t AccTail 30.82\n",
      "Epoch: [193] \t Loss 1.7854 \t Acc 50.74 \t AccHead 56.95 \t AccTail 30.76\n",
      "Epoch: [194] \t Loss 1.7918 \t Acc 54.74 \t AccHead 61.03 \t AccTail 34.48\n",
      "Epoch: [195] \t Loss 1.7761 \t Acc 52.65 \t AccHead 59.55 \t AccTail 30.46\n",
      "Epoch: [196] \t Loss 1.7547 \t Acc 55.74 \t AccHead 62.04 \t AccTail 35.43\n",
      "Epoch: [197] \t Loss 1.7378 \t Acc 54.86 \t AccHead 60.69 \t AccTail 36.11\n",
      "Epoch: [198] \t Loss 1.7259 \t Acc 58.00 \t AccHead 64.33 \t AccTail 37.63\n",
      "Epoch: [199] \t Loss 1.7048 \t Acc 54.16 \t AccHead 59.99 \t AccTail 35.41\n",
      "Epoch: [200] \t Loss 1.7267 \t Acc 55.93 \t AccHead 61.99 \t AccTail 36.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 14:28:40,257]\u001b[0m Trial 11 finished with value: 9.487391471862793 and parameters: {'n_epoch': 200, 'weight_decay': 0.004207112562455028}. Best is trial 6 with value: 10.572550773620605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 9.49 \t AccHead 18.94 \t AccTail 0.18\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'CIFAR100' #['CIFAR10', 'CIFAR100']\n",
    "IMB_TYPE = 'exp' #['exp', 'step']\n",
    "IMB_FACTOR = 0.1 #[0.1, 0.01]\n",
    "train_loader, test_loader, num_classes = get_loaders()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sampler = optuna.samplers.TPESampler()\n",
    "    study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "    study.optimize(func=train_model, n_trials=12)\n",
    "    joblib.dump(study, 'set_100_exp_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0079d08e-4f28-47b1-830a-3ec4255be70b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T14:28:40.652440Z",
     "iopub.status.busy": "2022-06-17T14:28:40.652028Z",
     "iopub.status.idle": "2022-06-17T14:28:40.674395Z",
     "shell.execute_reply": "2022-06-17T14:28:40.673847Z",
     "shell.execute_reply.started": "2022-06-17T14:28:40.652413Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_n_epoch</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.033485</td>\n",
       "      <td>0 days 00:31:00.387800</td>\n",
       "      <td>200</td>\n",
       "      <td>0.037809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.340223</td>\n",
       "      <td>0 days 00:13:55.552840</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9.270360</td>\n",
       "      <td>0 days 00:30:53.134421</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8.691608</td>\n",
       "      <td>0 days 00:14:00.592525</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9.125672</td>\n",
       "      <td>0 days 00:13:54.098197</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>10.272840</td>\n",
       "      <td>0 days 00:30:27.863838</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>10.572551</td>\n",
       "      <td>0 days 00:30:33.004942</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>8.360893</td>\n",
       "      <td>0 days 00:13:42.935642</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.033485</td>\n",
       "      <td>0 days 00:13:18.556360</td>\n",
       "      <td>90</td>\n",
       "      <td>0.068770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.033485</td>\n",
       "      <td>0 days 00:13:26.297676</td>\n",
       "      <td>90</td>\n",
       "      <td>0.047246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number      value               duration  params_n_epoch  \\\n",
       "0       0   1.033485 0 days 00:31:00.387800             200   \n",
       "1       1   8.340223 0 days 00:13:55.552840              90   \n",
       "2       2   9.270360 0 days 00:30:53.134421             200   \n",
       "3       3   8.691608 0 days 00:14:00.592525              90   \n",
       "4       4   9.125672 0 days 00:13:54.098197              90   \n",
       "5       5  10.272840 0 days 00:30:27.863838             200   \n",
       "6       6  10.572551 0 days 00:30:33.004942             200   \n",
       "7       7   8.360893 0 days 00:13:42.935642              90   \n",
       "8       8   1.033485 0 days 00:13:18.556360              90   \n",
       "9       9   1.033485 0 days 00:13:26.297676              90   \n",
       "\n",
       "   params_weight_decay  \n",
       "0             0.037809  \n",
       "1             0.000682  \n",
       "2             0.000013  \n",
       "3             0.000073  \n",
       "4             0.000073  \n",
       "5             0.000257  \n",
       "6             0.001405  \n",
       "7             0.000526  \n",
       "8             0.068770  \n",
       "9             0.047246  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = joblib.load('set_100_exp_1.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e70b41d4-e124-4a66-84c9-42a07641137b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T16:02:36.110645Z",
     "iopub.status.busy": "2022-06-17T16:02:36.109977Z",
     "iopub.status.idle": "2022-06-17T19:27:31.289964Z",
     "shell.execute_reply": "2022-06-17T19:27:31.289017Z",
     "shell.execute_reply.started": "2022-06-17T16:02:36.110560Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 16:03:15,090]\u001b[0m A new study created in memory with name: no-name-321e1921-bd7e-447f-b691-f731909c9dd7\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls num list(train_dataset):\n",
      "[400, 381, 364, 347, 332, 316, 302, 288, 275, 263, 251, 239, 228, 218, 208, 199, 190, 181, 173, 165, 157, 150, 143, 137, 130, 125, 119, 113, 108, 103, 99, 94, 90, 86, 82, 78, 74, 71, 68, 65, 62, 59, 56, 54, 51, 49, 47, 44, 42, 40, 39, 37, 35, 33, 32, 30, 29, 28, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 16, 15, 14, 14, 13, 12, 12, 11, 11, 10, 10, 9, 9, 8, 8, 8, 7, 7, 6, 6, 6, 6, 5, 5, 5, 5, 4, 4, 4, 4, 4]\n",
      "cls num list(val_dataset):\n",
      "[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
      "Epoch: [001] \t Loss 4.2883 \t Acc 3.86 \t AccHead 4.23 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 3.7641 \t Acc 11.09 \t AccHead 12.14 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 3.7307 \t Acc 11.44 \t AccHead 12.53 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 3.7217 \t Acc 6.24 \t AccHead 6.83 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 3.7381 \t Acc 9.63 \t AccHead 10.55 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 3.7077 \t Acc 8.77 \t AccHead 9.61 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 3.7167 \t Acc 9.04 \t AccHead 9.89 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 3.7117 \t Acc 9.35 \t AccHead 10.24 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 3.7127 \t Acc 10.60 \t AccHead 11.60 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 3.7160 \t Acc 7.29 \t AccHead 7.98 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 3.7316 \t Acc 10.97 \t AccHead 12.01 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 3.7038 \t Acc 11.92 \t AccHead 13.04 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 3.7148 \t Acc 8.05 \t AccHead 8.81 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 3.7291 \t Acc 8.16 \t AccHead 8.94 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 3.7178 \t Acc 9.10 \t AccHead 9.97 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 3.7073 \t Acc 13.25 \t AccHead 14.51 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 3.7072 \t Acc 9.32 \t AccHead 10.20 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 3.7187 \t Acc 11.05 \t AccHead 12.10 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 3.7293 \t Acc 8.82 \t AccHead 9.65 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 3.7293 \t Acc 10.31 \t AccHead 11.28 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 3.7388 \t Acc 11.39 \t AccHead 12.48 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 3.7365 \t Acc 7.88 \t AccHead 8.63 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 3.7274 \t Acc 10.47 \t AccHead 11.46 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 3.7404 \t Acc 6.70 \t AccHead 7.34 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 3.7253 \t Acc 8.73 \t AccHead 9.57 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 3.7228 \t Acc 10.13 \t AccHead 11.10 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 3.7523 \t Acc 7.96 \t AccHead 8.72 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 3.7397 \t Acc 11.03 \t AccHead 12.08 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 3.7331 \t Acc 9.74 \t AccHead 10.66 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 3.7459 \t Acc 8.20 \t AccHead 8.98 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 3.7413 \t Acc 11.12 \t AccHead 12.18 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 3.7302 \t Acc 11.57 \t AccHead 12.66 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 3.7293 \t Acc 5.76 \t AccHead 6.30 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 3.7497 \t Acc 9.32 \t AccHead 10.20 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 3.7438 \t Acc 9.57 \t AccHead 10.48 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 3.7589 \t Acc 6.86 \t AccHead 7.51 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 3.7544 \t Acc 9.95 \t AccHead 10.89 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 3.7493 \t Acc 9.42 \t AccHead 10.32 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 3.7400 \t Acc 11.46 \t AccHead 12.56 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 3.7508 \t Acc 6.53 \t AccHead 7.15 \t AccTail 0.00\n",
      "Epoch: [041] \t Loss 3.7615 \t Acc 5.19 \t AccHead 5.68 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 3.7519 \t Acc 8.97 \t AccHead 9.81 \t AccTail 0.00\n",
      "Epoch: [043] \t Loss 3.7640 \t Acc 8.10 \t AccHead 8.87 \t AccTail 0.00\n",
      "Epoch: [044] \t Loss 3.7537 \t Acc 8.82 \t AccHead 9.65 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 3.7520 \t Acc 10.62 \t AccHead 11.63 \t AccTail 0.00\n",
      "Epoch: [046] \t Loss 3.7447 \t Acc 7.61 \t AccHead 8.34 \t AccTail 0.00\n",
      "Epoch: [047] \t Loss 3.7615 \t Acc 11.26 \t AccHead 12.33 \t AccTail 0.00\n",
      "Epoch: [048] \t Loss 3.7586 \t Acc 9.92 \t AccHead 10.87 \t AccTail 0.00\n",
      "Epoch: [049] \t Loss 3.7777 \t Acc 6.10 \t AccHead 6.68 \t AccTail 0.00\n",
      "Epoch: [050] \t Loss 3.7514 \t Acc 9.01 \t AccHead 9.87 \t AccTail 0.00\n",
      "Epoch: [051] \t Loss 3.7786 \t Acc 9.35 \t AccHead 10.24 \t AccTail 0.00\n",
      "Epoch: [052] \t Loss 3.7784 \t Acc 8.51 \t AccHead 9.32 \t AccTail 0.00\n",
      "Epoch: [053] \t Loss 3.7666 \t Acc 5.92 \t AccHead 6.49 \t AccTail 0.00\n",
      "Epoch: [054] \t Loss 3.7674 \t Acc 10.25 \t AccHead 11.22 \t AccTail 0.00\n",
      "Epoch: [055] \t Loss 3.7774 \t Acc 5.60 \t AccHead 6.13 \t AccTail 0.00\n",
      "Epoch: [056] \t Loss 3.7673 \t Acc 7.94 \t AccHead 8.70 \t AccTail 0.00\n",
      "Epoch: [057] \t Loss 3.7854 \t Acc 11.71 \t AccHead 12.82 \t AccTail 0.00\n",
      "Epoch: [058] \t Loss 3.7606 \t Acc 7.86 \t AccHead 8.61 \t AccTail 0.00\n",
      "Epoch: [059] \t Loss 3.7831 \t Acc 7.11 \t AccHead 7.79 \t AccTail 0.00\n",
      "Epoch: [060] \t Loss 3.7627 \t Acc 9.96 \t AccHead 10.90 \t AccTail 0.00\n",
      "Epoch: [061] \t Loss 3.7486 \t Acc 7.89 \t AccHead 8.64 \t AccTail 0.00\n",
      "Epoch: [062] \t Loss 3.7951 \t Acc 9.26 \t AccHead 10.13 \t AccTail 0.00\n",
      "Epoch: [063] \t Loss 3.7833 \t Acc 10.61 \t AccHead 11.62 \t AccTail 0.00\n",
      "Epoch: [064] \t Loss 3.8094 \t Acc 5.89 \t AccHead 6.45 \t AccTail 0.00\n",
      "Epoch: [065] \t Loss 3.7933 \t Acc 9.62 \t AccHead 10.54 \t AccTail 0.00\n",
      "Epoch: [066] \t Loss 3.7988 \t Acc 6.44 \t AccHead 7.05 \t AccTail 0.00\n",
      "Epoch: [067] \t Loss 3.7897 \t Acc 9.03 \t AccHead 9.89 \t AccTail 0.00\n",
      "Epoch: [068] \t Loss 3.8006 \t Acc 7.80 \t AccHead 8.55 \t AccTail 0.00\n",
      "Epoch: [069] \t Loss 3.7905 \t Acc 6.16 \t AccHead 6.74 \t AccTail 0.00\n",
      "Epoch: [070] \t Loss 3.8077 \t Acc 7.63 \t AccHead 8.35 \t AccTail 0.00\n",
      "Epoch: [071] \t Loss 3.8069 \t Acc 6.80 \t AccHead 7.45 \t AccTail 0.00\n",
      "Epoch: [072] \t Loss 3.7824 \t Acc 9.06 \t AccHead 9.92 \t AccTail 0.00\n",
      "Epoch: [073] \t Loss 3.8007 \t Acc 7.03 \t AccHead 7.70 \t AccTail 0.00\n",
      "Epoch: [074] \t Loss 3.7981 \t Acc 5.53 \t AccHead 6.05 \t AccTail 0.00\n",
      "Epoch: [075] \t Loss 3.7898 \t Acc 8.62 \t AccHead 9.44 \t AccTail 0.00\n",
      "Epoch: [076] \t Loss 3.7878 \t Acc 4.78 \t AccHead 5.23 \t AccTail 0.00\n",
      "Epoch: [077] \t Loss 3.8017 \t Acc 5.74 \t AccHead 6.28 \t AccTail 0.00\n",
      "Epoch: [078] \t Loss 3.7995 \t Acc 5.34 \t AccHead 5.85 \t AccTail 0.00\n",
      "Epoch: [079] \t Loss 3.8042 \t Acc 7.71 \t AccHead 8.44 \t AccTail 0.00\n",
      "Epoch: [080] \t Loss 3.8163 \t Acc 5.61 \t AccHead 6.14 \t AccTail 0.00\n",
      "Epoch: [081] \t Loss 3.9449 \t Acc 3.33 \t AccHead 3.65 \t AccTail 0.00\n",
      "Epoch: [082] \t Loss 3.8716 \t Acc 7.79 \t AccHead 8.53 \t AccTail 0.00\n",
      "Epoch: [083] \t Loss 3.8779 \t Acc 4.00 \t AccHead 4.38 \t AccTail 0.00\n",
      "Epoch: [084] \t Loss 3.8594 \t Acc 8.75 \t AccHead 9.58 \t AccTail 0.00\n",
      "Epoch: [085] \t Loss 3.8707 \t Acc 4.70 \t AccHead 5.15 \t AccTail 0.00\n",
      "Epoch: [086] \t Loss 3.8617 \t Acc 5.10 \t AccHead 5.58 \t AccTail 0.00\n",
      "Epoch: [087] \t Loss 3.8593 \t Acc 2.09 \t AccHead 2.29 \t AccTail 0.00\n",
      "Epoch: [088] \t Loss 3.8682 \t Acc 7.36 \t AccHead 8.06 \t AccTail 0.00\n",
      "Epoch: [089] \t Loss 3.8657 \t Acc 4.61 \t AccHead 5.05 \t AccTail 0.00\n",
      "Epoch: [090] \t Loss 3.8856 \t Acc 4.38 \t AccHead 4.80 \t AccTail 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 16:13:36,390]\u001b[0m Trial 0 finished with value: 1.1318795680999756 and parameters: {'n_epoch': 90, 'weight_decay': 0.029962751900251588}. Best is trial 0 with value: 1.1318795680999756.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 1.13 \t AccHead 2.27 \t AccTail 0.00\n",
      "Epoch: [001] \t Loss 4.4172 \t Acc 13.77 \t AccHead 15.08 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 3.7580 \t Acc 13.76 \t AccHead 15.06 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 3.5137 \t Acc 18.62 \t AccHead 20.38 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 3.3362 \t Acc 20.95 \t AccHead 22.82 \t AccTail 1.47\n",
      "Epoch: [005] \t Loss 3.2219 \t Acc 21.62 \t AccHead 23.44 \t AccTail 2.42\n",
      "Epoch: [006] \t Loss 3.0980 \t Acc 23.30 \t AccHead 25.30 \t AccTail 2.40\n",
      "Epoch: [007] \t Loss 2.9979 \t Acc 26.67 \t AccHead 28.61 \t AccTail 6.20\n",
      "Epoch: [008] \t Loss 2.9962 \t Acc 28.04 \t AccHead 30.24 \t AccTail 4.85\n",
      "Epoch: [009] \t Loss 2.8349 \t Acc 28.25 \t AccHead 30.49 \t AccTail 4.70\n",
      "Epoch: [010] \t Loss 2.7655 \t Acc 30.18 \t AccHead 32.65 \t AccTail 4.17\n",
      "Epoch: [011] \t Loss 2.6749 \t Acc 30.74 \t AccHead 33.19 \t AccTail 4.74\n",
      "Epoch: [012] \t Loss 2.5877 \t Acc 33.23 \t AccHead 35.82 \t AccTail 5.92\n",
      "Epoch: [013] \t Loss 2.5619 \t Acc 35.94 \t AccHead 38.87 \t AccTail 5.21\n",
      "Epoch: [014] \t Loss 2.4583 \t Acc 37.26 \t AccHead 39.99 \t AccTail 8.25\n",
      "Epoch: [015] \t Loss 2.4292 \t Acc 39.72 \t AccHead 42.78 \t AccTail 7.51\n",
      "Epoch: [016] \t Loss 2.3524 \t Acc 36.36 \t AccHead 39.02 \t AccTail 8.33\n",
      "Epoch: [017] \t Loss 2.3483 \t Acc 37.76 \t AccHead 40.66 \t AccTail 7.36\n",
      "Epoch: [018] \t Loss 2.2581 \t Acc 40.76 \t AccHead 43.89 \t AccTail 7.81\n",
      "Epoch: [019] \t Loss 2.2156 \t Acc 43.40 \t AccHead 46.58 \t AccTail 9.83\n",
      "Epoch: [020] \t Loss 2.1715 \t Acc 36.81 \t AccHead 39.40 \t AccTail 9.65\n",
      "Epoch: [021] \t Loss 2.1341 \t Acc 42.19 \t AccHead 45.01 \t AccTail 12.38\n",
      "Epoch: [022] \t Loss 2.1009 \t Acc 41.29 \t AccHead 44.10 \t AccTail 11.71\n",
      "Epoch: [023] \t Loss 2.0616 \t Acc 45.97 \t AccHead 48.92 \t AccTail 14.71\n",
      "Epoch: [024] \t Loss 2.0505 \t Acc 43.56 \t AccHead 46.29 \t AccTail 14.99\n",
      "Epoch: [025] \t Loss 1.9652 \t Acc 44.31 \t AccHead 47.33 \t AccTail 12.40\n",
      "Epoch: [026] \t Loss 1.9388 \t Acc 47.34 \t AccHead 50.65 \t AccTail 12.30\n",
      "Epoch: [027] \t Loss 1.9429 \t Acc 44.23 \t AccHead 47.03 \t AccTail 14.78\n",
      "Epoch: [028] \t Loss 1.9137 \t Acc 44.25 \t AccHead 47.15 \t AccTail 13.92\n",
      "Epoch: [029] \t Loss 1.8496 \t Acc 45.58 \t AccHead 48.74 \t AccTail 12.35\n",
      "Epoch: [030] \t Loss 1.8335 \t Acc 48.55 \t AccHead 51.60 \t AccTail 16.53\n",
      "Epoch: [031] \t Loss 1.8080 \t Acc 51.73 \t AccHead 54.97 \t AccTail 17.50\n",
      "Epoch: [032] \t Loss 1.7967 \t Acc 41.91 \t AccHead 44.04 \t AccTail 19.49\n",
      "Epoch: [033] \t Loss 1.8009 \t Acc 50.03 \t AccHead 53.24 \t AccTail 16.29\n",
      "Epoch: [034] \t Loss 1.7035 \t Acc 47.92 \t AccHead 50.64 \t AccTail 19.33\n",
      "Epoch: [035] \t Loss 1.7036 \t Acc 52.39 \t AccHead 55.66 \t AccTail 17.99\n",
      "Epoch: [036] \t Loss 1.6759 \t Acc 53.12 \t AccHead 56.49 \t AccTail 17.74\n",
      "Epoch: [037] \t Loss 1.6700 \t Acc 53.56 \t AccHead 56.83 \t AccTail 19.09\n",
      "Epoch: [038] \t Loss 1.6496 \t Acc 56.39 \t AccHead 59.74 \t AccTail 21.36\n",
      "Epoch: [039] \t Loss 1.6105 \t Acc 53.00 \t AccHead 55.68 \t AccTail 24.90\n",
      "Epoch: [040] \t Loss 1.5883 \t Acc 54.38 \t AccHead 56.99 \t AccTail 26.92\n",
      "Epoch: [041] \t Loss 1.5641 \t Acc 54.01 \t AccHead 56.76 \t AccTail 25.17\n",
      "Epoch: [042] \t Loss 1.5243 \t Acc 53.16 \t AccHead 56.47 \t AccTail 18.02\n",
      "Epoch: [043] \t Loss 1.5404 \t Acc 54.64 \t AccHead 58.11 \t AccTail 17.95\n",
      "Epoch: [044] \t Loss 1.5364 \t Acc 58.16 \t AccHead 61.11 \t AccTail 27.21\n",
      "Epoch: [045] \t Loss 1.5084 \t Acc 53.49 \t AccHead 56.15 \t AccTail 25.44\n",
      "Epoch: [046] \t Loss 1.4831 \t Acc 57.60 \t AccHead 60.09 \t AccTail 31.26\n",
      "Epoch: [047] \t Loss 1.4847 \t Acc 56.10 \t AccHead 58.74 \t AccTail 28.42\n",
      "Epoch: [048] \t Loss 1.4388 \t Acc 55.62 \t AccHead 58.83 \t AccTail 21.88\n",
      "Epoch: [049] \t Loss 1.4279 \t Acc 58.05 \t AccHead 60.65 \t AccTail 30.39\n",
      "Epoch: [050] \t Loss 1.4035 \t Acc 52.88 \t AccHead 55.67 \t AccTail 23.66\n",
      "Epoch: [051] \t Loss 1.3972 \t Acc 59.74 \t AccHead 62.47 \t AccTail 30.96\n",
      "Epoch: [052] \t Loss 1.3464 \t Acc 58.44 \t AccHead 60.67 \t AccTail 35.03\n",
      "Epoch: [053] \t Loss 1.3805 \t Acc 61.29 \t AccHead 64.10 \t AccTail 31.58\n",
      "Epoch: [054] \t Loss 1.3364 \t Acc 60.40 \t AccHead 63.15 \t AccTail 31.26\n",
      "Epoch: [055] \t Loss 1.3143 \t Acc 55.76 \t AccHead 58.91 \t AccTail 22.43\n",
      "Epoch: [056] \t Loss 1.2975 \t Acc 59.76 \t AccHead 62.42 \t AccTail 31.53\n",
      "Epoch: [057] \t Loss 1.3360 \t Acc 61.42 \t AccHead 64.18 \t AccTail 32.35\n",
      "Epoch: [058] \t Loss 1.2881 \t Acc 57.70 \t AccHead 60.05 \t AccTail 32.88\n",
      "Epoch: [059] \t Loss 1.2436 \t Acc 62.10 \t AccHead 65.07 \t AccTail 31.06\n",
      "Epoch: [060] \t Loss 1.2853 \t Acc 61.95 \t AccHead 64.84 \t AccTail 31.49\n",
      "Epoch: [061] \t Loss 1.2280 \t Acc 64.39 \t AccHead 66.85 \t AccTail 38.44\n",
      "Epoch: [062] \t Loss 1.2383 \t Acc 64.00 \t AccHead 66.66 \t AccTail 36.14\n",
      "Epoch: [063] \t Loss 1.2635 \t Acc 60.95 \t AccHead 63.03 \t AccTail 38.95\n",
      "Epoch: [064] \t Loss 1.2471 \t Acc 66.91 \t AccHead 69.25 \t AccTail 42.26\n",
      "Epoch: [065] \t Loss 1.1627 \t Acc 62.14 \t AccHead 64.16 \t AccTail 41.07\n",
      "Epoch: [066] \t Loss 1.1638 \t Acc 60.24 \t AccHead 62.63 \t AccTail 35.08\n",
      "Epoch: [067] \t Loss 1.1641 \t Acc 60.81 \t AccHead 62.76 \t AccTail 40.11\n",
      "Epoch: [068] \t Loss 1.1563 \t Acc 68.87 \t AccHead 70.69 \t AccTail 49.80\n",
      "Epoch: [069] \t Loss 1.1250 \t Acc 62.62 \t AccHead 64.98 \t AccTail 37.69\n",
      "Epoch: [070] \t Loss 1.1308 \t Acc 65.80 \t AccHead 68.16 \t AccTail 40.99\n",
      "Epoch: [071] \t Loss 1.1071 \t Acc 67.18 \t AccHead 69.24 \t AccTail 45.27\n",
      "Epoch: [072] \t Loss 1.1509 \t Acc 67.11 \t AccHead 69.51 \t AccTail 41.88\n",
      "Epoch: [073] \t Loss 1.0848 \t Acc 67.04 \t AccHead 68.82 \t AccTail 48.32\n",
      "Epoch: [074] \t Loss 1.0868 \t Acc 70.18 \t AccHead 72.33 \t AccTail 47.58\n",
      "Epoch: [075] \t Loss 1.1082 \t Acc 66.92 \t AccHead 70.00 \t AccTail 34.67\n",
      "Epoch: [076] \t Loss 1.1042 \t Acc 63.71 \t AccHead 65.61 \t AccTail 43.76\n",
      "Epoch: [077] \t Loss 1.0917 \t Acc 66.57 \t AccHead 67.95 \t AccTail 51.96\n",
      "Epoch: [078] \t Loss 1.0934 \t Acc 60.84 \t AccHead 63.36 \t AccTail 34.45\n",
      "Epoch: [079] \t Loss 1.0280 \t Acc 69.39 \t AccHead 71.41 \t AccTail 48.33\n",
      "Epoch: [080] \t Loss 1.0340 \t Acc 67.51 \t AccHead 69.37 \t AccTail 47.99\n",
      "Epoch: [081] \t Loss 1.0479 \t Acc 71.23 \t AccHead 73.09 \t AccTail 51.56\n",
      "Epoch: [082] \t Loss 1.0138 \t Acc 71.32 \t AccHead 73.37 \t AccTail 49.60\n",
      "Epoch: [083] \t Loss 1.0290 \t Acc 68.18 \t AccHead 70.16 \t AccTail 47.30\n",
      "Epoch: [084] \t Loss 1.0212 \t Acc 68.94 \t AccHead 70.67 \t AccTail 50.54\n",
      "Epoch: [085] \t Loss 0.9630 \t Acc 67.74 \t AccHead 69.34 \t AccTail 50.87\n",
      "Epoch: [086] \t Loss 1.0053 \t Acc 64.03 \t AccHead 65.70 \t AccTail 46.51\n",
      "Epoch: [087] \t Loss 0.9757 \t Acc 70.98 \t AccHead 72.61 \t AccTail 53.76\n",
      "Epoch: [088] \t Loss 0.9653 \t Acc 64.68 \t AccHead 65.96 \t AccTail 51.27\n",
      "Epoch: [089] \t Loss 0.9671 \t Acc 69.19 \t AccHead 70.40 \t AccTail 56.51\n",
      "Epoch: [090] \t Loss 1.0134 \t Acc 70.44 \t AccHead 72.35 \t AccTail 50.20\n",
      "Epoch: [091] \t Loss 1.0053 \t Acc 71.05 \t AccHead 72.91 \t AccTail 51.47\n",
      "Epoch: [092] \t Loss 0.9586 \t Acc 73.19 \t AccHead 74.99 \t AccTail 54.18\n",
      "Epoch: [093] \t Loss 0.9501 \t Acc 71.64 \t AccHead 73.44 \t AccTail 52.70\n",
      "Epoch: [094] \t Loss 0.9579 \t Acc 67.35 \t AccHead 69.61 \t AccTail 43.53\n",
      "Epoch: [095] \t Loss 0.9402 \t Acc 54.16 \t AccHead 55.15 \t AccTail 43.72\n",
      "Epoch: [096] \t Loss 0.9347 \t Acc 67.98 \t AccHead 69.26 \t AccTail 54.62\n",
      "Epoch: [097] \t Loss 0.9766 \t Acc 72.41 \t AccHead 74.05 \t AccTail 55.23\n",
      "Epoch: [098] \t Loss 0.9270 \t Acc 70.50 \t AccHead 72.18 \t AccTail 52.82\n",
      "Epoch: [099] \t Loss 0.9403 \t Acc 71.64 \t AccHead 72.48 \t AccTail 62.82\n",
      "Epoch: [100] \t Loss 0.9774 \t Acc 72.82 \t AccHead 73.87 \t AccTail 61.74\n",
      "Epoch: [101] \t Loss 0.8851 \t Acc 64.37 \t AccHead 65.47 \t AccTail 52.76\n",
      "Epoch: [102] \t Loss 0.9270 \t Acc 72.21 \t AccHead 73.40 \t AccTail 59.65\n",
      "Epoch: [103] \t Loss 0.9083 \t Acc 67.53 \t AccHead 69.12 \t AccTail 50.74\n",
      "Epoch: [104] \t Loss 0.8911 \t Acc 67.29 \t AccHead 68.81 \t AccTail 51.28\n",
      "Epoch: [105] \t Loss 0.9804 \t Acc 73.26 \t AccHead 74.77 \t AccTail 57.43\n",
      "Epoch: [106] \t Loss 0.8905 \t Acc 69.58 \t AccHead 70.61 \t AccTail 58.68\n",
      "Epoch: [107] \t Loss 0.9008 \t Acc 65.71 \t AccHead 68.00 \t AccTail 41.61\n",
      "Epoch: [108] \t Loss 0.9235 \t Acc 69.32 \t AccHead 71.25 \t AccTail 48.99\n",
      "Epoch: [109] \t Loss 0.9203 \t Acc 73.06 \t AccHead 74.66 \t AccTail 56.24\n",
      "Epoch: [110] \t Loss 0.8825 \t Acc 70.66 \t AccHead 71.81 \t AccTail 58.63\n",
      "Epoch: [111] \t Loss 0.8851 \t Acc 68.98 \t AccHead 70.10 \t AccTail 57.20\n",
      "Epoch: [112] \t Loss 0.8788 \t Acc 64.86 \t AccHead 66.69 \t AccTail 45.58\n",
      "Epoch: [113] \t Loss 0.8741 \t Acc 71.04 \t AccHead 72.20 \t AccTail 58.85\n",
      "Epoch: [114] \t Loss 0.8733 \t Acc 66.39 \t AccHead 68.02 \t AccTail 49.26\n",
      "Epoch: [115] \t Loss 0.8741 \t Acc 75.47 \t AccHead 76.37 \t AccTail 65.99\n",
      "Epoch: [116] \t Loss 0.8480 \t Acc 68.17 \t AccHead 68.49 \t AccTail 64.78\n",
      "Epoch: [117] \t Loss 0.8734 \t Acc 70.49 \t AccHead 72.54 \t AccTail 48.86\n",
      "Epoch: [118] \t Loss 0.8347 \t Acc 73.48 \t AccHead 74.65 \t AccTail 61.11\n",
      "Epoch: [119] \t Loss 0.8602 \t Acc 71.43 \t AccHead 72.73 \t AccTail 57.83\n",
      "Epoch: [120] \t Loss 0.8655 \t Acc 73.22 \t AccHead 73.70 \t AccTail 68.18\n",
      "Epoch: [121] \t Loss 0.8423 \t Acc 69.79 \t AccHead 71.28 \t AccTail 54.04\n",
      "Epoch: [122] \t Loss 0.8436 \t Acc 67.21 \t AccHead 68.15 \t AccTail 57.32\n",
      "Epoch: [123] \t Loss 0.8776 \t Acc 65.96 \t AccHead 67.38 \t AccTail 51.07\n",
      "Epoch: [124] \t Loss 0.8149 \t Acc 71.96 \t AccHead 73.29 \t AccTail 57.87\n",
      "Epoch: [125] \t Loss 0.8192 \t Acc 76.12 \t AccHead 77.40 \t AccTail 62.65\n",
      "Epoch: [126] \t Loss 0.8387 \t Acc 69.88 \t AccHead 70.73 \t AccTail 60.92\n",
      "Epoch: [127] \t Loss 0.8460 \t Acc 73.54 \t AccHead 74.63 \t AccTail 62.12\n",
      "Epoch: [128] \t Loss 0.8426 \t Acc 72.80 \t AccHead 73.95 \t AccTail 60.59\n",
      "Epoch: [129] \t Loss 0.8362 \t Acc 73.04 \t AccHead 74.21 \t AccTail 60.81\n",
      "Epoch: [130] \t Loss 0.8311 \t Acc 72.42 \t AccHead 73.55 \t AccTail 60.49\n",
      "Epoch: [131] \t Loss 0.8177 \t Acc 73.34 \t AccHead 74.47 \t AccTail 61.60\n",
      "Epoch: [132] \t Loss 0.8521 \t Acc 73.17 \t AccHead 74.28 \t AccTail 61.42\n",
      "Epoch: [133] \t Loss 0.8008 \t Acc 75.01 \t AccHead 76.14 \t AccTail 63.20\n",
      "Epoch: [134] \t Loss 0.8427 \t Acc 75.55 \t AccHead 77.11 \t AccTail 59.17\n",
      "Epoch: [135] \t Loss 0.8220 \t Acc 69.53 \t AccHead 70.59 \t AccTail 58.45\n",
      "Epoch: [136] \t Loss 0.7703 \t Acc 74.55 \t AccHead 75.11 \t AccTail 68.59\n",
      "Epoch: [137] \t Loss 0.8412 \t Acc 74.42 \t AccHead 75.84 \t AccTail 59.43\n",
      "Epoch: [138] \t Loss 0.8367 \t Acc 76.35 \t AccHead 77.19 \t AccTail 67.56\n",
      "Epoch: [139] \t Loss 0.7434 \t Acc 76.75 \t AccHead 78.30 \t AccTail 60.46\n",
      "Epoch: [140] \t Loss 0.7789 \t Acc 70.44 \t AccHead 71.27 \t AccTail 61.69\n",
      "Epoch: [141] \t Loss 0.8345 \t Acc 71.41 \t AccHead 72.56 \t AccTail 59.22\n",
      "Epoch: [142] \t Loss 0.8445 \t Acc 74.08 \t AccHead 74.98 \t AccTail 64.66\n",
      "Epoch: [143] \t Loss 0.7676 \t Acc 76.71 \t AccHead 77.94 \t AccTail 63.95\n",
      "Epoch: [144] \t Loss 0.8362 \t Acc 73.55 \t AccHead 74.90 \t AccTail 59.32\n",
      "Epoch: [145] \t Loss 0.7820 \t Acc 77.54 \t AccHead 78.18 \t AccTail 70.82\n",
      "Epoch: [146] \t Loss 0.7580 \t Acc 73.23 \t AccHead 73.77 \t AccTail 67.43\n",
      "Epoch: [147] \t Loss 0.8230 \t Acc 74.67 \t AccHead 75.30 \t AccTail 68.09\n",
      "Epoch: [148] \t Loss 0.8055 \t Acc 75.40 \t AccHead 76.78 \t AccTail 60.81\n",
      "Epoch: [149] \t Loss 0.7980 \t Acc 73.02 \t AccHead 73.97 \t AccTail 62.99\n",
      "Epoch: [150] \t Loss 0.7571 \t Acc 67.18 \t AccHead 68.22 \t AccTail 56.20\n",
      "Epoch: [151] \t Loss 0.4182 \t Acc 95.65 \t AccHead 96.00 \t AccTail 91.96\n",
      "Epoch: [152] \t Loss 0.2056 \t Acc 97.61 \t AccHead 97.87 \t AccTail 94.91\n",
      "Epoch: [153] \t Loss 0.1486 \t Acc 98.39 \t AccHead 98.54 \t AccTail 96.76\n",
      "Epoch: [154] \t Loss 0.1143 \t Acc 98.93 \t AccHead 99.04 \t AccTail 97.71\n",
      "Epoch: [155] \t Loss 0.0978 \t Acc 99.10 \t AccHead 99.17 \t AccTail 98.39\n",
      "Epoch: [156] \t Loss 0.0880 \t Acc 99.42 \t AccHead 99.48 \t AccTail 98.79\n",
      "Epoch: [157] \t Loss 0.0744 \t Acc 99.45 \t AccHead 99.51 \t AccTail 98.79\n",
      "Epoch: [158] \t Loss 0.0684 \t Acc 99.49 \t AccHead 99.57 \t AccTail 98.66\n",
      "Epoch: [159] \t Loss 0.0606 \t Acc 99.56 \t AccHead 99.58 \t AccTail 99.33\n",
      "Epoch: [160] \t Loss 0.0578 \t Acc 99.69 \t AccHead 99.77 \t AccTail 98.79\n",
      "Epoch: [161] \t Loss 0.0533 \t Acc 99.72 \t AccHead 99.76 \t AccTail 99.33\n",
      "Epoch: [162] \t Loss 0.0480 \t Acc 99.72 \t AccHead 99.72 \t AccTail 99.73\n",
      "Epoch: [163] \t Loss 0.0454 \t Acc 99.81 \t AccHead 99.80 \t AccTail 100.00\n",
      "Epoch: [164] \t Loss 0.0445 \t Acc 99.76 \t AccHead 99.78 \t AccTail 99.46\n",
      "Epoch: [165] \t Loss 0.0416 \t Acc 99.80 \t AccHead 99.82 \t AccTail 99.60\n",
      "Epoch: [166] \t Loss 0.0426 \t Acc 99.86 \t AccHead 99.86 \t AccTail 99.86\n",
      "Epoch: [167] \t Loss 0.0355 \t Acc 99.92 \t AccHead 99.92 \t AccTail 99.87\n",
      "Epoch: [168] \t Loss 0.0350 \t Acc 99.85 \t AccHead 99.89 \t AccTail 99.46\n",
      "Epoch: [169] \t Loss 0.0330 \t Acc 99.93 \t AccHead 99.92 \t AccTail 100.00\n",
      "Epoch: [170] \t Loss 0.0319 \t Acc 99.90 \t AccHead 99.91 \t AccTail 99.73\n",
      "Epoch: [171] \t Loss 0.0317 \t Acc 99.90 \t AccHead 99.90 \t AccTail 99.87\n",
      "Epoch: [172] \t Loss 0.0291 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [173] \t Loss 0.0305 \t Acc 99.92 \t AccHead 99.94 \t AccTail 99.73\n",
      "Epoch: [174] \t Loss 0.0285 \t Acc 99.91 \t AccHead 99.92 \t AccTail 99.73\n",
      "Epoch: [175] \t Loss 0.0268 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [176] \t Loss 0.0264 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [177] \t Loss 0.0253 \t Acc 99.92 \t AccHead 99.92 \t AccTail 99.87\n",
      "Epoch: [178] \t Loss 0.0256 \t Acc 99.94 \t AccHead 99.94 \t AccTail 100.00\n",
      "Epoch: [179] \t Loss 0.0245 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [180] \t Loss 0.0228 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [181] \t Loss 0.0219 \t Acc 99.94 \t AccHead 99.95 \t AccTail 99.87\n",
      "Epoch: [182] \t Loss 0.0226 \t Acc 99.93 \t AccHead 99.94 \t AccTail 99.87\n",
      "Epoch: [183] \t Loss 0.0215 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [184] \t Loss 0.0216 \t Acc 99.97 \t AccHead 99.99 \t AccTail 99.73\n",
      "Epoch: [185] \t Loss 0.0219 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [186] \t Loss 0.0206 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [187] \t Loss 0.0207 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [188] \t Loss 0.0218 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [189] \t Loss 0.0218 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [190] \t Loss 0.0197 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [191] \t Loss 0.0201 \t Acc 99.98 \t AccHead 99.99 \t AccTail 99.87\n",
      "Epoch: [192] \t Loss 0.0204 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [193] \t Loss 0.0175 \t Acc 99.95 \t AccHead 99.96 \t AccTail 99.87\n",
      "Epoch: [194] \t Loss 0.0191 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [195] \t Loss 0.0183 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [196] \t Loss 0.0185 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [197] \t Loss 0.0169 \t Acc 100.00 \t AccHead 100.00 \t AccTail 100.00\n",
      "Epoch: [198] \t Loss 0.0173 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [199] \t Loss 0.0165 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [200] \t Loss 0.0172 \t Acc 99.94 \t AccHead 99.94 \t AccTail 100.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 16:37:08,144]\u001b[0m Trial 1 finished with value: 6.085150718688965 and parameters: {'n_epoch': 200, 'weight_decay': 0.0010427751130644657}. Best is trial 1 with value: 6.085150718688965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 6.09 \t AccHead 12.10 \t AccTail 0.10\n",
      "Epoch: [001] \t Loss 4.5270 \t Acc 13.88 \t AccHead 15.20 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 3.7754 \t Acc 14.06 \t AccHead 15.39 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 3.5232 \t Acc 18.85 \t AccHead 20.63 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 3.3341 \t Acc 21.93 \t AccHead 24.02 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 3.1884 \t Acc 24.03 \t AccHead 26.03 \t AccTail 3.08\n",
      "Epoch: [006] \t Loss 3.0876 \t Acc 25.13 \t AccHead 27.06 \t AccTail 4.71\n",
      "Epoch: [007] \t Loss 2.9801 \t Acc 27.32 \t AccHead 29.56 \t AccTail 3.64\n",
      "Epoch: [008] \t Loss 2.8997 \t Acc 31.51 \t AccHead 34.04 \t AccTail 4.84\n",
      "Epoch: [009] \t Loss 2.8129 \t Acc 30.45 \t AccHead 32.56 \t AccTail 8.10\n",
      "Epoch: [010] \t Loss 2.7304 \t Acc 32.66 \t AccHead 35.10 \t AccTail 6.98\n",
      "Epoch: [011] \t Loss 2.6555 \t Acc 34.46 \t AccHead 37.17 \t AccTail 5.80\n",
      "Epoch: [012] \t Loss 2.5892 \t Acc 37.29 \t AccHead 40.09 \t AccTail 7.69\n",
      "Epoch: [013] \t Loss 2.5297 \t Acc 37.08 \t AccHead 39.79 \t AccTail 8.27\n",
      "Epoch: [014] \t Loss 2.4525 \t Acc 39.02 \t AccHead 41.87 \t AccTail 9.01\n",
      "Epoch: [015] \t Loss 2.3872 \t Acc 38.74 \t AccHead 41.51 \t AccTail 9.45\n",
      "Epoch: [016] \t Loss 2.3358 \t Acc 39.02 \t AccHead 41.72 \t AccTail 10.60\n",
      "Epoch: [017] \t Loss 2.2837 \t Acc 41.39 \t AccHead 44.42 \t AccTail 9.43\n",
      "Epoch: [018] \t Loss 2.2067 \t Acc 40.10 \t AccHead 42.71 \t AccTail 12.53\n",
      "Epoch: [019] \t Loss 2.1504 \t Acc 43.90 \t AccHead 46.75 \t AccTail 13.86\n",
      "Epoch: [020] \t Loss 2.0791 \t Acc 45.43 \t AccHead 48.20 \t AccTail 16.17\n",
      "Epoch: [021] \t Loss 2.0084 \t Acc 42.71 \t AccHead 45.68 \t AccTail 11.44\n",
      "Epoch: [022] \t Loss 1.9623 \t Acc 49.31 \t AccHead 52.60 \t AccTail 14.67\n",
      "Epoch: [023] \t Loss 1.8927 \t Acc 50.14 \t AccHead 53.20 \t AccTail 17.90\n",
      "Epoch: [024] \t Loss 1.8601 \t Acc 52.38 \t AccHead 55.37 \t AccTail 21.02\n",
      "Epoch: [025] \t Loss 1.8102 \t Acc 48.89 \t AccHead 51.60 \t AccTail 20.35\n",
      "Epoch: [026] \t Loss 1.7081 \t Acc 49.90 \t AccHead 52.73 \t AccTail 20.03\n",
      "Epoch: [027] \t Loss 1.6924 \t Acc 54.52 \t AccHead 57.23 \t AccTail 26.08\n",
      "Epoch: [028] \t Loss 1.6487 \t Acc 53.09 \t AccHead 56.21 \t AccTail 20.30\n",
      "Epoch: [029] \t Loss 1.6114 \t Acc 57.92 \t AccHead 61.01 \t AccTail 25.30\n",
      "Epoch: [030] \t Loss 1.5335 \t Acc 57.64 \t AccHead 60.44 \t AccTail 28.03\n",
      "Epoch: [031] \t Loss 1.5108 \t Acc 58.82 \t AccHead 61.29 \t AccTail 32.84\n",
      "Epoch: [032] \t Loss 1.4476 \t Acc 55.75 \t AccHead 58.62 \t AccTail 25.20\n",
      "Epoch: [033] \t Loss 1.3990 \t Acc 59.93 \t AccHead 62.54 \t AccTail 32.57\n",
      "Epoch: [034] \t Loss 1.3656 \t Acc 61.25 \t AccHead 63.87 \t AccTail 33.78\n",
      "Epoch: [035] \t Loss 1.3026 \t Acc 61.53 \t AccHead 63.53 \t AccTail 40.46\n",
      "Epoch: [036] \t Loss 1.2755 \t Acc 61.81 \t AccHead 64.03 \t AccTail 38.44\n",
      "Epoch: [037] \t Loss 1.2419 \t Acc 62.93 \t AccHead 65.53 \t AccTail 35.57\n",
      "Epoch: [038] \t Loss 1.2069 \t Acc 62.55 \t AccHead 64.51 \t AccTail 41.96\n",
      "Epoch: [039] \t Loss 1.1638 \t Acc 65.22 \t AccHead 66.95 \t AccTail 47.05\n",
      "Epoch: [040] \t Loss 1.1490 \t Acc 68.65 \t AccHead 70.50 \t AccTail 49.13\n",
      "Epoch: [041] \t Loss 1.0882 \t Acc 67.16 \t AccHead 68.96 \t AccTail 48.18\n",
      "Epoch: [042] \t Loss 1.0521 \t Acc 70.97 \t AccHead 73.32 \t AccTail 46.08\n",
      "Epoch: [043] \t Loss 1.0127 \t Acc 69.61 \t AccHead 71.32 \t AccTail 51.68\n",
      "Epoch: [044] \t Loss 0.9790 \t Acc 72.22 \t AccHead 73.57 \t AccTail 58.12\n",
      "Epoch: [045] \t Loss 0.9661 \t Acc 72.41 \t AccHead 74.18 \t AccTail 53.76\n",
      "Epoch: [046] \t Loss 0.9424 \t Acc 68.95 \t AccHead 70.10 \t AccTail 56.82\n",
      "Epoch: [047] \t Loss 0.8643 \t Acc 72.39 \t AccHead 73.77 \t AccTail 57.85\n",
      "Epoch: [048] \t Loss 0.8537 \t Acc 74.62 \t AccHead 75.84 \t AccTail 61.74\n",
      "Epoch: [049] \t Loss 0.8437 \t Acc 72.53 \t AccHead 73.51 \t AccTail 62.20\n",
      "Epoch: [050] \t Loss 0.8238 \t Acc 78.06 \t AccHead 79.22 \t AccTail 65.72\n",
      "Epoch: [051] \t Loss 0.7545 \t Acc 75.92 \t AccHead 76.54 \t AccTail 69.35\n",
      "Epoch: [052] \t Loss 0.7938 \t Acc 76.96 \t AccHead 77.57 \t AccTail 70.49\n",
      "Epoch: [053] \t Loss 0.7769 \t Acc 78.77 \t AccHead 79.98 \t AccTail 66.04\n",
      "Epoch: [054] \t Loss 0.6783 \t Acc 77.62 \t AccHead 79.01 \t AccTail 63.05\n",
      "Epoch: [055] \t Loss 0.7438 \t Acc 79.48 \t AccHead 80.51 \t AccTail 68.63\n",
      "Epoch: [056] \t Loss 0.6709 \t Acc 78.07 \t AccHead 79.58 \t AccTail 62.20\n",
      "Epoch: [057] \t Loss 0.6711 \t Acc 82.82 \t AccHead 83.75 \t AccTail 72.97\n",
      "Epoch: [058] \t Loss 0.6812 \t Acc 79.16 \t AccHead 80.14 \t AccTail 68.91\n",
      "Epoch: [059] \t Loss 0.6095 \t Acc 79.45 \t AccHead 80.74 \t AccTail 66.00\n",
      "Epoch: [060] \t Loss 0.6643 \t Acc 80.97 \t AccHead 82.30 \t AccTail 66.85\n",
      "Epoch: [061] \t Loss 0.6235 \t Acc 82.45 \t AccHead 83.26 \t AccTail 73.89\n",
      "Epoch: [062] \t Loss 0.5953 \t Acc 80.64 \t AccHead 81.22 \t AccTail 74.56\n",
      "Epoch: [063] \t Loss 0.6062 \t Acc 82.30 \t AccHead 82.65 \t AccTail 78.60\n",
      "Epoch: [064] \t Loss 0.5829 \t Acc 84.71 \t AccHead 85.52 \t AccTail 76.22\n",
      "Epoch: [065] \t Loss 0.5755 \t Acc 83.40 \t AccHead 83.74 \t AccTail 79.79\n",
      "Epoch: [066] \t Loss 0.5689 \t Acc 82.78 \t AccHead 83.16 \t AccTail 78.73\n",
      "Epoch: [067] \t Loss 0.5612 \t Acc 84.79 \t AccHead 85.39 \t AccTail 78.54\n",
      "Epoch: [068] \t Loss 0.5436 \t Acc 81.02 \t AccHead 81.72 \t AccTail 73.66\n",
      "Epoch: [069] \t Loss 0.5337 \t Acc 81.41 \t AccHead 82.23 \t AccTail 72.79\n",
      "Epoch: [070] \t Loss 0.5260 \t Acc 85.20 \t AccHead 85.62 \t AccTail 80.86\n",
      "Epoch: [071] \t Loss 0.4817 \t Acc 85.67 \t AccHead 86.31 \t AccTail 78.93\n",
      "Epoch: [072] \t Loss 0.5214 \t Acc 85.06 \t AccHead 85.72 \t AccTail 78.17\n",
      "Epoch: [073] \t Loss 0.5194 \t Acc 82.32 \t AccHead 82.70 \t AccTail 78.38\n",
      "Epoch: [074] \t Loss 0.5170 \t Acc 86.75 \t AccHead 86.97 \t AccTail 84.43\n",
      "Epoch: [075] \t Loss 0.4901 \t Acc 82.66 \t AccHead 83.50 \t AccTail 73.78\n",
      "Epoch: [076] \t Loss 0.4679 \t Acc 85.30 \t AccHead 85.73 \t AccTail 80.70\n",
      "Epoch: [077] \t Loss 0.4665 \t Acc 81.45 \t AccHead 82.14 \t AccTail 74.23\n",
      "Epoch: [078] \t Loss 0.4837 \t Acc 86.87 \t AccHead 87.32 \t AccTail 82.12\n",
      "Epoch: [079] \t Loss 0.4778 \t Acc 84.04 \t AccHead 84.80 \t AccTail 76.04\n",
      "Epoch: [080] \t Loss 0.4831 \t Acc 89.30 \t AccHead 89.64 \t AccTail 85.64\n",
      "Epoch: [081] \t Loss 0.4686 \t Acc 84.99 \t AccHead 85.18 \t AccTail 83.04\n",
      "Epoch: [082] \t Loss 0.4452 \t Acc 86.73 \t AccHead 87.28 \t AccTail 80.99\n",
      "Epoch: [083] \t Loss 0.4422 \t Acc 87.57 \t AccHead 87.87 \t AccTail 84.45\n",
      "Epoch: [084] \t Loss 0.4448 \t Acc 83.06 \t AccHead 84.12 \t AccTail 71.89\n",
      "Epoch: [085] \t Loss 0.4467 \t Acc 84.74 \t AccHead 85.17 \t AccTail 80.08\n",
      "Epoch: [086] \t Loss 0.4575 \t Acc 86.74 \t AccHead 87.23 \t AccTail 81.62\n",
      "Epoch: [087] \t Loss 0.4273 \t Acc 89.83 \t AccHead 90.13 \t AccTail 86.64\n",
      "Epoch: [088] \t Loss 0.4383 \t Acc 85.17 \t AccHead 85.58 \t AccTail 80.83\n",
      "Epoch: [089] \t Loss 0.4675 \t Acc 83.97 \t AccHead 84.33 \t AccTail 80.14\n",
      "Epoch: [090] \t Loss 0.4315 \t Acc 84.18 \t AccHead 85.21 \t AccTail 73.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 16:47:59,987]\u001b[0m Trial 2 finished with value: 5.192108154296875 and parameters: {'n_epoch': 90, 'weight_decay': 0.0004932462173669543}. Best is trial 1 with value: 6.085150718688965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 5.19 \t AccHead 10.35 \t AccTail 0.06\n",
      "Epoch: [001] \t Loss 4.3899 \t Acc 13.06 \t AccHead 14.30 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 3.8199 \t Acc 17.58 \t AccHead 19.13 \t AccTail 1.47\n",
      "Epoch: [003] \t Loss 3.5142 \t Acc 18.77 \t AccHead 20.39 \t AccTail 1.74\n",
      "Epoch: [004] \t Loss 3.2954 \t Acc 19.89 \t AccHead 21.75 \t AccTail 0.40\n",
      "Epoch: [005] \t Loss 3.1582 \t Acc 24.29 \t AccHead 26.44 \t AccTail 1.62\n",
      "Epoch: [006] \t Loss 3.0729 \t Acc 27.12 \t AccHead 29.19 \t AccTail 5.37\n",
      "Epoch: [007] \t Loss 2.9531 \t Acc 28.57 \t AccHead 30.76 \t AccTail 5.62\n",
      "Epoch: [008] \t Loss 2.8792 \t Acc 31.03 \t AccHead 33.25 \t AccTail 7.55\n",
      "Epoch: [009] \t Loss 2.7856 \t Acc 30.69 \t AccHead 33.07 \t AccTail 5.65\n",
      "Epoch: [010] \t Loss 2.6887 \t Acc 33.10 \t AccHead 35.36 \t AccTail 9.48\n",
      "Epoch: [011] \t Loss 2.6009 \t Acc 34.48 \t AccHead 37.02 \t AccTail 7.90\n",
      "Epoch: [012] \t Loss 2.5448 \t Acc 36.80 \t AccHead 39.31 \t AccTail 10.36\n",
      "Epoch: [013] \t Loss 2.5070 \t Acc 36.28 \t AccHead 38.85 \t AccTail 9.35\n",
      "Epoch: [014] \t Loss 2.4088 \t Acc 39.61 \t AccHead 41.88 \t AccTail 15.56\n",
      "Epoch: [015] \t Loss 2.3127 \t Acc 38.86 \t AccHead 41.35 \t AccTail 12.55\n",
      "Epoch: [016] \t Loss 2.2654 \t Acc 43.58 \t AccHead 46.45 \t AccTail 13.40\n",
      "Epoch: [017] \t Loss 2.1670 \t Acc 43.24 \t AccHead 46.14 \t AccTail 12.63\n",
      "Epoch: [018] \t Loss 2.0984 \t Acc 44.31 \t AccHead 46.92 \t AccTail 17.00\n",
      "Epoch: [019] \t Loss 2.0514 \t Acc 45.76 \t AccHead 48.33 \t AccTail 18.68\n",
      "Epoch: [020] \t Loss 1.9914 \t Acc 49.04 \t AccHead 51.58 \t AccTail 22.46\n",
      "Epoch: [021] \t Loss 1.9142 \t Acc 48.33 \t AccHead 51.19 \t AccTail 18.28\n",
      "Epoch: [022] \t Loss 1.8686 \t Acc 50.02 \t AccHead 52.68 \t AccTail 22.19\n",
      "Epoch: [023] \t Loss 1.8201 \t Acc 56.56 \t AccHead 59.08 \t AccTail 30.16\n",
      "Epoch: [024] \t Loss 1.7086 \t Acc 55.84 \t AccHead 58.15 \t AccTail 31.49\n",
      "Epoch: [025] \t Loss 1.6669 \t Acc 56.42 \t AccHead 59.18 \t AccTail 27.52\n",
      "Epoch: [026] \t Loss 1.5527 \t Acc 58.30 \t AccHead 60.11 \t AccTail 39.33\n",
      "Epoch: [027] \t Loss 1.4903 \t Acc 61.64 \t AccHead 63.52 \t AccTail 41.82\n",
      "Epoch: [028] \t Loss 1.4247 \t Acc 59.49 \t AccHead 61.45 \t AccTail 38.78\n",
      "Epoch: [029] \t Loss 1.3962 \t Acc 62.13 \t AccHead 64.18 \t AccTail 40.62\n",
      "Epoch: [030] \t Loss 1.2606 \t Acc 66.69 \t AccHead 68.09 \t AccTail 52.01\n",
      "Epoch: [031] \t Loss 1.2402 \t Acc 67.64 \t AccHead 69.51 \t AccTail 47.98\n",
      "Epoch: [032] \t Loss 1.1600 \t Acc 66.36 \t AccHead 68.46 \t AccTail 44.31\n",
      "Epoch: [033] \t Loss 1.1072 \t Acc 72.33 \t AccHead 73.86 \t AccTail 56.14\n",
      "Epoch: [034] \t Loss 1.0091 \t Acc 74.06 \t AccHead 75.17 \t AccTail 62.38\n",
      "Epoch: [035] \t Loss 0.9619 \t Acc 75.06 \t AccHead 76.33 \t AccTail 61.71\n",
      "Epoch: [036] \t Loss 0.9109 \t Acc 79.07 \t AccHead 80.06 \t AccTail 68.64\n",
      "Epoch: [037] \t Loss 0.8269 \t Acc 78.04 \t AccHead 79.22 \t AccTail 65.73\n",
      "Epoch: [038] \t Loss 0.7886 \t Acc 80.26 \t AccHead 80.82 \t AccTail 74.36\n",
      "Epoch: [039] \t Loss 0.7240 \t Acc 81.46 \t AccHead 82.12 \t AccTail 74.50\n",
      "Epoch: [040] \t Loss 0.7106 \t Acc 83.55 \t AccHead 84.36 \t AccTail 75.03\n",
      "Epoch: [041] \t Loss 0.6372 \t Acc 84.98 \t AccHead 85.72 \t AccTail 77.18\n",
      "Epoch: [042] \t Loss 0.6023 \t Acc 84.89 \t AccHead 85.56 \t AccTail 77.87\n",
      "Epoch: [043] \t Loss 0.5812 \t Acc 86.12 \t AccHead 86.55 \t AccTail 81.64\n",
      "Epoch: [044] \t Loss 0.5265 \t Acc 88.60 \t AccHead 88.91 \t AccTail 85.33\n",
      "Epoch: [045] \t Loss 0.4736 \t Acc 89.49 \t AccHead 89.82 \t AccTail 86.02\n",
      "Epoch: [046] \t Loss 0.4660 \t Acc 89.55 \t AccHead 89.86 \t AccTail 86.25\n",
      "Epoch: [047] \t Loss 0.4580 \t Acc 86.29 \t AccHead 86.38 \t AccTail 85.33\n",
      "Epoch: [048] \t Loss 0.4204 \t Acc 88.23 \t AccHead 88.45 \t AccTail 85.92\n",
      "Epoch: [049] \t Loss 0.3907 \t Acc 89.05 \t AccHead 89.35 \t AccTail 85.91\n",
      "Epoch: [050] \t Loss 0.3682 \t Acc 90.69 \t AccHead 90.67 \t AccTail 90.99\n",
      "Epoch: [051] \t Loss 0.3694 \t Acc 92.21 \t AccHead 92.42 \t AccTail 90.05\n",
      "Epoch: [052] \t Loss 0.3145 \t Acc 91.35 \t AccHead 91.34 \t AccTail 91.39\n",
      "Epoch: [053] \t Loss 0.3259 \t Acc 92.61 \t AccHead 92.76 \t AccTail 90.97\n",
      "Epoch: [054] \t Loss 0.3073 \t Acc 91.27 \t AccHead 91.30 \t AccTail 90.90\n",
      "Epoch: [055] \t Loss 0.2645 \t Acc 95.01 \t AccHead 95.14 \t AccTail 93.68\n",
      "Epoch: [056] \t Loss 0.2375 \t Acc 93.55 \t AccHead 93.55 \t AccTail 93.56\n",
      "Epoch: [057] \t Loss 0.2554 \t Acc 91.27 \t AccHead 91.38 \t AccTail 90.09\n",
      "Epoch: [058] \t Loss 0.2647 \t Acc 92.21 \t AccHead 92.32 \t AccTail 91.03\n",
      "Epoch: [059] \t Loss 0.2311 \t Acc 94.50 \t AccHead 94.46 \t AccTail 94.91\n",
      "Epoch: [060] \t Loss 0.2124 \t Acc 94.08 \t AccHead 94.16 \t AccTail 93.15\n",
      "Epoch: [061] \t Loss 0.2242 \t Acc 94.88 \t AccHead 94.87 \t AccTail 95.05\n",
      "Epoch: [062] \t Loss 0.2006 \t Acc 95.44 \t AccHead 95.39 \t AccTail 95.95\n",
      "Epoch: [063] \t Loss 0.2063 \t Acc 95.18 \t AccHead 95.24 \t AccTail 94.61\n",
      "Epoch: [064] \t Loss 0.1875 \t Acc 95.20 \t AccHead 95.35 \t AccTail 93.52\n",
      "Epoch: [065] \t Loss 0.1872 \t Acc 95.81 \t AccHead 95.86 \t AccTail 95.30\n",
      "Epoch: [066] \t Loss 0.1526 \t Acc 96.62 \t AccHead 96.68 \t AccTail 95.96\n",
      "Epoch: [067] \t Loss 0.1619 \t Acc 96.35 \t AccHead 96.46 \t AccTail 95.17\n",
      "Epoch: [068] \t Loss 0.1543 \t Acc 95.65 \t AccHead 95.73 \t AccTail 94.77\n",
      "Epoch: [069] \t Loss 0.1391 \t Acc 96.82 \t AccHead 96.88 \t AccTail 96.10\n",
      "Epoch: [070] \t Loss 0.1456 \t Acc 97.07 \t AccHead 97.15 \t AccTail 96.26\n",
      "Epoch: [071] \t Loss 0.1512 \t Acc 95.64 \t AccHead 95.63 \t AccTail 95.69\n",
      "Epoch: [072] \t Loss 0.1504 \t Acc 96.62 \t AccHead 96.68 \t AccTail 95.94\n",
      "Epoch: [073] \t Loss 0.1523 \t Acc 97.35 \t AccHead 97.38 \t AccTail 97.05\n",
      "Epoch: [074] \t Loss 0.1401 \t Acc 97.22 \t AccHead 97.24 \t AccTail 97.04\n",
      "Epoch: [075] \t Loss 0.1239 \t Acc 97.34 \t AccHead 97.46 \t AccTail 96.09\n",
      "Epoch: [076] \t Loss 0.1146 \t Acc 97.75 \t AccHead 97.83 \t AccTail 96.92\n",
      "Epoch: [077] \t Loss 0.1139 \t Acc 97.80 \t AccHead 97.93 \t AccTail 96.37\n",
      "Epoch: [078] \t Loss 0.1246 \t Acc 96.92 \t AccHead 97.05 \t AccTail 95.57\n",
      "Epoch: [079] \t Loss 0.1275 \t Acc 97.59 \t AccHead 97.66 \t AccTail 96.76\n",
      "Epoch: [080] \t Loss 0.0990 \t Acc 98.12 \t AccHead 98.20 \t AccTail 97.33\n",
      "Epoch: [081] \t Loss 0.0932 \t Acc 98.04 \t AccHead 98.02 \t AccTail 98.26\n",
      "Epoch: [082] \t Loss 0.0945 \t Acc 97.82 \t AccHead 97.91 \t AccTail 96.90\n",
      "Epoch: [083] \t Loss 0.0936 \t Acc 97.75 \t AccHead 97.83 \t AccTail 96.91\n",
      "Epoch: [084] \t Loss 0.0930 \t Acc 98.25 \t AccHead 98.20 \t AccTail 98.79\n",
      "Epoch: [085] \t Loss 0.0834 \t Acc 98.46 \t AccHead 98.54 \t AccTail 97.58\n",
      "Epoch: [086] \t Loss 0.0955 \t Acc 98.30 \t AccHead 98.38 \t AccTail 97.45\n",
      "Epoch: [087] \t Loss 0.0820 \t Acc 97.88 \t AccHead 97.75 \t AccTail 99.19\n",
      "Epoch: [088] \t Loss 0.0743 \t Acc 98.48 \t AccHead 98.44 \t AccTail 98.93\n",
      "Epoch: [089] \t Loss 0.0760 \t Acc 98.40 \t AccHead 98.35 \t AccTail 98.92\n",
      "Epoch: [090] \t Loss 0.0708 \t Acc 98.88 \t AccHead 98.88 \t AccTail 98.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 16:58:51,148]\u001b[0m Trial 3 finished with value: 5.430944919586182 and parameters: {'n_epoch': 90, 'weight_decay': 3.892267784409615e-05}. Best is trial 1 with value: 6.085150718688965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 5.43 \t AccHead 10.75 \t AccTail 0.14\n",
      "Epoch: [001] \t Loss 4.2646 \t Acc 4.58 \t AccHead 5.02 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 4.0860 \t Acc 4.47 \t AccHead 4.89 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 4.0552 \t Acc 4.64 \t AccHead 5.08 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 4.0586 \t Acc 7.04 \t AccHead 7.71 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 4.0446 \t Acc 7.21 \t AccHead 7.89 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 4.0488 \t Acc 6.52 \t AccHead 7.14 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 4.0519 \t Acc 4.02 \t AccHead 4.41 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 4.0494 \t Acc 6.65 \t AccHead 7.28 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 4.0586 \t Acc 6.68 \t AccHead 7.31 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 4.0499 \t Acc 3.85 \t AccHead 4.21 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 4.0521 \t Acc 5.42 \t AccHead 5.94 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 4.0569 \t Acc 3.99 \t AccHead 4.37 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 4.0479 \t Acc 4.63 \t AccHead 5.07 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 4.0486 \t Acc 3.88 \t AccHead 4.25 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 4.0579 \t Acc 5.55 \t AccHead 6.08 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 4.0487 \t Acc 4.07 \t AccHead 4.46 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 4.0487 \t Acc 5.77 \t AccHead 6.32 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 4.0496 \t Acc 7.44 \t AccHead 8.14 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 4.0441 \t Acc 4.16 \t AccHead 4.56 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 4.0534 \t Acc 4.72 \t AccHead 5.17 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 4.0692 \t Acc 6.80 \t AccHead 7.45 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 4.0573 \t Acc 4.40 \t AccHead 4.81 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 4.0480 \t Acc 5.54 \t AccHead 6.07 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 4.0562 \t Acc 5.49 \t AccHead 6.01 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 4.0451 \t Acc 6.28 \t AccHead 6.88 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 4.0467 \t Acc 3.64 \t AccHead 3.99 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 4.0435 \t Acc 6.82 \t AccHead 7.47 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 4.0413 \t Acc 4.00 \t AccHead 4.38 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 4.0464 \t Acc 5.60 \t AccHead 6.13 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 4.0582 \t Acc 4.22 \t AccHead 4.62 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 4.0529 \t Acc 4.09 \t AccHead 4.48 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 4.0683 \t Acc 4.40 \t AccHead 4.81 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 4.0551 \t Acc 3.31 \t AccHead 3.63 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 4.0438 \t Acc 4.62 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 4.0473 \t Acc 6.59 \t AccHead 7.22 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 4.0807 \t Acc 4.41 \t AccHead 4.83 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 4.1330 \t Acc 4.59 \t AccHead 5.03 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 4.1367 \t Acc 4.19 \t AccHead 4.59 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 4.1277 \t Acc 3.16 \t AccHead 3.46 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 4.1309 \t Acc 4.63 \t AccHead 5.07 \t AccTail 0.00\n",
      "Epoch: [041] \t Loss 4.1316 \t Acc 4.59 \t AccHead 5.03 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 4.1329 \t Acc 4.61 \t AccHead 5.05 \t AccTail 0.00\n",
      "Epoch: [043] \t Loss 4.1249 \t Acc 4.03 \t AccHead 4.42 \t AccTail 0.00\n",
      "Epoch: [044] \t Loss 4.1267 \t Acc 4.22 \t AccHead 4.62 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 4.1323 \t Acc 3.66 \t AccHead 4.01 \t AccTail 0.00\n",
      "Epoch: [046] \t Loss 4.1316 \t Acc 4.37 \t AccHead 4.79 \t AccTail 0.00\n",
      "Epoch: [047] \t Loss 4.1281 \t Acc 4.59 \t AccHead 5.03 \t AccTail 0.00\n",
      "Epoch: [048] \t Loss 4.1295 \t Acc 4.61 \t AccHead 5.05 \t AccTail 0.00\n",
      "Epoch: [049] \t Loss 4.1295 \t Acc 3.99 \t AccHead 4.37 \t AccTail 0.00\n",
      "Epoch: [050] \t Loss 4.1281 \t Acc 4.61 \t AccHead 5.04 \t AccTail 0.00\n",
      "Epoch: [051] \t Loss 4.1292 \t Acc 4.63 \t AccHead 5.07 \t AccTail 0.00\n",
      "Epoch: [052] \t Loss 4.1230 \t Acc 4.59 \t AccHead 5.03 \t AccTail 0.00\n",
      "Epoch: [053] \t Loss 4.1330 \t Acc 4.40 \t AccHead 4.81 \t AccTail 0.00\n",
      "Epoch: [054] \t Loss 4.1353 \t Acc 4.62 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [055] \t Loss 4.1333 \t Acc 4.21 \t AccHead 4.61 \t AccTail 0.00\n",
      "Epoch: [056] \t Loss 4.1292 \t Acc 4.58 \t AccHead 5.02 \t AccTail 0.00\n",
      "Epoch: [057] \t Loss 4.1349 \t Acc 4.01 \t AccHead 4.39 \t AccTail 0.00\n",
      "Epoch: [058] \t Loss 4.1290 \t Acc 4.01 \t AccHead 4.39 \t AccTail 0.00\n",
      "Epoch: [059] \t Loss 4.1309 \t Acc 3.99 \t AccHead 4.37 \t AccTail 0.00\n",
      "Epoch: [060] \t Loss 4.1336 \t Acc 4.41 \t AccHead 4.82 \t AccTail 0.00\n",
      "Epoch: [061] \t Loss 4.1336 \t Acc 4.20 \t AccHead 4.59 \t AccTail 0.00\n",
      "Epoch: [062] \t Loss 4.1262 \t Acc 4.14 \t AccHead 4.53 \t AccTail 0.00\n",
      "Epoch: [063] \t Loss 4.1327 \t Acc 4.62 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [064] \t Loss 4.1298 \t Acc 4.17 \t AccHead 4.57 \t AccTail 0.00\n",
      "Epoch: [065] \t Loss 4.1380 \t Acc 4.63 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [066] \t Loss 4.1315 \t Acc 4.62 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [067] \t Loss 4.1295 \t Acc 4.20 \t AccHead 4.60 \t AccTail 0.00\n",
      "Epoch: [068] \t Loss 4.1285 \t Acc 3.65 \t AccHead 3.99 \t AccTail 0.00\n",
      "Epoch: [069] \t Loss 4.1310 \t Acc 3.84 \t AccHead 4.20 \t AccTail 0.00\n",
      "Epoch: [070] \t Loss 4.1261 \t Acc 3.50 \t AccHead 3.83 \t AccTail 0.00\n",
      "Epoch: [071] \t Loss 4.1281 \t Acc 4.21 \t AccHead 4.61 \t AccTail 0.00\n",
      "Epoch: [072] \t Loss 4.1304 \t Acc 3.65 \t AccHead 3.99 \t AccTail 0.00\n",
      "Epoch: [073] \t Loss 4.1261 \t Acc 4.37 \t AccHead 4.79 \t AccTail 0.00\n",
      "Epoch: [074] \t Loss 4.1349 \t Acc 4.17 \t AccHead 4.57 \t AccTail 0.00\n",
      "Epoch: [075] \t Loss 4.1307 \t Acc 4.63 \t AccHead 5.07 \t AccTail 0.00\n",
      "Epoch: [076] \t Loss 4.1282 \t Acc 4.62 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [077] \t Loss 4.1302 \t Acc 4.62 \t AccHead 5.05 \t AccTail 0.00\n",
      "Epoch: [078] \t Loss 4.1314 \t Acc 4.19 \t AccHead 4.59 \t AccTail 0.00\n",
      "Epoch: [079] \t Loss 4.1265 \t Acc 3.99 \t AccHead 4.37 \t AccTail 0.00\n",
      "Epoch: [080] \t Loss 4.1331 \t Acc 4.63 \t AccHead 5.07 \t AccTail 0.00\n",
      "Epoch: [081] \t Loss 4.1335 \t Acc 4.58 \t AccHead 5.02 \t AccTail 0.00\n",
      "Epoch: [082] \t Loss 4.1303 \t Acc 4.22 \t AccHead 4.62 \t AccTail 0.00\n",
      "Epoch: [083] \t Loss 4.1357 \t Acc 4.62 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [084] \t Loss 4.1321 \t Acc 4.17 \t AccHead 4.57 \t AccTail 0.00\n",
      "Epoch: [085] \t Loss 4.1273 \t Acc 4.43 \t AccHead 4.85 \t AccTail 0.00\n",
      "Epoch: [086] \t Loss 4.1279 \t Acc 3.32 \t AccHead 3.64 \t AccTail 0.00\n",
      "Epoch: [087] \t Loss 4.1305 \t Acc 4.42 \t AccHead 4.84 \t AccTail 0.00\n",
      "Epoch: [088] \t Loss 4.1279 \t Acc 4.38 \t AccHead 4.80 \t AccTail 0.00\n",
      "Epoch: [089] \t Loss 4.1284 \t Acc 4.58 \t AccHead 5.02 \t AccTail 0.00\n",
      "Epoch: [090] \t Loss 4.1321 \t Acc 4.00 \t AccHead 4.38 \t AccTail 0.00\n",
      "Epoch: [091] \t Loss 4.1298 \t Acc 4.15 \t AccHead 4.55 \t AccTail 0.00\n",
      "Epoch: [092] \t Loss 4.1294 \t Acc 4.37 \t AccHead 4.79 \t AccTail 0.00\n",
      "Epoch: [093] \t Loss 4.1390 \t Acc 3.79 \t AccHead 4.15 \t AccTail 0.00\n",
      "Epoch: [094] \t Loss 4.1283 \t Acc 4.23 \t AccHead 4.63 \t AccTail 0.00\n",
      "Epoch: [095] \t Loss 4.1326 \t Acc 4.61 \t AccHead 5.04 \t AccTail 0.00\n",
      "Epoch: [096] \t Loss 4.1336 \t Acc 4.62 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [097] \t Loss 4.1290 \t Acc 4.65 \t AccHead 5.09 \t AccTail 0.00\n",
      "Epoch: [098] \t Loss 4.1277 \t Acc 4.63 \t AccHead 5.07 \t AccTail 0.00\n",
      "Epoch: [099] \t Loss 4.1272 \t Acc 4.61 \t AccHead 5.04 \t AccTail 0.00\n",
      "Epoch: [100] \t Loss 4.1316 \t Acc 3.96 \t AccHead 4.34 \t AccTail 0.00\n",
      "Epoch: [101] \t Loss 4.1320 \t Acc 4.63 \t AccHead 5.07 \t AccTail 0.00\n",
      "Epoch: [102] \t Loss 4.1294 \t Acc 4.43 \t AccHead 4.85 \t AccTail 0.00\n",
      "Epoch: [103] \t Loss 4.1310 \t Acc 4.22 \t AccHead 4.62 \t AccTail 0.00\n",
      "Epoch: [104] \t Loss 4.1328 \t Acc 3.86 \t AccHead 4.22 \t AccTail 0.00\n",
      "Epoch: [105] \t Loss 4.1273 \t Acc 3.64 \t AccHead 3.98 \t AccTail 0.00\n",
      "Epoch: [106] \t Loss 4.1316 \t Acc 4.00 \t AccHead 4.38 \t AccTail 0.00\n",
      "Epoch: [107] \t Loss 4.1275 \t Acc 4.62 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [108] \t Loss 4.1271 \t Acc 4.62 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [109] \t Loss 4.1345 \t Acc 3.50 \t AccHead 3.83 \t AccTail 0.00\n",
      "Epoch: [110] \t Loss 4.1314 \t Acc 4.61 \t AccHead 5.04 \t AccTail 0.00\n",
      "Epoch: [111] \t Loss 4.1303 \t Acc 3.85 \t AccHead 4.21 \t AccTail 0.00\n",
      "Epoch: [112] \t Loss 4.1269 \t Acc 4.19 \t AccHead 4.58 \t AccTail 0.00\n",
      "Epoch: [113] \t Loss 4.1313 \t Acc 4.36 \t AccHead 4.77 \t AccTail 0.00\n",
      "Epoch: [114] \t Loss 4.1282 \t Acc 3.79 \t AccHead 4.15 \t AccTail 0.00\n",
      "Epoch: [115] \t Loss 4.1358 \t Acc 4.05 \t AccHead 4.43 \t AccTail 0.00\n",
      "Epoch: [116] \t Loss 4.1369 \t Acc 4.38 \t AccHead 4.80 \t AccTail 0.00\n",
      "Epoch: [117] \t Loss 4.1314 \t Acc 4.41 \t AccHead 4.83 \t AccTail 0.00\n",
      "Epoch: [118] \t Loss 4.1270 \t Acc 4.42 \t AccHead 4.84 \t AccTail 0.00\n",
      "Epoch: [119] \t Loss 4.1316 \t Acc 4.38 \t AccHead 4.80 \t AccTail 0.00\n",
      "Epoch: [120] \t Loss 4.1285 \t Acc 3.84 \t AccHead 4.20 \t AccTail 0.00\n",
      "Epoch: [121] \t Loss 4.1330 \t Acc 4.02 \t AccHead 4.41 \t AccTail 0.00\n",
      "Epoch: [122] \t Loss 4.1279 \t Acc 4.21 \t AccHead 4.61 \t AccTail 0.00\n",
      "Epoch: [123] \t Loss 4.1350 \t Acc 3.96 \t AccHead 4.34 \t AccTail 0.00\n",
      "Epoch: [124] \t Loss 4.1276 \t Acc 4.41 \t AccHead 4.83 \t AccTail 0.00\n",
      "Epoch: [125] \t Loss 4.1289 \t Acc 4.59 \t AccHead 5.03 \t AccTail 0.00\n",
      "Epoch: [126] \t Loss 4.1323 \t Acc 4.59 \t AccHead 5.03 \t AccTail 0.00\n",
      "Epoch: [127] \t Loss 4.1300 \t Acc 4.59 \t AccHead 5.03 \t AccTail 0.00\n",
      "Epoch: [128] \t Loss 4.1255 \t Acc 4.40 \t AccHead 4.81 \t AccTail 0.00\n",
      "Epoch: [129] \t Loss 4.1310 \t Acc 4.62 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [130] \t Loss 4.1326 \t Acc 4.57 \t AccHead 5.01 \t AccTail 0.00\n",
      "Epoch: [131] \t Loss 4.1269 \t Acc 4.17 \t AccHead 4.57 \t AccTail 0.00\n",
      "Epoch: [132] \t Loss 4.1243 \t Acc 4.62 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [133] \t Loss 4.1260 \t Acc 4.63 \t AccHead 5.07 \t AccTail 0.00\n",
      "Epoch: [134] \t Loss 4.1310 \t Acc 3.81 \t AccHead 4.18 \t AccTail 0.00\n",
      "Epoch: [135] \t Loss 4.1311 \t Acc 4.40 \t AccHead 4.81 \t AccTail 0.00\n",
      "Epoch: [136] \t Loss 4.1261 \t Acc 4.05 \t AccHead 4.43 \t AccTail 0.00\n",
      "Epoch: [137] \t Loss 4.1323 \t Acc 4.02 \t AccHead 4.40 \t AccTail 0.00\n",
      "Epoch: [138] \t Loss 4.1299 \t Acc 4.41 \t AccHead 4.82 \t AccTail 0.00\n",
      "Epoch: [139] \t Loss 4.1265 \t Acc 4.37 \t AccHead 4.79 \t AccTail 0.00\n",
      "Epoch: [140] \t Loss 4.1296 \t Acc 4.58 \t AccHead 5.02 \t AccTail 0.00\n",
      "Epoch: [141] \t Loss 4.1315 \t Acc 4.64 \t AccHead 5.08 \t AccTail 0.00\n",
      "Epoch: [142] \t Loss 4.1353 \t Acc 3.49 \t AccHead 3.82 \t AccTail 0.00\n",
      "Epoch: [143] \t Loss 4.1292 \t Acc 4.63 \t AccHead 5.07 \t AccTail 0.00\n",
      "Epoch: [144] \t Loss 4.1273 \t Acc 4.62 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [145] \t Loss 4.1293 \t Acc 4.62 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [146] \t Loss 4.1318 \t Acc 4.58 \t AccHead 5.02 \t AccTail 0.00\n",
      "Epoch: [147] \t Loss 4.1237 \t Acc 4.59 \t AccHead 5.03 \t AccTail 0.00\n",
      "Epoch: [148] \t Loss 4.1259 \t Acc 4.37 \t AccHead 4.79 \t AccTail 0.00\n",
      "Epoch: [149] \t Loss 4.1309 \t Acc 4.36 \t AccHead 4.78 \t AccTail 0.00\n",
      "Epoch: [150] \t Loss 4.1280 \t Acc 4.15 \t AccHead 4.55 \t AccTail 0.00\n",
      "Epoch: [151] \t Loss 4.1269 \t Acc 4.38 \t AccHead 4.80 \t AccTail 0.00\n",
      "Epoch: [152] \t Loss 4.1106 \t Acc 4.63 \t AccHead 5.07 \t AccTail 0.00\n",
      "Epoch: [153] \t Loss 4.1085 \t Acc 4.64 \t AccHead 5.08 \t AccTail 0.00\n",
      "Epoch: [154] \t Loss 4.1061 \t Acc 4.61 \t AccHead 5.04 \t AccTail 0.00\n",
      "Epoch: [155] \t Loss 4.1070 \t Acc 4.58 \t AccHead 5.01 \t AccTail 0.00\n",
      "Epoch: [156] \t Loss 4.1058 \t Acc 4.59 \t AccHead 5.03 \t AccTail 0.00\n",
      "Epoch: [157] \t Loss 4.1067 \t Acc 4.62 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [158] \t Loss 4.1074 \t Acc 4.63 \t AccHead 5.07 \t AccTail 0.00\n",
      "Epoch: [159] \t Loss 4.1061 \t Acc 4.43 \t AccHead 4.85 \t AccTail 0.00\n",
      "Epoch: [160] \t Loss 4.1073 \t Acc 4.62 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [161] \t Loss 4.1076 \t Acc 4.64 \t AccHead 5.08 \t AccTail 0.00\n",
      "Epoch: [162] \t Loss 4.1093 \t Acc 4.61 \t AccHead 5.04 \t AccTail 0.00\n",
      "Epoch: [163] \t Loss 4.1078 \t Acc 4.40 \t AccHead 4.81 \t AccTail 0.00\n",
      "Epoch: [164] \t Loss 4.1063 \t Acc 4.63 \t AccHead 5.07 \t AccTail 0.00\n",
      "Epoch: [165] \t Loss 4.1060 \t Acc 4.41 \t AccHead 4.83 \t AccTail 0.00\n",
      "Epoch: [166] \t Loss 4.1067 \t Acc 4.62 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [167] \t Loss 4.1070 \t Acc 4.62 \t AccHead 5.05 \t AccTail 0.00\n",
      "Epoch: [168] \t Loss 4.1058 \t Acc 4.58 \t AccHead 5.02 \t AccTail 0.00\n",
      "Epoch: [169] \t Loss 4.1086 \t Acc 4.62 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [170] \t Loss 4.1062 \t Acc 4.59 \t AccHead 5.03 \t AccTail 0.00\n",
      "Epoch: [171] \t Loss 4.1066 \t Acc 4.61 \t AccHead 5.04 \t AccTail 0.00\n",
      "Epoch: [172] \t Loss 4.1070 \t Acc 4.61 \t AccHead 5.04 \t AccTail 0.00\n",
      "Epoch: [173] \t Loss 4.1061 \t Acc 4.61 \t AccHead 5.04 \t AccTail 0.00\n",
      "Epoch: [174] \t Loss 4.1088 \t Acc 4.58 \t AccHead 5.02 \t AccTail 0.00\n",
      "Epoch: [175] \t Loss 4.1066 \t Acc 4.57 \t AccHead 5.00 \t AccTail 0.00\n",
      "Epoch: [176] \t Loss 4.1064 \t Acc 4.20 \t AccHead 4.60 \t AccTail 0.00\n",
      "Epoch: [177] \t Loss 4.1053 \t Acc 4.62 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [178] \t Loss 4.1075 \t Acc 4.34 \t AccHead 4.75 \t AccTail 0.00\n",
      "Epoch: [179] \t Loss 4.1090 \t Acc 4.61 \t AccHead 5.04 \t AccTail 0.00\n",
      "Epoch: [180] \t Loss 4.1052 \t Acc 4.65 \t AccHead 5.10 \t AccTail 0.00\n",
      "Epoch: [181] \t Loss 4.1063 \t Acc 4.63 \t AccHead 5.07 \t AccTail 0.00\n",
      "Epoch: [182] \t Loss 4.1067 \t Acc 4.63 \t AccHead 5.07 \t AccTail 0.00\n",
      "Epoch: [183] \t Loss 4.1059 \t Acc 4.64 \t AccHead 5.08 \t AccTail 0.00\n",
      "Epoch: [184] \t Loss 4.1081 \t Acc 4.62 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [185] \t Loss 4.1077 \t Acc 4.65 \t AccHead 5.09 \t AccTail 0.00\n",
      "Epoch: [186] \t Loss 4.1039 \t Acc 4.65 \t AccHead 5.09 \t AccTail 0.00\n",
      "Epoch: [187] \t Loss 4.1089 \t Acc 4.63 \t AccHead 5.07 \t AccTail 0.00\n",
      "Epoch: [188] \t Loss 4.1077 \t Acc 4.61 \t AccHead 5.04 \t AccTail 0.00\n",
      "Epoch: [189] \t Loss 4.1059 \t Acc 4.37 \t AccHead 4.79 \t AccTail 0.00\n",
      "Epoch: [190] \t Loss 4.1092 \t Acc 4.43 \t AccHead 4.85 \t AccTail 0.00\n",
      "Epoch: [191] \t Loss 4.1073 \t Acc 4.61 \t AccHead 5.05 \t AccTail 0.00\n",
      "Epoch: [192] \t Loss 4.1062 \t Acc 4.61 \t AccHead 5.04 \t AccTail 0.00\n",
      "Epoch: [193] \t Loss 4.1049 \t Acc 4.61 \t AccHead 5.04 \t AccTail 0.00\n",
      "Epoch: [194] \t Loss 4.1061 \t Acc 4.63 \t AccHead 5.07 \t AccTail 0.00\n",
      "Epoch: [195] \t Loss 4.1072 \t Acc 4.63 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [196] \t Loss 4.1073 \t Acc 4.57 \t AccHead 5.01 \t AccTail 0.00\n",
      "Epoch: [197] \t Loss 4.1049 \t Acc 4.61 \t AccHead 5.05 \t AccTail 0.00\n",
      "Epoch: [198] \t Loss 4.1080 \t Acc 4.64 \t AccHead 5.08 \t AccTail 0.00\n",
      "Epoch: [199] \t Loss 4.1066 \t Acc 4.58 \t AccHead 5.02 \t AccTail 0.00\n",
      "Epoch: [200] \t Loss 4.1058 \t Acc 4.42 \t AccHead 4.84 \t AccTail 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 17:22:36,118]\u001b[0m Trial 4 finished with value: 1.038421630859375 and parameters: {'n_epoch': 200, 'weight_decay': 0.06635934769237037}. Best is trial 1 with value: 6.085150718688965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 1.04 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [001] \t Loss 4.5871 \t Acc 12.16 \t AccHead 13.32 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 3.6847 \t Acc 16.83 \t AccHead 18.36 \t AccTail 0.54\n",
      "Epoch: [003] \t Loss 3.4530 \t Acc 17.75 \t AccHead 19.42 \t AccTail 0.13\n",
      "Epoch: [004] \t Loss 3.2975 \t Acc 21.74 \t AccHead 23.63 \t AccTail 1.62\n",
      "Epoch: [005] \t Loss 3.1553 \t Acc 23.65 \t AccHead 25.79 \t AccTail 1.07\n",
      "Epoch: [006] \t Loss 3.0579 \t Acc 24.52 \t AccHead 26.75 \t AccTail 1.08\n",
      "Epoch: [007] \t Loss 2.9434 \t Acc 27.16 \t AccHead 29.36 \t AccTail 4.02\n",
      "Epoch: [008] \t Loss 2.8652 \t Acc 30.71 \t AccHead 33.15 \t AccTail 4.98\n",
      "Epoch: [009] \t Loss 2.7608 \t Acc 30.87 \t AccHead 33.37 \t AccTail 4.45\n",
      "Epoch: [010] \t Loss 2.7122 \t Acc 33.17 \t AccHead 35.86 \t AccTail 4.97\n",
      "Epoch: [011] \t Loss 2.6050 \t Acc 32.30 \t AccHead 34.69 \t AccTail 6.79\n",
      "Epoch: [012] \t Loss 2.5515 \t Acc 33.96 \t AccHead 36.45 \t AccTail 7.77\n",
      "Epoch: [013] \t Loss 2.4861 \t Acc 38.83 \t AccHead 41.64 \t AccTail 9.05\n",
      "Epoch: [014] \t Loss 2.4152 \t Acc 39.19 \t AccHead 42.09 \t AccTail 8.84\n",
      "Epoch: [015] \t Loss 2.3269 \t Acc 40.68 \t AccHead 43.97 \t AccTail 5.94\n",
      "Epoch: [016] \t Loss 2.2638 \t Acc 42.20 \t AccHead 45.35 \t AccTail 9.33\n",
      "Epoch: [017] \t Loss 2.2140 \t Acc 41.60 \t AccHead 44.25 \t AccTail 13.90\n",
      "Epoch: [018] \t Loss 2.1507 \t Acc 44.36 \t AccHead 47.33 \t AccTail 13.04\n",
      "Epoch: [019] \t Loss 2.0933 \t Acc 46.30 \t AccHead 49.27 \t AccTail 14.96\n",
      "Epoch: [020] \t Loss 2.0201 \t Acc 44.57 \t AccHead 47.02 \t AccTail 18.79\n",
      "Epoch: [021] \t Loss 1.9981 \t Acc 49.34 \t AccHead 52.29 \t AccTail 18.00\n",
      "Epoch: [022] \t Loss 1.9293 \t Acc 48.43 \t AccHead 51.07 \t AccTail 20.67\n",
      "Epoch: [023] \t Loss 1.8847 \t Acc 51.71 \t AccHead 54.59 \t AccTail 21.63\n",
      "Epoch: [024] \t Loss 1.8188 \t Acc 48.55 \t AccHead 51.38 \t AccTail 18.82\n",
      "Epoch: [025] \t Loss 1.7985 \t Acc 51.94 \t AccHead 54.78 \t AccTail 22.09\n",
      "Epoch: [026] \t Loss 1.7127 \t Acc 53.28 \t AccHead 56.05 \t AccTail 24.23\n",
      "Epoch: [027] \t Loss 1.6625 \t Acc 54.08 \t AccHead 56.96 \t AccTail 23.79\n",
      "Epoch: [028] \t Loss 1.6529 \t Acc 54.31 \t AccHead 57.26 \t AccTail 23.11\n",
      "Epoch: [029] \t Loss 1.5981 \t Acc 51.49 \t AccHead 54.18 \t AccTail 23.25\n",
      "Epoch: [030] \t Loss 1.5478 \t Acc 57.53 \t AccHead 60.37 \t AccTail 27.84\n",
      "Epoch: [031] \t Loss 1.4858 \t Acc 59.01 \t AccHead 61.87 \t AccTail 28.99\n",
      "Epoch: [032] \t Loss 1.4961 \t Acc 57.26 \t AccHead 59.99 \t AccTail 28.69\n",
      "Epoch: [033] \t Loss 1.4058 \t Acc 58.07 \t AccHead 60.58 \t AccTail 31.68\n",
      "Epoch: [034] \t Loss 1.3721 \t Acc 60.65 \t AccHead 63.28 \t AccTail 32.84\n",
      "Epoch: [035] \t Loss 1.3322 \t Acc 62.05 \t AccHead 64.99 \t AccTail 31.14\n",
      "Epoch: [036] \t Loss 1.3401 \t Acc 61.93 \t AccHead 64.21 \t AccTail 37.99\n",
      "Epoch: [037] \t Loss 1.2855 \t Acc 64.59 \t AccHead 67.47 \t AccTail 34.27\n",
      "Epoch: [038] \t Loss 1.2525 \t Acc 65.81 \t AccHead 67.67 \t AccTail 46.31\n",
      "Epoch: [039] \t Loss 1.2158 \t Acc 64.90 \t AccHead 67.09 \t AccTail 41.86\n",
      "Epoch: [040] \t Loss 1.1573 \t Acc 64.66 \t AccHead 67.69 \t AccTail 32.75\n",
      "Epoch: [041] \t Loss 1.1332 \t Acc 66.78 \t AccHead 69.29 \t AccTail 40.40\n",
      "Epoch: [042] \t Loss 1.1074 \t Acc 69.04 \t AccHead 71.15 \t AccTail 47.00\n",
      "Epoch: [043] \t Loss 1.0781 \t Acc 66.80 \t AccHead 69.51 \t AccTail 38.39\n",
      "Epoch: [044] \t Loss 1.0871 \t Acc 67.74 \t AccHead 69.08 \t AccTail 53.57\n",
      "Epoch: [045] \t Loss 1.0460 \t Acc 67.18 \t AccHead 69.39 \t AccTail 43.88\n",
      "Epoch: [046] \t Loss 0.9878 \t Acc 69.90 \t AccHead 71.48 \t AccTail 53.36\n",
      "Epoch: [047] \t Loss 0.9745 \t Acc 71.91 \t AccHead 73.29 \t AccTail 57.34\n",
      "Epoch: [048] \t Loss 0.9262 \t Acc 69.60 \t AccHead 71.03 \t AccTail 54.68\n",
      "Epoch: [049] \t Loss 0.9010 \t Acc 74.94 \t AccHead 76.66 \t AccTail 56.89\n",
      "Epoch: [050] \t Loss 0.8883 \t Acc 75.29 \t AccHead 76.79 \t AccTail 59.49\n",
      "Epoch: [051] \t Loss 0.8902 \t Acc 74.30 \t AccHead 75.91 \t AccTail 57.37\n",
      "Epoch: [052] \t Loss 0.8680 \t Acc 72.27 \t AccHead 73.59 \t AccTail 58.45\n",
      "Epoch: [053] \t Loss 0.8631 \t Acc 75.65 \t AccHead 76.99 \t AccTail 61.54\n",
      "Epoch: [054] \t Loss 0.8241 \t Acc 77.01 \t AccHead 78.63 \t AccTail 59.84\n",
      "Epoch: [055] \t Loss 0.7828 \t Acc 74.91 \t AccHead 76.74 \t AccTail 55.65\n",
      "Epoch: [056] \t Loss 0.7712 \t Acc 74.25 \t AccHead 75.36 \t AccTail 62.53\n",
      "Epoch: [057] \t Loss 0.7594 \t Acc 80.08 \t AccHead 81.69 \t AccTail 63.17\n",
      "Epoch: [058] \t Loss 0.7335 \t Acc 79.27 \t AccHead 80.63 \t AccTail 64.92\n",
      "Epoch: [059] \t Loss 0.6862 \t Acc 79.85 \t AccHead 80.92 \t AccTail 68.51\n",
      "Epoch: [060] \t Loss 0.7278 \t Acc 77.02 \t AccHead 78.17 \t AccTail 64.76\n",
      "Epoch: [061] \t Loss 0.7443 \t Acc 77.95 \t AccHead 78.95 \t AccTail 67.47\n",
      "Epoch: [062] \t Loss 0.6970 \t Acc 71.64 \t AccHead 72.39 \t AccTail 63.76\n",
      "Epoch: [063] \t Loss 0.7025 \t Acc 82.08 \t AccHead 83.11 \t AccTail 71.24\n",
      "Epoch: [064] \t Loss 0.6276 \t Acc 79.61 \t AccHead 79.97 \t AccTail 75.74\n",
      "Epoch: [065] \t Loss 0.6923 \t Acc 75.83 \t AccHead 76.84 \t AccTail 65.14\n",
      "Epoch: [066] \t Loss 0.6282 \t Acc 79.06 \t AccHead 80.51 \t AccTail 63.76\n",
      "Epoch: [067] \t Loss 0.6048 \t Acc 80.97 \t AccHead 81.38 \t AccTail 76.71\n",
      "Epoch: [068] \t Loss 0.6097 \t Acc 80.91 \t AccHead 81.59 \t AccTail 73.76\n",
      "Epoch: [069] \t Loss 0.6249 \t Acc 80.48 \t AccHead 81.07 \t AccTail 74.29\n",
      "Epoch: [070] \t Loss 0.5823 \t Acc 80.84 \t AccHead 81.98 \t AccTail 68.94\n",
      "Epoch: [071] \t Loss 0.6156 \t Acc 77.57 \t AccHead 78.51 \t AccTail 67.61\n",
      "Epoch: [072] \t Loss 0.6236 \t Acc 82.05 \t AccHead 83.19 \t AccTail 70.11\n",
      "Epoch: [073] \t Loss 0.5665 \t Acc 84.56 \t AccHead 84.96 \t AccTail 80.43\n",
      "Epoch: [074] \t Loss 0.5738 \t Acc 80.62 \t AccHead 80.55 \t AccTail 81.34\n",
      "Epoch: [075] \t Loss 0.5597 \t Acc 84.84 \t AccHead 85.31 \t AccTail 79.95\n",
      "Epoch: [076] \t Loss 0.5500 \t Acc 83.15 \t AccHead 83.94 \t AccTail 74.80\n",
      "Epoch: [077] \t Loss 0.5352 \t Acc 81.95 \t AccHead 82.37 \t AccTail 77.57\n",
      "Epoch: [078] \t Loss 0.5610 \t Acc 79.59 \t AccHead 80.36 \t AccTail 71.49\n",
      "Epoch: [079] \t Loss 0.5821 \t Acc 82.11 \t AccHead 82.69 \t AccTail 76.01\n",
      "Epoch: [080] \t Loss 0.5098 \t Acc 84.38 \t AccHead 85.05 \t AccTail 77.22\n",
      "Epoch: [081] \t Loss 0.4983 \t Acc 83.62 \t AccHead 84.12 \t AccTail 78.31\n",
      "Epoch: [082] \t Loss 0.5759 \t Acc 81.80 \t AccHead 82.15 \t AccTail 78.12\n",
      "Epoch: [083] \t Loss 0.5511 \t Acc 86.99 \t AccHead 87.45 \t AccTail 82.10\n",
      "Epoch: [084] \t Loss 0.5043 \t Acc 85.40 \t AccHead 85.98 \t AccTail 79.30\n",
      "Epoch: [085] \t Loss 0.4947 \t Acc 82.00 \t AccHead 82.68 \t AccTail 74.73\n",
      "Epoch: [086] \t Loss 0.5607 \t Acc 84.00 \t AccHead 84.27 \t AccTail 81.13\n",
      "Epoch: [087] \t Loss 0.4995 \t Acc 86.52 \t AccHead 87.08 \t AccTail 80.70\n",
      "Epoch: [088] \t Loss 0.4762 \t Acc 79.72 \t AccHead 80.70 \t AccTail 69.45\n",
      "Epoch: [089] \t Loss 0.5030 \t Acc 85.68 \t AccHead 86.04 \t AccTail 81.85\n",
      "Epoch: [090] \t Loss 0.5497 \t Acc 83.01 \t AccHead 83.33 \t AccTail 79.68\n",
      "Epoch: [091] \t Loss 0.4968 \t Acc 87.36 \t AccHead 87.50 \t AccTail 85.87\n",
      "Epoch: [092] \t Loss 0.4893 \t Acc 82.01 \t AccHead 82.59 \t AccTail 75.84\n",
      "Epoch: [093] \t Loss 0.5282 \t Acc 81.05 \t AccHead 81.65 \t AccTail 74.83\n",
      "Epoch: [094] \t Loss 0.4818 \t Acc 82.63 \t AccHead 83.06 \t AccTail 78.09\n",
      "Epoch: [095] \t Loss 0.4679 \t Acc 88.00 \t AccHead 88.94 \t AccTail 78.06\n",
      "Epoch: [096] \t Loss 0.4332 \t Acc 83.69 \t AccHead 84.08 \t AccTail 79.52\n",
      "Epoch: [097] \t Loss 0.4668 \t Acc 81.44 \t AccHead 81.46 \t AccTail 81.21\n",
      "Epoch: [098] \t Loss 0.5436 \t Acc 83.98 \t AccHead 84.27 \t AccTail 80.94\n",
      "Epoch: [099] \t Loss 0.4816 \t Acc 85.09 \t AccHead 85.80 \t AccTail 77.55\n",
      "Epoch: [100] \t Loss 0.4957 \t Acc 85.30 \t AccHead 85.24 \t AccTail 85.91\n",
      "Epoch: [101] \t Loss 0.4471 \t Acc 85.77 \t AccHead 86.46 \t AccTail 78.57\n",
      "Epoch: [102] \t Loss 0.4667 \t Acc 84.47 \t AccHead 84.89 \t AccTail 79.97\n",
      "Epoch: [103] \t Loss 0.5208 \t Acc 78.63 \t AccHead 79.01 \t AccTail 74.60\n",
      "Epoch: [104] \t Loss 0.4634 \t Acc 81.17 \t AccHead 81.34 \t AccTail 79.35\n",
      "Epoch: [105] \t Loss 0.4681 \t Acc 83.97 \t AccHead 83.97 \t AccTail 83.98\n",
      "Epoch: [106] \t Loss 0.4439 \t Acc 85.66 \t AccHead 85.92 \t AccTail 82.86\n",
      "Epoch: [107] \t Loss 0.4274 \t Acc 83.73 \t AccHead 84.21 \t AccTail 78.73\n",
      "Epoch: [108] \t Loss 0.4422 \t Acc 86.68 \t AccHead 86.68 \t AccTail 86.69\n",
      "Epoch: [109] \t Loss 0.4511 \t Acc 86.44 \t AccHead 87.00 \t AccTail 80.51\n",
      "Epoch: [110] \t Loss 0.4371 \t Acc 84.93 \t AccHead 85.60 \t AccTail 77.90\n",
      "Epoch: [111] \t Loss 0.4483 \t Acc 84.35 \t AccHead 84.62 \t AccTail 81.56\n",
      "Epoch: [112] \t Loss 0.4926 \t Acc 83.75 \t AccHead 84.26 \t AccTail 78.36\n",
      "Epoch: [113] \t Loss 0.4557 \t Acc 85.51 \t AccHead 86.00 \t AccTail 80.35\n",
      "Epoch: [114] \t Loss 0.4475 \t Acc 88.29 \t AccHead 88.54 \t AccTail 85.68\n",
      "Epoch: [115] \t Loss 0.4511 \t Acc 87.17 \t AccHead 87.58 \t AccTail 82.89\n",
      "Epoch: [116] \t Loss 0.4256 \t Acc 89.74 \t AccHead 89.84 \t AccTail 88.72\n",
      "Epoch: [117] \t Loss 0.4156 \t Acc 86.26 \t AccHead 86.74 \t AccTail 81.24\n",
      "Epoch: [118] \t Loss 0.4218 \t Acc 88.56 \t AccHead 88.79 \t AccTail 86.16\n",
      "Epoch: [119] \t Loss 0.4131 \t Acc 86.86 \t AccHead 87.35 \t AccTail 81.65\n",
      "Epoch: [120] \t Loss 0.4310 \t Acc 87.62 \t AccHead 87.91 \t AccTail 84.58\n",
      "Epoch: [121] \t Loss 0.4770 \t Acc 82.93 \t AccHead 83.37 \t AccTail 78.33\n",
      "Epoch: [122] \t Loss 0.4907 \t Acc 82.70 \t AccHead 83.38 \t AccTail 75.47\n",
      "Epoch: [123] \t Loss 0.4502 \t Acc 85.84 \t AccHead 86.51 \t AccTail 78.85\n",
      "Epoch: [124] \t Loss 0.4453 \t Acc 86.28 \t AccHead 86.80 \t AccTail 80.78\n",
      "Epoch: [125] \t Loss 0.4133 \t Acc 87.05 \t AccHead 87.40 \t AccTail 83.33\n",
      "Epoch: [126] \t Loss 0.4307 \t Acc 87.20 \t AccHead 87.51 \t AccTail 83.85\n",
      "Epoch: [127] \t Loss 0.3812 \t Acc 89.11 \t AccHead 89.34 \t AccTail 86.68\n",
      "Epoch: [128] \t Loss 0.3610 \t Acc 85.62 \t AccHead 85.70 \t AccTail 84.79\n",
      "Epoch: [129] \t Loss 0.4139 \t Acc 82.77 \t AccHead 83.84 \t AccTail 71.47\n",
      "Epoch: [130] \t Loss 0.4661 \t Acc 89.18 \t AccHead 89.57 \t AccTail 85.10\n",
      "Epoch: [131] \t Loss 0.4264 \t Acc 89.40 \t AccHead 89.56 \t AccTail 87.77\n",
      "Epoch: [132] \t Loss 0.4133 \t Acc 87.80 \t AccHead 88.00 \t AccTail 85.70\n",
      "Epoch: [133] \t Loss 0.4415 \t Acc 88.98 \t AccHead 89.48 \t AccTail 83.78\n",
      "Epoch: [134] \t Loss 0.4465 \t Acc 81.55 \t AccHead 81.66 \t AccTail 80.41\n",
      "Epoch: [135] \t Loss 0.4609 \t Acc 86.64 \t AccHead 86.66 \t AccTail 86.44\n",
      "Epoch: [136] \t Loss 0.4036 \t Acc 89.18 \t AccHead 89.64 \t AccTail 84.38\n",
      "Epoch: [137] \t Loss 0.4452 \t Acc 88.43 \t AccHead 88.48 \t AccTail 87.90\n",
      "Epoch: [138] \t Loss 0.4121 \t Acc 90.57 \t AccHead 90.93 \t AccTail 86.72\n",
      "Epoch: [139] \t Loss 0.4213 \t Acc 86.84 \t AccHead 87.08 \t AccTail 84.21\n",
      "Epoch: [140] \t Loss 0.3820 \t Acc 88.83 \t AccHead 89.41 \t AccTail 82.73\n",
      "Epoch: [141] \t Loss 0.3821 \t Acc 87.73 \t AccHead 87.70 \t AccTail 88.12\n",
      "Epoch: [142] \t Loss 0.3821 \t Acc 89.82 \t AccHead 90.20 \t AccTail 85.83\n",
      "Epoch: [143] \t Loss 0.3874 \t Acc 89.51 \t AccHead 89.82 \t AccTail 86.25\n",
      "Epoch: [144] \t Loss 0.4131 \t Acc 88.48 \t AccHead 88.54 \t AccTail 87.83\n",
      "Epoch: [145] \t Loss 0.4366 \t Acc 87.67 \t AccHead 87.88 \t AccTail 85.52\n",
      "Epoch: [146] \t Loss 0.4154 \t Acc 84.22 \t AccHead 84.26 \t AccTail 83.81\n",
      "Epoch: [147] \t Loss 0.4314 \t Acc 82.38 \t AccHead 82.97 \t AccTail 76.21\n",
      "Epoch: [148] \t Loss 0.4613 \t Acc 86.21 \t AccHead 86.39 \t AccTail 84.21\n",
      "Epoch: [149] \t Loss 0.3893 \t Acc 88.98 \t AccHead 89.34 \t AccTail 85.23\n",
      "Epoch: [150] \t Loss 0.3583 \t Acc 90.46 \t AccHead 90.61 \t AccTail 88.95\n",
      "Epoch: [151] \t Loss 0.1773 \t Acc 98.62 \t AccHead 98.67 \t AccTail 98.12\n",
      "Epoch: [152] \t Loss 0.0789 \t Acc 99.44 \t AccHead 99.45 \t AccTail 99.33\n",
      "Epoch: [153] \t Loss 0.0507 \t Acc 99.51 \t AccHead 99.49 \t AccTail 99.73\n",
      "Epoch: [154] \t Loss 0.0462 \t Acc 99.70 \t AccHead 99.67 \t AccTail 100.00\n",
      "Epoch: [155] \t Loss 0.0379 \t Acc 99.74 \t AccHead 99.74 \t AccTail 99.73\n",
      "Epoch: [156] \t Loss 0.0333 \t Acc 99.83 \t AccHead 99.83 \t AccTail 99.73\n",
      "Epoch: [157] \t Loss 0.0314 \t Acc 99.80 \t AccHead 99.78 \t AccTail 100.00\n",
      "Epoch: [158] \t Loss 0.0264 \t Acc 99.85 \t AccHead 99.86 \t AccTail 99.73\n",
      "Epoch: [159] \t Loss 0.0236 \t Acc 99.91 \t AccHead 99.90 \t AccTail 100.00\n",
      "Epoch: [160] \t Loss 0.0221 \t Acc 99.91 \t AccHead 99.91 \t AccTail 99.87\n",
      "Epoch: [161] \t Loss 0.0221 \t Acc 99.93 \t AccHead 99.92 \t AccTail 100.00\n",
      "Epoch: [162] \t Loss 0.0205 \t Acc 99.91 \t AccHead 99.91 \t AccTail 99.87\n",
      "Epoch: [163] \t Loss 0.0201 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [164] \t Loss 0.0183 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [165] \t Loss 0.0158 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [166] \t Loss 0.0170 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [167] \t Loss 0.0155 \t Acc 99.92 \t AccHead 99.91 \t AccTail 100.00\n",
      "Epoch: [168] \t Loss 0.0165 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [169] \t Loss 0.0142 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [170] \t Loss 0.0154 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [171] \t Loss 0.0144 \t Acc 99.97 \t AccHead 99.97 \t AccTail 99.87\n",
      "Epoch: [172] \t Loss 0.0132 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [173] \t Loss 0.0141 \t Acc 99.97 \t AccHead 99.97 \t AccTail 99.87\n",
      "Epoch: [174] \t Loss 0.0132 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [175] \t Loss 0.0132 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [176] \t Loss 0.0131 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [177] \t Loss 0.0119 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [178] \t Loss 0.0122 \t Acc 99.98 \t AccHead 99.99 \t AccTail 99.87\n",
      "Epoch: [179] \t Loss 0.0118 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [180] \t Loss 0.0119 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [181] \t Loss 0.0122 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [182] \t Loss 0.0113 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [183] \t Loss 0.0112 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [184] \t Loss 0.0108 \t Acc 99.97 \t AccHead 99.97 \t AccTail 99.87\n",
      "Epoch: [185] \t Loss 0.0106 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [186] \t Loss 0.0102 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [187] \t Loss 0.0101 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [188] \t Loss 0.0100 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [189] \t Loss 0.0102 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [190] \t Loss 0.0102 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [191] \t Loss 0.0096 \t Acc 100.00 \t AccHead 100.00 \t AccTail 100.00\n",
      "Epoch: [192] \t Loss 0.0096 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [193] \t Loss 0.0103 \t Acc 100.00 \t AccHead 100.00 \t AccTail 100.00\n",
      "Epoch: [194] \t Loss 0.0104 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [195] \t Loss 0.0097 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [196] \t Loss 0.0103 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [197] \t Loss 0.0102 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [198] \t Loss 0.0094 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [199] \t Loss 0.0096 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [200] \t Loss 0.0097 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 17:46:22,051]\u001b[0m Trial 5 finished with value: 6.085150718688965 and parameters: {'n_epoch': 200, 'weight_decay': 0.0005706725534138756}. Best is trial 1 with value: 6.085150718688965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 6.09 \t AccHead 12.10 \t AccTail 0.10\n",
      "Epoch: [001] \t Loss 4.2367 \t Acc 4.16 \t AccHead 4.56 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 3.6687 \t Acc 7.28 \t AccHead 7.97 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 3.6661 \t Acc 9.65 \t AccHead 10.57 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 3.6302 \t Acc 12.01 \t AccHead 13.16 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 3.6200 \t Acc 12.53 \t AccHead 13.73 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 3.6161 \t Acc 10.38 \t AccHead 11.37 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 3.6258 \t Acc 12.55 \t AccHead 13.74 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 3.6194 \t Acc 8.20 \t AccHead 8.97 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 3.6208 \t Acc 8.19 \t AccHead 8.97 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 3.6343 \t Acc 8.93 \t AccHead 9.78 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 3.5997 \t Acc 10.39 \t AccHead 11.38 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 3.6089 \t Acc 10.86 \t AccHead 11.89 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 3.6214 \t Acc 12.05 \t AccHead 13.19 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 3.6151 \t Acc 13.97 \t AccHead 15.29 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 3.6184 \t Acc 12.91 \t AccHead 14.14 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 3.5932 \t Acc 13.09 \t AccHead 14.35 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 3.6014 \t Acc 12.65 \t AccHead 13.85 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 3.6219 \t Acc 13.60 \t AccHead 14.88 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 3.6071 \t Acc 12.03 \t AccHead 13.18 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 3.5997 \t Acc 12.37 \t AccHead 13.56 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 3.6067 \t Acc 12.35 \t AccHead 13.52 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 3.6097 \t Acc 10.95 \t AccHead 11.99 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 3.6109 \t Acc 11.46 \t AccHead 12.55 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 3.6240 \t Acc 11.17 \t AccHead 12.23 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 3.6359 \t Acc 12.74 \t AccHead 13.95 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 3.6282 \t Acc 10.26 \t AccHead 11.23 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 3.6305 \t Acc 11.47 \t AccHead 12.56 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 3.6302 \t Acc 11.59 \t AccHead 12.69 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 3.6201 \t Acc 12.19 \t AccHead 13.34 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 3.6082 \t Acc 8.33 \t AccHead 9.12 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 3.6215 \t Acc 10.76 \t AccHead 11.79 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 3.6135 \t Acc 11.82 \t AccHead 12.94 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 3.6237 \t Acc 11.57 \t AccHead 12.66 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 3.6221 \t Acc 10.19 \t AccHead 11.16 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 3.6269 \t Acc 10.23 \t AccHead 11.19 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 3.6306 \t Acc 12.90 \t AccHead 14.12 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 3.6260 \t Acc 10.07 \t AccHead 11.03 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 3.6280 \t Acc 11.08 \t AccHead 12.13 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 3.6231 \t Acc 11.75 \t AccHead 12.86 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 3.6383 \t Acc 12.20 \t AccHead 13.35 \t AccTail 0.00\n",
      "Epoch: [041] \t Loss 3.6271 \t Acc 11.45 \t AccHead 12.54 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 3.6492 \t Acc 11.46 \t AccHead 12.55 \t AccTail 0.00\n",
      "Epoch: [043] \t Loss 3.6485 \t Acc 6.46 \t AccHead 7.07 \t AccTail 0.00\n",
      "Epoch: [044] \t Loss 3.6432 \t Acc 14.26 \t AccHead 15.61 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 3.6296 \t Acc 9.41 \t AccHead 10.30 \t AccTail 0.00\n",
      "Epoch: [046] \t Loss 3.6533 \t Acc 12.80 \t AccHead 14.02 \t AccTail 0.00\n",
      "Epoch: [047] \t Loss 3.6577 \t Acc 10.37 \t AccHead 11.35 \t AccTail 0.00\n",
      "Epoch: [048] \t Loss 3.6460 \t Acc 11.32 \t AccHead 12.40 \t AccTail 0.00\n",
      "Epoch: [049] \t Loss 3.6422 \t Acc 11.44 \t AccHead 12.53 \t AccTail 0.00\n",
      "Epoch: [050] \t Loss 3.6343 \t Acc 7.61 \t AccHead 8.33 \t AccTail 0.00\n",
      "Epoch: [051] \t Loss 3.6423 \t Acc 8.83 \t AccHead 9.66 \t AccTail 0.00\n",
      "Epoch: [052] \t Loss 3.6595 \t Acc 11.91 \t AccHead 13.04 \t AccTail 0.00\n",
      "Epoch: [053] \t Loss 3.6545 \t Acc 11.85 \t AccHead 12.96 \t AccTail 0.00\n",
      "Epoch: [054] \t Loss 3.6472 \t Acc 6.98 \t AccHead 7.65 \t AccTail 0.00\n",
      "Epoch: [055] \t Loss 3.6474 \t Acc 11.54 \t AccHead 12.63 \t AccTail 0.00\n",
      "Epoch: [056] \t Loss 3.6485 \t Acc 8.37 \t AccHead 9.17 \t AccTail 0.00\n",
      "Epoch: [057] \t Loss 3.6554 \t Acc 9.43 \t AccHead 10.33 \t AccTail 0.00\n",
      "Epoch: [058] \t Loss 3.6632 \t Acc 8.49 \t AccHead 9.30 \t AccTail 0.00\n",
      "Epoch: [059] \t Loss 3.6480 \t Acc 12.41 \t AccHead 13.59 \t AccTail 0.00\n",
      "Epoch: [060] \t Loss 3.6431 \t Acc 9.57 \t AccHead 10.48 \t AccTail 0.00\n",
      "Epoch: [061] \t Loss 3.6508 \t Acc 11.01 \t AccHead 12.06 \t AccTail 0.00\n",
      "Epoch: [062] \t Loss 3.6745 \t Acc 12.22 \t AccHead 13.38 \t AccTail 0.00\n",
      "Epoch: [063] \t Loss 3.6604 \t Acc 12.01 \t AccHead 13.16 \t AccTail 0.00\n",
      "Epoch: [064] \t Loss 3.6554 \t Acc 10.83 \t AccHead 11.86 \t AccTail 0.00\n",
      "Epoch: [065] \t Loss 3.6577 \t Acc 12.49 \t AccHead 13.68 \t AccTail 0.00\n",
      "Epoch: [066] \t Loss 3.6516 \t Acc 10.40 \t AccHead 11.38 \t AccTail 0.00\n",
      "Epoch: [067] \t Loss 3.6533 \t Acc 7.85 \t AccHead 8.59 \t AccTail 0.00\n",
      "Epoch: [068] \t Loss 3.6685 \t Acc 9.34 \t AccHead 10.23 \t AccTail 0.00\n",
      "Epoch: [069] \t Loss 3.6628 \t Acc 8.69 \t AccHead 9.51 \t AccTail 0.00\n",
      "Epoch: [070] \t Loss 3.6840 \t Acc 9.98 \t AccHead 10.93 \t AccTail 0.00\n",
      "Epoch: [071] \t Loss 3.6589 \t Acc 9.51 \t AccHead 10.41 \t AccTail 0.00\n",
      "Epoch: [072] \t Loss 3.6432 \t Acc 13.58 \t AccHead 14.87 \t AccTail 0.00\n",
      "Epoch: [073] \t Loss 3.6534 \t Acc 11.21 \t AccHead 12.26 \t AccTail 0.00\n",
      "Epoch: [074] \t Loss 3.6690 \t Acc 10.09 \t AccHead 11.04 \t AccTail 0.00\n",
      "Epoch: [075] \t Loss 3.6614 \t Acc 10.90 \t AccHead 11.94 \t AccTail 0.00\n",
      "Epoch: [076] \t Loss 3.6693 \t Acc 11.02 \t AccHead 12.06 \t AccTail 0.00\n",
      "Epoch: [077] \t Loss 3.6673 \t Acc 12.35 \t AccHead 13.52 \t AccTail 0.00\n",
      "Epoch: [078] \t Loss 3.6505 \t Acc 7.91 \t AccHead 8.66 \t AccTail 0.00\n",
      "Epoch: [079] \t Loss 3.6526 \t Acc 9.01 \t AccHead 9.87 \t AccTail 0.00\n",
      "Epoch: [080] \t Loss 3.6510 \t Acc 9.46 \t AccHead 10.36 \t AccTail 0.00\n",
      "Epoch: [081] \t Loss 3.6694 \t Acc 12.23 \t AccHead 13.40 \t AccTail 0.00\n",
      "Epoch: [082] \t Loss 3.6526 \t Acc 9.31 \t AccHead 10.18 \t AccTail 0.00\n",
      "Epoch: [083] \t Loss 3.6576 \t Acc 12.47 \t AccHead 13.65 \t AccTail 0.00\n",
      "Epoch: [084] \t Loss 3.6544 \t Acc 7.71 \t AccHead 8.44 \t AccTail 0.00\n",
      "Epoch: [085] \t Loss 3.6569 \t Acc 10.09 \t AccHead 11.04 \t AccTail 0.00\n",
      "Epoch: [086] \t Loss 3.6878 \t Acc 9.47 \t AccHead 10.36 \t AccTail 0.00\n",
      "Epoch: [087] \t Loss 3.6800 \t Acc 13.77 \t AccHead 15.07 \t AccTail 0.00\n",
      "Epoch: [088] \t Loss 3.6701 \t Acc 10.25 \t AccHead 11.22 \t AccTail 0.00\n",
      "Epoch: [089] \t Loss 3.6690 \t Acc 11.04 \t AccHead 12.09 \t AccTail 0.00\n",
      "Epoch: [090] \t Loss 3.6814 \t Acc 10.59 \t AccHead 11.60 \t AccTail 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 17:56:39,915]\u001b[0m Trial 6 finished with value: 2.2533748149871826 and parameters: {'n_epoch': 90, 'weight_decay': 0.02201613428178216}. Best is trial 1 with value: 6.085150718688965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 2.25 \t AccHead 4.52 \t AccTail 0.00\n",
      "Epoch: [001] \t Loss 4.2691 \t Acc 4.87 \t AccHead 5.34 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 3.5986 \t Acc 8.45 \t AccHead 9.26 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 3.4820 \t Acc 10.37 \t AccHead 11.35 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 3.3998 \t Acc 12.84 \t AccHead 14.06 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 3.3549 \t Acc 17.86 \t AccHead 19.57 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 3.3211 \t Acc 18.21 \t AccHead 19.95 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 3.2954 \t Acc 19.74 \t AccHead 21.61 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 3.2517 \t Acc 12.98 \t AccHead 14.22 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 3.2597 \t Acc 15.68 \t AccHead 17.17 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 3.2207 \t Acc 21.40 \t AccHead 23.44 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 3.2428 \t Acc 17.58 \t AccHead 19.25 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 3.2147 \t Acc 21.07 \t AccHead 23.07 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 3.2049 \t Acc 20.72 \t AccHead 22.69 \t AccTail 0.13\n",
      "Epoch: [014] \t Loss 3.1840 \t Acc 20.43 \t AccHead 22.37 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 3.1879 \t Acc 19.37 \t AccHead 21.21 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 3.1708 \t Acc 21.09 \t AccHead 23.09 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 3.1522 \t Acc 18.33 \t AccHead 20.07 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 3.1838 \t Acc 20.62 \t AccHead 22.58 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 3.1662 \t Acc 16.80 \t AccHead 18.40 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 3.1525 \t Acc 18.97 \t AccHead 20.75 \t AccTail 0.13\n",
      "Epoch: [021] \t Loss 3.1773 \t Acc 17.76 \t AccHead 19.45 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 3.1476 \t Acc 21.09 \t AccHead 23.10 \t AccTail 0.13\n",
      "Epoch: [023] \t Loss 3.1513 \t Acc 20.08 \t AccHead 21.88 \t AccTail 1.08\n",
      "Epoch: [024] \t Loss 3.1529 \t Acc 23.06 \t AccHead 25.25 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 3.1301 \t Acc 19.65 \t AccHead 21.51 \t AccTail 0.13\n",
      "Epoch: [026] \t Loss 3.1352 \t Acc 18.07 \t AccHead 19.80 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 3.1456 \t Acc 19.29 \t AccHead 21.13 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 3.1616 \t Acc 15.30 \t AccHead 16.75 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 3.1198 \t Acc 18.40 \t AccHead 20.14 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 3.1064 \t Acc 21.92 \t AccHead 23.98 \t AccTail 0.27\n",
      "Epoch: [031] \t Loss 3.1448 \t Acc 16.35 \t AccHead 17.90 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 3.1336 \t Acc 19.30 \t AccHead 21.08 \t AccTail 0.54\n",
      "Epoch: [033] \t Loss 3.1336 \t Acc 16.76 \t AccHead 18.34 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 3.1207 \t Acc 21.63 \t AccHead 23.66 \t AccTail 0.27\n",
      "Epoch: [035] \t Loss 3.1013 \t Acc 21.61 \t AccHead 23.61 \t AccTail 0.67\n",
      "Epoch: [036] \t Loss 3.0791 \t Acc 19.04 \t AccHead 20.48 \t AccTail 3.90\n",
      "Epoch: [037] \t Loss 3.1483 \t Acc 20.32 \t AccHead 22.20 \t AccTail 0.54\n",
      "Epoch: [038] \t Loss 3.1144 \t Acc 14.41 \t AccHead 15.78 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 3.0951 \t Acc 17.20 \t AccHead 18.83 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 3.1102 \t Acc 19.46 \t AccHead 21.20 \t AccTail 1.08\n",
      "Epoch: [041] \t Loss 3.1059 \t Acc 14.82 \t AccHead 16.23 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 3.0892 \t Acc 22.69 \t AccHead 24.85 \t AccTail 0.00\n",
      "Epoch: [043] \t Loss 3.0798 \t Acc 18.87 \t AccHead 20.58 \t AccTail 0.94\n",
      "Epoch: [044] \t Loss 3.1086 \t Acc 22.18 \t AccHead 24.30 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 3.0969 \t Acc 17.29 \t AccHead 18.83 \t AccTail 1.08\n",
      "Epoch: [046] \t Loss 3.1076 \t Acc 15.59 \t AccHead 17.06 \t AccTail 0.13\n",
      "Epoch: [047] \t Loss 3.1107 \t Acc 18.68 \t AccHead 20.42 \t AccTail 0.40\n",
      "Epoch: [048] \t Loss 3.1231 \t Acc 21.65 \t AccHead 23.66 \t AccTail 0.54\n",
      "Epoch: [049] \t Loss 3.1355 \t Acc 15.68 \t AccHead 17.04 \t AccTail 1.35\n",
      "Epoch: [050] \t Loss 3.1506 \t Acc 19.73 \t AccHead 21.60 \t AccTail 0.00\n",
      "Epoch: [051] \t Loss 3.1867 \t Acc 21.74 \t AccHead 23.79 \t AccTail 0.00\n",
      "Epoch: [052] \t Loss 3.1687 \t Acc 19.25 \t AccHead 21.07 \t AccTail 0.00\n",
      "Epoch: [053] \t Loss 3.1506 \t Acc 18.56 \t AccHead 20.26 \t AccTail 0.67\n",
      "Epoch: [054] \t Loss 3.1368 \t Acc 17.65 \t AccHead 19.34 \t AccTail 0.00\n",
      "Epoch: [055] \t Loss 3.1367 \t Acc 19.71 \t AccHead 21.59 \t AccTail 0.00\n",
      "Epoch: [056] \t Loss 3.1323 \t Acc 20.58 \t AccHead 22.35 \t AccTail 1.89\n",
      "Epoch: [057] \t Loss 3.1208 \t Acc 18.00 \t AccHead 19.71 \t AccTail 0.00\n",
      "Epoch: [058] \t Loss 3.1278 \t Acc 8.92 \t AccHead 9.77 \t AccTail 0.00\n",
      "Epoch: [059] \t Loss 3.1792 \t Acc 21.13 \t AccHead 22.94 \t AccTail 2.14\n",
      "Epoch: [060] \t Loss 3.1422 \t Acc 20.34 \t AccHead 22.20 \t AccTail 0.54\n",
      "Epoch: [061] \t Loss 3.1465 \t Acc 13.54 \t AccHead 14.82 \t AccTail 0.00\n",
      "Epoch: [062] \t Loss 3.1549 \t Acc 15.89 \t AccHead 17.38 \t AccTail 0.14\n",
      "Epoch: [063] \t Loss 3.1728 \t Acc 21.12 \t AccHead 23.10 \t AccTail 0.27\n",
      "Epoch: [064] \t Loss 3.1367 \t Acc 21.61 \t AccHead 23.51 \t AccTail 1.61\n",
      "Epoch: [065] \t Loss 3.1755 \t Acc 21.44 \t AccHead 23.42 \t AccTail 0.41\n",
      "Epoch: [066] \t Loss 3.1636 \t Acc 20.30 \t AccHead 22.22 \t AccTail 0.13\n",
      "Epoch: [067] \t Loss 3.1629 \t Acc 13.14 \t AccHead 14.39 \t AccTail 0.00\n",
      "Epoch: [068] \t Loss 3.1338 \t Acc 18.61 \t AccHead 20.33 \t AccTail 0.54\n",
      "Epoch: [069] \t Loss 3.1855 \t Acc 19.53 \t AccHead 21.39 \t AccTail 0.00\n",
      "Epoch: [070] \t Loss 3.1391 \t Acc 19.90 \t AccHead 21.76 \t AccTail 0.40\n",
      "Epoch: [071] \t Loss 3.1671 \t Acc 18.03 \t AccHead 19.71 \t AccTail 0.40\n",
      "Epoch: [072] \t Loss 3.1576 \t Acc 18.06 \t AccHead 19.62 \t AccTail 1.74\n",
      "Epoch: [073] \t Loss 3.1363 \t Acc 18.99 \t AccHead 20.71 \t AccTail 0.81\n",
      "Epoch: [074] \t Loss 3.1319 \t Acc 21.19 \t AccHead 23.05 \t AccTail 1.61\n",
      "Epoch: [075] \t Loss 3.1575 \t Acc 16.95 \t AccHead 18.55 \t AccTail 0.13\n",
      "Epoch: [076] \t Loss 3.1420 \t Acc 16.48 \t AccHead 18.03 \t AccTail 0.13\n",
      "Epoch: [077] \t Loss 3.1485 \t Acc 18.95 \t AccHead 20.74 \t AccTail 0.13\n",
      "Epoch: [078] \t Loss 3.1396 \t Acc 20.28 \t AccHead 22.14 \t AccTail 0.54\n",
      "Epoch: [079] \t Loss 3.1339 \t Acc 21.27 \t AccHead 23.28 \t AccTail 0.00\n",
      "Epoch: [080] \t Loss 3.1323 \t Acc 17.75 \t AccHead 19.33 \t AccTail 1.08\n",
      "Epoch: [081] \t Loss 3.1611 \t Acc 21.44 \t AccHead 23.44 \t AccTail 0.40\n",
      "Epoch: [082] \t Loss 3.1396 \t Acc 20.83 \t AccHead 22.80 \t AccTail 0.00\n",
      "Epoch: [083] \t Loss 3.1209 \t Acc 21.55 \t AccHead 23.57 \t AccTail 0.40\n",
      "Epoch: [084] \t Loss 3.1638 \t Acc 20.34 \t AccHead 22.27 \t AccTail 0.00\n",
      "Epoch: [085] \t Loss 3.1322 \t Acc 17.20 \t AccHead 18.79 \t AccTail 0.40\n",
      "Epoch: [086] \t Loss 3.1396 \t Acc 19.31 \t AccHead 21.15 \t AccTail 0.00\n",
      "Epoch: [087] \t Loss 3.1254 \t Acc 19.85 \t AccHead 21.50 \t AccTail 2.42\n",
      "Epoch: [088] \t Loss 3.1282 \t Acc 16.85 \t AccHead 18.45 \t AccTail 0.00\n",
      "Epoch: [089] \t Loss 3.1019 \t Acc 16.06 \t AccHead 17.56 \t AccTail 0.14\n",
      "Epoch: [090] \t Loss 3.1142 \t Acc 13.54 \t AccHead 14.54 \t AccTail 2.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 18:07:09,551]\u001b[0m Trial 7 finished with value: 2.585669755935669 and parameters: {'n_epoch': 90, 'weight_decay': 0.007837153889062564}. Best is trial 1 with value: 6.085150718688965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 2.59 \t AccHead 5.17 \t AccTail 0.02\n",
      "Epoch: [001] \t Loss 4.5650 \t Acc 11.23 \t AccHead 12.30 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 3.6591 \t Acc 16.59 \t AccHead 18.16 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 3.4650 \t Acc 19.44 \t AccHead 21.26 \t AccTail 0.27\n",
      "Epoch: [004] \t Loss 3.2957 \t Acc 21.00 \t AccHead 22.94 \t AccTail 0.54\n",
      "Epoch: [005] \t Loss 3.1449 \t Acc 21.43 \t AccHead 23.35 \t AccTail 1.21\n",
      "Epoch: [006] \t Loss 3.0667 \t Acc 25.20 \t AccHead 27.25 \t AccTail 3.50\n",
      "Epoch: [007] \t Loss 2.9543 \t Acc 26.48 \t AccHead 28.57 \t AccTail 4.44\n",
      "Epoch: [008] \t Loss 2.8596 \t Acc 26.06 \t AccHead 28.15 \t AccTail 4.04\n",
      "Epoch: [009] \t Loss 2.8411 \t Acc 28.40 \t AccHead 30.80 \t AccTail 3.22\n",
      "Epoch: [010] \t Loss 2.7670 \t Acc 31.06 \t AccHead 33.55 \t AccTail 5.08\n",
      "Epoch: [011] \t Loss 2.6790 \t Acc 31.83 \t AccHead 34.11 \t AccTail 8.02\n",
      "Epoch: [012] \t Loss 2.6323 \t Acc 30.56 \t AccHead 33.20 \t AccTail 2.94\n",
      "Epoch: [013] \t Loss 2.5642 \t Acc 34.68 \t AccHead 37.67 \t AccTail 3.46\n",
      "Epoch: [014] \t Loss 2.4914 \t Acc 32.16 \t AccHead 34.66 \t AccTail 5.80\n",
      "Epoch: [015] \t Loss 2.4841 \t Acc 35.48 \t AccHead 38.18 \t AccTail 6.78\n",
      "Epoch: [016] \t Loss 2.4010 \t Acc 39.02 \t AccHead 42.08 \t AccTail 6.72\n",
      "Epoch: [017] \t Loss 2.3581 \t Acc 39.65 \t AccHead 42.85 \t AccTail 5.91\n",
      "Epoch: [018] \t Loss 2.3362 \t Acc 38.40 \t AccHead 41.14 \t AccTail 9.65\n",
      "Epoch: [019] \t Loss 2.2910 \t Acc 38.62 \t AccHead 41.70 \t AccTail 6.41\n",
      "Epoch: [020] \t Loss 2.2662 \t Acc 41.42 \t AccHead 44.45 \t AccTail 9.42\n",
      "Epoch: [021] \t Loss 2.2213 \t Acc 38.71 \t AccHead 41.33 \t AccTail 11.05\n",
      "Epoch: [022] \t Loss 2.2017 \t Acc 42.76 \t AccHead 45.84 \t AccTail 10.35\n",
      "Epoch: [023] \t Loss 2.1812 \t Acc 40.73 \t AccHead 43.67 \t AccTail 9.80\n",
      "Epoch: [024] \t Loss 2.1410 \t Acc 40.21 \t AccHead 43.05 \t AccTail 10.12\n",
      "Epoch: [025] \t Loss 2.1601 \t Acc 41.77 \t AccHead 44.40 \t AccTail 14.17\n",
      "Epoch: [026] \t Loss 2.1096 \t Acc 45.18 \t AccHead 48.41 \t AccTail 11.28\n",
      "Epoch: [027] \t Loss 2.0828 \t Acc 40.17 \t AccHead 42.80 \t AccTail 12.40\n",
      "Epoch: [028] \t Loss 2.0829 \t Acc 42.77 \t AccHead 45.47 \t AccTail 14.38\n",
      "Epoch: [029] \t Loss 2.0650 \t Acc 43.13 \t AccHead 45.82 \t AccTail 14.78\n",
      "Epoch: [030] \t Loss 2.0148 \t Acc 44.85 \t AccHead 48.15 \t AccTail 10.17\n",
      "Epoch: [031] \t Loss 1.9997 \t Acc 45.95 \t AccHead 49.30 \t AccTail 10.54\n",
      "Epoch: [032] \t Loss 2.0026 \t Acc 46.25 \t AccHead 49.61 \t AccTail 10.77\n",
      "Epoch: [033] \t Loss 1.9812 \t Acc 46.40 \t AccHead 49.64 \t AccTail 12.13\n",
      "Epoch: [034] \t Loss 1.9952 \t Acc 48.05 \t AccHead 51.23 \t AccTail 14.73\n",
      "Epoch: [035] \t Loss 1.9431 \t Acc 46.05 \t AccHead 48.66 \t AccTail 18.46\n",
      "Epoch: [036] \t Loss 1.9114 \t Acc 44.39 \t AccHead 46.97 \t AccTail 17.20\n",
      "Epoch: [037] \t Loss 1.8719 \t Acc 45.28 \t AccHead 47.93 \t AccTail 17.43\n",
      "Epoch: [038] \t Loss 1.8941 \t Acc 44.52 \t AccHead 47.36 \t AccTail 14.75\n",
      "Epoch: [039] \t Loss 1.8765 \t Acc 44.81 \t AccHead 47.45 \t AccTail 17.05\n",
      "Epoch: [040] \t Loss 1.8950 \t Acc 44.87 \t AccHead 47.82 \t AccTail 13.73\n",
      "Epoch: [041] \t Loss 1.8510 \t Acc 48.19 \t AccHead 51.39 \t AccTail 14.73\n",
      "Epoch: [042] \t Loss 1.8498 \t Acc 45.90 \t AccHead 48.85 \t AccTail 14.78\n",
      "Epoch: [043] \t Loss 1.8454 \t Acc 49.43 \t AccHead 52.47 \t AccTail 17.65\n",
      "Epoch: [044] \t Loss 1.8233 \t Acc 49.67 \t AccHead 53.22 \t AccTail 12.35\n",
      "Epoch: [045] \t Loss 1.8305 \t Acc 48.53 \t AccHead 51.42 \t AccTail 18.03\n",
      "Epoch: [046] \t Loss 1.7859 \t Acc 47.87 \t AccHead 50.65 \t AccTail 18.46\n",
      "Epoch: [047] \t Loss 1.7804 \t Acc 49.02 \t AccHead 51.79 \t AccTail 20.05\n",
      "Epoch: [048] \t Loss 1.7808 \t Acc 50.07 \t AccHead 53.56 \t AccTail 13.31\n",
      "Epoch: [049] \t Loss 1.7865 \t Acc 50.86 \t AccHead 53.49 \t AccTail 23.32\n",
      "Epoch: [050] \t Loss 1.7371 \t Acc 49.07 \t AccHead 51.96 \t AccTail 18.29\n",
      "Epoch: [051] \t Loss 1.7731 \t Acc 49.09 \t AccHead 52.24 \t AccTail 16.18\n",
      "Epoch: [052] \t Loss 1.7406 \t Acc 53.08 \t AccHead 55.96 \t AccTail 22.82\n",
      "Epoch: [053] \t Loss 1.7628 \t Acc 47.12 \t AccHead 49.75 \t AccTail 19.54\n",
      "Epoch: [054] \t Loss 1.6989 \t Acc 50.89 \t AccHead 53.86 \t AccTail 19.62\n",
      "Epoch: [055] \t Loss 1.7246 \t Acc 49.87 \t AccHead 52.72 \t AccTail 19.97\n",
      "Epoch: [056] \t Loss 1.7046 \t Acc 53.33 \t AccHead 56.12 \t AccTail 24.13\n",
      "Epoch: [057] \t Loss 1.7045 \t Acc 50.42 \t AccHead 53.25 \t AccTail 20.59\n",
      "Epoch: [058] \t Loss 1.7347 \t Acc 52.09 \t AccHead 55.19 \t AccTail 19.54\n",
      "Epoch: [059] \t Loss 1.6658 \t Acc 51.20 \t AccHead 54.11 \t AccTail 20.72\n",
      "Epoch: [060] \t Loss 1.6752 \t Acc 50.30 \t AccHead 53.52 \t AccTail 16.42\n",
      "Epoch: [061] \t Loss 1.6868 \t Acc 51.56 \t AccHead 53.91 \t AccTail 26.72\n",
      "Epoch: [062] \t Loss 1.6505 \t Acc 50.54 \t AccHead 53.55 \t AccTail 18.45\n",
      "Epoch: [063] \t Loss 1.6841 \t Acc 52.43 \t AccHead 55.56 \t AccTail 19.30\n",
      "Epoch: [064] \t Loss 1.6368 \t Acc 51.18 \t AccHead 54.11 \t AccTail 20.14\n",
      "Epoch: [065] \t Loss 1.6300 \t Acc 51.94 \t AccHead 55.29 \t AccTail 16.76\n",
      "Epoch: [066] \t Loss 1.6310 \t Acc 56.62 \t AccHead 59.59 \t AccTail 25.17\n",
      "Epoch: [067] \t Loss 1.6416 \t Acc 49.43 \t AccHead 52.02 \t AccTail 22.15\n",
      "Epoch: [068] \t Loss 1.6470 \t Acc 55.54 \t AccHead 58.64 \t AccTail 22.85\n",
      "Epoch: [069] \t Loss 1.6436 \t Acc 53.96 \t AccHead 57.01 \t AccTail 21.98\n",
      "Epoch: [070] \t Loss 1.6133 \t Acc 49.90 \t AccHead 52.16 \t AccTail 26.04\n",
      "Epoch: [071] \t Loss 1.5801 \t Acc 54.68 \t AccHead 58.09 \t AccTail 18.62\n",
      "Epoch: [072] \t Loss 1.6135 \t Acc 51.57 \t AccHead 54.43 \t AccTail 21.51\n",
      "Epoch: [073] \t Loss 1.5963 \t Acc 54.76 \t AccHead 57.72 \t AccTail 23.55\n",
      "Epoch: [074] \t Loss 1.5809 \t Acc 52.95 \t AccHead 56.05 \t AccTail 20.30\n",
      "Epoch: [075] \t Loss 1.6055 \t Acc 56.39 \t AccHead 59.33 \t AccTail 25.40\n",
      "Epoch: [076] \t Loss 1.5892 \t Acc 50.90 \t AccHead 53.99 \t AccTail 18.22\n",
      "Epoch: [077] \t Loss 1.5685 \t Acc 53.58 \t AccHead 56.67 \t AccTail 21.00\n",
      "Epoch: [078] \t Loss 1.5994 \t Acc 54.77 \t AccHead 57.46 \t AccTail 26.38\n",
      "Epoch: [079] \t Loss 1.5852 \t Acc 56.28 \t AccHead 59.72 \t AccTail 20.05\n",
      "Epoch: [080] \t Loss 1.5589 \t Acc 53.78 \t AccHead 56.52 \t AccTail 24.66\n",
      "Epoch: [081] \t Loss 1.5512 \t Acc 55.05 \t AccHead 57.82 \t AccTail 25.71\n",
      "Epoch: [082] \t Loss 1.5564 \t Acc 54.76 \t AccHead 57.81 \t AccTail 22.68\n",
      "Epoch: [083] \t Loss 1.5524 \t Acc 53.58 \t AccHead 56.21 \t AccTail 25.91\n",
      "Epoch: [084] \t Loss 1.5473 \t Acc 55.53 \t AccHead 58.30 \t AccTail 26.41\n",
      "Epoch: [085] \t Loss 1.5597 \t Acc 51.70 \t AccHead 54.03 \t AccTail 27.31\n",
      "Epoch: [086] \t Loss 1.5633 \t Acc 52.25 \t AccHead 54.72 \t AccTail 26.21\n",
      "Epoch: [087] \t Loss 1.5431 \t Acc 53.57 \t AccHead 56.47 \t AccTail 23.16\n",
      "Epoch: [088] \t Loss 1.5365 \t Acc 43.70 \t AccHead 45.75 \t AccTail 22.15\n",
      "Epoch: [089] \t Loss 1.5411 \t Acc 58.34 \t AccHead 61.31 \t AccTail 27.18\n",
      "Epoch: [090] \t Loss 1.4960 \t Acc 52.67 \t AccHead 55.16 \t AccTail 26.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 18:17:42,642]\u001b[0m Trial 8 finished with value: 4.95327091217041 and parameters: {'n_epoch': 90, 'weight_decay': 0.0015525209917736722}. Best is trial 1 with value: 6.085150718688965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 4.95 \t AccHead 9.90 \t AccTail 0.04\n",
      "Epoch: [001] \t Loss 4.5689 \t Acc 12.57 \t AccHead 13.77 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 3.7146 \t Acc 15.50 \t AccHead 16.98 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 3.4782 \t Acc 18.14 \t AccHead 19.82 \t AccTail 0.40\n",
      "Epoch: [004] \t Loss 3.3061 \t Acc 20.71 \t AccHead 22.58 \t AccTail 1.07\n",
      "Epoch: [005] \t Loss 3.1744 \t Acc 25.10 \t AccHead 27.44 \t AccTail 0.54\n",
      "Epoch: [006] \t Loss 3.0739 \t Acc 26.62 \t AccHead 28.73 \t AccTail 4.44\n",
      "Epoch: [007] \t Loss 2.9832 \t Acc 28.32 \t AccHead 30.62 \t AccTail 4.05\n",
      "Epoch: [008] \t Loss 2.8622 \t Acc 30.45 \t AccHead 32.92 \t AccTail 4.31\n",
      "Epoch: [009] \t Loss 2.7755 \t Acc 30.98 \t AccHead 33.28 \t AccTail 6.85\n",
      "Epoch: [010] \t Loss 2.7079 \t Acc 31.34 \t AccHead 33.60 \t AccTail 7.64\n",
      "Epoch: [011] \t Loss 2.5922 \t Acc 35.89 \t AccHead 38.41 \t AccTail 9.50\n",
      "Epoch: [012] \t Loss 2.5353 \t Acc 36.59 \t AccHead 39.38 \t AccTail 7.36\n",
      "Epoch: [013] \t Loss 2.4573 \t Acc 36.86 \t AccHead 39.62 \t AccTail 7.91\n",
      "Epoch: [014] \t Loss 2.3960 \t Acc 37.72 \t AccHead 40.47 \t AccTail 8.74\n",
      "Epoch: [015] \t Loss 2.3513 \t Acc 39.41 \t AccHead 42.11 \t AccTail 11.13\n",
      "Epoch: [016] \t Loss 2.2638 \t Acc 42.93 \t AccHead 45.84 \t AccTail 12.25\n",
      "Epoch: [017] \t Loss 2.2153 \t Acc 41.27 \t AccHead 44.45 \t AccTail 7.57\n",
      "Epoch: [018] \t Loss 2.1376 \t Acc 42.89 \t AccHead 46.19 \t AccTail 8.08\n",
      "Epoch: [019] \t Loss 2.1031 \t Acc 46.33 \t AccHead 49.04 \t AccTail 17.65\n",
      "Epoch: [020] \t Loss 2.0232 \t Acc 44.05 \t AccHead 46.97 \t AccTail 13.40\n",
      "Epoch: [021] \t Loss 2.0053 \t Acc 45.00 \t AccHead 47.95 \t AccTail 13.78\n",
      "Epoch: [022] \t Loss 1.9534 \t Acc 47.59 \t AccHead 50.56 \t AccTail 16.47\n",
      "Epoch: [023] \t Loss 1.9047 \t Acc 48.92 \t AccHead 52.18 \t AccTail 14.63\n",
      "Epoch: [024] \t Loss 1.8691 \t Acc 48.39 \t AccHead 51.51 \t AccTail 15.57\n",
      "Epoch: [025] \t Loss 1.8176 \t Acc 45.53 \t AccHead 48.16 \t AccTail 17.81\n",
      "Epoch: [026] \t Loss 1.7824 \t Acc 49.85 \t AccHead 52.73 \t AccTail 19.49\n",
      "Epoch: [027] \t Loss 1.7438 \t Acc 53.40 \t AccHead 56.54 \t AccTail 20.40\n",
      "Epoch: [028] \t Loss 1.6728 \t Acc 55.33 \t AccHead 58.47 \t AccTail 22.39\n",
      "Epoch: [029] \t Loss 1.6566 \t Acc 48.78 \t AccHead 51.23 \t AccTail 22.81\n",
      "Epoch: [030] \t Loss 1.6159 \t Acc 53.38 \t AccHead 56.67 \t AccTail 18.34\n",
      "Epoch: [031] \t Loss 1.5839 \t Acc 55.04 \t AccHead 57.85 \t AccTail 25.44\n",
      "Epoch: [032] \t Loss 1.5546 \t Acc 55.71 \t AccHead 58.62 \t AccTail 24.97\n",
      "Epoch: [033] \t Loss 1.5115 \t Acc 55.01 \t AccHead 58.29 \t AccTail 20.46\n",
      "Epoch: [034] \t Loss 1.4929 \t Acc 53.18 \t AccHead 56.19 \t AccTail 21.51\n",
      "Epoch: [035] \t Loss 1.4711 \t Acc 60.65 \t AccHead 62.93 \t AccTail 36.49\n",
      "Epoch: [036] \t Loss 1.4212 \t Acc 58.37 \t AccHead 61.12 \t AccTail 29.49\n",
      "Epoch: [037] \t Loss 1.3653 \t Acc 61.40 \t AccHead 64.37 \t AccTail 30.29\n",
      "Epoch: [038] \t Loss 1.3681 \t Acc 61.12 \t AccHead 63.90 \t AccTail 31.76\n",
      "Epoch: [039] \t Loss 1.3702 \t Acc 60.24 \t AccHead 62.67 \t AccTail 34.59\n",
      "Epoch: [040] \t Loss 1.3273 \t Acc 61.11 \t AccHead 63.35 \t AccTail 37.55\n",
      "Epoch: [041] \t Loss 1.2882 \t Acc 62.80 \t AccHead 65.61 \t AccTail 33.24\n",
      "Epoch: [042] \t Loss 1.2804 \t Acc 59.00 \t AccHead 61.58 \t AccTail 31.71\n",
      "Epoch: [043] \t Loss 1.2367 \t Acc 63.28 \t AccHead 66.35 \t AccTail 30.81\n",
      "Epoch: [044] \t Loss 1.1733 \t Acc 66.59 \t AccHead 68.80 \t AccTail 43.51\n",
      "Epoch: [045] \t Loss 1.1553 \t Acc 66.09 \t AccHead 67.92 \t AccTail 46.85\n",
      "Epoch: [046] \t Loss 1.1656 \t Acc 63.69 \t AccHead 65.69 \t AccTail 42.70\n",
      "Epoch: [047] \t Loss 1.1234 \t Acc 64.96 \t AccHead 67.20 \t AccTail 41.50\n",
      "Epoch: [048] \t Loss 1.1335 \t Acc 65.21 \t AccHead 67.05 \t AccTail 45.86\n",
      "Epoch: [049] \t Loss 1.0861 \t Acc 67.96 \t AccHead 70.30 \t AccTail 43.28\n",
      "Epoch: [050] \t Loss 1.0550 \t Acc 65.47 \t AccHead 67.13 \t AccTail 48.05\n",
      "Epoch: [051] \t Loss 1.0358 \t Acc 66.69 \t AccHead 68.45 \t AccTail 48.12\n",
      "Epoch: [052] \t Loss 1.0453 \t Acc 67.49 \t AccHead 69.38 \t AccTail 47.58\n",
      "Epoch: [053] \t Loss 0.9908 \t Acc 70.73 \t AccHead 72.79 \t AccTail 48.99\n",
      "Epoch: [054] \t Loss 1.0114 \t Acc 71.58 \t AccHead 73.38 \t AccTail 52.81\n",
      "Epoch: [055] \t Loss 0.9703 \t Acc 70.13 \t AccHead 72.47 \t AccTail 45.34\n",
      "Epoch: [056] \t Loss 0.9533 \t Acc 72.68 \t AccHead 74.69 \t AccTail 51.54\n",
      "Epoch: [057] \t Loss 0.9040 \t Acc 73.16 \t AccHead 74.56 \t AccTail 58.32\n",
      "Epoch: [058] \t Loss 0.9061 \t Acc 70.70 \t AccHead 72.32 \t AccTail 53.62\n",
      "Epoch: [059] \t Loss 0.8630 \t Acc 71.20 \t AccHead 72.83 \t AccTail 54.14\n",
      "Epoch: [060] \t Loss 0.8926 \t Acc 75.01 \t AccHead 76.38 \t AccTail 60.59\n",
      "Epoch: [061] \t Loss 0.8739 \t Acc 73.87 \t AccHead 75.48 \t AccTail 56.97\n",
      "Epoch: [062] \t Loss 0.8344 \t Acc 74.81 \t AccHead 76.39 \t AccTail 58.26\n",
      "Epoch: [063] \t Loss 0.8523 \t Acc 77.22 \t AccHead 78.15 \t AccTail 67.38\n",
      "Epoch: [064] \t Loss 0.7768 \t Acc 78.91 \t AccHead 80.03 \t AccTail 67.11\n",
      "Epoch: [065] \t Loss 0.8086 \t Acc 72.00 \t AccHead 73.15 \t AccTail 60.03\n",
      "Epoch: [066] \t Loss 0.7929 \t Acc 72.18 \t AccHead 73.44 \t AccTail 58.87\n",
      "Epoch: [067] \t Loss 0.8065 \t Acc 70.35 \t AccHead 71.92 \t AccTail 53.88\n",
      "Epoch: [068] \t Loss 0.7655 \t Acc 78.64 \t AccHead 79.70 \t AccTail 67.43\n",
      "Epoch: [069] \t Loss 0.7948 \t Acc 76.98 \t AccHead 77.69 \t AccTail 69.61\n",
      "Epoch: [070] \t Loss 0.7665 \t Acc 80.21 \t AccHead 80.62 \t AccTail 75.94\n",
      "Epoch: [071] \t Loss 0.6856 \t Acc 77.95 \t AccHead 79.39 \t AccTail 62.65\n",
      "Epoch: [072] \t Loss 0.7692 \t Acc 78.36 \t AccHead 79.41 \t AccTail 67.16\n",
      "Epoch: [073] \t Loss 0.7228 \t Acc 77.05 \t AccHead 78.78 \t AccTail 58.93\n",
      "Epoch: [074] \t Loss 0.7189 \t Acc 79.62 \t AccHead 80.61 \t AccTail 69.25\n",
      "Epoch: [075] \t Loss 0.6905 \t Acc 78.63 \t AccHead 78.97 \t AccTail 74.97\n",
      "Epoch: [076] \t Loss 0.7409 \t Acc 79.96 \t AccHead 81.04 \t AccTail 68.59\n",
      "Epoch: [077] \t Loss 0.6739 \t Acc 77.51 \t AccHead 78.34 \t AccTail 68.72\n",
      "Epoch: [078] \t Loss 0.6951 \t Acc 77.17 \t AccHead 77.62 \t AccTail 72.37\n",
      "Epoch: [079] \t Loss 0.6632 \t Acc 80.96 \t AccHead 81.78 \t AccTail 72.27\n",
      "Epoch: [080] \t Loss 0.6681 \t Acc 78.74 \t AccHead 79.61 \t AccTail 69.59\n",
      "Epoch: [081] \t Loss 0.6937 \t Acc 77.67 \t AccHead 79.12 \t AccTail 62.42\n",
      "Epoch: [082] \t Loss 0.6458 \t Acc 79.62 \t AccHead 80.59 \t AccTail 69.44\n",
      "Epoch: [083] \t Loss 0.6614 \t Acc 79.23 \t AccHead 79.56 \t AccTail 75.81\n",
      "Epoch: [084] \t Loss 0.6579 \t Acc 80.56 \t AccHead 81.32 \t AccTail 72.53\n",
      "Epoch: [085] \t Loss 0.6437 \t Acc 77.94 \t AccHead 78.60 \t AccTail 70.93\n",
      "Epoch: [086] \t Loss 0.6427 \t Acc 77.02 \t AccHead 77.33 \t AccTail 73.76\n",
      "Epoch: [087] \t Loss 0.6538 \t Acc 81.30 \t AccHead 82.37 \t AccTail 69.99\n",
      "Epoch: [088] \t Loss 0.6314 \t Acc 77.78 \t AccHead 78.18 \t AccTail 73.49\n",
      "Epoch: [089] \t Loss 0.5923 \t Acc 83.96 \t AccHead 84.33 \t AccTail 79.97\n",
      "Epoch: [090] \t Loss 0.6184 \t Acc 77.76 \t AccHead 78.54 \t AccTail 69.57\n",
      "Epoch: [091] \t Loss 0.6306 \t Acc 77.64 \t AccHead 78.32 \t AccTail 70.45\n",
      "Epoch: [092] \t Loss 0.6204 \t Acc 74.66 \t AccHead 74.79 \t AccTail 73.36\n",
      "Epoch: [093] \t Loss 0.6136 \t Acc 77.93 \t AccHead 78.72 \t AccTail 69.58\n",
      "Epoch: [094] \t Loss 0.5923 \t Acc 79.08 \t AccHead 79.73 \t AccTail 72.21\n",
      "Epoch: [095] \t Loss 0.6374 \t Acc 80.82 \t AccHead 81.63 \t AccTail 72.31\n",
      "Epoch: [096] \t Loss 0.5764 \t Acc 80.62 \t AccHead 80.69 \t AccTail 79.84\n",
      "Epoch: [097] \t Loss 0.5969 \t Acc 77.53 \t AccHead 78.76 \t AccTail 64.61\n",
      "Epoch: [098] \t Loss 0.6188 \t Acc 83.79 \t AccHead 84.41 \t AccTail 77.28\n",
      "Epoch: [099] \t Loss 0.5980 \t Acc 80.88 \t AccHead 81.06 \t AccTail 78.89\n",
      "Epoch: [100] \t Loss 0.5913 \t Acc 80.06 \t AccHead 80.34 \t AccTail 77.08\n",
      "Epoch: [101] \t Loss 0.5887 \t Acc 83.33 \t AccHead 83.90 \t AccTail 77.25\n",
      "Epoch: [102] \t Loss 0.5631 \t Acc 80.62 \t AccHead 81.34 \t AccTail 73.08\n",
      "Epoch: [103] \t Loss 0.6151 \t Acc 82.52 \t AccHead 83.08 \t AccTail 76.64\n",
      "Epoch: [104] \t Loss 0.5414 \t Acc 83.83 \t AccHead 84.47 \t AccTail 77.05\n",
      "Epoch: [105] \t Loss 0.5871 \t Acc 79.24 \t AccHead 80.08 \t AccTail 70.47\n",
      "Epoch: [106] \t Loss 0.5685 \t Acc 85.23 \t AccHead 85.58 \t AccTail 81.45\n",
      "Epoch: [107] \t Loss 0.5323 \t Acc 84.47 \t AccHead 85.42 \t AccTail 74.43\n",
      "Epoch: [108] \t Loss 0.6282 \t Acc 82.36 \t AccHead 83.19 \t AccTail 73.56\n",
      "Epoch: [109] \t Loss 0.6094 \t Acc 80.47 \t AccHead 81.18 \t AccTail 72.93\n",
      "Epoch: [110] \t Loss 0.5600 \t Acc 80.56 \t AccHead 80.96 \t AccTail 76.41\n",
      "Epoch: [111] \t Loss 0.5339 \t Acc 81.11 \t AccHead 81.33 \t AccTail 78.82\n",
      "Epoch: [112] \t Loss 0.6054 \t Acc 79.28 \t AccHead 80.06 \t AccTail 71.10\n",
      "Epoch: [113] \t Loss 0.5887 \t Acc 83.19 \t AccHead 83.58 \t AccTail 79.03\n",
      "Epoch: [114] \t Loss 0.5389 \t Acc 85.98 \t AccHead 86.45 \t AccTail 81.02\n",
      "Epoch: [115] \t Loss 0.5499 \t Acc 80.43 \t AccHead 80.96 \t AccTail 74.93\n",
      "Epoch: [116] \t Loss 0.5532 \t Acc 81.12 \t AccHead 82.01 \t AccTail 71.77\n",
      "Epoch: [117] \t Loss 0.5565 \t Acc 84.91 \t AccHead 85.63 \t AccTail 77.38\n",
      "Epoch: [118] \t Loss 0.5538 \t Acc 83.16 \t AccHead 83.78 \t AccTail 76.61\n",
      "Epoch: [119] \t Loss 0.5409 \t Acc 84.19 \t AccHead 84.64 \t AccTail 79.41\n",
      "Epoch: [120] \t Loss 0.5628 \t Acc 82.61 \t AccHead 82.66 \t AccTail 82.15\n",
      "Epoch: [121] \t Loss 0.5575 \t Acc 76.96 \t AccHead 77.67 \t AccTail 69.45\n",
      "Epoch: [122] \t Loss 0.5537 \t Acc 83.97 \t AccHead 84.40 \t AccTail 79.46\n",
      "Epoch: [123] \t Loss 0.5480 \t Acc 83.84 \t AccHead 84.21 \t AccTail 79.92\n",
      "Epoch: [124] \t Loss 0.5181 \t Acc 84.81 \t AccHead 85.25 \t AccTail 80.13\n",
      "Epoch: [125] \t Loss 0.5420 \t Acc 82.98 \t AccHead 83.42 \t AccTail 78.30\n",
      "Epoch: [126] \t Loss 0.5196 \t Acc 79.96 \t AccHead 80.13 \t AccTail 78.15\n",
      "Epoch: [127] \t Loss 0.5601 \t Acc 79.91 \t AccHead 80.46 \t AccTail 74.12\n",
      "Epoch: [128] \t Loss 0.4930 \t Acc 86.82 \t AccHead 87.35 \t AccTail 81.32\n",
      "Epoch: [129] \t Loss 0.5231 \t Acc 84.19 \t AccHead 85.34 \t AccTail 72.04\n",
      "Epoch: [130] \t Loss 0.5861 \t Acc 82.84 \t AccHead 83.23 \t AccTail 78.71\n",
      "Epoch: [131] \t Loss 0.5189 \t Acc 86.98 \t AccHead 87.16 \t AccTail 84.99\n",
      "Epoch: [132] \t Loss 0.5017 \t Acc 82.14 \t AccHead 82.33 \t AccTail 80.05\n",
      "Epoch: [133] \t Loss 0.5514 \t Acc 85.34 \t AccHead 85.84 \t AccTail 80.05\n",
      "Epoch: [134] \t Loss 0.4981 \t Acc 86.68 \t AccHead 87.29 \t AccTail 80.27\n",
      "Epoch: [135] \t Loss 0.5533 \t Acc 82.85 \t AccHead 83.27 \t AccTail 78.36\n",
      "Epoch: [136] \t Loss 0.5170 \t Acc 87.10 \t AccHead 87.07 \t AccTail 87.48\n",
      "Epoch: [137] \t Loss 0.4860 \t Acc 85.52 \t AccHead 86.44 \t AccTail 75.87\n",
      "Epoch: [138] \t Loss 0.4989 \t Acc 82.71 \t AccHead 83.44 \t AccTail 75.03\n",
      "Epoch: [139] \t Loss 0.5813 \t Acc 82.57 \t AccHead 83.40 \t AccTail 73.79\n",
      "Epoch: [140] \t Loss 0.5023 \t Acc 83.14 \t AccHead 83.67 \t AccTail 77.49\n",
      "Epoch: [141] \t Loss 0.5349 \t Acc 81.02 \t AccHead 81.55 \t AccTail 75.37\n",
      "Epoch: [142] \t Loss 0.5019 \t Acc 86.40 \t AccHead 86.87 \t AccTail 81.50\n",
      "Epoch: [143] \t Loss 0.5021 \t Acc 84.77 \t AccHead 85.23 \t AccTail 79.97\n",
      "Epoch: [144] \t Loss 0.5331 \t Acc 85.25 \t AccHead 85.39 \t AccTail 83.76\n",
      "Epoch: [145] \t Loss 0.5566 \t Acc 84.83 \t AccHead 85.08 \t AccTail 82.17\n",
      "Epoch: [146] \t Loss 0.5085 \t Acc 86.09 \t AccHead 86.49 \t AccTail 81.83\n",
      "Epoch: [147] \t Loss 0.4432 \t Acc 84.75 \t AccHead 85.05 \t AccTail 81.59\n",
      "Epoch: [148] \t Loss 0.5279 \t Acc 82.73 \t AccHead 83.15 \t AccTail 78.31\n",
      "Epoch: [149] \t Loss 0.5738 \t Acc 80.99 \t AccHead 80.97 \t AccTail 81.23\n",
      "Epoch: [150] \t Loss 0.5381 \t Acc 82.12 \t AccHead 82.49 \t AccTail 78.21\n",
      "Epoch: [151] \t Loss 0.2574 \t Acc 98.02 \t AccHead 98.10 \t AccTail 97.17\n",
      "Epoch: [152] \t Loss 0.1083 \t Acc 99.03 \t AccHead 99.03 \t AccTail 99.05\n",
      "Epoch: [153] \t Loss 0.0807 \t Acc 99.37 \t AccHead 99.37 \t AccTail 99.33\n",
      "Epoch: [154] \t Loss 0.0640 \t Acc 99.56 \t AccHead 99.58 \t AccTail 99.33\n",
      "Epoch: [155] \t Loss 0.0536 \t Acc 99.66 \t AccHead 99.67 \t AccTail 99.60\n",
      "Epoch: [156] \t Loss 0.0455 \t Acc 99.55 \t AccHead 99.60 \t AccTail 98.93\n",
      "Epoch: [157] \t Loss 0.0425 \t Acc 99.73 \t AccHead 99.74 \t AccTail 99.59\n",
      "Epoch: [158] \t Loss 0.0370 \t Acc 99.77 \t AccHead 99.77 \t AccTail 99.73\n",
      "Epoch: [159] \t Loss 0.0356 \t Acc 99.87 \t AccHead 99.86 \t AccTail 100.00\n",
      "Epoch: [160] \t Loss 0.0328 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [161] \t Loss 0.0272 \t Acc 99.91 \t AccHead 99.91 \t AccTail 99.86\n",
      "Epoch: [162] \t Loss 0.0272 \t Acc 99.88 \t AccHead 99.89 \t AccTail 99.87\n",
      "Epoch: [163] \t Loss 0.0242 \t Acc 99.94 \t AccHead 99.94 \t AccTail 100.00\n",
      "Epoch: [164] \t Loss 0.0226 \t Acc 99.91 \t AccHead 99.90 \t AccTail 100.00\n",
      "Epoch: [165] \t Loss 0.0226 \t Acc 99.86 \t AccHead 99.87 \t AccTail 99.73\n",
      "Epoch: [166] \t Loss 0.0218 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [167] \t Loss 0.0221 \t Acc 99.91 \t AccHead 99.91 \t AccTail 99.87\n",
      "Epoch: [168] \t Loss 0.0227 \t Acc 99.94 \t AccHead 99.94 \t AccTail 100.00\n",
      "Epoch: [169] \t Loss 0.0185 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [170] \t Loss 0.0183 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [171] \t Loss 0.0171 \t Acc 99.97 \t AccHead 99.97 \t AccTail 99.87\n",
      "Epoch: [172] \t Loss 0.0191 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [173] \t Loss 0.0178 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [174] \t Loss 0.0164 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [175] \t Loss 0.0164 \t Acc 99.93 \t AccHead 99.92 \t AccTail 100.00\n",
      "Epoch: [176] \t Loss 0.0167 \t Acc 99.97 \t AccHead 99.97 \t AccTail 99.87\n",
      "Epoch: [177] \t Loss 0.0167 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [178] \t Loss 0.0159 \t Acc 100.00 \t AccHead 100.00 \t AccTail 100.00\n",
      "Epoch: [179] \t Loss 0.0162 \t Acc 100.00 \t AccHead 100.00 \t AccTail 100.00\n",
      "Epoch: [180] \t Loss 0.0150 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [181] \t Loss 0.0146 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [182] \t Loss 0.0145 \t Acc 99.99 \t AccHead 100.00 \t AccTail 99.87\n",
      "Epoch: [183] \t Loss 0.0139 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [184] \t Loss 0.0149 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [185] \t Loss 0.0136 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [186] \t Loss 0.0140 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [187] \t Loss 0.0131 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [188] \t Loss 0.0130 \t Acc 99.98 \t AccHead 99.99 \t AccTail 99.87\n",
      "Epoch: [189] \t Loss 0.0134 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [190] \t Loss 0.0120 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [191] \t Loss 0.0125 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [192] \t Loss 0.0123 \t Acc 100.00 \t AccHead 100.00 \t AccTail 100.00\n",
      "Epoch: [193] \t Loss 0.0124 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [194] \t Loss 0.0126 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [195] \t Loss 0.0123 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [196] \t Loss 0.0124 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [197] \t Loss 0.0122 \t Acc 99.98 \t AccHead 99.99 \t AccTail 99.87\n",
      "Epoch: [198] \t Loss 0.0126 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [199] \t Loss 0.0121 \t Acc 99.98 \t AccHead 99.99 \t AccTail 99.87\n",
      "Epoch: [200] \t Loss 0.0126 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 18:40:40,496]\u001b[0m Trial 9 finished with value: 5.908618927001953 and parameters: {'n_epoch': 200, 'weight_decay': 0.0006971952593850431}. Best is trial 1 with value: 6.085150718688965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 5.91 \t AccHead 11.83 \t AccTail 0.02\n",
      "Epoch: [001] \t Loss 4.5958 \t Acc 13.46 \t AccHead 14.73 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 3.7850 \t Acc 15.65 \t AccHead 17.12 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 3.5140 \t Acc 18.39 \t AccHead 20.13 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 3.3308 \t Acc 20.57 \t AccHead 22.40 \t AccTail 1.22\n",
      "Epoch: [005] \t Loss 3.1809 \t Acc 24.63 \t AccHead 26.70 \t AccTail 2.70\n",
      "Epoch: [006] \t Loss 3.0882 \t Acc 25.02 \t AccHead 27.18 \t AccTail 2.41\n",
      "Epoch: [007] \t Loss 2.9970 \t Acc 26.67 \t AccHead 28.96 \t AccTail 2.43\n",
      "Epoch: [008] \t Loss 2.9138 \t Acc 29.99 \t AccHead 31.97 \t AccTail 9.14\n",
      "Epoch: [009] \t Loss 2.8128 \t Acc 31.65 \t AccHead 33.84 \t AccTail 8.48\n",
      "Epoch: [010] \t Loss 2.7306 \t Acc 32.59 \t AccHead 35.06 \t AccTail 6.81\n",
      "Epoch: [011] \t Loss 2.6504 \t Acc 32.91 \t AccHead 35.22 \t AccTail 8.39\n",
      "Epoch: [012] \t Loss 2.5759 \t Acc 34.70 \t AccHead 37.02 \t AccTail 10.43\n",
      "Epoch: [013] \t Loss 2.5045 \t Acc 37.59 \t AccHead 40.11 \t AccTail 11.04\n",
      "Epoch: [014] \t Loss 2.4273 \t Acc 39.56 \t AccHead 42.09 \t AccTail 12.82\n",
      "Epoch: [015] \t Loss 2.3841 \t Acc 39.65 \t AccHead 42.01 \t AccTail 14.86\n",
      "Epoch: [016] \t Loss 2.2993 \t Acc 41.62 \t AccHead 44.31 \t AccTail 13.29\n",
      "Epoch: [017] \t Loss 2.2594 \t Acc 33.08 \t AccHead 35.08 \t AccTail 12.17\n",
      "Epoch: [018] \t Loss 2.2316 \t Acc 44.92 \t AccHead 47.88 \t AccTail 13.90\n",
      "Epoch: [019] \t Loss 2.1229 \t Acc 44.86 \t AccHead 47.64 \t AccTail 15.75\n",
      "Epoch: [020] \t Loss 2.0427 \t Acc 47.62 \t AccHead 50.44 \t AccTail 17.99\n",
      "Epoch: [021] \t Loss 1.9556 \t Acc 50.57 \t AccHead 53.55 \t AccTail 19.30\n",
      "Epoch: [022] \t Loss 1.8908 \t Acc 50.10 \t AccHead 53.13 \t AccTail 18.08\n",
      "Epoch: [023] \t Loss 1.8464 \t Acc 52.88 \t AccHead 55.36 \t AccTail 26.97\n",
      "Epoch: [024] \t Loss 1.8222 \t Acc 51.15 \t AccHead 54.00 \t AccTail 21.05\n",
      "Epoch: [025] \t Loss 1.7573 \t Acc 54.31 \t AccHead 56.94 \t AccTail 26.49\n",
      "Epoch: [026] \t Loss 1.6508 \t Acc 56.35 \t AccHead 58.81 \t AccTail 30.46\n",
      "Epoch: [027] \t Loss 1.5724 \t Acc 60.45 \t AccHead 63.21 \t AccTail 31.27\n",
      "Epoch: [028] \t Loss 1.4783 \t Acc 61.54 \t AccHead 63.90 \t AccTail 36.86\n",
      "Epoch: [029] \t Loss 1.4599 \t Acc 63.46 \t AccHead 65.77 \t AccTail 39.14\n",
      "Epoch: [030] \t Loss 1.3714 \t Acc 64.66 \t AccHead 66.83 \t AccTail 41.80\n",
      "Epoch: [031] \t Loss 1.3072 \t Acc 64.62 \t AccHead 66.39 \t AccTail 46.05\n",
      "Epoch: [032] \t Loss 1.2143 \t Acc 72.06 \t AccHead 73.98 \t AccTail 51.95\n",
      "Epoch: [033] \t Loss 1.1305 \t Acc 72.80 \t AccHead 74.23 \t AccTail 57.66\n",
      "Epoch: [034] \t Loss 1.0769 \t Acc 73.04 \t AccHead 74.42 \t AccTail 58.67\n",
      "Epoch: [035] \t Loss 1.0118 \t Acc 73.76 \t AccHead 75.05 \t AccTail 60.22\n",
      "Epoch: [036] \t Loss 0.9409 \t Acc 74.55 \t AccHead 75.94 \t AccTail 59.92\n",
      "Epoch: [037] \t Loss 0.8864 \t Acc 79.55 \t AccHead 80.74 \t AccTail 66.98\n",
      "Epoch: [038] \t Loss 0.8726 \t Acc 77.22 \t AccHead 78.08 \t AccTail 68.15\n",
      "Epoch: [039] \t Loss 0.7749 \t Acc 81.27 \t AccHead 82.22 \t AccTail 71.35\n",
      "Epoch: [040] \t Loss 0.7584 \t Acc 79.85 \t AccHead 80.84 \t AccTail 69.49\n",
      "Epoch: [041] \t Loss 0.6889 \t Acc 83.22 \t AccHead 84.09 \t AccTail 74.06\n",
      "Epoch: [042] \t Loss 0.6519 \t Acc 84.98 \t AccHead 85.31 \t AccTail 81.48\n",
      "Epoch: [043] \t Loss 0.6105 \t Acc 85.27 \t AccHead 85.94 \t AccTail 78.26\n",
      "Epoch: [044] \t Loss 0.5792 \t Acc 86.37 \t AccHead 86.87 \t AccTail 81.10\n",
      "Epoch: [045] \t Loss 0.5116 \t Acc 86.56 \t AccHead 87.31 \t AccTail 78.63\n",
      "Epoch: [046] \t Loss 0.5320 \t Acc 89.45 \t AccHead 89.87 \t AccTail 84.98\n",
      "Epoch: [047] \t Loss 0.4768 \t Acc 87.91 \t AccHead 88.29 \t AccTail 83.83\n",
      "Epoch: [048] \t Loss 0.4473 \t Acc 89.04 \t AccHead 89.24 \t AccTail 86.87\n",
      "Epoch: [049] \t Loss 0.3966 \t Acc 91.34 \t AccHead 91.67 \t AccTail 87.79\n",
      "Epoch: [050] \t Loss 0.3605 \t Acc 91.86 \t AccHead 91.99 \t AccTail 90.48\n",
      "Epoch: [051] \t Loss 0.3587 \t Acc 90.90 \t AccHead 91.19 \t AccTail 87.95\n",
      "Epoch: [052] \t Loss 0.3480 \t Acc 90.47 \t AccHead 91.08 \t AccTail 84.05\n",
      "Epoch: [053] \t Loss 0.3376 \t Acc 91.87 \t AccHead 92.15 \t AccTail 88.99\n",
      "Epoch: [054] \t Loss 0.3149 \t Acc 92.93 \t AccHead 93.17 \t AccTail 90.46\n",
      "Epoch: [055] \t Loss 0.2944 \t Acc 93.63 \t AccHead 93.81 \t AccTail 91.71\n",
      "Epoch: [056] \t Loss 0.2703 \t Acc 94.58 \t AccHead 94.66 \t AccTail 93.71\n",
      "Epoch: [057] \t Loss 0.2572 \t Acc 94.26 \t AccHead 94.28 \t AccTail 94.10\n",
      "Epoch: [058] \t Loss 0.2538 \t Acc 93.66 \t AccHead 93.82 \t AccTail 91.91\n",
      "Epoch: [059] \t Loss 0.2480 \t Acc 94.69 \t AccHead 94.80 \t AccTail 93.55\n",
      "Epoch: [060] \t Loss 0.2315 \t Acc 95.08 \t AccHead 95.24 \t AccTail 93.41\n",
      "Epoch: [061] \t Loss 0.2021 \t Acc 95.17 \t AccHead 95.47 \t AccTail 92.09\n",
      "Epoch: [062] \t Loss 0.2229 \t Acc 94.50 \t AccHead 94.51 \t AccTail 94.37\n",
      "Epoch: [063] \t Loss 0.2027 \t Acc 95.93 \t AccHead 95.98 \t AccTail 95.43\n",
      "Epoch: [064] \t Loss 0.1890 \t Acc 95.97 \t AccHead 96.07 \t AccTail 94.88\n",
      "Epoch: [065] \t Loss 0.1893 \t Acc 96.01 \t AccHead 96.12 \t AccTail 94.86\n",
      "Epoch: [066] \t Loss 0.1825 \t Acc 96.70 \t AccHead 96.66 \t AccTail 97.15\n",
      "Epoch: [067] \t Loss 0.1582 \t Acc 96.37 \t AccHead 96.42 \t AccTail 95.83\n",
      "Epoch: [068] \t Loss 0.1595 \t Acc 96.68 \t AccHead 96.88 \t AccTail 94.49\n",
      "Epoch: [069] \t Loss 0.1460 \t Acc 97.41 \t AccHead 97.54 \t AccTail 96.08\n",
      "Epoch: [070] \t Loss 0.1306 \t Acc 97.19 \t AccHead 97.16 \t AccTail 97.46\n",
      "Epoch: [071] \t Loss 0.1417 \t Acc 96.74 \t AccHead 96.72 \t AccTail 96.90\n",
      "Epoch: [072] \t Loss 0.1163 \t Acc 97.46 \t AccHead 97.43 \t AccTail 97.72\n",
      "Epoch: [073] \t Loss 0.1213 \t Acc 97.59 \t AccHead 97.56 \t AccTail 97.86\n",
      "Epoch: [074] \t Loss 0.1095 \t Acc 97.53 \t AccHead 97.70 \t AccTail 95.70\n",
      "Epoch: [075] \t Loss 0.1224 \t Acc 97.32 \t AccHead 97.38 \t AccTail 96.62\n",
      "Epoch: [076] \t Loss 0.1169 \t Acc 97.74 \t AccHead 97.66 \t AccTail 98.53\n",
      "Epoch: [077] \t Loss 0.1117 \t Acc 97.28 \t AccHead 97.36 \t AccTail 96.50\n",
      "Epoch: [078] \t Loss 0.1162 \t Acc 97.94 \t AccHead 97.87 \t AccTail 98.66\n",
      "Epoch: [079] \t Loss 0.1204 \t Acc 97.80 \t AccHead 97.79 \t AccTail 97.85\n",
      "Epoch: [080] \t Loss 0.1070 \t Acc 97.85 \t AccHead 98.01 \t AccTail 96.22\n",
      "Epoch: [081] \t Loss 0.1038 \t Acc 98.55 \t AccHead 98.63 \t AccTail 97.72\n",
      "Epoch: [082] \t Loss 0.0835 \t Acc 97.90 \t AccHead 97.98 \t AccTail 97.05\n",
      "Epoch: [083] \t Loss 0.0872 \t Acc 98.53 \t AccHead 98.62 \t AccTail 97.59\n",
      "Epoch: [084] \t Loss 0.0823 \t Acc 98.53 \t AccHead 98.62 \t AccTail 97.58\n",
      "Epoch: [085] \t Loss 0.0765 \t Acc 98.38 \t AccHead 98.45 \t AccTail 97.59\n",
      "Epoch: [086] \t Loss 0.0740 \t Acc 98.55 \t AccHead 98.51 \t AccTail 99.06\n",
      "Epoch: [087] \t Loss 0.0873 \t Acc 97.99 \t AccHead 98.01 \t AccTail 97.84\n",
      "Epoch: [088] \t Loss 0.0845 \t Acc 98.20 \t AccHead 98.19 \t AccTail 98.39\n",
      "Epoch: [089] \t Loss 0.0718 \t Acc 98.79 \t AccHead 98.83 \t AccTail 98.38\n",
      "Epoch: [090] \t Loss 0.0823 \t Acc 98.48 \t AccHead 98.53 \t AccTail 97.99\n",
      "Epoch: [091] \t Loss 0.0857 \t Acc 98.46 \t AccHead 98.49 \t AccTail 98.13\n",
      "Epoch: [092] \t Loss 0.0852 \t Acc 97.87 \t AccHead 97.91 \t AccTail 97.44\n",
      "Epoch: [093] \t Loss 0.0813 \t Acc 98.23 \t AccHead 98.24 \t AccTail 98.13\n",
      "Epoch: [094] \t Loss 0.0722 \t Acc 99.07 \t AccHead 99.07 \t AccTail 99.06\n",
      "Epoch: [095] \t Loss 0.0784 \t Acc 98.68 \t AccHead 98.70 \t AccTail 98.52\n",
      "Epoch: [096] \t Loss 0.0836 \t Acc 98.05 \t AccHead 98.03 \t AccTail 98.25\n",
      "Epoch: [097] \t Loss 0.0770 \t Acc 98.34 \t AccHead 98.29 \t AccTail 98.93\n",
      "Epoch: [098] \t Loss 0.0776 \t Acc 98.67 \t AccHead 98.67 \t AccTail 98.66\n",
      "Epoch: [099] \t Loss 0.0609 \t Acc 98.73 \t AccHead 98.74 \t AccTail 98.65\n",
      "Epoch: [100] \t Loss 0.0657 \t Acc 98.61 \t AccHead 98.52 \t AccTail 99.60\n",
      "Epoch: [101] \t Loss 0.0449 \t Acc 99.14 \t AccHead 99.14 \t AccTail 99.06\n",
      "Epoch: [102] \t Loss 0.0433 \t Acc 99.44 \t AccHead 99.44 \t AccTail 99.46\n",
      "Epoch: [103] \t Loss 0.0412 \t Acc 99.18 \t AccHead 99.20 \t AccTail 99.05\n",
      "Epoch: [104] \t Loss 0.0480 \t Acc 98.94 \t AccHead 99.00 \t AccTail 98.26\n",
      "Epoch: [105] \t Loss 0.0574 \t Acc 98.67 \t AccHead 98.70 \t AccTail 98.38\n",
      "Epoch: [106] \t Loss 0.0656 \t Acc 98.62 \t AccHead 98.57 \t AccTail 99.19\n",
      "Epoch: [107] \t Loss 0.0630 \t Acc 99.00 \t AccHead 99.02 \t AccTail 98.79\n",
      "Epoch: [108] \t Loss 0.0520 \t Acc 99.11 \t AccHead 99.22 \t AccTail 97.98\n",
      "Epoch: [109] \t Loss 0.0449 \t Acc 99.16 \t AccHead 99.09 \t AccTail 99.87\n",
      "Epoch: [110] \t Loss 0.0466 \t Acc 99.17 \t AccHead 99.13 \t AccTail 99.60\n",
      "Epoch: [111] \t Loss 0.0402 \t Acc 99.36 \t AccHead 99.32 \t AccTail 99.73\n",
      "Epoch: [112] \t Loss 0.0446 \t Acc 98.92 \t AccHead 98.86 \t AccTail 99.47\n",
      "Epoch: [113] \t Loss 0.0481 \t Acc 99.16 \t AccHead 99.17 \t AccTail 99.06\n",
      "Epoch: [114] \t Loss 0.0434 \t Acc 99.14 \t AccHead 99.11 \t AccTail 99.46\n",
      "Epoch: [115] \t Loss 0.0374 \t Acc 99.20 \t AccHead 99.21 \t AccTail 99.06\n",
      "Epoch: [116] \t Loss 0.0402 \t Acc 99.18 \t AccHead 99.21 \t AccTail 98.93\n",
      "Epoch: [117] \t Loss 0.0493 \t Acc 99.29 \t AccHead 99.26 \t AccTail 99.60\n",
      "Epoch: [118] \t Loss 0.0359 \t Acc 99.58 \t AccHead 99.62 \t AccTail 99.20\n",
      "Epoch: [119] \t Loss 0.0341 \t Acc 99.41 \t AccHead 99.44 \t AccTail 99.06\n",
      "Epoch: [120] \t Loss 0.0373 \t Acc 99.56 \t AccHead 99.55 \t AccTail 99.60\n",
      "Epoch: [121] \t Loss 0.0328 \t Acc 99.35 \t AccHead 99.32 \t AccTail 99.60\n",
      "Epoch: [122] \t Loss 0.0418 \t Acc 99.44 \t AccHead 99.39 \t AccTail 100.00\n",
      "Epoch: [123] \t Loss 0.0368 \t Acc 99.45 \t AccHead 99.44 \t AccTail 99.60\n",
      "Epoch: [124] \t Loss 0.0289 \t Acc 99.49 \t AccHead 99.51 \t AccTail 99.19\n",
      "Epoch: [125] \t Loss 0.0331 \t Acc 99.45 \t AccHead 99.45 \t AccTail 99.46\n",
      "Epoch: [126] \t Loss 0.0407 \t Acc 99.36 \t AccHead 99.34 \t AccTail 99.59\n",
      "Epoch: [127] \t Loss 0.0358 \t Acc 99.65 \t AccHead 99.67 \t AccTail 99.47\n",
      "Epoch: [128] \t Loss 0.0278 \t Acc 99.43 \t AccHead 99.44 \t AccTail 99.33\n",
      "Epoch: [129] \t Loss 0.0370 \t Acc 99.39 \t AccHead 99.40 \t AccTail 99.33\n",
      "Epoch: [130] \t Loss 0.0351 \t Acc 99.53 \t AccHead 99.51 \t AccTail 99.73\n",
      "Epoch: [131] \t Loss 0.0271 \t Acc 99.65 \t AccHead 99.66 \t AccTail 99.60\n",
      "Epoch: [132] \t Loss 0.0284 \t Acc 99.48 \t AccHead 99.50 \t AccTail 99.19\n",
      "Epoch: [133] \t Loss 0.0335 \t Acc 99.59 \t AccHead 99.63 \t AccTail 99.19\n",
      "Epoch: [134] \t Loss 0.0374 \t Acc 99.49 \t AccHead 99.50 \t AccTail 99.33\n",
      "Epoch: [135] \t Loss 0.0313 \t Acc 99.39 \t AccHead 99.40 \t AccTail 99.33\n",
      "Epoch: [136] \t Loss 0.0308 \t Acc 99.39 \t AccHead 99.43 \t AccTail 99.06\n",
      "Epoch: [137] \t Loss 0.0300 \t Acc 99.64 \t AccHead 99.67 \t AccTail 99.33\n",
      "Epoch: [138] \t Loss 0.0265 \t Acc 99.56 \t AccHead 99.54 \t AccTail 99.73\n",
      "Epoch: [139] \t Loss 0.0296 \t Acc 99.36 \t AccHead 99.37 \t AccTail 99.19\n",
      "Epoch: [140] \t Loss 0.0352 \t Acc 99.22 \t AccHead 99.18 \t AccTail 99.60\n",
      "Epoch: [141] \t Loss 0.0345 \t Acc 99.39 \t AccHead 99.37 \t AccTail 99.60\n",
      "Epoch: [142] \t Loss 0.0292 \t Acc 99.45 \t AccHead 99.46 \t AccTail 99.33\n",
      "Epoch: [143] \t Loss 0.0323 \t Acc 99.55 \t AccHead 99.55 \t AccTail 99.46\n",
      "Epoch: [144] \t Loss 0.0305 \t Acc 99.60 \t AccHead 99.60 \t AccTail 99.60\n",
      "Epoch: [145] \t Loss 0.0300 \t Acc 99.50 \t AccHead 99.49 \t AccTail 99.60\n",
      "Epoch: [146] \t Loss 0.0258 \t Acc 99.57 \t AccHead 99.57 \t AccTail 99.60\n",
      "Epoch: [147] \t Loss 0.0327 \t Acc 99.52 \t AccHead 99.53 \t AccTail 99.46\n",
      "Epoch: [148] \t Loss 0.0364 \t Acc 99.51 \t AccHead 99.51 \t AccTail 99.46\n",
      "Epoch: [149] \t Loss 0.0326 \t Acc 99.51 \t AccHead 99.51 \t AccTail 99.46\n",
      "Epoch: [150] \t Loss 0.0300 \t Acc 99.50 \t AccHead 99.48 \t AccTail 99.73\n",
      "Epoch: [151] \t Loss 0.0223 \t Acc 99.79 \t AccHead 99.78 \t AccTail 99.87\n",
      "Epoch: [152] \t Loss 0.0149 \t Acc 99.87 \t AccHead 99.87 \t AccTail 99.86\n",
      "Epoch: [153] \t Loss 0.0132 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [154] \t Loss 0.0092 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [155] \t Loss 0.0073 \t Acc 99.94 \t AccHead 99.95 \t AccTail 99.87\n",
      "Epoch: [156] \t Loss 0.0086 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [157] \t Loss 0.0067 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [158] \t Loss 0.0048 \t Acc 99.95 \t AccHead 99.96 \t AccTail 99.87\n",
      "Epoch: [159] \t Loss 0.0046 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [160] \t Loss 0.0048 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [161] \t Loss 0.0053 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [162] \t Loss 0.0047 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [163] \t Loss 0.0049 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [164] \t Loss 0.0048 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [165] \t Loss 0.0040 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [166] \t Loss 0.0040 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [167] \t Loss 0.0035 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [168] \t Loss 0.0042 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [169] \t Loss 0.0032 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [170] \t Loss 0.0049 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [171] \t Loss 0.0037 \t Acc 100.00 \t AccHead 100.00 \t AccTail 100.00\n",
      "Epoch: [172] \t Loss 0.0034 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [173] \t Loss 0.0030 \t Acc 100.00 \t AccHead 100.00 \t AccTail 100.00\n",
      "Epoch: [174] \t Loss 0.0042 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [175] \t Loss 0.0032 \t Acc 100.00 \t AccHead 100.00 \t AccTail 100.00\n",
      "Epoch: [176] \t Loss 0.0035 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [177] \t Loss 0.0029 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [178] \t Loss 0.0033 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [179] \t Loss 0.0031 \t Acc 100.00 \t AccHead 100.00 \t AccTail 100.00\n",
      "Epoch: [180] \t Loss 0.0034 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [181] \t Loss 0.0035 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [182] \t Loss 0.0024 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [183] \t Loss 0.0027 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [184] \t Loss 0.0027 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [185] \t Loss 0.0026 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [186] \t Loss 0.0036 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [187] \t Loss 0.0029 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [188] \t Loss 0.0031 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [189] \t Loss 0.0035 \t Acc 100.00 \t AccHead 100.00 \t AccTail 100.00\n",
      "Epoch: [190] \t Loss 0.0028 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [191] \t Loss 0.0026 \t Acc 100.00 \t AccHead 100.00 \t AccTail 100.00\n",
      "Epoch: [192] \t Loss 0.0027 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [193] \t Loss 0.0024 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [194] \t Loss 0.0028 \t Acc 100.00 \t AccHead 100.00 \t AccTail 100.00\n",
      "Epoch: [195] \t Loss 0.0023 \t Acc 100.00 \t AccHead 100.00 \t AccTail 100.00\n",
      "Epoch: [196] \t Loss 0.0023 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [197] \t Loss 0.0030 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [198] \t Loss 0.0019 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [199] \t Loss 0.0022 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [200] \t Loss 0.0020 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 19:03:42,494]\u001b[0m Trial 10 finished with value: 5.233644962310791 and parameters: {'n_epoch': 200, 'weight_decay': 1.9900147700126848e-05}. Best is trial 1 with value: 6.085150718688965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 5.23 \t AccHead 10.35 \t AccTail 0.14\n",
      "Epoch: [001] \t Loss 4.4502 \t Acc 11.95 \t AccHead 13.00 \t AccTail 0.81\n",
      "Epoch: [002] \t Loss 3.7310 \t Acc 16.66 \t AccHead 18.17 \t AccTail 0.81\n",
      "Epoch: [003] \t Loss 3.4609 \t Acc 19.80 \t AccHead 21.67 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 3.3011 \t Acc 20.81 \t AccHead 22.51 \t AccTail 3.08\n",
      "Epoch: [005] \t Loss 3.1876 \t Acc 23.67 \t AccHead 25.55 \t AccTail 3.90\n",
      "Epoch: [006] \t Loss 3.0444 \t Acc 26.74 \t AccHead 29.01 \t AccTail 2.82\n",
      "Epoch: [007] \t Loss 2.9403 \t Acc 27.61 \t AccHead 29.98 \t AccTail 2.69\n",
      "Epoch: [008] \t Loss 2.8422 \t Acc 29.23 \t AccHead 31.65 \t AccTail 3.89\n",
      "Epoch: [009] \t Loss 2.7711 \t Acc 32.78 \t AccHead 35.32 \t AccTail 5.81\n",
      "Epoch: [010] \t Loss 2.6837 \t Acc 32.33 \t AccHead 34.61 \t AccTail 8.36\n",
      "Epoch: [011] \t Loss 2.5790 \t Acc 36.45 \t AccHead 39.46 \t AccTail 4.83\n",
      "Epoch: [012] \t Loss 2.5239 \t Acc 37.40 \t AccHead 39.58 \t AccTail 14.57\n",
      "Epoch: [013] \t Loss 2.4239 \t Acc 39.60 \t AccHead 42.45 \t AccTail 9.46\n",
      "Epoch: [014] \t Loss 2.3681 \t Acc 38.85 \t AccHead 41.76 \t AccTail 8.20\n",
      "Epoch: [015] \t Loss 2.3038 \t Acc 39.03 \t AccHead 41.67 \t AccTail 11.26\n",
      "Epoch: [016] \t Loss 2.2315 \t Acc 40.53 \t AccHead 43.11 \t AccTail 13.44\n",
      "Epoch: [017] \t Loss 2.1948 \t Acc 43.76 \t AccHead 46.88 \t AccTail 11.01\n",
      "Epoch: [018] \t Loss 2.0811 \t Acc 44.76 \t AccHead 47.27 \t AccTail 18.47\n",
      "Epoch: [019] \t Loss 2.0335 \t Acc 46.88 \t AccHead 50.03 \t AccTail 13.61\n",
      "Epoch: [020] \t Loss 1.9661 \t Acc 49.34 \t AccHead 52.51 \t AccTail 15.70\n",
      "Epoch: [021] \t Loss 1.9058 \t Acc 48.44 \t AccHead 51.54 \t AccTail 15.54\n",
      "Epoch: [022] \t Loss 1.8187 \t Acc 53.80 \t AccHead 56.79 \t AccTail 22.42\n",
      "Epoch: [023] \t Loss 1.7607 \t Acc 53.37 \t AccHead 56.01 \t AccTail 25.70\n",
      "Epoch: [024] \t Loss 1.7036 \t Acc 56.88 \t AccHead 59.66 \t AccTail 27.65\n",
      "Epoch: [025] \t Loss 1.6286 \t Acc 57.08 \t AccHead 59.54 \t AccTail 31.28\n",
      "Epoch: [026] \t Loss 1.5376 \t Acc 59.29 \t AccHead 61.72 \t AccTail 33.87\n",
      "Epoch: [027] \t Loss 1.5058 \t Acc 60.06 \t AccHead 62.27 \t AccTail 36.74\n",
      "Epoch: [028] \t Loss 1.4486 \t Acc 64.05 \t AccHead 66.36 \t AccTail 39.68\n",
      "Epoch: [029] \t Loss 1.3670 \t Acc 65.04 \t AccHead 67.29 \t AccTail 41.40\n",
      "Epoch: [030] \t Loss 1.2759 \t Acc 63.40 \t AccHead 65.53 \t AccTail 40.94\n",
      "Epoch: [031] \t Loss 1.2557 \t Acc 68.54 \t AccHead 70.61 \t AccTail 46.85\n",
      "Epoch: [032] \t Loss 1.1767 \t Acc 64.88 \t AccHead 66.92 \t AccTail 43.24\n",
      "Epoch: [033] \t Loss 1.1220 \t Acc 67.57 \t AccHead 69.05 \t AccTail 52.08\n",
      "Epoch: [034] \t Loss 1.0618 \t Acc 64.63 \t AccHead 66.81 \t AccTail 41.64\n",
      "Epoch: [035] \t Loss 1.0032 \t Acc 72.66 \t AccHead 74.12 \t AccTail 57.30\n",
      "Epoch: [036] \t Loss 0.9441 \t Acc 74.62 \t AccHead 76.36 \t AccTail 56.16\n",
      "Epoch: [037] \t Loss 0.8772 \t Acc 78.79 \t AccHead 80.14 \t AccTail 64.51\n",
      "Epoch: [038] \t Loss 0.8237 \t Acc 77.71 \t AccHead 78.98 \t AccTail 64.19\n",
      "Epoch: [039] \t Loss 0.7842 \t Acc 79.86 \t AccHead 80.68 \t AccTail 71.28\n",
      "Epoch: [040] \t Loss 0.7442 \t Acc 79.99 \t AccHead 81.07 \t AccTail 68.56\n",
      "Epoch: [041] \t Loss 0.6584 \t Acc 83.05 \t AccHead 84.12 \t AccTail 71.74\n",
      "Epoch: [042] \t Loss 0.6740 \t Acc 80.12 \t AccHead 81.23 \t AccTail 68.46\n",
      "Epoch: [043] \t Loss 0.6308 \t Acc 83.57 \t AccHead 84.09 \t AccTail 78.12\n",
      "Epoch: [044] \t Loss 0.5562 \t Acc 84.54 \t AccHead 85.18 \t AccTail 77.82\n",
      "Epoch: [045] \t Loss 0.5390 \t Acc 85.73 \t AccHead 86.05 \t AccTail 82.31\n",
      "Epoch: [046] \t Loss 0.5266 \t Acc 86.77 \t AccHead 87.15 \t AccTail 82.71\n",
      "Epoch: [047] \t Loss 0.4714 \t Acc 86.29 \t AccHead 86.93 \t AccTail 79.49\n",
      "Epoch: [048] \t Loss 0.4868 \t Acc 89.89 \t AccHead 89.88 \t AccTail 90.04\n",
      "Epoch: [049] \t Loss 0.4347 \t Acc 88.53 \t AccHead 88.91 \t AccTail 84.49\n",
      "Epoch: [050] \t Loss 0.3955 \t Acc 90.82 \t AccHead 91.25 \t AccTail 86.35\n",
      "Epoch: [051] \t Loss 0.3778 \t Acc 91.04 \t AccHead 91.20 \t AccTail 89.44\n",
      "Epoch: [052] \t Loss 0.3644 \t Acc 92.50 \t AccHead 92.62 \t AccTail 91.26\n",
      "Epoch: [053] \t Loss 0.3465 \t Acc 91.81 \t AccHead 92.30 \t AccTail 86.69\n",
      "Epoch: [054] \t Loss 0.3706 \t Acc 90.50 \t AccHead 90.91 \t AccTail 86.12\n",
      "Epoch: [055] \t Loss 0.3075 \t Acc 91.10 \t AccHead 91.38 \t AccTail 88.16\n",
      "Epoch: [056] \t Loss 0.2954 \t Acc 94.20 \t AccHead 94.35 \t AccTail 92.72\n",
      "Epoch: [057] \t Loss 0.2851 \t Acc 92.92 \t AccHead 93.08 \t AccTail 91.26\n",
      "Epoch: [058] \t Loss 0.2802 \t Acc 93.89 \t AccHead 93.87 \t AccTail 94.09\n",
      "Epoch: [059] \t Loss 0.2519 \t Acc 93.30 \t AccHead 93.52 \t AccTail 90.90\n",
      "Epoch: [060] \t Loss 0.2268 \t Acc 94.02 \t AccHead 94.15 \t AccTail 92.64\n",
      "Epoch: [061] \t Loss 0.2449 \t Acc 93.87 \t AccHead 94.24 \t AccTail 89.96\n",
      "Epoch: [062] \t Loss 0.2266 \t Acc 93.98 \t AccHead 94.04 \t AccTail 93.41\n",
      "Epoch: [063] \t Loss 0.2068 \t Acc 94.54 \t AccHead 94.65 \t AccTail 93.44\n",
      "Epoch: [064] \t Loss 0.2161 \t Acc 94.50 \t AccHead 94.52 \t AccTail 94.26\n",
      "Epoch: [065] \t Loss 0.2161 \t Acc 95.86 \t AccHead 95.80 \t AccTail 96.52\n",
      "Epoch: [066] \t Loss 0.1837 \t Acc 95.38 \t AccHead 95.47 \t AccTail 94.49\n",
      "Epoch: [067] \t Loss 0.1919 \t Acc 93.74 \t AccHead 94.00 \t AccTail 90.99\n",
      "Epoch: [068] \t Loss 0.1889 \t Acc 95.78 \t AccHead 95.69 \t AccTail 96.76\n",
      "Epoch: [069] \t Loss 0.1976 \t Acc 96.14 \t AccHead 96.15 \t AccTail 95.99\n",
      "Epoch: [070] \t Loss 0.1682 \t Acc 96.65 \t AccHead 96.83 \t AccTail 94.74\n",
      "Epoch: [071] \t Loss 0.1298 \t Acc 96.63 \t AccHead 96.69 \t AccTail 95.96\n",
      "Epoch: [072] \t Loss 0.1595 \t Acc 96.71 \t AccHead 96.72 \t AccTail 96.64\n",
      "Epoch: [073] \t Loss 0.1526 \t Acc 95.64 \t AccHead 95.76 \t AccTail 94.36\n",
      "Epoch: [074] \t Loss 0.1762 \t Acc 95.48 \t AccHead 95.44 \t AccTail 95.85\n",
      "Epoch: [075] \t Loss 0.1439 \t Acc 97.40 \t AccHead 97.52 \t AccTail 96.12\n",
      "Epoch: [076] \t Loss 0.1363 \t Acc 96.83 \t AccHead 97.00 \t AccTail 95.00\n",
      "Epoch: [077] \t Loss 0.1467 \t Acc 97.07 \t AccHead 97.06 \t AccTail 97.17\n",
      "Epoch: [078] \t Loss 0.1186 \t Acc 97.21 \t AccHead 97.22 \t AccTail 97.18\n",
      "Epoch: [079] \t Loss 0.1355 \t Acc 97.20 \t AccHead 97.32 \t AccTail 95.96\n",
      "Epoch: [080] \t Loss 0.1463 \t Acc 96.39 \t AccHead 96.39 \t AccTail 96.36\n",
      "Epoch: [081] \t Loss 0.1286 \t Acc 97.20 \t AccHead 97.29 \t AccTail 96.26\n",
      "Epoch: [082] \t Loss 0.1198 \t Acc 97.35 \t AccHead 97.43 \t AccTail 96.50\n",
      "Epoch: [083] \t Loss 0.1376 \t Acc 97.40 \t AccHead 97.46 \t AccTail 96.78\n",
      "Epoch: [084] \t Loss 0.1251 \t Acc 97.32 \t AccHead 97.26 \t AccTail 97.98\n",
      "Epoch: [085] \t Loss 0.1277 \t Acc 96.93 \t AccHead 96.99 \t AccTail 96.36\n",
      "Epoch: [086] \t Loss 0.1336 \t Acc 96.46 \t AccHead 96.57 \t AccTail 95.27\n",
      "Epoch: [087] \t Loss 0.1218 \t Acc 97.41 \t AccHead 97.46 \t AccTail 96.91\n",
      "Epoch: [088] \t Loss 0.1161 \t Acc 96.94 \t AccHead 96.93 \t AccTail 97.05\n",
      "Epoch: [089] \t Loss 0.1051 \t Acc 97.54 \t AccHead 97.63 \t AccTail 96.64\n",
      "Epoch: [090] \t Loss 0.1060 \t Acc 97.39 \t AccHead 97.56 \t AccTail 95.53\n",
      "Epoch: [091] \t Loss 0.1077 \t Acc 97.50 \t AccHead 97.54 \t AccTail 97.18\n",
      "Epoch: [092] \t Loss 0.1185 \t Acc 96.48 \t AccHead 96.72 \t AccTail 93.94\n",
      "Epoch: [093] \t Loss 0.1128 \t Acc 97.80 \t AccHead 97.83 \t AccTail 97.44\n",
      "Epoch: [094] \t Loss 0.1195 \t Acc 97.00 \t AccHead 96.98 \t AccTail 97.29\n",
      "Epoch: [095] \t Loss 0.1188 \t Acc 97.84 \t AccHead 97.89 \t AccTail 97.31\n",
      "Epoch: [096] \t Loss 0.1060 \t Acc 96.86 \t AccHead 96.83 \t AccTail 97.19\n",
      "Epoch: [097] \t Loss 0.1230 \t Acc 96.94 \t AccHead 96.97 \t AccTail 96.63\n",
      "Epoch: [098] \t Loss 0.1186 \t Acc 98.60 \t AccHead 98.65 \t AccTail 98.12\n",
      "Epoch: [099] \t Loss 0.1066 \t Acc 97.62 \t AccHead 97.65 \t AccTail 97.31\n",
      "Epoch: [100] \t Loss 0.0879 \t Acc 98.05 \t AccHead 98.12 \t AccTail 97.30\n",
      "Epoch: [101] \t Loss 0.0822 \t Acc 98.24 \t AccHead 98.29 \t AccTail 97.72\n",
      "Epoch: [102] \t Loss 0.0837 \t Acc 97.89 \t AccHead 97.89 \t AccTail 97.85\n",
      "Epoch: [103] \t Loss 0.1079 \t Acc 98.04 \t AccHead 98.03 \t AccTail 98.12\n",
      "Epoch: [104] \t Loss 0.1284 \t Acc 97.68 \t AccHead 97.77 \t AccTail 96.78\n",
      "Epoch: [105] \t Loss 0.1151 \t Acc 96.67 \t AccHead 96.69 \t AccTail 96.35\n",
      "Epoch: [106] \t Loss 0.1146 \t Acc 97.75 \t AccHead 97.79 \t AccTail 97.32\n",
      "Epoch: [107] \t Loss 0.1083 \t Acc 97.48 \t AccHead 97.48 \t AccTail 97.45\n",
      "Epoch: [108] \t Loss 0.1096 \t Acc 97.95 \t AccHead 98.02 \t AccTail 97.17\n",
      "Epoch: [109] \t Loss 0.0913 \t Acc 97.87 \t AccHead 97.82 \t AccTail 98.39\n",
      "Epoch: [110] \t Loss 0.0980 \t Acc 97.92 \t AccHead 98.05 \t AccTail 96.63\n",
      "Epoch: [111] \t Loss 0.0971 \t Acc 98.45 \t AccHead 98.46 \t AccTail 98.39\n",
      "Epoch: [112] \t Loss 0.0863 \t Acc 97.90 \t AccHead 97.86 \t AccTail 98.38\n",
      "Epoch: [113] \t Loss 0.0820 \t Acc 98.50 \t AccHead 98.52 \t AccTail 98.25\n",
      "Epoch: [114] \t Loss 0.0910 \t Acc 97.35 \t AccHead 97.28 \t AccTail 98.12\n",
      "Epoch: [115] \t Loss 0.0899 \t Acc 98.24 \t AccHead 98.21 \t AccTail 98.52\n",
      "Epoch: [116] \t Loss 0.0971 \t Acc 98.02 \t AccHead 98.02 \t AccTail 97.99\n",
      "Epoch: [117] \t Loss 0.0712 \t Acc 98.53 \t AccHead 98.58 \t AccTail 97.98\n",
      "Epoch: [118] \t Loss 0.0695 \t Acc 98.57 \t AccHead 98.62 \t AccTail 97.98\n",
      "Epoch: [119] \t Loss 0.0720 \t Acc 98.52 \t AccHead 98.54 \t AccTail 98.26\n",
      "Epoch: [120] \t Loss 0.0736 \t Acc 96.99 \t AccHead 97.19 \t AccTail 94.90\n",
      "Epoch: [121] \t Loss 0.0797 \t Acc 97.28 \t AccHead 97.37 \t AccTail 96.35\n",
      "Epoch: [122] \t Loss 0.0832 \t Acc 98.59 \t AccHead 98.65 \t AccTail 97.98\n",
      "Epoch: [123] \t Loss 0.0737 \t Acc 98.57 \t AccHead 98.61 \t AccTail 98.12\n",
      "Epoch: [124] \t Loss 0.0824 \t Acc 98.40 \t AccHead 98.40 \t AccTail 98.39\n",
      "Epoch: [125] \t Loss 0.1026 \t Acc 97.56 \t AccHead 97.57 \t AccTail 97.45\n",
      "Epoch: [126] \t Loss 0.1215 \t Acc 97.89 \t AccHead 97.80 \t AccTail 98.80\n",
      "Epoch: [127] \t Loss 0.0997 \t Acc 97.38 \t AccHead 97.41 \t AccTail 97.04\n",
      "Epoch: [128] \t Loss 0.1010 \t Acc 97.42 \t AccHead 97.42 \t AccTail 97.45\n",
      "Epoch: [129] \t Loss 0.1064 \t Acc 98.13 \t AccHead 98.16 \t AccTail 97.85\n",
      "Epoch: [130] \t Loss 0.1046 \t Acc 97.73 \t AccHead 97.71 \t AccTail 97.86\n",
      "Epoch: [131] \t Loss 0.1081 \t Acc 97.00 \t AccHead 96.96 \t AccTail 97.44\n",
      "Epoch: [132] \t Loss 0.1098 \t Acc 97.22 \t AccHead 97.27 \t AccTail 96.77\n",
      "Epoch: [133] \t Loss 0.1113 \t Acc 97.36 \t AccHead 97.49 \t AccTail 96.09\n",
      "Epoch: [134] \t Loss 0.1103 \t Acc 97.87 \t AccHead 97.89 \t AccTail 97.57\n",
      "Epoch: [135] \t Loss 0.0988 \t Acc 98.08 \t AccHead 98.11 \t AccTail 97.71\n",
      "Epoch: [136] \t Loss 0.0902 \t Acc 98.31 \t AccHead 98.32 \t AccTail 98.24\n",
      "Epoch: [137] \t Loss 0.0803 \t Acc 98.04 \t AccHead 97.89 \t AccTail 99.59\n",
      "Epoch: [138] \t Loss 0.0812 \t Acc 98.06 \t AccHead 98.06 \t AccTail 98.12\n",
      "Epoch: [139] \t Loss 0.0928 \t Acc 97.11 \t AccHead 97.15 \t AccTail 96.63\n",
      "Epoch: [140] \t Loss 0.1030 \t Acc 97.46 \t AccHead 97.52 \t AccTail 96.78\n",
      "Epoch: [141] \t Loss 0.0952 \t Acc 97.33 \t AccHead 97.32 \t AccTail 97.45\n",
      "Epoch: [142] \t Loss 0.1032 \t Acc 97.98 \t AccHead 97.97 \t AccTail 98.11\n",
      "Epoch: [143] \t Loss 0.0873 \t Acc 97.82 \t AccHead 97.88 \t AccTail 97.17\n",
      "Epoch: [144] \t Loss 0.0866 \t Acc 98.50 \t AccHead 98.46 \t AccTail 98.92\n",
      "Epoch: [145] \t Loss 0.0606 \t Acc 98.81 \t AccHead 98.94 \t AccTail 97.45\n",
      "Epoch: [146] \t Loss 0.0681 \t Acc 97.91 \t AccHead 97.93 \t AccTail 97.72\n",
      "Epoch: [147] \t Loss 0.0821 \t Acc 97.91 \t AccHead 97.84 \t AccTail 98.66\n",
      "Epoch: [148] \t Loss 0.0938 \t Acc 96.84 \t AccHead 96.84 \t AccTail 96.89\n",
      "Epoch: [149] \t Loss 0.1153 \t Acc 97.34 \t AccHead 97.46 \t AccTail 96.09\n",
      "Epoch: [150] \t Loss 0.0848 \t Acc 97.48 \t AccHead 97.46 \t AccTail 97.70\n",
      "Epoch: [151] \t Loss 0.0497 \t Acc 99.60 \t AccHead 99.58 \t AccTail 99.87\n",
      "Epoch: [152] \t Loss 0.0273 \t Acc 99.86 \t AccHead 99.87 \t AccTail 99.73\n",
      "Epoch: [153] \t Loss 0.0208 \t Acc 99.85 \t AccHead 99.83 \t AccTail 100.00\n",
      "Epoch: [154] \t Loss 0.0162 \t Acc 99.92 \t AccHead 99.91 \t AccTail 100.00\n",
      "Epoch: [155] \t Loss 0.0135 \t Acc 99.91 \t AccHead 99.91 \t AccTail 99.87\n",
      "Epoch: [156] \t Loss 0.0134 \t Acc 99.94 \t AccHead 99.95 \t AccTail 99.87\n",
      "Epoch: [157] \t Loss 0.0129 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [158] \t Loss 0.0109 \t Acc 99.92 \t AccHead 99.92 \t AccTail 99.87\n",
      "Epoch: [159] \t Loss 0.0103 \t Acc 99.94 \t AccHead 99.95 \t AccTail 99.87\n",
      "Epoch: [160] \t Loss 0.0102 \t Acc 99.94 \t AccHead 99.94 \t AccTail 100.00\n",
      "Epoch: [161] \t Loss 0.0087 \t Acc 99.94 \t AccHead 99.94 \t AccTail 100.00\n",
      "Epoch: [162] \t Loss 0.0082 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [163] \t Loss 0.0083 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [164] \t Loss 0.0071 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [165] \t Loss 0.0078 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [166] \t Loss 0.0069 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [167] \t Loss 0.0069 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [168] \t Loss 0.0059 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [169] \t Loss 0.0066 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [170] \t Loss 0.0063 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [171] \t Loss 0.0060 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [172] \t Loss 0.0053 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [173] \t Loss 0.0051 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [174] \t Loss 0.0054 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [175] \t Loss 0.0049 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [176] \t Loss 0.0050 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [177] \t Loss 0.0053 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [178] \t Loss 0.0049 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [179] \t Loss 0.0053 \t Acc 99.98 \t AccHead 99.99 \t AccTail 99.87\n",
      "Epoch: [180] \t Loss 0.0047 \t Acc 99.95 \t AccHead 99.95 \t AccTail 100.00\n",
      "Epoch: [181] \t Loss 0.0046 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [182] \t Loss 0.0045 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [183] \t Loss 0.0042 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [184] \t Loss 0.0041 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [185] \t Loss 0.0040 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [186] \t Loss 0.0046 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [187] \t Loss 0.0043 \t Acc 100.00 \t AccHead 100.00 \t AccTail 100.00\n",
      "Epoch: [188] \t Loss 0.0043 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [189] \t Loss 0.0037 \t Acc 100.00 \t AccHead 100.00 \t AccTail 100.00\n",
      "Epoch: [190] \t Loss 0.0042 \t Acc 99.97 \t AccHead 99.96 \t AccTail 100.00\n",
      "Epoch: [191] \t Loss 0.0037 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [192] \t Loss 0.0041 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [193] \t Loss 0.0036 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [194] \t Loss 0.0033 \t Acc 100.00 \t AccHead 100.00 \t AccTail 100.00\n",
      "Epoch: [195] \t Loss 0.0033 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [196] \t Loss 0.0036 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [197] \t Loss 0.0043 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [198] \t Loss 0.0032 \t Acc 99.98 \t AccHead 99.97 \t AccTail 100.00\n",
      "Epoch: [199] \t Loss 0.0033 \t Acc 99.99 \t AccHead 99.99 \t AccTail 100.00\n",
      "Epoch: [200] \t Loss 0.0035 \t Acc 100.00 \t AccHead 100.00 \t AccTail 100.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 19:27:31,273]\u001b[0m Trial 11 finished with value: 5.763239860534668 and parameters: {'n_epoch': 200, 'weight_decay': 0.00010004247095947701}. Best is trial 1 with value: 6.085150718688965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 5.76 \t AccHead 11.35 \t AccTail 0.21\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'CIFAR100' #['CIFAR10', 'CIFAR100']\n",
    "IMB_TYPE = 'exp' #['exp', 'step']\n",
    "IMB_FACTOR = 0.01 #[0.1, 0.01]\n",
    "train_loader, test_loader, num_classes = get_loaders()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sampler = optuna.samplers.TPESampler()\n",
    "    study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "    study.optimize(func=train_model, n_trials=12)\n",
    "    joblib.dump(study, 'set_100_exp_01.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e6f55776-3a0a-40df-82d9-a0d7207b0d8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T19:27:31.305990Z",
     "iopub.status.busy": "2022-06-17T19:27:31.305781Z",
     "iopub.status.idle": "2022-06-17T19:27:31.322650Z",
     "shell.execute_reply": "2022-06-17T19:27:31.322116Z",
     "shell.execute_reply.started": "2022-06-17T19:27:31.305970Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_n_epoch</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.131880</td>\n",
       "      <td>0 days 00:10:21.297956</td>\n",
       "      <td>90</td>\n",
       "      <td>0.029963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.085151</td>\n",
       "      <td>0 days 00:23:31.749703</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.192108</td>\n",
       "      <td>0 days 00:10:51.839308</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.430945</td>\n",
       "      <td>0 days 00:10:51.158423</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.038422</td>\n",
       "      <td>0 days 00:23:44.966203</td>\n",
       "      <td>200</td>\n",
       "      <td>0.066359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6.085151</td>\n",
       "      <td>0 days 00:23:45.929806</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2.253375</td>\n",
       "      <td>0 days 00:10:17.861273</td>\n",
       "      <td>90</td>\n",
       "      <td>0.022016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2.585670</td>\n",
       "      <td>0 days 00:10:29.631700</td>\n",
       "      <td>90</td>\n",
       "      <td>0.007837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>4.953271</td>\n",
       "      <td>0 days 00:10:33.087734</td>\n",
       "      <td>90</td>\n",
       "      <td>0.001553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5.908619</td>\n",
       "      <td>0 days 00:22:57.850075</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number     value               duration  params_n_epoch  \\\n",
       "0       0  1.131880 0 days 00:10:21.297956              90   \n",
       "1       1  6.085151 0 days 00:23:31.749703             200   \n",
       "2       2  5.192108 0 days 00:10:51.839308              90   \n",
       "3       3  5.430945 0 days 00:10:51.158423              90   \n",
       "4       4  1.038422 0 days 00:23:44.966203             200   \n",
       "5       5  6.085151 0 days 00:23:45.929806             200   \n",
       "6       6  2.253375 0 days 00:10:17.861273              90   \n",
       "7       7  2.585670 0 days 00:10:29.631700              90   \n",
       "8       8  4.953271 0 days 00:10:33.087734              90   \n",
       "9       9  5.908619 0 days 00:22:57.850075             200   \n",
       "\n",
       "   params_weight_decay  \n",
       "0             0.029963  \n",
       "1             0.001043  \n",
       "2             0.000493  \n",
       "3             0.000039  \n",
       "4             0.066359  \n",
       "5             0.000571  \n",
       "6             0.022016  \n",
       "7             0.007837  \n",
       "8             0.001553  \n",
       "9             0.000697  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = joblib.load('set_100_exp_01.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b3165925-11d3-4dcb-80ee-cb9ae0a3c0c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T19:27:31.323794Z",
     "iopub.status.busy": "2022-06-17T19:27:31.323577Z",
     "iopub.status.idle": "2022-06-18T01:07:59.702785Z",
     "shell.execute_reply": "2022-06-18T01:07:59.701503Z",
     "shell.execute_reply.started": "2022-06-17T19:27:31.323780Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 19:28:10,867]\u001b[0m A new study created in memory with name: no-name-c7df62e4-26df-4cb5-bfbd-4aaeb4fa50e4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls num list(train_dataset):\n",
      "[400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40]\n",
      "cls num list(val_dataset):\n",
      "[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
      "Epoch: [001] \t Loss 4.2457 \t Acc 8.35 \t AccHead 9.43 \t AccTail 0.50\n",
      "Epoch: [002] \t Loss 3.7361 \t Acc 10.88 \t AccHead 12.32 \t AccTail 0.38\n",
      "Epoch: [003] \t Loss 3.5693 \t Acc 14.63 \t AccHead 15.85 \t AccTail 5.75\n",
      "Epoch: [004] \t Loss 3.4419 \t Acc 16.40 \t AccHead 18.13 \t AccTail 3.77\n",
      "Epoch: [005] \t Loss 3.3549 \t Acc 17.79 \t AccHead 19.35 \t AccTail 6.50\n",
      "Epoch: [006] \t Loss 3.2948 \t Acc 17.84 \t AccHead 19.69 \t AccTail 4.38\n",
      "Epoch: [007] \t Loss 3.2460 \t Acc 19.88 \t AccHead 21.97 \t AccTail 4.71\n",
      "Epoch: [008] \t Loss 3.1918 \t Acc 20.53 \t AccHead 22.81 \t AccTail 3.96\n",
      "Epoch: [009] \t Loss 3.1395 \t Acc 20.29 \t AccHead 22.21 \t AccTail 6.32\n",
      "Epoch: [010] \t Loss 3.1016 \t Acc 22.09 \t AccHead 24.17 \t AccTail 6.93\n",
      "Epoch: [011] \t Loss 3.0733 \t Acc 18.76 \t AccHead 20.60 \t AccTail 5.38\n",
      "Epoch: [012] \t Loss 3.0319 \t Acc 22.54 \t AccHead 25.07 \t AccTail 4.15\n",
      "Epoch: [013] \t Loss 3.0050 \t Acc 23.39 \t AccHead 25.31 \t AccTail 9.35\n",
      "Epoch: [014] \t Loss 2.9788 \t Acc 21.08 \t AccHead 23.45 \t AccTail 3.84\n",
      "Epoch: [015] \t Loss 2.9719 \t Acc 23.53 \t AccHead 25.47 \t AccTail 9.41\n",
      "Epoch: [016] \t Loss 2.9445 \t Acc 25.59 \t AccHead 28.05 \t AccTail 7.70\n",
      "Epoch: [017] \t Loss 2.9281 \t Acc 22.84 \t AccHead 25.20 \t AccTail 5.63\n",
      "Epoch: [018] \t Loss 2.9190 \t Acc 23.02 \t AccHead 25.85 \t AccTail 2.40\n",
      "Epoch: [019] \t Loss 2.9197 \t Acc 23.11 \t AccHead 25.10 \t AccTail 8.57\n",
      "Epoch: [020] \t Loss 2.8945 \t Acc 23.45 \t AccHead 25.88 \t AccTail 5.72\n",
      "Epoch: [021] \t Loss 2.9068 \t Acc 23.89 \t AccHead 25.80 \t AccTail 9.93\n",
      "Epoch: [022] \t Loss 2.9026 \t Acc 24.79 \t AccHead 27.25 \t AccTail 6.95\n",
      "Epoch: [023] \t Loss 2.8781 \t Acc 26.02 \t AccHead 28.36 \t AccTail 8.96\n",
      "Epoch: [024] \t Loss 2.8832 \t Acc 24.30 \t AccHead 26.57 \t AccTail 7.73\n",
      "Epoch: [025] \t Loss 2.8724 \t Acc 24.90 \t AccHead 27.02 \t AccTail 9.54\n",
      "Epoch: [026] \t Loss 2.8669 \t Acc 24.69 \t AccHead 27.01 \t AccTail 7.77\n",
      "Epoch: [027] \t Loss 2.8532 \t Acc 25.54 \t AccHead 27.52 \t AccTail 11.09\n",
      "Epoch: [028] \t Loss 2.8612 \t Acc 25.92 \t AccHead 28.57 \t AccTail 6.62\n",
      "Epoch: [029] \t Loss 2.8591 \t Acc 25.71 \t AccHead 27.71 \t AccTail 11.15\n",
      "Epoch: [030] \t Loss 2.8699 \t Acc 25.09 \t AccHead 27.32 \t AccTail 8.87\n",
      "Epoch: [031] \t Loss 2.8403 \t Acc 25.29 \t AccHead 27.72 \t AccTail 7.65\n",
      "Epoch: [032] \t Loss 2.8436 \t Acc 24.94 \t AccHead 26.95 \t AccTail 10.32\n",
      "Epoch: [033] \t Loss 2.8343 \t Acc 26.62 \t AccHead 29.11 \t AccTail 8.53\n",
      "Epoch: [034] \t Loss 2.8342 \t Acc 29.57 \t AccHead 32.87 \t AccTail 5.59\n",
      "Epoch: [035] \t Loss 2.8426 \t Acc 24.98 \t AccHead 27.92 \t AccTail 3.54\n",
      "Epoch: [036] \t Loss 2.8395 \t Acc 22.52 \t AccHead 24.82 \t AccTail 5.82\n",
      "Epoch: [037] \t Loss 2.8172 \t Acc 25.40 \t AccHead 27.75 \t AccTail 8.26\n",
      "Epoch: [038] \t Loss 2.8316 \t Acc 23.54 \t AccHead 25.93 \t AccTail 6.10\n",
      "Epoch: [039] \t Loss 2.8106 \t Acc 25.74 \t AccHead 27.71 \t AccTail 11.35\n",
      "Epoch: [040] \t Loss 2.8171 \t Acc 24.80 \t AccHead 27.21 \t AccTail 7.24\n",
      "Epoch: [041] \t Loss 2.8224 \t Acc 26.44 \t AccHead 28.90 \t AccTail 8.52\n",
      "Epoch: [042] \t Loss 2.8319 \t Acc 26.30 \t AccHead 28.70 \t AccTail 8.79\n",
      "Epoch: [043] \t Loss 2.8085 \t Acc 25.49 \t AccHead 27.87 \t AccTail 8.17\n",
      "Epoch: [044] \t Loss 2.8258 \t Acc 23.57 \t AccHead 25.60 \t AccTail 8.76\n",
      "Epoch: [045] \t Loss 2.8189 \t Acc 27.84 \t AccHead 30.61 \t AccTail 7.65\n",
      "Epoch: [046] \t Loss 2.8151 \t Acc 25.40 \t AccHead 27.63 \t AccTail 9.14\n",
      "Epoch: [047] \t Loss 2.8193 \t Acc 24.11 \t AccHead 25.52 \t AccTail 13.85\n",
      "Epoch: [048] \t Loss 2.8192 \t Acc 27.02 \t AccHead 29.41 \t AccTail 9.67\n",
      "Epoch: [049] \t Loss 2.8098 \t Acc 25.66 \t AccHead 28.34 \t AccTail 6.20\n",
      "Epoch: [050] \t Loss 2.8079 \t Acc 27.20 \t AccHead 30.29 \t AccTail 4.64\n",
      "Epoch: [051] \t Loss 2.8040 \t Acc 28.16 \t AccHead 30.96 \t AccTail 7.83\n",
      "Epoch: [052] \t Loss 2.8114 \t Acc 24.72 \t AccHead 27.01 \t AccTail 8.11\n",
      "Epoch: [053] \t Loss 2.8079 \t Acc 25.21 \t AccHead 26.93 \t AccTail 12.71\n",
      "Epoch: [054] \t Loss 2.8051 \t Acc 26.34 \t AccHead 28.88 \t AccTail 7.82\n",
      "Epoch: [055] \t Loss 2.8100 \t Acc 25.16 \t AccHead 27.71 \t AccTail 6.59\n",
      "Epoch: [056] \t Loss 2.8153 \t Acc 27.65 \t AccHead 30.11 \t AccTail 9.71\n",
      "Epoch: [057] \t Loss 2.8008 \t Acc 27.08 \t AccHead 29.94 \t AccTail 6.24\n",
      "Epoch: [058] \t Loss 2.7897 \t Acc 27.34 \t AccHead 29.98 \t AccTail 8.15\n",
      "Epoch: [059] \t Loss 2.8093 \t Acc 25.34 \t AccHead 27.59 \t AccTail 8.95\n",
      "Epoch: [060] \t Loss 2.7859 \t Acc 26.48 \t AccHead 28.62 \t AccTail 10.90\n",
      "Epoch: [061] \t Loss 2.8173 \t Acc 22.58 \t AccHead 24.35 \t AccTail 9.71\n",
      "Epoch: [062] \t Loss 2.7994 \t Acc 27.39 \t AccHead 29.22 \t AccTail 14.06\n",
      "Epoch: [063] \t Loss 2.8066 \t Acc 26.91 \t AccHead 28.90 \t AccTail 12.38\n",
      "Epoch: [064] \t Loss 2.8022 \t Acc 23.62 \t AccHead 25.53 \t AccTail 9.67\n",
      "Epoch: [065] \t Loss 2.8103 \t Acc 24.43 \t AccHead 26.85 \t AccTail 6.81\n",
      "Epoch: [066] \t Loss 2.7978 \t Acc 25.58 \t AccHead 28.12 \t AccTail 7.05\n",
      "Epoch: [067] \t Loss 2.8116 \t Acc 26.87 \t AccHead 29.03 \t AccTail 11.09\n",
      "Epoch: [068] \t Loss 2.8148 \t Acc 25.24 \t AccHead 28.32 \t AccTail 2.82\n",
      "Epoch: [069] \t Loss 2.8013 \t Acc 28.79 \t AccHead 31.66 \t AccTail 7.91\n",
      "Epoch: [070] \t Loss 2.8007 \t Acc 27.06 \t AccHead 29.55 \t AccTail 8.92\n",
      "Epoch: [071] \t Loss 2.8015 \t Acc 24.38 \t AccHead 26.55 \t AccTail 8.63\n",
      "Epoch: [072] \t Loss 2.8048 \t Acc 27.27 \t AccHead 30.28 \t AccTail 5.33\n",
      "Epoch: [073] \t Loss 2.7861 \t Acc 23.89 \t AccHead 26.20 \t AccTail 7.14\n",
      "Epoch: [074] \t Loss 2.7985 \t Acc 23.08 \t AccHead 24.95 \t AccTail 9.44\n",
      "Epoch: [075] \t Loss 2.8112 \t Acc 25.39 \t AccHead 28.40 \t AccTail 3.43\n",
      "Epoch: [076] \t Loss 2.7843 \t Acc 22.27 \t AccHead 24.56 \t AccTail 5.60\n",
      "Epoch: [077] \t Loss 2.7899 \t Acc 26.94 \t AccHead 29.53 \t AccTail 8.04\n",
      "Epoch: [078] \t Loss 2.8041 \t Acc 26.79 \t AccHead 29.68 \t AccTail 5.75\n",
      "Epoch: [079] \t Loss 2.7930 \t Acc 27.98 \t AccHead 30.47 \t AccTail 9.92\n",
      "Epoch: [080] \t Loss 2.8016 \t Acc 25.08 \t AccHead 26.67 \t AccTail 13.50\n",
      "Epoch: [081] \t Loss 2.7928 \t Acc 25.21 \t AccHead 27.12 \t AccTail 11.34\n",
      "Epoch: [082] \t Loss 2.7994 \t Acc 26.28 \t AccHead 29.02 \t AccTail 6.29\n",
      "Epoch: [083] \t Loss 2.7831 \t Acc 22.95 \t AccHead 25.22 \t AccTail 6.45\n",
      "Epoch: [084] \t Loss 2.7938 \t Acc 24.49 \t AccHead 26.97 \t AccTail 6.40\n",
      "Epoch: [085] \t Loss 2.7842 \t Acc 25.85 \t AccHead 28.00 \t AccTail 10.21\n",
      "Epoch: [086] \t Loss 2.7946 \t Acc 28.11 \t AccHead 31.02 \t AccTail 6.89\n",
      "Epoch: [087] \t Loss 2.7828 \t Acc 28.07 \t AccHead 30.34 \t AccTail 11.52\n",
      "Epoch: [088] \t Loss 2.7837 \t Acc 26.88 \t AccHead 28.51 \t AccTail 14.99\n",
      "Epoch: [089] \t Loss 2.7980 \t Acc 26.13 \t AccHead 28.81 \t AccTail 6.63\n",
      "Epoch: [090] \t Loss 2.8007 \t Acc 23.43 \t AccHead 25.27 \t AccTail 10.05\n",
      "Epoch: [091] \t Loss 2.8099 \t Acc 26.84 \t AccHead 29.32 \t AccTail 8.82\n",
      "Epoch: [092] \t Loss 2.7833 \t Acc 27.73 \t AccHead 30.10 \t AccTail 10.51\n",
      "Epoch: [093] \t Loss 2.7975 \t Acc 27.03 \t AccHead 29.55 \t AccTail 8.64\n",
      "Epoch: [094] \t Loss 2.8070 \t Acc 26.04 \t AccHead 28.75 \t AccTail 6.25\n",
      "Epoch: [095] \t Loss 2.7934 \t Acc 24.93 \t AccHead 27.13 \t AccTail 8.91\n",
      "Epoch: [096] \t Loss 2.7709 \t Acc 28.22 \t AccHead 30.96 \t AccTail 8.32\n",
      "Epoch: [097] \t Loss 2.7862 \t Acc 25.06 \t AccHead 26.74 \t AccTail 12.77\n",
      "Epoch: [098] \t Loss 2.7889 \t Acc 23.38 \t AccHead 25.60 \t AccTail 7.22\n",
      "Epoch: [099] \t Loss 2.7974 \t Acc 28.66 \t AccHead 31.31 \t AccTail 9.40\n",
      "Epoch: [100] \t Loss 2.7888 \t Acc 27.89 \t AccHead 29.85 \t AccTail 13.61\n",
      "Epoch: [101] \t Loss 2.7910 \t Acc 24.51 \t AccHead 27.29 \t AccTail 4.30\n",
      "Epoch: [102] \t Loss 2.7988 \t Acc 26.26 \t AccHead 28.19 \t AccTail 12.21\n",
      "Epoch: [103] \t Loss 2.7967 \t Acc 21.85 \t AccHead 24.33 \t AccTail 3.81\n",
      "Epoch: [104] \t Loss 2.7862 \t Acc 28.58 \t AccHead 31.60 \t AccTail 6.59\n",
      "Epoch: [105] \t Loss 2.7967 \t Acc 25.32 \t AccHead 27.57 \t AccTail 8.94\n",
      "Epoch: [106] \t Loss 2.7884 \t Acc 26.06 \t AccHead 28.86 \t AccTail 5.67\n",
      "Epoch: [107] \t Loss 2.7829 \t Acc 27.93 \t AccHead 30.02 \t AccTail 12.69\n",
      "Epoch: [108] \t Loss 2.7904 \t Acc 27.52 \t AccHead 30.09 \t AccTail 8.77\n",
      "Epoch: [109] \t Loss 2.8019 \t Acc 24.51 \t AccHead 27.17 \t AccTail 5.08\n",
      "Epoch: [110] \t Loss 2.7960 \t Acc 29.43 \t AccHead 31.80 \t AccTail 12.14\n",
      "Epoch: [111] \t Loss 2.8060 \t Acc 27.06 \t AccHead 29.52 \t AccTail 9.10\n",
      "Epoch: [112] \t Loss 2.8067 \t Acc 27.35 \t AccHead 29.57 \t AccTail 11.19\n",
      "Epoch: [113] \t Loss 2.7951 \t Acc 25.55 \t AccHead 27.73 \t AccTail 9.67\n",
      "Epoch: [114] \t Loss 2.8092 \t Acc 29.20 \t AccHead 31.26 \t AccTail 14.18\n",
      "Epoch: [115] \t Loss 2.7933 \t Acc 25.26 \t AccHead 27.40 \t AccTail 9.61\n",
      "Epoch: [116] \t Loss 2.8001 \t Acc 24.25 \t AccHead 26.65 \t AccTail 6.74\n",
      "Epoch: [117] \t Loss 2.8096 \t Acc 25.82 \t AccHead 28.27 \t AccTail 7.99\n",
      "Epoch: [118] \t Loss 2.7908 \t Acc 27.83 \t AccHead 30.02 \t AccTail 11.91\n",
      "Epoch: [119] \t Loss 2.8016 \t Acc 27.82 \t AccHead 30.48 \t AccTail 8.47\n",
      "Epoch: [120] \t Loss 2.8033 \t Acc 25.84 \t AccHead 28.09 \t AccTail 9.51\n",
      "Epoch: [121] \t Loss 2.7754 \t Acc 28.15 \t AccHead 30.93 \t AccTail 7.96\n",
      "Epoch: [122] \t Loss 2.7858 \t Acc 26.90 \t AccHead 29.52 \t AccTail 7.84\n",
      "Epoch: [123] \t Loss 2.7843 \t Acc 25.74 \t AccHead 28.27 \t AccTail 7.27\n",
      "Epoch: [124] \t Loss 2.7867 \t Acc 27.58 \t AccHead 30.04 \t AccTail 9.66\n",
      "Epoch: [125] \t Loss 2.7876 \t Acc 24.82 \t AccHead 27.53 \t AccTail 5.10\n",
      "Epoch: [126] \t Loss 2.7887 \t Acc 28.32 \t AccHead 31.17 \t AccTail 7.54\n",
      "Epoch: [127] \t Loss 2.7875 \t Acc 25.21 \t AccHead 27.50 \t AccTail 8.53\n",
      "Epoch: [128] \t Loss 2.7744 \t Acc 26.37 \t AccHead 28.76 \t AccTail 8.98\n",
      "Epoch: [129] \t Loss 2.7905 \t Acc 24.12 \t AccHead 26.58 \t AccTail 6.17\n",
      "Epoch: [130] \t Loss 2.8036 \t Acc 23.88 \t AccHead 25.45 \t AccTail 12.42\n",
      "Epoch: [131] \t Loss 2.7904 \t Acc 28.03 \t AccHead 30.81 \t AccTail 7.71\n",
      "Epoch: [132] \t Loss 2.7840 \t Acc 26.99 \t AccHead 28.85 \t AccTail 13.45\n",
      "Epoch: [133] \t Loss 2.7797 \t Acc 24.60 \t AccHead 26.85 \t AccTail 8.30\n",
      "Epoch: [134] \t Loss 2.7919 \t Acc 24.95 \t AccHead 27.14 \t AccTail 8.98\n",
      "Epoch: [135] \t Loss 2.7854 \t Acc 26.82 \t AccHead 29.20 \t AccTail 9.54\n",
      "Epoch: [136] \t Loss 2.7959 \t Acc 26.13 \t AccHead 29.13 \t AccTail 4.22\n",
      "Epoch: [137] \t Loss 2.7878 \t Acc 21.83 \t AccHead 23.30 \t AccTail 11.18\n",
      "Epoch: [138] \t Loss 2.7901 \t Acc 26.26 \t AccHead 28.25 \t AccTail 11.85\n",
      "Epoch: [139] \t Loss 2.7957 \t Acc 25.63 \t AccHead 27.49 \t AccTail 12.11\n",
      "Epoch: [140] \t Loss 2.7848 \t Acc 24.15 \t AccHead 25.53 \t AccTail 14.11\n",
      "Epoch: [141] \t Loss 2.7920 \t Acc 28.07 \t AccHead 30.62 \t AccTail 9.45\n",
      "Epoch: [142] \t Loss 2.7945 \t Acc 25.36 \t AccHead 28.23 \t AccTail 4.46\n",
      "Epoch: [143] \t Loss 2.7952 \t Acc 23.38 \t AccHead 24.73 \t AccTail 13.56\n",
      "Epoch: [144] \t Loss 2.7862 \t Acc 24.57 \t AccHead 27.52 \t AccTail 3.05\n",
      "Epoch: [145] \t Loss 2.7967 \t Acc 28.52 \t AccHead 31.70 \t AccTail 5.37\n",
      "Epoch: [146] \t Loss 2.7934 \t Acc 26.77 \t AccHead 29.37 \t AccTail 7.85\n",
      "Epoch: [147] \t Loss 2.7933 \t Acc 27.02 \t AccHead 29.50 \t AccTail 8.95\n",
      "Epoch: [148] \t Loss 2.7929 \t Acc 27.05 \t AccHead 29.09 \t AccTail 12.13\n",
      "Epoch: [149] \t Loss 2.7852 \t Acc 26.18 \t AccHead 28.51 \t AccTail 9.27\n",
      "Epoch: [150] \t Loss 2.7985 \t Acc 19.71 \t AccHead 21.36 \t AccTail 7.66\n",
      "Epoch: [151] \t Loss 2.3647 \t Acc 42.52 \t AccHead 46.10 \t AccTail 16.42\n",
      "Epoch: [152] \t Loss 2.1747 \t Acc 44.13 \t AccHead 48.06 \t AccTail 15.44\n",
      "Epoch: [153] \t Loss 2.1082 \t Acc 44.67 \t AccHead 48.24 \t AccTail 18.71\n",
      "Epoch: [154] \t Loss 2.0495 \t Acc 46.62 \t AccHead 50.21 \t AccTail 20.46\n",
      "Epoch: [155] \t Loss 1.9992 \t Acc 47.66 \t AccHead 51.32 \t AccTail 20.92\n",
      "Epoch: [156] \t Loss 1.9525 \t Acc 47.91 \t AccHead 51.97 \t AccTail 18.33\n",
      "Epoch: [157] \t Loss 1.9276 \t Acc 48.06 \t AccHead 51.82 \t AccTail 20.63\n",
      "Epoch: [158] \t Loss 1.8939 \t Acc 48.60 \t AccHead 52.46 \t AccTail 20.50\n",
      "Epoch: [159] \t Loss 1.8755 \t Acc 49.41 \t AccHead 53.17 \t AccTail 22.06\n",
      "Epoch: [160] \t Loss 1.8539 \t Acc 50.55 \t AccHead 54.30 \t AccTail 23.23\n",
      "Epoch: [161] \t Loss 1.8303 \t Acc 50.91 \t AccHead 54.38 \t AccTail 25.70\n",
      "Epoch: [162] \t Loss 1.8033 \t Acc 51.20 \t AccHead 55.46 \t AccTail 20.21\n",
      "Epoch: [163] \t Loss 1.7939 \t Acc 50.24 \t AccHead 53.72 \t AccTail 24.90\n",
      "Epoch: [164] \t Loss 1.7665 \t Acc 51.65 \t AccHead 55.69 \t AccTail 22.26\n",
      "Epoch: [165] \t Loss 1.7582 \t Acc 52.84 \t AccHead 57.30 \t AccTail 20.39\n",
      "Epoch: [166] \t Loss 1.7429 \t Acc 53.06 \t AccHead 56.76 \t AccTail 26.03\n",
      "Epoch: [167] \t Loss 1.7225 \t Acc 52.27 \t AccHead 55.61 \t AccTail 28.01\n",
      "Epoch: [168] \t Loss 1.6893 \t Acc 53.68 \t AccHead 57.23 \t AccTail 27.83\n",
      "Epoch: [169] \t Loss 1.6759 \t Acc 53.51 \t AccHead 57.26 \t AccTail 26.23\n",
      "Epoch: [170] \t Loss 1.6718 \t Acc 53.33 \t AccHead 56.58 \t AccTail 29.61\n",
      "Epoch: [171] \t Loss 1.6396 \t Acc 54.61 \t AccHead 58.28 \t AccTail 27.92\n",
      "Epoch: [172] \t Loss 1.6113 \t Acc 55.62 \t AccHead 59.49 \t AccTail 27.45\n",
      "Epoch: [173] \t Loss 1.6217 \t Acc 56.04 \t AccHead 59.60 \t AccTail 30.15\n",
      "Epoch: [174] \t Loss 1.5887 \t Acc 56.58 \t AccHead 59.75 \t AccTail 33.52\n",
      "Epoch: [175] \t Loss 1.5787 \t Acc 56.93 \t AccHead 59.98 \t AccTail 34.73\n",
      "Epoch: [176] \t Loss 1.5522 \t Acc 56.34 \t AccHead 59.84 \t AccTail 30.90\n",
      "Epoch: [177] \t Loss 1.5251 \t Acc 54.83 \t AccHead 58.21 \t AccTail 30.26\n",
      "Epoch: [178] \t Loss 1.5097 \t Acc 59.24 \t AccHead 63.20 \t AccTail 30.40\n",
      "Epoch: [179] \t Loss 1.4968 \t Acc 58.35 \t AccHead 61.81 \t AccTail 33.10\n",
      "Epoch: [180] \t Loss 1.4709 \t Acc 59.42 \t AccHead 62.74 \t AccTail 35.21\n",
      "Epoch: [181] \t Loss 1.4611 \t Acc 57.51 \t AccHead 60.74 \t AccTail 34.03\n",
      "Epoch: [182] \t Loss 1.4524 \t Acc 58.32 \t AccHead 61.68 \t AccTail 33.88\n",
      "Epoch: [183] \t Loss 1.4281 \t Acc 60.35 \t AccHead 64.01 \t AccTail 33.74\n",
      "Epoch: [184] \t Loss 1.4234 \t Acc 59.48 \t AccHead 63.17 \t AccTail 32.65\n",
      "Epoch: [185] \t Loss 1.3965 \t Acc 58.98 \t AccHead 62.41 \t AccTail 33.99\n",
      "Epoch: [186] \t Loss 1.3666 \t Acc 62.95 \t AccHead 66.25 \t AccTail 38.87\n",
      "Epoch: [187] \t Loss 1.3592 \t Acc 61.14 \t AccHead 64.84 \t AccTail 34.16\n",
      "Epoch: [188] \t Loss 1.3375 \t Acc 62.00 \t AccHead 65.60 \t AccTail 35.86\n",
      "Epoch: [189] \t Loss 1.3215 \t Acc 63.12 \t AccHead 66.23 \t AccTail 40.44\n",
      "Epoch: [190] \t Loss 1.3114 \t Acc 63.64 \t AccHead 67.61 \t AccTail 34.70\n",
      "Epoch: [191] \t Loss 1.3051 \t Acc 61.39 \t AccHead 65.33 \t AccTail 32.63\n",
      "Epoch: [192] \t Loss 1.3011 \t Acc 65.28 \t AccHead 68.38 \t AccTail 42.76\n",
      "Epoch: [193] \t Loss 1.2878 \t Acc 64.09 \t AccHead 67.54 \t AccTail 38.93\n",
      "Epoch: [194] \t Loss 1.2713 \t Acc 64.48 \t AccHead 67.61 \t AccTail 41.67\n",
      "Epoch: [195] \t Loss 1.2529 \t Acc 64.19 \t AccHead 67.89 \t AccTail 37.09\n",
      "Epoch: [196] \t Loss 1.2288 \t Acc 65.54 \t AccHead 68.52 \t AccTail 43.84\n",
      "Epoch: [197] \t Loss 1.2178 \t Acc 63.90 \t AccHead 66.90 \t AccTail 42.08\n",
      "Epoch: [198] \t Loss 1.2135 \t Acc 63.57 \t AccHead 66.38 \t AccTail 43.02\n",
      "Epoch: [199] \t Loss 1.1919 \t Acc 67.41 \t AccHead 70.61 \t AccTail 44.14\n",
      "Epoch: [200] \t Loss 1.1640 \t Acc 68.64 \t AccHead 72.17 \t AccTail 42.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 20:04:36,708]\u001b[0m Trial 0 finished with value: 9.79477596282959 and parameters: {'n_epoch': 200, 'weight_decay': 0.0023139210554174432}. Best is trial 0 with value: 9.79477596282959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 9.79 \t AccHead 17.21 \t AccTail 2.45\n",
      "Epoch: [001] \t Loss 4.1851 \t Acc 5.85 \t AccHead 6.65 \t AccTail 0.00\n",
      "Epoch: [002] \t Loss 3.7992 \t Acc 9.88 \t AccHead 11.24 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 3.6958 \t Acc 9.07 \t AccHead 9.18 \t AccTail 8.28\n",
      "Epoch: [004] \t Loss 3.6457 \t Acc 13.79 \t AccHead 14.83 \t AccTail 6.22\n",
      "Epoch: [005] \t Loss 3.5874 \t Acc 13.26 \t AccHead 14.19 \t AccTail 6.45\n",
      "Epoch: [006] \t Loss 3.5562 \t Acc 13.22 \t AccHead 14.14 \t AccTail 6.51\n",
      "Epoch: [007] \t Loss 3.5398 \t Acc 13.18 \t AccHead 14.27 \t AccTail 5.25\n",
      "Epoch: [008] \t Loss 3.5208 \t Acc 12.63 \t AccHead 13.77 \t AccTail 4.38\n",
      "Epoch: [009] \t Loss 3.5156 \t Acc 13.69 \t AccHead 15.39 \t AccTail 1.37\n",
      "Epoch: [010] \t Loss 3.4999 \t Acc 13.78 \t AccHead 14.83 \t AccTail 6.13\n",
      "Epoch: [011] \t Loss 3.4906 \t Acc 14.79 \t AccHead 16.27 \t AccTail 4.00\n",
      "Epoch: [012] \t Loss 3.4827 \t Acc 11.48 \t AccHead 12.49 \t AccTail 4.11\n",
      "Epoch: [013] \t Loss 3.4736 \t Acc 12.87 \t AccHead 13.51 \t AccTail 8.18\n",
      "Epoch: [014] \t Loss 3.4693 \t Acc 10.74 \t AccHead 11.86 \t AccTail 2.55\n",
      "Epoch: [015] \t Loss 3.4792 \t Acc 14.70 \t AccHead 16.10 \t AccTail 4.56\n",
      "Epoch: [016] \t Loss 3.4719 \t Acc 12.39 \t AccHead 14.03 \t AccTail 0.38\n",
      "Epoch: [017] \t Loss 3.4678 \t Acc 12.83 \t AccHead 14.07 \t AccTail 3.84\n",
      "Epoch: [018] \t Loss 3.4448 \t Acc 14.89 \t AccHead 16.72 \t AccTail 1.56\n",
      "Epoch: [019] \t Loss 3.4663 \t Acc 13.90 \t AccHead 15.38 \t AccTail 3.12\n",
      "Epoch: [020] \t Loss 3.4565 \t Acc 14.24 \t AccHead 15.07 \t AccTail 8.18\n",
      "Epoch: [021] \t Loss 3.4429 \t Acc 11.96 \t AccHead 13.24 \t AccTail 2.66\n",
      "Epoch: [022] \t Loss 3.4508 \t Acc 12.63 \t AccHead 13.75 \t AccTail 4.53\n",
      "Epoch: [023] \t Loss 3.4348 \t Acc 17.10 \t AccHead 19.15 \t AccTail 2.25\n",
      "Epoch: [024] \t Loss 3.4594 \t Acc 14.33 \t AccHead 15.64 \t AccTail 4.75\n",
      "Epoch: [025] \t Loss 3.4471 \t Acc 12.58 \t AccHead 13.78 \t AccTail 3.84\n",
      "Epoch: [026] \t Loss 3.4419 \t Acc 14.89 \t AccHead 16.14 \t AccTail 5.71\n",
      "Epoch: [027] \t Loss 3.4250 \t Acc 13.21 \t AccHead 14.41 \t AccTail 4.46\n",
      "Epoch: [028] \t Loss 3.4296 \t Acc 12.89 \t AccHead 14.21 \t AccTail 3.20\n",
      "Epoch: [029] \t Loss 3.4275 \t Acc 15.17 \t AccHead 16.21 \t AccTail 7.57\n",
      "Epoch: [030] \t Loss 3.4242 \t Acc 16.73 \t AccHead 18.06 \t AccTail 7.01\n",
      "Epoch: [031] \t Loss 3.4245 \t Acc 14.84 \t AccHead 16.67 \t AccTail 1.56\n",
      "Epoch: [032] \t Loss 3.4088 \t Acc 11.14 \t AccHead 11.86 \t AccTail 5.90\n",
      "Epoch: [033] \t Loss 3.4147 \t Acc 13.25 \t AccHead 13.79 \t AccTail 9.38\n",
      "Epoch: [034] \t Loss 3.4071 \t Acc 16.07 \t AccHead 17.26 \t AccTail 7.35\n",
      "Epoch: [035] \t Loss 3.4143 \t Acc 10.50 \t AccHead 11.05 \t AccTail 6.50\n",
      "Epoch: [036] \t Loss 3.4106 \t Acc 15.25 \t AccHead 17.15 \t AccTail 1.45\n",
      "Epoch: [037] \t Loss 3.4121 \t Acc 15.51 \t AccHead 17.13 \t AccTail 3.70\n",
      "Epoch: [038] \t Loss 3.4138 \t Acc 13.07 \t AccHead 13.91 \t AccTail 6.94\n",
      "Epoch: [039] \t Loss 3.4087 \t Acc 14.09 \t AccHead 15.49 \t AccTail 3.88\n",
      "Epoch: [040] \t Loss 3.4188 \t Acc 15.69 \t AccHead 17.72 \t AccTail 0.99\n",
      "Epoch: [041] \t Loss 3.4254 \t Acc 14.15 \t AccHead 15.55 \t AccTail 3.96\n",
      "Epoch: [042] \t Loss 3.4255 \t Acc 13.88 \t AccHead 15.03 \t AccTail 5.52\n",
      "Epoch: [043] \t Loss 3.4063 \t Acc 11.34 \t AccHead 12.45 \t AccTail 3.28\n",
      "Epoch: [044] \t Loss 3.4160 \t Acc 15.23 \t AccHead 16.70 \t AccTail 4.50\n",
      "Epoch: [045] \t Loss 3.4150 \t Acc 6.33 \t AccHead 7.12 \t AccTail 0.57\n",
      "Epoch: [046] \t Loss 3.4191 \t Acc 15.43 \t AccHead 16.85 \t AccTail 5.10\n",
      "Epoch: [047] \t Loss 3.4282 \t Acc 15.68 \t AccHead 16.82 \t AccTail 7.31\n",
      "Epoch: [048] \t Loss 3.4103 \t Acc 14.21 \t AccHead 15.35 \t AccTail 5.94\n",
      "Epoch: [049] \t Loss 3.4407 \t Acc 13.52 \t AccHead 15.14 \t AccTail 1.67\n",
      "Epoch: [050] \t Loss 3.4336 \t Acc 15.37 \t AccHead 16.73 \t AccTail 5.42\n",
      "Epoch: [051] \t Loss 3.4272 \t Acc 15.37 \t AccHead 17.04 \t AccTail 3.16\n",
      "Epoch: [052] \t Loss 3.4220 \t Acc 15.82 \t AccHead 17.83 \t AccTail 1.14\n",
      "Epoch: [053] \t Loss 3.4139 \t Acc 16.61 \t AccHead 18.34 \t AccTail 4.00\n",
      "Epoch: [054] \t Loss 3.4139 \t Acc 16.21 \t AccHead 17.30 \t AccTail 8.31\n",
      "Epoch: [055] \t Loss 3.4284 \t Acc 15.70 \t AccHead 17.17 \t AccTail 4.99\n",
      "Epoch: [056] \t Loss 3.4219 \t Acc 16.51 \t AccHead 17.94 \t AccTail 6.09\n",
      "Epoch: [057] \t Loss 3.4293 \t Acc 14.41 \t AccHead 15.87 \t AccTail 3.77\n",
      "Epoch: [058] \t Loss 3.4274 \t Acc 13.40 \t AccHead 15.07 \t AccTail 1.26\n",
      "Epoch: [059] \t Loss 3.4219 \t Acc 13.87 \t AccHead 14.93 \t AccTail 6.17\n",
      "Epoch: [060] \t Loss 3.4368 \t Acc 12.87 \t AccHead 14.41 \t AccTail 1.64\n",
      "Epoch: [061] \t Loss 3.4160 \t Acc 15.79 \t AccHead 17.00 \t AccTail 6.93\n",
      "Epoch: [062] \t Loss 3.4226 \t Acc 13.31 \t AccHead 14.75 \t AccTail 2.85\n",
      "Epoch: [063] \t Loss 3.4290 \t Acc 13.86 \t AccHead 14.93 \t AccTail 6.09\n",
      "Epoch: [064] \t Loss 3.4281 \t Acc 13.37 \t AccHead 15.14 \t AccTail 0.46\n",
      "Epoch: [065] \t Loss 3.4370 \t Acc 15.57 \t AccHead 17.37 \t AccTail 2.47\n",
      "Epoch: [066] \t Loss 3.4215 \t Acc 12.49 \t AccHead 13.54 \t AccTail 4.79\n",
      "Epoch: [067] \t Loss 3.4217 \t Acc 15.25 \t AccHead 16.58 \t AccTail 5.52\n",
      "Epoch: [068] \t Loss 3.4265 \t Acc 13.83 \t AccHead 15.41 \t AccTail 2.32\n",
      "Epoch: [069] \t Loss 3.4257 \t Acc 13.29 \t AccHead 14.55 \t AccTail 4.04\n",
      "Epoch: [070] \t Loss 3.4302 \t Acc 14.69 \t AccHead 16.43 \t AccTail 2.05\n",
      "Epoch: [071] \t Loss 3.4258 \t Acc 15.73 \t AccHead 16.52 \t AccTail 9.97\n",
      "Epoch: [072] \t Loss 3.4237 \t Acc 12.94 \t AccHead 14.50 \t AccTail 1.56\n",
      "Epoch: [073] \t Loss 3.4327 \t Acc 11.10 \t AccHead 12.56 \t AccTail 0.46\n",
      "Epoch: [074] \t Loss 3.4293 \t Acc 14.97 \t AccHead 16.56 \t AccTail 3.39\n",
      "Epoch: [075] \t Loss 3.4236 \t Acc 13.38 \t AccHead 14.53 \t AccTail 5.03\n",
      "Epoch: [076] \t Loss 3.4432 \t Acc 14.31 \t AccHead 15.72 \t AccTail 3.99\n",
      "Epoch: [077] \t Loss 3.4301 \t Acc 14.25 \t AccHead 16.12 \t AccTail 0.65\n",
      "Epoch: [078] \t Loss 3.4260 \t Acc 15.27 \t AccHead 17.29 \t AccTail 0.57\n",
      "Epoch: [079] \t Loss 3.4248 \t Acc 14.63 \t AccHead 16.00 \t AccTail 4.68\n",
      "Epoch: [080] \t Loss 3.4353 \t Acc 14.85 \t AccHead 15.68 \t AccTail 8.86\n",
      "Epoch: [081] \t Loss 3.4254 \t Acc 14.21 \t AccHead 15.57 \t AccTail 4.30\n",
      "Epoch: [082] \t Loss 3.4160 \t Acc 14.35 \t AccHead 15.66 \t AccTail 4.76\n",
      "Epoch: [083] \t Loss 3.4311 \t Acc 14.79 \t AccHead 16.29 \t AccTail 3.88\n",
      "Epoch: [084] \t Loss 3.4310 \t Acc 14.37 \t AccHead 15.53 \t AccTail 5.93\n",
      "Epoch: [085] \t Loss 3.4323 \t Acc 11.08 \t AccHead 12.55 \t AccTail 0.30\n",
      "Epoch: [086] \t Loss 3.4233 \t Acc 10.80 \t AccHead 11.65 \t AccTail 4.60\n",
      "Epoch: [087] \t Loss 3.4288 \t Acc 12.97 \t AccHead 14.73 \t AccTail 0.15\n",
      "Epoch: [088] \t Loss 3.4306 \t Acc 13.49 \t AccHead 15.05 \t AccTail 2.13\n",
      "Epoch: [089] \t Loss 3.4141 \t Acc 16.34 \t AccHead 17.79 \t AccTail 5.78\n",
      "Epoch: [090] \t Loss 3.4277 \t Acc 13.44 \t AccHead 14.83 \t AccTail 3.31\n",
      "Epoch: [091] \t Loss 3.4168 \t Acc 14.49 \t AccHead 16.10 \t AccTail 2.74\n",
      "Epoch: [092] \t Loss 3.4450 \t Acc 13.81 \t AccHead 15.41 \t AccTail 2.13\n",
      "Epoch: [093] \t Loss 3.4210 \t Acc 13.52 \t AccHead 15.17 \t AccTail 1.49\n",
      "Epoch: [094] \t Loss 3.4188 \t Acc 10.89 \t AccHead 11.81 \t AccTail 4.19\n",
      "Epoch: [095] \t Loss 3.4302 \t Acc 13.54 \t AccHead 15.03 \t AccTail 2.77\n",
      "Epoch: [096] \t Loss 3.4292 \t Acc 10.36 \t AccHead 11.55 \t AccTail 1.67\n",
      "Epoch: [097] \t Loss 3.4374 \t Acc 13.05 \t AccHead 14.24 \t AccTail 4.38\n",
      "Epoch: [098] \t Loss 3.4482 \t Acc 15.27 \t AccHead 16.78 \t AccTail 4.23\n",
      "Epoch: [099] \t Loss 3.4340 \t Acc 13.28 \t AccHead 14.49 \t AccTail 4.46\n",
      "Epoch: [100] \t Loss 3.4275 \t Acc 13.50 \t AccHead 14.83 \t AccTail 3.82\n",
      "Epoch: [101] \t Loss 3.4295 \t Acc 11.78 \t AccHead 12.83 \t AccTail 4.08\n",
      "Epoch: [102] \t Loss 3.4347 \t Acc 11.23 \t AccHead 12.71 \t AccTail 0.50\n",
      "Epoch: [103] \t Loss 3.4380 \t Acc 13.01 \t AccHead 14.52 \t AccTail 2.05\n",
      "Epoch: [104] \t Loss 3.4324 \t Acc 15.79 \t AccHead 17.45 \t AccTail 3.65\n",
      "Epoch: [105] \t Loss 3.4296 \t Acc 13.64 \t AccHead 14.82 \t AccTail 5.07\n",
      "Epoch: [106] \t Loss 3.4393 \t Acc 14.28 \t AccHead 15.57 \t AccTail 4.90\n",
      "Epoch: [107] \t Loss 3.4490 \t Acc 13.13 \t AccHead 14.23 \t AccTail 5.14\n",
      "Epoch: [108] \t Loss 3.4405 \t Acc 13.92 \t AccHead 14.86 \t AccTail 7.05\n",
      "Epoch: [109] \t Loss 3.4385 \t Acc 13.73 \t AccHead 14.95 \t AccTail 4.87\n",
      "Epoch: [110] \t Loss 3.4313 \t Acc 12.60 \t AccHead 13.53 \t AccTail 5.79\n",
      "Epoch: [111] \t Loss 3.4405 \t Acc 12.17 \t AccHead 13.71 \t AccTail 0.99\n",
      "Epoch: [112] \t Loss 3.4293 \t Acc 12.37 \t AccHead 13.86 \t AccTail 1.52\n",
      "Epoch: [113] \t Loss 3.4367 \t Acc 9.96 \t AccHead 11.26 \t AccTail 0.53\n",
      "Epoch: [114] \t Loss 3.4383 \t Acc 14.43 \t AccHead 16.28 \t AccTail 0.95\n",
      "Epoch: [115] \t Loss 3.4301 \t Acc 11.91 \t AccHead 13.41 \t AccTail 1.03\n",
      "Epoch: [116] \t Loss 3.4409 \t Acc 13.50 \t AccHead 14.46 \t AccTail 6.51\n",
      "Epoch: [117] \t Loss 3.4218 \t Acc 13.38 \t AccHead 14.53 \t AccTail 4.99\n",
      "Epoch: [118] \t Loss 3.4387 \t Acc 10.48 \t AccHead 10.46 \t AccTail 10.62\n",
      "Epoch: [119] \t Loss 3.4280 \t Acc 16.36 \t AccHead 17.62 \t AccTail 7.19\n",
      "Epoch: [120] \t Loss 3.4386 \t Acc 15.27 \t AccHead 16.35 \t AccTail 7.38\n",
      "Epoch: [121] \t Loss 3.4320 \t Acc 14.78 \t AccHead 16.11 \t AccTail 5.14\n",
      "Epoch: [122] \t Loss 3.4318 \t Acc 12.91 \t AccHead 14.14 \t AccTail 3.96\n",
      "Epoch: [123] \t Loss 3.4385 \t Acc 13.79 \t AccHead 15.41 \t AccTail 1.98\n",
      "Epoch: [124] \t Loss 3.4287 \t Acc 15.35 \t AccHead 16.94 \t AccTail 3.74\n",
      "Epoch: [125] \t Loss 3.4410 \t Acc 14.44 \t AccHead 15.80 \t AccTail 4.51\n",
      "Epoch: [126] \t Loss 3.4469 \t Acc 14.46 \t AccHead 14.94 \t AccTail 11.00\n",
      "Epoch: [127] \t Loss 3.4367 \t Acc 14.60 \t AccHead 15.98 \t AccTail 4.53\n",
      "Epoch: [128] \t Loss 3.4344 \t Acc 15.22 \t AccHead 16.18 \t AccTail 8.23\n",
      "Epoch: [129] \t Loss 3.4459 \t Acc 13.40 \t AccHead 14.79 \t AccTail 3.24\n",
      "Epoch: [130] \t Loss 3.4437 \t Acc 14.71 \t AccHead 15.50 \t AccTail 8.95\n",
      "Epoch: [131] \t Loss 3.4411 \t Acc 10.05 \t AccHead 11.34 \t AccTail 0.69\n",
      "Epoch: [132] \t Loss 3.4402 \t Acc 11.59 \t AccHead 13.12 \t AccTail 0.42\n",
      "Epoch: [133] \t Loss 3.4346 \t Acc 12.12 \t AccHead 13.72 \t AccTail 0.53\n",
      "Epoch: [134] \t Loss 3.4462 \t Acc 14.12 \t AccHead 15.22 \t AccTail 6.10\n",
      "Epoch: [135] \t Loss 3.4403 \t Acc 12.42 \t AccHead 13.97 \t AccTail 1.14\n",
      "Epoch: [136] \t Loss 3.4338 \t Acc 14.20 \t AccHead 15.88 \t AccTail 1.94\n",
      "Epoch: [137] \t Loss 3.4573 \t Acc 13.52 \t AccHead 14.53 \t AccTail 6.14\n",
      "Epoch: [138] \t Loss 3.4395 \t Acc 13.33 \t AccHead 14.81 \t AccTail 2.51\n",
      "Epoch: [139] \t Loss 3.4476 \t Acc 12.03 \t AccHead 13.44 \t AccTail 1.79\n",
      "Epoch: [140] \t Loss 3.4533 \t Acc 13.96 \t AccHead 14.98 \t AccTail 6.55\n",
      "Epoch: [141] \t Loss 3.4530 \t Acc 15.68 \t AccHead 16.99 \t AccTail 6.20\n",
      "Epoch: [142] \t Loss 3.4419 \t Acc 15.28 \t AccHead 16.56 \t AccTail 5.95\n",
      "Epoch: [143] \t Loss 3.4540 \t Acc 12.14 \t AccHead 13.01 \t AccTail 5.83\n",
      "Epoch: [144] \t Loss 3.4419 \t Acc 14.51 \t AccHead 15.91 \t AccTail 4.33\n",
      "Epoch: [145] \t Loss 3.4479 \t Acc 15.32 \t AccHead 16.89 \t AccTail 3.85\n",
      "Epoch: [146] \t Loss 3.4464 \t Acc 13.68 \t AccHead 14.95 \t AccTail 4.46\n",
      "Epoch: [147] \t Loss 3.4421 \t Acc 13.80 \t AccHead 15.36 \t AccTail 2.40\n",
      "Epoch: [148] \t Loss 3.4450 \t Acc 15.44 \t AccHead 16.94 \t AccTail 4.53\n",
      "Epoch: [149] \t Loss 3.4460 \t Acc 14.71 \t AccHead 16.05 \t AccTail 4.94\n",
      "Epoch: [150] \t Loss 3.4220 \t Acc 12.14 \t AccHead 13.57 \t AccTail 1.68\n",
      "Epoch: [151] \t Loss 3.1158 \t Acc 24.85 \t AccHead 27.17 \t AccTail 7.91\n",
      "Epoch: [152] \t Loss 2.9729 \t Acc 26.86 \t AccHead 29.32 \t AccTail 8.91\n",
      "Epoch: [153] \t Loss 2.9123 \t Acc 26.87 \t AccHead 29.51 \t AccTail 7.68\n",
      "Epoch: [154] \t Loss 2.8838 \t Acc 28.36 \t AccHead 30.97 \t AccTail 9.35\n",
      "Epoch: [155] \t Loss 2.8466 \t Acc 27.71 \t AccHead 29.93 \t AccTail 11.60\n",
      "Epoch: [156] \t Loss 2.8250 \t Acc 28.40 \t AccHead 31.03 \t AccTail 9.25\n",
      "Epoch: [157] \t Loss 2.7998 \t Acc 29.90 \t AccHead 32.69 \t AccTail 9.59\n",
      "Epoch: [158] \t Loss 2.7926 \t Acc 29.17 \t AccHead 31.63 \t AccTail 11.22\n",
      "Epoch: [159] \t Loss 2.7598 \t Acc 29.71 \t AccHead 32.11 \t AccTail 12.13\n",
      "Epoch: [160] \t Loss 2.7438 \t Acc 31.27 \t AccHead 34.08 \t AccTail 10.84\n",
      "Epoch: [161] \t Loss 2.7292 \t Acc 30.17 \t AccHead 33.23 \t AccTail 7.98\n",
      "Epoch: [162] \t Loss 2.7205 \t Acc 31.43 \t AccHead 34.37 \t AccTail 10.07\n",
      "Epoch: [163] \t Loss 2.6944 \t Acc 28.69 \t AccHead 31.18 \t AccTail 10.56\n",
      "Epoch: [164] \t Loss 2.6800 \t Acc 31.58 \t AccHead 34.79 \t AccTail 8.25\n",
      "Epoch: [165] \t Loss 2.6736 \t Acc 30.67 \t AccHead 33.34 \t AccTail 11.23\n",
      "Epoch: [166] \t Loss 2.6527 \t Acc 29.36 \t AccHead 32.58 \t AccTail 5.94\n",
      "Epoch: [167] \t Loss 2.6466 \t Acc 31.40 \t AccHead 34.05 \t AccTail 12.12\n",
      "Epoch: [168] \t Loss 2.6341 \t Acc 30.46 \t AccHead 32.95 \t AccTail 12.37\n",
      "Epoch: [169] \t Loss 2.6152 \t Acc 31.04 \t AccHead 33.79 \t AccTail 10.98\n",
      "Epoch: [170] \t Loss 2.6191 \t Acc 33.04 \t AccHead 36.00 \t AccTail 11.52\n",
      "Epoch: [171] \t Loss 2.5970 \t Acc 32.62 \t AccHead 35.84 \t AccTail 9.21\n",
      "Epoch: [172] \t Loss 2.5957 \t Acc 33.09 \t AccHead 36.25 \t AccTail 10.08\n",
      "Epoch: [173] \t Loss 2.5786 \t Acc 31.75 \t AccHead 34.44 \t AccTail 12.21\n",
      "Epoch: [174] \t Loss 2.5695 \t Acc 34.27 \t AccHead 37.59 \t AccTail 10.12\n",
      "Epoch: [175] \t Loss 2.5634 \t Acc 30.42 \t AccHead 32.90 \t AccTail 12.28\n",
      "Epoch: [176] \t Loss 2.5620 \t Acc 32.77 \t AccHead 35.36 \t AccTail 13.91\n",
      "Epoch: [177] \t Loss 2.5400 \t Acc 32.78 \t AccHead 35.59 \t AccTail 12.30\n",
      "Epoch: [178] \t Loss 2.5376 \t Acc 35.40 \t AccHead 38.62 \t AccTail 11.89\n",
      "Epoch: [179] \t Loss 2.5425 \t Acc 33.30 \t AccHead 36.25 \t AccTail 11.77\n",
      "Epoch: [180] \t Loss 2.5379 \t Acc 34.14 \t AccHead 36.89 \t AccTail 14.13\n",
      "Epoch: [181] \t Loss 2.5149 \t Acc 33.07 \t AccHead 36.32 \t AccTail 9.38\n",
      "Epoch: [182] \t Loss 2.5272 \t Acc 32.10 \t AccHead 35.34 \t AccTail 8.54\n",
      "Epoch: [183] \t Loss 2.5133 \t Acc 36.80 \t AccHead 40.11 \t AccTail 12.75\n",
      "Epoch: [184] \t Loss 2.5082 \t Acc 34.72 \t AccHead 37.95 \t AccTail 11.22\n",
      "Epoch: [185] \t Loss 2.5163 \t Acc 35.08 \t AccHead 38.17 \t AccTail 12.51\n",
      "Epoch: [186] \t Loss 2.5036 \t Acc 34.65 \t AccHead 37.74 \t AccTail 12.15\n",
      "Epoch: [187] \t Loss 2.4933 \t Acc 34.92 \t AccHead 37.84 \t AccTail 13.63\n",
      "Epoch: [188] \t Loss 2.4900 \t Acc 33.81 \t AccHead 36.35 \t AccTail 15.27\n",
      "Epoch: [189] \t Loss 2.4779 \t Acc 34.26 \t AccHead 37.03 \t AccTail 14.16\n",
      "Epoch: [190] \t Loss 2.4862 \t Acc 34.91 \t AccHead 37.98 \t AccTail 12.50\n",
      "Epoch: [191] \t Loss 2.4758 \t Acc 36.25 \t AccHead 39.48 \t AccTail 12.69\n",
      "Epoch: [192] \t Loss 2.4759 \t Acc 33.32 \t AccHead 36.61 \t AccTail 9.39\n",
      "Epoch: [193] \t Loss 2.4736 \t Acc 35.86 \t AccHead 39.35 \t AccTail 10.46\n",
      "Epoch: [194] \t Loss 2.4722 \t Acc 35.63 \t AccHead 39.23 \t AccTail 9.37\n",
      "Epoch: [195] \t Loss 2.4776 \t Acc 35.59 \t AccHead 38.24 \t AccTail 16.31\n",
      "Epoch: [196] \t Loss 2.4681 \t Acc 34.38 \t AccHead 37.38 \t AccTail 12.50\n",
      "Epoch: [197] \t Loss 2.4484 \t Acc 35.85 \t AccHead 39.05 \t AccTail 12.54\n",
      "Epoch: [198] \t Loss 2.4593 \t Acc 35.68 \t AccHead 38.55 \t AccTail 14.74\n",
      "Epoch: [199] \t Loss 2.4367 \t Acc 35.67 \t AccHead 39.16 \t AccTail 10.23\n",
      "Epoch: [200] \t Loss 2.4558 \t Acc 35.22 \t AccHead 38.36 \t AccTail 12.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 20:41:16,712]\u001b[0m Trial 1 finished with value: 5.358623504638672 and parameters: {'n_epoch': 200, 'weight_decay': 0.005398742405683055}. Best is trial 0 with value: 9.79477596282959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 5.36 \t AccHead 10.65 \t AccTail 0.12\n",
      "Epoch: [001] \t Loss 4.2938 \t Acc 6.15 \t AccHead 6.99 \t AccTail 0.04\n",
      "Epoch: [002] \t Loss 3.7755 \t Acc 11.13 \t AccHead 12.50 \t AccTail 1.18\n",
      "Epoch: [003] \t Loss 3.6330 \t Acc 12.08 \t AccHead 13.22 \t AccTail 3.76\n",
      "Epoch: [004] \t Loss 3.5253 \t Acc 14.94 \t AccHead 16.62 \t AccTail 2.67\n",
      "Epoch: [005] \t Loss 3.4518 \t Acc 14.21 \t AccHead 14.96 \t AccTail 8.75\n",
      "Epoch: [006] \t Loss 3.4115 \t Acc 11.05 \t AccHead 12.22 \t AccTail 2.51\n",
      "Epoch: [007] \t Loss 3.3735 \t Acc 15.46 \t AccHead 17.20 \t AccTail 2.78\n",
      "Epoch: [008] \t Loss 3.3324 \t Acc 15.53 \t AccHead 16.71 \t AccTail 7.00\n",
      "Epoch: [009] \t Loss 3.3069 \t Acc 18.63 \t AccHead 20.77 \t AccTail 3.01\n",
      "Epoch: [010] \t Loss 3.2631 \t Acc 19.32 \t AccHead 20.78 \t AccTail 8.62\n",
      "Epoch: [011] \t Loss 3.2388 \t Acc 17.16 \t AccHead 19.12 \t AccTail 2.89\n",
      "Epoch: [012] \t Loss 3.1981 \t Acc 17.69 \t AccHead 19.78 \t AccTail 2.40\n",
      "Epoch: [013] \t Loss 3.2019 \t Acc 19.07 \t AccHead 20.53 \t AccTail 8.43\n",
      "Epoch: [014] \t Loss 3.1946 \t Acc 16.23 \t AccHead 18.30 \t AccTail 1.10\n",
      "Epoch: [015] \t Loss 3.1706 \t Acc 17.03 \t AccHead 17.59 \t AccTail 12.90\n",
      "Epoch: [016] \t Loss 3.1650 \t Acc 19.12 \t AccHead 21.05 \t AccTail 5.07\n",
      "Epoch: [017] \t Loss 3.1425 \t Acc 21.06 \t AccHead 23.34 \t AccTail 4.42\n",
      "Epoch: [018] \t Loss 3.1501 \t Acc 18.39 \t AccHead 19.80 \t AccTail 8.08\n",
      "Epoch: [019] \t Loss 3.1394 \t Acc 21.91 \t AccHead 23.85 \t AccTail 7.74\n",
      "Epoch: [020] \t Loss 3.1355 \t Acc 16.27 \t AccHead 17.20 \t AccTail 9.49\n",
      "Epoch: [021] \t Loss 3.1393 \t Acc 16.64 \t AccHead 18.47 \t AccTail 3.24\n",
      "Epoch: [022] \t Loss 3.1336 \t Acc 20.59 \t AccHead 22.56 \t AccTail 6.25\n",
      "Epoch: [023] \t Loss 3.1106 \t Acc 15.50 \t AccHead 17.47 \t AccTail 1.10\n",
      "Epoch: [024] \t Loss 3.1363 \t Acc 18.07 \t AccHead 19.99 \t AccTail 4.11\n",
      "Epoch: [025] \t Loss 3.1196 \t Acc 19.87 \t AccHead 22.46 \t AccTail 0.99\n",
      "Epoch: [026] \t Loss 3.1244 \t Acc 20.01 \t AccHead 22.04 \t AccTail 5.29\n",
      "Epoch: [027] \t Loss 3.1208 \t Acc 21.51 \t AccHead 23.54 \t AccTail 6.74\n",
      "Epoch: [028] \t Loss 3.1268 \t Acc 20.72 \t AccHead 22.37 \t AccTail 8.69\n",
      "Epoch: [029] \t Loss 3.1200 \t Acc 21.30 \t AccHead 23.30 \t AccTail 6.73\n",
      "Epoch: [030] \t Loss 3.1217 \t Acc 15.31 \t AccHead 17.21 \t AccTail 1.48\n",
      "Epoch: [031] \t Loss 3.1061 \t Acc 21.51 \t AccHead 23.38 \t AccTail 7.94\n",
      "Epoch: [032] \t Loss 3.1084 \t Acc 19.30 \t AccHead 21.61 \t AccTail 2.40\n",
      "Epoch: [033] \t Loss 3.1192 \t Acc 21.35 \t AccHead 23.11 \t AccTail 8.52\n",
      "Epoch: [034] \t Loss 3.1054 \t Acc 22.11 \t AccHead 24.21 \t AccTail 6.84\n",
      "Epoch: [035] \t Loss 3.1230 \t Acc 19.24 \t AccHead 21.42 \t AccTail 3.39\n",
      "Epoch: [036] \t Loss 3.1118 \t Acc 19.60 \t AccHead 21.33 \t AccTail 6.99\n",
      "Epoch: [037] \t Loss 3.1166 \t Acc 17.54 \t AccHead 18.15 \t AccTail 13.05\n",
      "Epoch: [038] \t Loss 3.1127 \t Acc 18.02 \t AccHead 20.29 \t AccTail 1.49\n",
      "Epoch: [039] \t Loss 3.1200 \t Acc 20.93 \t AccHead 22.76 \t AccTail 7.59\n",
      "Epoch: [040] \t Loss 3.1090 \t Acc 20.62 \t AccHead 22.78 \t AccTail 4.84\n",
      "Epoch: [041] \t Loss 3.1137 \t Acc 19.38 \t AccHead 21.40 \t AccTail 4.60\n",
      "Epoch: [042] \t Loss 3.1037 \t Acc 21.93 \t AccHead 24.19 \t AccTail 5.48\n",
      "Epoch: [043] \t Loss 3.1064 \t Acc 16.39 \t AccHead 18.38 \t AccTail 1.94\n",
      "Epoch: [044] \t Loss 3.0957 \t Acc 22.36 \t AccHead 25.05 \t AccTail 2.82\n",
      "Epoch: [045] \t Loss 3.1269 \t Acc 19.08 \t AccHead 20.95 \t AccTail 5.48\n",
      "Epoch: [046] \t Loss 3.1237 \t Acc 16.01 \t AccHead 17.14 \t AccTail 7.71\n",
      "Epoch: [047] \t Loss 3.1032 \t Acc 18.79 \t AccHead 19.81 \t AccTail 11.35\n",
      "Epoch: [048] \t Loss 3.1119 \t Acc 19.54 \t AccHead 20.90 \t AccTail 9.63\n",
      "Epoch: [049] \t Loss 3.1189 \t Acc 20.03 \t AccHead 21.21 \t AccTail 11.45\n",
      "Epoch: [050] \t Loss 3.1192 \t Acc 15.85 \t AccHead 17.74 \t AccTail 2.13\n",
      "Epoch: [051] \t Loss 3.1003 \t Acc 18.47 \t AccHead 20.26 \t AccTail 5.47\n",
      "Epoch: [052] \t Loss 3.1032 \t Acc 19.45 \t AccHead 21.61 \t AccTail 3.74\n",
      "Epoch: [053] \t Loss 3.1142 \t Acc 21.92 \t AccHead 23.54 \t AccTail 10.09\n",
      "Epoch: [054] \t Loss 3.1084 \t Acc 23.45 \t AccHead 25.77 \t AccTail 6.58\n",
      "Epoch: [055] \t Loss 3.1099 \t Acc 20.78 \t AccHead 23.14 \t AccTail 3.62\n",
      "Epoch: [056] \t Loss 3.1182 \t Acc 21.40 \t AccHead 23.54 \t AccTail 5.76\n",
      "Epoch: [057] \t Loss 3.1136 \t Acc 22.11 \t AccHead 24.65 \t AccTail 3.65\n",
      "Epoch: [058] \t Loss 3.1141 \t Acc 17.82 \t AccHead 19.90 \t AccTail 2.70\n",
      "Epoch: [059] \t Loss 3.1106 \t Acc 22.40 \t AccHead 24.62 \t AccTail 6.22\n",
      "Epoch: [060] \t Loss 3.1042 \t Acc 18.61 \t AccHead 19.98 \t AccTail 8.57\n",
      "Epoch: [061] \t Loss 3.1231 \t Acc 21.01 \t AccHead 23.24 \t AccTail 4.72\n",
      "Epoch: [062] \t Loss 3.1250 \t Acc 19.40 \t AccHead 20.91 \t AccTail 8.44\n",
      "Epoch: [063] \t Loss 3.1128 \t Acc 12.59 \t AccHead 14.15 \t AccTail 1.22\n",
      "Epoch: [064] \t Loss 3.1155 \t Acc 22.00 \t AccHead 23.54 \t AccTail 10.74\n",
      "Epoch: [065] \t Loss 3.1119 \t Acc 18.13 \t AccHead 19.95 \t AccTail 4.90\n",
      "Epoch: [066] \t Loss 3.1060 \t Acc 16.96 \t AccHead 17.27 \t AccTail 14.68\n",
      "Epoch: [067] \t Loss 3.1099 \t Acc 21.85 \t AccHead 23.53 \t AccTail 9.56\n",
      "Epoch: [068] \t Loss 3.1084 \t Acc 20.29 \t AccHead 22.57 \t AccTail 3.70\n",
      "Epoch: [069] \t Loss 3.0914 \t Acc 23.30 \t AccHead 25.25 \t AccTail 9.17\n",
      "Epoch: [070] \t Loss 3.0943 \t Acc 19.90 \t AccHead 21.94 \t AccTail 5.06\n",
      "Epoch: [071] \t Loss 3.1064 \t Acc 18.83 \t AccHead 20.83 \t AccTail 4.27\n",
      "Epoch: [072] \t Loss 3.1043 \t Acc 20.80 \t AccHead 23.26 \t AccTail 2.86\n",
      "Epoch: [073] \t Loss 3.1046 \t Acc 15.96 \t AccHead 17.60 \t AccTail 3.96\n",
      "Epoch: [074] \t Loss 3.1142 \t Acc 20.15 \t AccHead 22.42 \t AccTail 3.65\n",
      "Epoch: [075] \t Loss 3.1191 \t Acc 18.41 \t AccHead 20.12 \t AccTail 6.01\n",
      "Epoch: [076] \t Loss 3.1080 \t Acc 18.71 \t AccHead 20.80 \t AccTail 3.53\n",
      "Epoch: [077] \t Loss 3.1044 \t Acc 19.52 \t AccHead 21.24 \t AccTail 6.99\n",
      "Epoch: [078] \t Loss 3.1125 \t Acc 18.40 \t AccHead 20.17 \t AccTail 5.52\n",
      "Epoch: [079] \t Loss 3.1163 \t Acc 22.06 \t AccHead 24.15 \t AccTail 6.81\n",
      "Epoch: [080] \t Loss 3.1052 \t Acc 17.56 \t AccHead 18.88 \t AccTail 7.88\n",
      "Epoch: [081] \t Loss 3.1160 \t Acc 19.28 \t AccHead 21.66 \t AccTail 1.94\n",
      "Epoch: [082] \t Loss 3.1167 \t Acc 17.29 \t AccHead 19.07 \t AccTail 4.30\n",
      "Epoch: [083] \t Loss 3.1109 \t Acc 13.64 \t AccHead 14.85 \t AccTail 4.87\n",
      "Epoch: [084] \t Loss 3.1038 \t Acc 20.08 \t AccHead 21.83 \t AccTail 7.41\n",
      "Epoch: [085] \t Loss 3.1217 \t Acc 22.84 \t AccHead 25.76 \t AccTail 1.56\n",
      "Epoch: [086] \t Loss 3.0974 \t Acc 20.91 \t AccHead 22.61 \t AccTail 8.50\n",
      "Epoch: [087] \t Loss 3.1261 \t Acc 19.20 \t AccHead 21.37 \t AccTail 3.35\n",
      "Epoch: [088] \t Loss 3.1092 \t Acc 19.18 \t AccHead 21.27 \t AccTail 3.96\n",
      "Epoch: [089] \t Loss 3.1153 \t Acc 19.53 \t AccHead 21.37 \t AccTail 6.16\n",
      "Epoch: [090] \t Loss 3.1084 \t Acc 15.74 \t AccHead 17.40 \t AccTail 3.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 20:57:48,392]\u001b[0m Trial 2 finished with value: 3.430763006210327 and parameters: {'n_epoch': 90, 'weight_decay': 0.003465435050737094}. Best is trial 0 with value: 9.79477596282959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 3.43 \t AccHead 6.88 \t AccTail 0.02\n",
      "Epoch: [001] \t Loss 4.2507 \t Acc 4.84 \t AccHead 5.40 \t AccTail 0.76\n",
      "Epoch: [002] \t Loss 4.1220 \t Acc 5.18 \t AccHead 5.89 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 4.1203 \t Acc 3.75 \t AccHead 4.11 \t AccTail 1.14\n",
      "Epoch: [004] \t Loss 4.1167 \t Acc 5.25 \t AccHead 5.90 \t AccTail 0.50\n",
      "Epoch: [005] \t Loss 4.1252 \t Acc 3.36 \t AccHead 3.83 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 4.1217 \t Acc 3.88 \t AccHead 2.81 \t AccTail 11.68\n",
      "Epoch: [007] \t Loss 4.1161 \t Acc 3.62 \t AccHead 4.12 \t AccTail 0.00\n",
      "Epoch: [008] \t Loss 4.1182 \t Acc 5.11 \t AccHead 5.81 \t AccTail 0.00\n",
      "Epoch: [009] \t Loss 4.1282 \t Acc 3.22 \t AccHead 3.66 \t AccTail 0.00\n",
      "Epoch: [010] \t Loss 4.1288 \t Acc 3.71 \t AccHead 4.22 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 4.1230 \t Acc 2.95 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 4.1220 \t Acc 3.31 \t AccHead 3.77 \t AccTail 0.00\n",
      "Epoch: [013] \t Loss 4.1585 \t Acc 3.57 \t AccHead 4.06 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 4.2301 \t Acc 2.45 \t AccHead 2.79 \t AccTail 0.00\n",
      "Epoch: [015] \t Loss 4.2051 \t Acc 2.81 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 4.2093 \t Acc 1.89 \t AccHead 2.14 \t AccTail 0.11\n",
      "Epoch: [017] \t Loss 4.2008 \t Acc 1.89 \t AccHead 2.15 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 4.2065 \t Acc 2.12 \t AccHead 2.41 \t AccTail 0.00\n",
      "Epoch: [019] \t Loss 4.2223 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 4.2722 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 4.2716 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [022] \t Loss 4.2724 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [023] \t Loss 4.2719 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 4.2722 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 4.2727 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [026] \t Loss 4.2719 \t Acc 1.82 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [027] \t Loss 4.2719 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [028] \t Loss 4.2709 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [029] \t Loss 4.2717 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 4.2712 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 4.2708 \t Acc 1.82 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 4.2736 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 4.2730 \t Acc 1.82 \t AccHead 2.06 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 4.2764 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 4.2704 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 4.2727 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 4.2725 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 4.2728 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [039] \t Loss 4.2702 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [040] \t Loss 4.2712 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [041] \t Loss 4.2734 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 4.2741 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [043] \t Loss 4.2742 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [044] \t Loss 4.2732 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 4.2723 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [046] \t Loss 4.2719 \t Acc 1.84 \t AccHead 0.00 \t AccTail 15.23\n",
      "Epoch: [047] \t Loss 4.2720 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [048] \t Loss 4.2766 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [049] \t Loss 4.2715 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [050] \t Loss 4.2720 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [051] \t Loss 4.2727 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [052] \t Loss 4.2737 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [053] \t Loss 4.2709 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [054] \t Loss 4.2701 \t Acc 1.82 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [055] \t Loss 4.2726 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [056] \t Loss 4.2730 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [057] \t Loss 4.2698 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [058] \t Loss 4.2742 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [059] \t Loss 4.2722 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [060] \t Loss 4.2735 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [061] \t Loss 4.2725 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [062] \t Loss 4.2716 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [063] \t Loss 4.2717 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [064] \t Loss 4.2721 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [065] \t Loss 4.2722 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [066] \t Loss 4.2724 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [067] \t Loss 4.2715 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [068] \t Loss 4.2736 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [069] \t Loss 4.2701 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [070] \t Loss 4.2732 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [071] \t Loss 4.2709 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [072] \t Loss 4.2745 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [073] \t Loss 4.2701 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [074] \t Loss 4.2705 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [075] \t Loss 4.2724 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [076] \t Loss 4.2731 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [077] \t Loss 4.2704 \t Acc 1.82 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [078] \t Loss 4.2733 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [079] \t Loss 4.2715 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [080] \t Loss 4.2731 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [081] \t Loss 4.2713 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [082] \t Loss 4.2747 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [083] \t Loss 4.2735 \t Acc 1.82 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [084] \t Loss 4.2741 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [085] \t Loss 4.2718 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [086] \t Loss 4.2708 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [087] \t Loss 4.2698 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [088] \t Loss 4.2710 \t Acc 1.82 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [089] \t Loss 4.2701 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [090] \t Loss 4.2724 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 21:14:30,695]\u001b[0m Trial 3 finished with value: 1.0364842414855957 and parameters: {'n_epoch': 90, 'weight_decay': 0.03709292452981726}. Best is trial 0 with value: 9.79477596282959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 1.04 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [001] \t Loss 4.1392 \t Acc 4.40 \t AccHead 4.96 \t AccTail 0.34\n",
      "Epoch: [002] \t Loss 3.9508 \t Acc 5.81 \t AccHead 6.38 \t AccTail 1.68\n",
      "Epoch: [003] \t Loss 3.9615 \t Acc 5.00 \t AccHead 5.69 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 3.9636 \t Acc 5.03 \t AccHead 5.69 \t AccTail 0.27\n",
      "Epoch: [005] \t Loss 3.9621 \t Acc 4.74 \t AccHead 4.16 \t AccTail 8.97\n",
      "Epoch: [006] \t Loss 3.9616 \t Acc 4.15 \t AccHead 4.73 \t AccTail 0.00\n",
      "Epoch: [007] \t Loss 3.9629 \t Acc 6.56 \t AccHead 7.31 \t AccTail 1.10\n",
      "Epoch: [008] \t Loss 3.9689 \t Acc 4.03 \t AccHead 4.51 \t AccTail 0.57\n",
      "Epoch: [009] \t Loss 3.9580 \t Acc 6.87 \t AccHead 7.71 \t AccTail 0.69\n",
      "Epoch: [010] \t Loss 3.9634 \t Acc 4.35 \t AccHead 4.94 \t AccTail 0.00\n",
      "Epoch: [011] \t Loss 3.9661 \t Acc 6.29 \t AccHead 7.15 \t AccTail 0.00\n",
      "Epoch: [012] \t Loss 3.9727 \t Acc 5.57 \t AccHead 6.00 \t AccTail 2.43\n",
      "Epoch: [013] \t Loss 3.9682 \t Acc 6.92 \t AccHead 7.34 \t AccTail 3.81\n",
      "Epoch: [014] \t Loss 3.9796 \t Acc 5.62 \t AccHead 6.38 \t AccTail 0.08\n",
      "Epoch: [015] \t Loss 3.9868 \t Acc 3.90 \t AccHead 4.44 \t AccTail 0.00\n",
      "Epoch: [016] \t Loss 3.9905 \t Acc 5.15 \t AccHead 5.84 \t AccTail 0.15\n",
      "Epoch: [017] \t Loss 3.9887 \t Acc 4.39 \t AccHead 4.98 \t AccTail 0.11\n",
      "Epoch: [018] \t Loss 3.9931 \t Acc 5.59 \t AccHead 6.34 \t AccTail 0.11\n",
      "Epoch: [019] \t Loss 3.9999 \t Acc 4.61 \t AccHead 4.89 \t AccTail 2.55\n",
      "Epoch: [020] \t Loss 4.0019 \t Acc 4.27 \t AccHead 4.86 \t AccTail 0.04\n",
      "Epoch: [021] \t Loss 3.9893 \t Acc 4.00 \t AccHead 4.54 \t AccTail 0.04\n",
      "Epoch: [022] \t Loss 3.9958 \t Acc 4.33 \t AccHead 4.81 \t AccTail 0.88\n",
      "Epoch: [023] \t Loss 3.9979 \t Acc 5.80 \t AccHead 6.60 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 3.9919 \t Acc 4.60 \t AccHead 5.23 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 4.0104 \t Acc 5.29 \t AccHead 5.26 \t AccTail 5.53\n",
      "Epoch: [026] \t Loss 4.0147 \t Acc 2.99 \t AccHead 3.38 \t AccTail 0.15\n",
      "Epoch: [027] \t Loss 4.0059 \t Acc 6.15 \t AccHead 6.97 \t AccTail 0.19\n",
      "Epoch: [028] \t Loss 3.9966 \t Acc 4.47 \t AccHead 4.68 \t AccTail 2.93\n",
      "Epoch: [029] \t Loss 4.0103 \t Acc 5.17 \t AccHead 5.88 \t AccTail 0.00\n",
      "Epoch: [030] \t Loss 4.0245 \t Acc 3.55 \t AccHead 4.04 \t AccTail 0.00\n",
      "Epoch: [031] \t Loss 4.0304 \t Acc 5.40 \t AccHead 6.15 \t AccTail 0.00\n",
      "Epoch: [032] \t Loss 4.0291 \t Acc 5.11 \t AccHead 5.73 \t AccTail 0.53\n",
      "Epoch: [033] \t Loss 4.0112 \t Acc 4.66 \t AccHead 5.29 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 4.0011 \t Acc 2.40 \t AccHead 2.73 \t AccTail 0.00\n",
      "Epoch: [035] \t Loss 4.0007 \t Acc 2.14 \t AccHead 2.44 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 4.0050 \t Acc 4.13 \t AccHead 4.69 \t AccTail 0.00\n",
      "Epoch: [037] \t Loss 4.0109 \t Acc 2.82 \t AccHead 3.20 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 4.0027 \t Acc 4.96 \t AccHead 5.63 \t AccTail 0.04\n",
      "Epoch: [039] \t Loss 4.0043 \t Acc 4.55 \t AccHead 4.25 \t AccTail 6.70\n",
      "Epoch: [040] \t Loss 4.0148 \t Acc 5.43 \t AccHead 5.74 \t AccTail 3.16\n",
      "Epoch: [041] \t Loss 4.0084 \t Acc 4.35 \t AccHead 4.95 \t AccTail 0.00\n",
      "Epoch: [042] \t Loss 4.0066 \t Acc 4.65 \t AccHead 5.27 \t AccTail 0.08\n",
      "Epoch: [043] \t Loss 4.0230 \t Acc 3.71 \t AccHead 3.10 \t AccTail 8.17\n",
      "Epoch: [044] \t Loss 4.0094 \t Acc 4.12 \t AccHead 4.69 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 4.0099 \t Acc 5.20 \t AccHead 5.90 \t AccTail 0.11\n",
      "Epoch: [046] \t Loss 4.0138 \t Acc 4.73 \t AccHead 5.19 \t AccTail 1.37\n",
      "Epoch: [047] \t Loss 4.0099 \t Acc 6.33 \t AccHead 7.19 \t AccTail 0.08\n",
      "Epoch: [048] \t Loss 4.0149 \t Acc 4.85 \t AccHead 5.21 \t AccTail 2.21\n",
      "Epoch: [049] \t Loss 4.0159 \t Acc 3.97 \t AccHead 4.45 \t AccTail 0.42\n",
      "Epoch: [050] \t Loss 4.0294 \t Acc 5.01 \t AccHead 5.51 \t AccTail 1.37\n",
      "Epoch: [051] \t Loss 4.0252 \t Acc 3.72 \t AccHead 4.17 \t AccTail 0.46\n",
      "Epoch: [052] \t Loss 4.0313 \t Acc 5.24 \t AccHead 5.96 \t AccTail 0.04\n",
      "Epoch: [053] \t Loss 4.0323 \t Acc 4.37 \t AccHead 4.94 \t AccTail 0.15\n",
      "Epoch: [054] \t Loss 4.0323 \t Acc 3.92 \t AccHead 4.28 \t AccTail 1.26\n",
      "Epoch: [055] \t Loss 4.0155 \t Acc 4.45 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [056] \t Loss 4.0326 \t Acc 3.38 \t AccHead 3.77 \t AccTail 0.50\n",
      "Epoch: [057] \t Loss 4.0245 \t Acc 6.52 \t AccHead 6.99 \t AccTail 3.09\n",
      "Epoch: [058] \t Loss 4.0248 \t Acc 3.92 \t AccHead 4.14 \t AccTail 2.33\n",
      "Epoch: [059] \t Loss 4.0322 \t Acc 5.29 \t AccHead 5.40 \t AccTail 4.50\n",
      "Epoch: [060] \t Loss 4.0315 \t Acc 5.74 \t AccHead 5.99 \t AccTail 3.93\n",
      "Epoch: [061] \t Loss 4.0321 \t Acc 4.41 \t AccHead 5.01 \t AccTail 0.00\n",
      "Epoch: [062] \t Loss 4.0312 \t Acc 3.55 \t AccHead 3.90 \t AccTail 0.95\n",
      "Epoch: [063] \t Loss 4.0233 \t Acc 4.33 \t AccHead 3.97 \t AccTail 6.92\n",
      "Epoch: [064] \t Loss 4.0425 \t Acc 4.43 \t AccHead 4.52 \t AccTail 3.81\n",
      "Epoch: [065] \t Loss 4.0336 \t Acc 4.79 \t AccHead 4.47 \t AccTail 7.17\n",
      "Epoch: [066] \t Loss 4.0353 \t Acc 4.50 \t AccHead 5.12 \t AccTail 0.00\n",
      "Epoch: [067] \t Loss 4.0307 \t Acc 5.72 \t AccHead 6.51 \t AccTail 0.00\n",
      "Epoch: [068] \t Loss 4.0322 \t Acc 5.62 \t AccHead 6.36 \t AccTail 0.19\n",
      "Epoch: [069] \t Loss 4.0286 \t Acc 5.48 \t AccHead 5.59 \t AccTail 4.73\n",
      "Epoch: [070] \t Loss 4.0269 \t Acc 5.06 \t AccHead 5.70 \t AccTail 0.34\n",
      "Epoch: [071] \t Loss 4.0332 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [072] \t Loss 4.0317 \t Acc 5.27 \t AccHead 5.90 \t AccTail 0.69\n",
      "Epoch: [073] \t Loss 4.0291 \t Acc 3.55 \t AccHead 4.04 \t AccTail 0.00\n",
      "Epoch: [074] \t Loss 4.0350 \t Acc 5.27 \t AccHead 5.99 \t AccTail 0.00\n",
      "Epoch: [075] \t Loss 4.0422 \t Acc 5.28 \t AccHead 5.91 \t AccTail 0.72\n",
      "Epoch: [076] \t Loss 4.0333 \t Acc 5.14 \t AccHead 5.84 \t AccTail 0.00\n",
      "Epoch: [077] \t Loss 4.0250 \t Acc 3.32 \t AccHead 3.78 \t AccTail 0.00\n",
      "Epoch: [078] \t Loss 4.0283 \t Acc 5.40 \t AccHead 6.14 \t AccTail 0.00\n",
      "Epoch: [079] \t Loss 4.0333 \t Acc 3.14 \t AccHead 3.49 \t AccTail 0.61\n",
      "Epoch: [080] \t Loss 4.0417 \t Acc 5.70 \t AccHead 6.49 \t AccTail 0.00\n",
      "Epoch: [081] \t Loss 4.0361 \t Acc 4.91 \t AccHead 4.99 \t AccTail 4.34\n",
      "Epoch: [082] \t Loss 4.0271 \t Acc 3.94 \t AccHead 3.81 \t AccTail 4.90\n",
      "Epoch: [083] \t Loss 4.0426 \t Acc 3.59 \t AccHead 2.52 \t AccTail 11.42\n",
      "Epoch: [084] \t Loss 4.0366 \t Acc 4.21 \t AccHead 4.57 \t AccTail 1.64\n",
      "Epoch: [085] \t Loss 4.0433 \t Acc 4.28 \t AccHead 4.87 \t AccTail 0.00\n",
      "Epoch: [086] \t Loss 4.0353 \t Acc 4.81 \t AccHead 4.58 \t AccTail 6.47\n",
      "Epoch: [087] \t Loss 4.0372 \t Acc 4.55 \t AccHead 5.07 \t AccTail 0.76\n",
      "Epoch: [088] \t Loss 4.0308 \t Acc 2.81 \t AccHead 3.04 \t AccTail 1.11\n",
      "Epoch: [089] \t Loss 4.0410 \t Acc 4.26 \t AccHead 4.72 \t AccTail 0.91\n",
      "Epoch: [090] \t Loss 4.0422 \t Acc 5.21 \t AccHead 5.93 \t AccTail 0.00\n",
      "Epoch: [091] \t Loss 4.0325 \t Acc 3.79 \t AccHead 3.53 \t AccTail 5.72\n",
      "Epoch: [092] \t Loss 4.0285 \t Acc 4.44 \t AccHead 5.05 \t AccTail 0.00\n",
      "Epoch: [093] \t Loss 4.0559 \t Acc 4.31 \t AccHead 4.89 \t AccTail 0.08\n",
      "Epoch: [094] \t Loss 4.0503 \t Acc 4.05 \t AccHead 4.19 \t AccTail 3.04\n",
      "Epoch: [095] \t Loss 4.0520 \t Acc 2.65 \t AccHead 3.01 \t AccTail 0.00\n",
      "Epoch: [096] \t Loss 4.0508 \t Acc 2.81 \t AccHead 3.19 \t AccTail 0.00\n",
      "Epoch: [097] \t Loss 4.0595 \t Acc 4.82 \t AccHead 5.36 \t AccTail 0.91\n",
      "Epoch: [098] \t Loss 4.0555 \t Acc 4.60 \t AccHead 5.23 \t AccTail 0.00\n",
      "Epoch: [099] \t Loss 4.0692 \t Acc 4.79 \t AccHead 5.43 \t AccTail 0.11\n",
      "Epoch: [100] \t Loss 4.0498 \t Acc 4.66 \t AccHead 5.21 \t AccTail 0.61\n",
      "Epoch: [101] \t Loss 4.0474 \t Acc 3.54 \t AccHead 3.88 \t AccTail 1.03\n",
      "Epoch: [102] \t Loss 4.0530 \t Acc 4.04 \t AccHead 4.60 \t AccTail 0.00\n",
      "Epoch: [103] \t Loss 4.0522 \t Acc 3.67 \t AccHead 3.72 \t AccTail 3.27\n",
      "Epoch: [104] \t Loss 4.0508 \t Acc 5.13 \t AccHead 5.83 \t AccTail 0.00\n",
      "Epoch: [105] \t Loss 4.0472 \t Acc 4.19 \t AccHead 4.38 \t AccTail 2.78\n",
      "Epoch: [106] \t Loss 4.0536 \t Acc 4.53 \t AccHead 5.15 \t AccTail 0.04\n",
      "Epoch: [107] \t Loss 4.0582 \t Acc 3.14 \t AccHead 3.43 \t AccTail 1.03\n",
      "Epoch: [108] \t Loss 4.0524 \t Acc 3.88 \t AccHead 4.42 \t AccTail 0.00\n",
      "Epoch: [109] \t Loss 4.0659 \t Acc 3.10 \t AccHead 3.51 \t AccTail 0.11\n",
      "Epoch: [110] \t Loss 4.1109 \t Acc 2.83 \t AccHead 3.18 \t AccTail 0.27\n",
      "Epoch: [111] \t Loss 4.1115 \t Acc 2.62 \t AccHead 2.86 \t AccTail 0.88\n",
      "Epoch: [112] \t Loss 4.1197 \t Acc 2.25 \t AccHead 2.56 \t AccTail 0.00\n",
      "Epoch: [113] \t Loss 4.1130 \t Acc 2.11 \t AccHead 2.33 \t AccTail 0.53\n",
      "Epoch: [114] \t Loss 4.1157 \t Acc 2.91 \t AccHead 3.27 \t AccTail 0.27\n",
      "Epoch: [115] \t Loss 4.1117 \t Acc 3.10 \t AccHead 3.52 \t AccTail 0.00\n",
      "Epoch: [116] \t Loss 4.1139 \t Acc 3.20 \t AccHead 3.64 \t AccTail 0.00\n",
      "Epoch: [117] \t Loss 4.1153 \t Acc 2.49 \t AccHead 2.83 \t AccTail 0.04\n",
      "Epoch: [118] \t Loss 4.1211 \t Acc 2.43 \t AccHead 2.76 \t AccTail 0.00\n",
      "Epoch: [119] \t Loss 4.1134 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [120] \t Loss 4.1158 \t Acc 3.23 \t AccHead 3.67 \t AccTail 0.00\n",
      "Epoch: [121] \t Loss 4.1269 \t Acc 3.17 \t AccHead 3.60 \t AccTail 0.00\n",
      "Epoch: [122] \t Loss 4.2257 \t Acc 1.79 \t AccHead 2.04 \t AccTail 0.00\n",
      "Epoch: [123] \t Loss 4.1946 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [124] \t Loss 4.2447 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [125] \t Loss 4.2431 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [126] \t Loss 4.2443 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [127] \t Loss 4.2462 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [128] \t Loss 4.2445 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [129] \t Loss 4.2440 \t Acc 1.82 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [130] \t Loss 4.2444 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [131] \t Loss 4.2452 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [132] \t Loss 4.2457 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [133] \t Loss 4.2453 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [134] \t Loss 4.2416 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [135] \t Loss 4.2414 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [136] \t Loss 4.2442 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [137] \t Loss 4.2443 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [138] \t Loss 4.2451 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [139] \t Loss 4.2458 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [140] \t Loss 4.2450 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [141] \t Loss 4.2434 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [142] \t Loss 4.2427 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [143] \t Loss 4.2438 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [144] \t Loss 4.2425 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [145] \t Loss 4.2466 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [146] \t Loss 4.2422 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [147] \t Loss 4.2454 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [148] \t Loss 4.2409 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [149] \t Loss 4.2465 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [150] \t Loss 4.2437 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [151] \t Loss 4.2267 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [152] \t Loss 4.2191 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [153] \t Loss 4.2173 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [154] \t Loss 4.2186 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [155] \t Loss 4.2185 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [156] \t Loss 4.2182 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [157] \t Loss 4.2174 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [158] \t Loss 4.2182 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [159] \t Loss 4.2182 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [160] \t Loss 4.2181 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [161] \t Loss 4.2179 \t Acc 1.81 \t AccHead 2.06 \t AccTail 0.00\n",
      "Epoch: [162] \t Loss 4.2180 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [163] \t Loss 4.2184 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [164] \t Loss 4.2176 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [165] \t Loss 4.2180 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [166] \t Loss 4.2185 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [167] \t Loss 4.2178 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [168] \t Loss 4.2182 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [169] \t Loss 4.2177 \t Acc 1.82 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [170] \t Loss 4.2187 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [171] \t Loss 4.2175 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [172] \t Loss 4.2180 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [173] \t Loss 4.2185 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [174] \t Loss 4.2179 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [175] \t Loss 4.2187 \t Acc 1.83 \t AccHead 0.00 \t AccTail 15.21\n",
      "Epoch: [176] \t Loss 4.2188 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [177] \t Loss 4.2185 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [178] \t Loss 4.2180 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [179] \t Loss 4.2184 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [180] \t Loss 4.2184 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [181] \t Loss 4.2180 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [182] \t Loss 4.2183 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [183] \t Loss 4.2182 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [184] \t Loss 4.2182 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [185] \t Loss 4.2181 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [186] \t Loss 4.2180 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [187] \t Loss 4.2183 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [188] \t Loss 4.2184 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [189] \t Loss 4.2181 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [190] \t Loss 4.2182 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [191] \t Loss 4.2177 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [192] \t Loss 4.2177 \t Acc 1.83 \t AccHead 0.00 \t AccTail 15.19\n",
      "Epoch: [193] \t Loss 4.2185 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [194] \t Loss 4.2184 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [195] \t Loss 4.2183 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [196] \t Loss 4.2176 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [197] \t Loss 4.2182 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [198] \t Loss 4.2178 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [199] \t Loss 4.2188 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [200] \t Loss 4.2173 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 21:51:20,017]\u001b[0m Trial 4 finished with value: 1.0364842414855957 and parameters: {'n_epoch': 200, 'weight_decay': 0.019981497093574704}. Best is trial 0 with value: 9.79477596282959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 1.04 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [001] \t Loss 4.2536 \t Acc 7.96 \t AccHead 8.84 \t AccTail 1.52\n",
      "Epoch: [002] \t Loss 3.7677 \t Acc 12.15 \t AccHead 13.42 \t AccTail 2.93\n",
      "Epoch: [003] \t Loss 3.6010 \t Acc 13.30 \t AccHead 14.90 \t AccTail 1.60\n",
      "Epoch: [004] \t Loss 3.4494 \t Acc 16.34 \t AccHead 17.54 \t AccTail 7.57\n",
      "Epoch: [005] \t Loss 3.3232 \t Acc 19.20 \t AccHead 20.79 \t AccTail 7.65\n",
      "Epoch: [006] \t Loss 3.2123 \t Acc 19.50 \t AccHead 21.19 \t AccTail 7.15\n",
      "Epoch: [007] \t Loss 3.1259 \t Acc 21.46 \t AccHead 23.08 \t AccTail 9.65\n",
      "Epoch: [008] \t Loss 3.0522 \t Acc 20.13 \t AccHead 21.27 \t AccTail 11.85\n",
      "Epoch: [009] \t Loss 2.9687 \t Acc 27.15 \t AccHead 29.95 \t AccTail 6.78\n",
      "Epoch: [010] \t Loss 2.9179 \t Acc 23.47 \t AccHead 25.63 \t AccTail 7.73\n",
      "Epoch: [011] \t Loss 2.8660 \t Acc 26.09 \t AccHead 28.83 \t AccTail 6.17\n",
      "Epoch: [012] \t Loss 2.8153 \t Acc 29.29 \t AccHead 32.76 \t AccTail 3.97\n",
      "Epoch: [013] \t Loss 2.7905 \t Acc 26.96 \t AccHead 29.30 \t AccTail 9.93\n",
      "Epoch: [014] \t Loss 2.7521 \t Acc 28.91 \t AccHead 31.53 \t AccTail 9.81\n",
      "Epoch: [015] \t Loss 2.7208 \t Acc 27.65 \t AccHead 30.47 \t AccTail 7.08\n",
      "Epoch: [016] \t Loss 2.7166 \t Acc 30.04 \t AccHead 32.83 \t AccTail 9.73\n",
      "Epoch: [017] \t Loss 2.6770 \t Acc 30.45 \t AccHead 33.40 \t AccTail 8.92\n",
      "Epoch: [018] \t Loss 2.6828 \t Acc 32.60 \t AccHead 35.97 \t AccTail 8.10\n",
      "Epoch: [019] \t Loss 2.6539 \t Acc 28.09 \t AccHead 30.46 \t AccTail 10.87\n",
      "Epoch: [020] \t Loss 2.6351 \t Acc 28.52 \t AccHead 30.02 \t AccTail 17.60\n",
      "Epoch: [021] \t Loss 2.6178 \t Acc 28.05 \t AccHead 30.54 \t AccTail 9.92\n",
      "Epoch: [022] \t Loss 2.6241 \t Acc 29.40 \t AccHead 32.03 \t AccTail 10.24\n",
      "Epoch: [023] \t Loss 2.5970 \t Acc 28.59 \t AccHead 31.50 \t AccTail 7.42\n",
      "Epoch: [024] \t Loss 2.5746 \t Acc 30.33 \t AccHead 32.79 \t AccTail 12.40\n",
      "Epoch: [025] \t Loss 2.5784 \t Acc 32.93 \t AccHead 36.04 \t AccTail 10.31\n",
      "Epoch: [026] \t Loss 2.5540 \t Acc 30.64 \t AccHead 33.10 \t AccTail 12.76\n",
      "Epoch: [027] \t Loss 2.5560 \t Acc 33.02 \t AccHead 36.24 \t AccTail 9.52\n",
      "Epoch: [028] \t Loss 2.5297 \t Acc 32.58 \t AccHead 35.15 \t AccTail 13.84\n",
      "Epoch: [029] \t Loss 2.5291 \t Acc 30.29 \t AccHead 33.28 \t AccTail 8.49\n",
      "Epoch: [030] \t Loss 2.5214 \t Acc 33.26 \t AccHead 35.78 \t AccTail 14.88\n",
      "Epoch: [031] \t Loss 2.5117 \t Acc 30.42 \t AccHead 33.20 \t AccTail 10.22\n",
      "Epoch: [032] \t Loss 2.4939 \t Acc 30.62 \t AccHead 33.02 \t AccTail 13.17\n",
      "Epoch: [033] \t Loss 2.4997 \t Acc 34.77 \t AccHead 38.10 \t AccTail 10.49\n",
      "Epoch: [034] \t Loss 2.5003 \t Acc 30.48 \t AccHead 33.21 \t AccTail 10.65\n",
      "Epoch: [035] \t Loss 2.4741 \t Acc 32.45 \t AccHead 35.18 \t AccTail 12.54\n",
      "Epoch: [036] \t Loss 2.4973 \t Acc 31.57 \t AccHead 34.23 \t AccTail 12.24\n",
      "Epoch: [037] \t Loss 2.4918 \t Acc 36.58 \t AccHead 39.56 \t AccTail 14.87\n",
      "Epoch: [038] \t Loss 2.4690 \t Acc 29.31 \t AccHead 31.92 \t AccTail 10.31\n",
      "Epoch: [039] \t Loss 2.4623 \t Acc 34.29 \t AccHead 37.76 \t AccTail 8.99\n",
      "Epoch: [040] \t Loss 2.4683 \t Acc 34.30 \t AccHead 37.77 \t AccTail 9.08\n",
      "Epoch: [041] \t Loss 2.4671 \t Acc 31.44 \t AccHead 33.87 \t AccTail 13.73\n",
      "Epoch: [042] \t Loss 2.4609 \t Acc 34.38 \t AccHead 36.78 \t AccTail 16.89\n",
      "Epoch: [043] \t Loss 2.4642 \t Acc 32.88 \t AccHead 35.22 \t AccTail 15.83\n",
      "Epoch: [044] \t Loss 2.4480 \t Acc 34.44 \t AccHead 37.48 \t AccTail 12.34\n",
      "Epoch: [045] \t Loss 2.4402 \t Acc 33.86 \t AccHead 37.45 \t AccTail 7.72\n",
      "Epoch: [046] \t Loss 2.4504 \t Acc 34.52 \t AccHead 36.99 \t AccTail 16.53\n",
      "Epoch: [047] \t Loss 2.4387 \t Acc 35.17 \t AccHead 38.54 \t AccTail 10.66\n",
      "Epoch: [048] \t Loss 2.4137 \t Acc 37.15 \t AccHead 39.95 \t AccTail 16.77\n",
      "Epoch: [049] \t Loss 2.4360 \t Acc 34.84 \t AccHead 37.26 \t AccTail 17.19\n",
      "Epoch: [050] \t Loss 2.4326 \t Acc 34.83 \t AccHead 37.65 \t AccTail 14.26\n",
      "Epoch: [051] \t Loss 2.4309 \t Acc 35.84 \t AccHead 39.10 \t AccTail 12.10\n",
      "Epoch: [052] \t Loss 2.4259 \t Acc 34.81 \t AccHead 37.68 \t AccTail 13.89\n",
      "Epoch: [053] \t Loss 2.4394 \t Acc 35.42 \t AccHead 38.66 \t AccTail 11.86\n",
      "Epoch: [054] \t Loss 2.4153 \t Acc 35.24 \t AccHead 37.83 \t AccTail 16.35\n",
      "Epoch: [055] \t Loss 2.4133 \t Acc 35.62 \t AccHead 38.29 \t AccTail 16.09\n",
      "Epoch: [056] \t Loss 2.4190 \t Acc 35.15 \t AccHead 37.48 \t AccTail 18.20\n",
      "Epoch: [057] \t Loss 2.4228 \t Acc 33.38 \t AccHead 36.40 \t AccTail 11.38\n",
      "Epoch: [058] \t Loss 2.4288 \t Acc 34.91 \t AccHead 37.28 \t AccTail 17.62\n",
      "Epoch: [059] \t Loss 2.4051 \t Acc 31.14 \t AccHead 34.03 \t AccTail 10.10\n",
      "Epoch: [060] \t Loss 2.4125 \t Acc 35.38 \t AccHead 38.72 \t AccTail 11.10\n",
      "Epoch: [061] \t Loss 2.4033 \t Acc 34.23 \t AccHead 36.52 \t AccTail 17.51\n",
      "Epoch: [062] \t Loss 2.4041 \t Acc 37.16 \t AccHead 40.27 \t AccTail 14.51\n",
      "Epoch: [063] \t Loss 2.4197 \t Acc 35.18 \t AccHead 37.97 \t AccTail 14.87\n",
      "Epoch: [064] \t Loss 2.4071 \t Acc 33.14 \t AccHead 36.72 \t AccTail 7.15\n",
      "Epoch: [065] \t Loss 2.4027 \t Acc 33.27 \t AccHead 35.63 \t AccTail 16.03\n",
      "Epoch: [066] \t Loss 2.4004 \t Acc 33.74 \t AccHead 36.73 \t AccTail 11.89\n",
      "Epoch: [067] \t Loss 2.3971 \t Acc 35.04 \t AccHead 37.85 \t AccTail 14.60\n",
      "Epoch: [068] \t Loss 2.3863 \t Acc 34.79 \t AccHead 37.52 \t AccTail 14.93\n",
      "Epoch: [069] \t Loss 2.3939 \t Acc 34.74 \t AccHead 38.12 \t AccTail 10.13\n",
      "Epoch: [070] \t Loss 2.4029 \t Acc 35.40 \t AccHead 38.63 \t AccTail 11.88\n",
      "Epoch: [071] \t Loss 2.3948 \t Acc 34.47 \t AccHead 37.93 \t AccTail 9.22\n",
      "Epoch: [072] \t Loss 2.4026 \t Acc 30.98 \t AccHead 33.67 \t AccTail 11.37\n",
      "Epoch: [073] \t Loss 2.3897 \t Acc 34.87 \t AccHead 38.11 \t AccTail 11.27\n",
      "Epoch: [074] \t Loss 2.4061 \t Acc 33.86 \t AccHead 36.44 \t AccTail 15.10\n",
      "Epoch: [075] \t Loss 2.4116 \t Acc 35.68 \t AccHead 38.27 \t AccTail 16.79\n",
      "Epoch: [076] \t Loss 2.3913 \t Acc 30.77 \t AccHead 32.40 \t AccTail 18.84\n",
      "Epoch: [077] \t Loss 2.4001 \t Acc 31.31 \t AccHead 33.51 \t AccTail 15.29\n",
      "Epoch: [078] \t Loss 2.4041 \t Acc 36.49 \t AccHead 39.24 \t AccTail 16.48\n",
      "Epoch: [079] \t Loss 2.3927 \t Acc 35.88 \t AccHead 38.57 \t AccTail 16.29\n",
      "Epoch: [080] \t Loss 2.3866 \t Acc 36.49 \t AccHead 39.23 \t AccTail 16.53\n",
      "Epoch: [081] \t Loss 2.3903 \t Acc 33.92 \t AccHead 36.69 \t AccTail 13.71\n",
      "Epoch: [082] \t Loss 2.3862 \t Acc 37.70 \t AccHead 40.96 \t AccTail 13.97\n",
      "Epoch: [083] \t Loss 2.3830 \t Acc 33.35 \t AccHead 36.14 \t AccTail 13.10\n",
      "Epoch: [084] \t Loss 2.3833 \t Acc 36.45 \t AccHead 39.22 \t AccTail 16.28\n",
      "Epoch: [085] \t Loss 2.3886 \t Acc 35.83 \t AccHead 38.73 \t AccTail 14.79\n",
      "Epoch: [086] \t Loss 2.3966 \t Acc 33.34 \t AccHead 35.58 \t AccTail 17.04\n",
      "Epoch: [087] \t Loss 2.3916 \t Acc 35.26 \t AccHead 37.45 \t AccTail 19.31\n",
      "Epoch: [088] \t Loss 2.3849 \t Acc 38.27 \t AccHead 41.10 \t AccTail 17.64\n",
      "Epoch: [089] \t Loss 2.3758 \t Acc 36.14 \t AccHead 38.78 \t AccTail 17.02\n",
      "Epoch: [090] \t Loss 2.3814 \t Acc 34.69 \t AccHead 37.51 \t AccTail 14.18\n",
      "Epoch: [091] \t Loss 2.3859 \t Acc 36.76 \t AccHead 40.38 \t AccTail 10.46\n",
      "Epoch: [092] \t Loss 2.3626 \t Acc 36.76 \t AccHead 39.82 \t AccTail 14.52\n",
      "Epoch: [093] \t Loss 2.3756 \t Acc 34.45 \t AccHead 37.19 \t AccTail 14.55\n",
      "Epoch: [094] \t Loss 2.3785 \t Acc 32.91 \t AccHead 35.61 \t AccTail 13.21\n",
      "Epoch: [095] \t Loss 2.3761 \t Acc 34.25 \t AccHead 37.55 \t AccTail 10.20\n",
      "Epoch: [096] \t Loss 2.3828 \t Acc 36.00 \t AccHead 38.97 \t AccTail 14.33\n",
      "Epoch: [097] \t Loss 2.3735 \t Acc 34.04 \t AccHead 36.26 \t AccTail 17.91\n",
      "Epoch: [098] \t Loss 2.3744 \t Acc 36.23 \t AccHead 39.66 \t AccTail 11.28\n",
      "Epoch: [099] \t Loss 2.3626 \t Acc 36.24 \t AccHead 39.42 \t AccTail 13.08\n",
      "Epoch: [100] \t Loss 2.3692 \t Acc 33.80 \t AccHead 36.76 \t AccTail 12.19\n",
      "Epoch: [101] \t Loss 2.3736 \t Acc 34.08 \t AccHead 37.63 \t AccTail 8.23\n",
      "Epoch: [102] \t Loss 2.3715 \t Acc 35.42 \t AccHead 38.23 \t AccTail 14.93\n",
      "Epoch: [103] \t Loss 2.3762 \t Acc 33.10 \t AccHead 36.26 \t AccTail 10.11\n",
      "Epoch: [104] \t Loss 2.3839 \t Acc 33.35 \t AccHead 35.49 \t AccTail 17.74\n",
      "Epoch: [105] \t Loss 2.3703 \t Acc 29.88 \t AccHead 32.12 \t AccTail 13.52\n",
      "Epoch: [106] \t Loss 2.3750 \t Acc 34.38 \t AccHead 37.23 \t AccTail 13.69\n",
      "Epoch: [107] \t Loss 2.3800 \t Acc 34.31 \t AccHead 37.59 \t AccTail 10.46\n",
      "Epoch: [108] \t Loss 2.3745 \t Acc 34.24 \t AccHead 36.89 \t AccTail 14.89\n",
      "Epoch: [109] \t Loss 2.3799 \t Acc 35.60 \t AccHead 38.17 \t AccTail 16.87\n",
      "Epoch: [110] \t Loss 2.3540 \t Acc 34.06 \t AccHead 36.34 \t AccTail 17.43\n",
      "Epoch: [111] \t Loss 2.3768 \t Acc 36.68 \t AccHead 39.87 \t AccTail 13.37\n",
      "Epoch: [112] \t Loss 2.3611 \t Acc 35.82 \t AccHead 39.01 \t AccTail 12.59\n",
      "Epoch: [113] \t Loss 2.3708 \t Acc 36.65 \t AccHead 39.49 \t AccTail 15.97\n",
      "Epoch: [114] \t Loss 2.3465 \t Acc 36.47 \t AccHead 39.46 \t AccTail 14.64\n",
      "Epoch: [115] \t Loss 2.3710 \t Acc 30.35 \t AccHead 31.87 \t AccTail 19.34\n",
      "Epoch: [116] \t Loss 2.3586 \t Acc 35.53 \t AccHead 38.02 \t AccTail 17.40\n",
      "Epoch: [117] \t Loss 2.3729 \t Acc 30.89 \t AccHead 32.23 \t AccTail 21.16\n",
      "Epoch: [118] \t Loss 2.3674 \t Acc 35.63 \t AccHead 38.52 \t AccTail 14.57\n",
      "Epoch: [119] \t Loss 2.3691 \t Acc 35.72 \t AccHead 38.58 \t AccTail 14.95\n",
      "Epoch: [120] \t Loss 2.3748 \t Acc 37.73 \t AccHead 40.38 \t AccTail 18.41\n",
      "Epoch: [121] \t Loss 2.3699 \t Acc 37.78 \t AccHead 41.31 \t AccTail 12.05\n",
      "Epoch: [122] \t Loss 2.3645 \t Acc 34.73 \t AccHead 37.95 \t AccTail 11.23\n",
      "Epoch: [123] \t Loss 2.3747 \t Acc 38.29 \t AccHead 41.26 \t AccTail 16.72\n",
      "Epoch: [124] \t Loss 2.3671 \t Acc 35.82 \t AccHead 38.97 \t AccTail 12.80\n",
      "Epoch: [125] \t Loss 2.3566 \t Acc 34.81 \t AccHead 37.59 \t AccTail 14.50\n",
      "Epoch: [126] \t Loss 2.3711 \t Acc 31.23 \t AccHead 33.52 \t AccTail 14.57\n",
      "Epoch: [127] \t Loss 2.3581 \t Acc 36.54 \t AccHead 39.30 \t AccTail 16.40\n",
      "Epoch: [128] \t Loss 2.3723 \t Acc 35.53 \t AccHead 38.11 \t AccTail 16.77\n",
      "Epoch: [129] \t Loss 2.3697 \t Acc 37.47 \t AccHead 40.65 \t AccTail 14.38\n",
      "Epoch: [130] \t Loss 2.3601 \t Acc 36.54 \t AccHead 39.54 \t AccTail 14.67\n",
      "Epoch: [131] \t Loss 2.3683 \t Acc 36.22 \t AccHead 38.87 \t AccTail 16.93\n",
      "Epoch: [132] \t Loss 2.3561 \t Acc 33.78 \t AccHead 37.20 \t AccTail 8.83\n",
      "Epoch: [133] \t Loss 2.3684 \t Acc 35.13 \t AccHead 38.23 \t AccTail 12.68\n",
      "Epoch: [134] \t Loss 2.3599 \t Acc 33.88 \t AccHead 36.95 \t AccTail 11.55\n",
      "Epoch: [135] \t Loss 2.3661 \t Acc 35.08 \t AccHead 38.00 \t AccTail 13.84\n",
      "Epoch: [136] \t Loss 2.3598 \t Acc 36.22 \t AccHead 38.78 \t AccTail 17.59\n",
      "Epoch: [137] \t Loss 2.3687 \t Acc 31.39 \t AccHead 33.88 \t AccTail 13.19\n",
      "Epoch: [138] \t Loss 2.3718 \t Acc 33.37 \t AccHead 36.05 \t AccTail 13.77\n",
      "Epoch: [139] \t Loss 2.3780 \t Acc 32.51 \t AccHead 34.67 \t AccTail 16.82\n",
      "Epoch: [140] \t Loss 2.3421 \t Acc 36.22 \t AccHead 38.68 \t AccTail 18.28\n",
      "Epoch: [141] \t Loss 2.3604 \t Acc 28.49 \t AccHead 30.01 \t AccTail 17.49\n",
      "Epoch: [142] \t Loss 2.3722 \t Acc 31.94 \t AccHead 34.65 \t AccTail 12.17\n",
      "Epoch: [143] \t Loss 2.3487 \t Acc 36.44 \t AccHead 39.44 \t AccTail 14.57\n",
      "Epoch: [144] \t Loss 2.3579 \t Acc 34.75 \t AccHead 37.78 \t AccTail 12.60\n",
      "Epoch: [145] \t Loss 2.3604 \t Acc 31.33 \t AccHead 33.71 \t AccTail 14.01\n",
      "Epoch: [146] \t Loss 2.3575 \t Acc 36.38 \t AccHead 39.41 \t AccTail 14.27\n",
      "Epoch: [147] \t Loss 2.3753 \t Acc 35.17 \t AccHead 37.33 \t AccTail 19.42\n",
      "Epoch: [148] \t Loss 2.3595 \t Acc 37.80 \t AccHead 40.34 \t AccTail 19.33\n",
      "Epoch: [149] \t Loss 2.3628 \t Acc 36.23 \t AccHead 39.07 \t AccTail 15.62\n",
      "Epoch: [150] \t Loss 2.3677 \t Acc 34.56 \t AccHead 37.33 \t AccTail 14.37\n",
      "Epoch: [151] \t Loss 1.9430 \t Acc 51.76 \t AccHead 55.36 \t AccTail 25.49\n",
      "Epoch: [152] \t Loss 1.7223 \t Acc 54.55 \t AccHead 58.03 \t AccTail 29.12\n",
      "Epoch: [153] \t Loss 1.6365 \t Acc 56.59 \t AccHead 59.85 \t AccTail 32.81\n",
      "Epoch: [154] \t Loss 1.5608 \t Acc 58.20 \t AccHead 61.83 \t AccTail 31.75\n",
      "Epoch: [155] \t Loss 1.4987 \t Acc 59.49 \t AccHead 63.21 \t AccTail 32.38\n",
      "Epoch: [156] \t Loss 1.4508 \t Acc 61.06 \t AccHead 64.57 \t AccTail 35.50\n",
      "Epoch: [157] \t Loss 1.4053 \t Acc 62.23 \t AccHead 65.70 \t AccTail 36.98\n",
      "Epoch: [158] \t Loss 1.3637 \t Acc 62.96 \t AccHead 66.74 \t AccTail 35.33\n",
      "Epoch: [159] \t Loss 1.3167 \t Acc 64.57 \t AccHead 67.74 \t AccTail 41.40\n",
      "Epoch: [160] \t Loss 1.2880 \t Acc 65.56 \t AccHead 68.81 \t AccTail 41.84\n",
      "Epoch: [161] \t Loss 1.2491 \t Acc 64.77 \t AccHead 67.71 \t AccTail 43.29\n",
      "Epoch: [162] \t Loss 1.2153 \t Acc 66.26 \t AccHead 69.34 \t AccTail 43.84\n",
      "Epoch: [163] \t Loss 1.2044 \t Acc 68.37 \t AccHead 71.64 \t AccTail 44.53\n",
      "Epoch: [164] \t Loss 1.1616 \t Acc 68.38 \t AccHead 71.33 \t AccTail 46.80\n",
      "Epoch: [165] \t Loss 1.1215 \t Acc 68.96 \t AccHead 71.44 \t AccTail 50.84\n",
      "Epoch: [166] \t Loss 1.1033 \t Acc 69.44 \t AccHead 71.99 \t AccTail 50.86\n",
      "Epoch: [167] \t Loss 1.0870 \t Acc 70.91 \t AccHead 74.07 \t AccTail 47.86\n",
      "Epoch: [168] \t Loss 1.0613 \t Acc 72.35 \t AccHead 75.06 \t AccTail 52.57\n",
      "Epoch: [169] \t Loss 1.0316 \t Acc 70.25 \t AccHead 73.07 \t AccTail 49.70\n",
      "Epoch: [170] \t Loss 1.0150 \t Acc 72.30 \t AccHead 74.93 \t AccTail 53.16\n",
      "Epoch: [171] \t Loss 0.9966 \t Acc 72.39 \t AccHead 75.17 \t AccTail 52.19\n",
      "Epoch: [172] \t Loss 0.9848 \t Acc 74.60 \t AccHead 77.23 \t AccTail 55.44\n",
      "Epoch: [173] \t Loss 0.9549 \t Acc 73.02 \t AccHead 75.28 \t AccTail 56.53\n",
      "Epoch: [174] \t Loss 0.9318 \t Acc 74.77 \t AccHead 77.08 \t AccTail 57.99\n",
      "Epoch: [175] \t Loss 0.9123 \t Acc 73.64 \t AccHead 76.11 \t AccTail 55.65\n",
      "Epoch: [176] \t Loss 0.8840 \t Acc 76.74 \t AccHead 78.75 \t AccTail 62.06\n",
      "Epoch: [177] \t Loss 0.8874 \t Acc 74.75 \t AccHead 77.02 \t AccTail 58.18\n",
      "Epoch: [178] \t Loss 0.8883 \t Acc 76.65 \t AccHead 78.82 \t AccTail 60.84\n",
      "Epoch: [179] \t Loss 0.8465 \t Acc 75.38 \t AccHead 77.54 \t AccTail 59.65\n",
      "Epoch: [180] \t Loss 0.8363 \t Acc 74.52 \t AccHead 77.32 \t AccTail 54.10\n",
      "Epoch: [181] \t Loss 0.8238 \t Acc 80.10 \t AccHead 81.88 \t AccTail 67.12\n",
      "Epoch: [182] \t Loss 0.8057 \t Acc 78.93 \t AccHead 80.53 \t AccTail 67.29\n",
      "Epoch: [183] \t Loss 0.7841 \t Acc 77.09 \t AccHead 78.98 \t AccTail 63.36\n",
      "Epoch: [184] \t Loss 0.7463 \t Acc 79.12 \t AccHead 81.36 \t AccTail 62.78\n",
      "Epoch: [185] \t Loss 0.7258 \t Acc 78.53 \t AccHead 80.22 \t AccTail 66.17\n",
      "Epoch: [186] \t Loss 0.7241 \t Acc 79.20 \t AccHead 81.06 \t AccTail 65.64\n",
      "Epoch: [187] \t Loss 0.7254 \t Acc 79.11 \t AccHead 80.66 \t AccTail 67.80\n",
      "Epoch: [188] \t Loss 0.7119 \t Acc 80.73 \t AccHead 82.36 \t AccTail 68.86\n",
      "Epoch: [189] \t Loss 0.6614 \t Acc 82.90 \t AccHead 84.47 \t AccTail 71.45\n",
      "Epoch: [190] \t Loss 0.6722 \t Acc 79.71 \t AccHead 80.99 \t AccTail 70.32\n",
      "Epoch: [191] \t Loss 0.6544 \t Acc 80.11 \t AccHead 81.30 \t AccTail 71.48\n",
      "Epoch: [192] \t Loss 0.6493 \t Acc 83.64 \t AccHead 85.11 \t AccTail 72.88\n",
      "Epoch: [193] \t Loss 0.6305 \t Acc 82.86 \t AccHead 84.07 \t AccTail 74.07\n",
      "Epoch: [194] \t Loss 0.6159 \t Acc 84.15 \t AccHead 85.19 \t AccTail 76.57\n",
      "Epoch: [195] \t Loss 0.5962 \t Acc 83.96 \t AccHead 85.08 \t AccTail 75.82\n",
      "Epoch: [196] \t Loss 0.6073 \t Acc 82.95 \t AccHead 83.66 \t AccTail 77.76\n",
      "Epoch: [197] \t Loss 0.5815 \t Acc 83.64 \t AccHead 84.49 \t AccTail 77.41\n",
      "Epoch: [198] \t Loss 0.5693 \t Acc 83.41 \t AccHead 84.47 \t AccTail 75.72\n",
      "Epoch: [199] \t Loss 0.5468 \t Acc 82.71 \t AccHead 84.41 \t AccTail 70.38\n",
      "Epoch: [200] \t Loss 0.5682 \t Acc 84.40 \t AccHead 85.36 \t AccTail 77.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 22:28:19,637]\u001b[0m Trial 5 finished with value: 10.157546043395996 and parameters: {'n_epoch': 200, 'weight_decay': 0.0013661514302774538}. Best is trial 5 with value: 10.157546043395996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 10.16 \t AccHead 17.85 \t AccTail 2.54\n",
      "Epoch: [001] \t Loss 4.1916 \t Acc 2.84 \t AccHead 3.22 \t AccTail 0.08\n",
      "Epoch: [002] \t Loss 3.8935 \t Acc 5.55 \t AccHead 6.04 \t AccTail 1.94\n",
      "Epoch: [003] \t Loss 3.8734 \t Acc 6.55 \t AccHead 7.44 \t AccTail 0.04\n",
      "Epoch: [004] \t Loss 3.8785 \t Acc 8.44 \t AccHead 9.60 \t AccTail 0.00\n",
      "Epoch: [005] \t Loss 3.8757 \t Acc 7.88 \t AccHead 8.72 \t AccTail 1.71\n",
      "Epoch: [006] \t Loss 3.8803 \t Acc 7.60 \t AccHead 8.53 \t AccTail 0.76\n",
      "Epoch: [007] \t Loss 3.8710 \t Acc 6.11 \t AccHead 6.83 \t AccTail 0.84\n",
      "Epoch: [008] \t Loss 3.8762 \t Acc 5.77 \t AccHead 6.46 \t AccTail 0.72\n",
      "Epoch: [009] \t Loss 3.8590 \t Acc 6.08 \t AccHead 6.51 \t AccTail 2.97\n",
      "Epoch: [010] \t Loss 3.8707 \t Acc 6.57 \t AccHead 7.34 \t AccTail 0.95\n",
      "Epoch: [011] \t Loss 3.8722 \t Acc 7.42 \t AccHead 7.98 \t AccTail 3.35\n",
      "Epoch: [012] \t Loss 3.8766 \t Acc 7.56 \t AccHead 8.30 \t AccTail 2.13\n",
      "Epoch: [013] \t Loss 3.8622 \t Acc 7.08 \t AccHead 8.02 \t AccTail 0.27\n",
      "Epoch: [014] \t Loss 3.8675 \t Acc 6.75 \t AccHead 7.56 \t AccTail 0.80\n",
      "Epoch: [015] \t Loss 3.8700 \t Acc 7.80 \t AccHead 8.86 \t AccTail 0.08\n",
      "Epoch: [016] \t Loss 3.8823 \t Acc 7.59 \t AccHead 8.52 \t AccTail 0.84\n",
      "Epoch: [017] \t Loss 3.8706 \t Acc 6.44 \t AccHead 7.31 \t AccTail 0.08\n",
      "Epoch: [018] \t Loss 3.8772 \t Acc 6.65 \t AccHead 7.40 \t AccTail 1.22\n",
      "Epoch: [019] \t Loss 3.8867 \t Acc 7.08 \t AccHead 7.93 \t AccTail 0.88\n",
      "Epoch: [020] \t Loss 3.9012 \t Acc 7.83 \t AccHead 8.69 \t AccTail 1.49\n",
      "Epoch: [021] \t Loss 3.8873 \t Acc 7.20 \t AccHead 8.13 \t AccTail 0.42\n",
      "Epoch: [022] \t Loss 3.8857 \t Acc 6.96 \t AccHead 7.90 \t AccTail 0.15\n",
      "Epoch: [023] \t Loss 3.8869 \t Acc 8.11 \t AccHead 8.88 \t AccTail 2.52\n",
      "Epoch: [024] \t Loss 3.8909 \t Acc 6.25 \t AccHead 7.11 \t AccTail 0.00\n",
      "Epoch: [025] \t Loss 3.9002 \t Acc 7.59 \t AccHead 7.89 \t AccTail 5.36\n",
      "Epoch: [026] \t Loss 3.8922 \t Acc 5.85 \t AccHead 6.58 \t AccTail 0.57\n",
      "Epoch: [027] \t Loss 3.8978 \t Acc 6.34 \t AccHead 7.20 \t AccTail 0.04\n",
      "Epoch: [028] \t Loss 3.8933 \t Acc 6.61 \t AccHead 7.44 \t AccTail 0.57\n",
      "Epoch: [029] \t Loss 3.8835 \t Acc 7.35 \t AccHead 8.35 \t AccTail 0.11\n",
      "Epoch: [030] \t Loss 3.8884 \t Acc 7.30 \t AccHead 8.29 \t AccTail 0.15\n",
      "Epoch: [031] \t Loss 3.8942 \t Acc 5.79 \t AccHead 6.53 \t AccTail 0.38\n",
      "Epoch: [032] \t Loss 3.8920 \t Acc 5.93 \t AccHead 6.06 \t AccTail 5.02\n",
      "Epoch: [033] \t Loss 3.8957 \t Acc 6.16 \t AccHead 6.93 \t AccTail 0.53\n",
      "Epoch: [034] \t Loss 3.8951 \t Acc 6.16 \t AccHead 6.62 \t AccTail 2.82\n",
      "Epoch: [035] \t Loss 3.9049 \t Acc 5.80 \t AccHead 6.35 \t AccTail 1.79\n",
      "Epoch: [036] \t Loss 3.9059 \t Acc 6.96 \t AccHead 7.40 \t AccTail 3.73\n",
      "Epoch: [037] \t Loss 3.9103 \t Acc 6.19 \t AccHead 6.97 \t AccTail 0.53\n",
      "Epoch: [038] \t Loss 3.9054 \t Acc 7.11 \t AccHead 7.98 \t AccTail 0.80\n",
      "Epoch: [039] \t Loss 3.9036 \t Acc 6.87 \t AccHead 7.28 \t AccTail 3.85\n",
      "Epoch: [040] \t Loss 3.9094 \t Acc 6.82 \t AccHead 7.75 \t AccTail 0.04\n",
      "Epoch: [041] \t Loss 3.9177 \t Acc 7.13 \t AccHead 7.17 \t AccTail 6.82\n",
      "Epoch: [042] \t Loss 3.9095 \t Acc 6.70 \t AccHead 7.63 \t AccTail 0.00\n",
      "Epoch: [043] \t Loss 3.9163 \t Acc 5.74 \t AccHead 6.44 \t AccTail 0.65\n",
      "Epoch: [044] \t Loss 3.9136 \t Acc 6.35 \t AccHead 6.82 \t AccTail 2.89\n",
      "Epoch: [045] \t Loss 3.9051 \t Acc 6.19 \t AccHead 7.03 \t AccTail 0.11\n",
      "Epoch: [046] \t Loss 3.9142 \t Acc 6.60 \t AccHead 7.33 \t AccTail 1.25\n",
      "Epoch: [047] \t Loss 3.9213 \t Acc 5.12 \t AccHead 5.38 \t AccTail 3.23\n",
      "Epoch: [048] \t Loss 3.9115 \t Acc 7.67 \t AccHead 8.67 \t AccTail 0.34\n",
      "Epoch: [049] \t Loss 3.9128 \t Acc 6.48 \t AccHead 7.10 \t AccTail 1.90\n",
      "Epoch: [050] \t Loss 3.9067 \t Acc 7.06 \t AccHead 8.01 \t AccTail 0.15\n",
      "Epoch: [051] \t Loss 3.9173 \t Acc 4.88 \t AccHead 5.55 \t AccTail 0.04\n",
      "Epoch: [052] \t Loss 3.9294 \t Acc 6.29 \t AccHead 7.15 \t AccTail 0.08\n",
      "Epoch: [053] \t Loss 3.9266 \t Acc 6.96 \t AccHead 7.92 \t AccTail 0.00\n",
      "Epoch: [054] \t Loss 3.9201 \t Acc 6.46 \t AccHead 7.27 \t AccTail 0.57\n",
      "Epoch: [055] \t Loss 3.9250 \t Acc 6.59 \t AccHead 7.49 \t AccTail 0.08\n",
      "Epoch: [056] \t Loss 3.9269 \t Acc 6.65 \t AccHead 7.56 \t AccTail 0.04\n",
      "Epoch: [057] \t Loss 3.9206 \t Acc 6.70 \t AccHead 7.22 \t AccTail 2.89\n",
      "Epoch: [058] \t Loss 3.9227 \t Acc 6.81 \t AccHead 7.75 \t AccTail 0.00\n",
      "Epoch: [059] \t Loss 3.9286 \t Acc 5.68 \t AccHead 6.38 \t AccTail 0.57\n",
      "Epoch: [060] \t Loss 3.9203 \t Acc 4.66 \t AccHead 5.30 \t AccTail 0.00\n",
      "Epoch: [061] \t Loss 3.9238 \t Acc 7.07 \t AccHead 7.20 \t AccTail 6.16\n",
      "Epoch: [062] \t Loss 3.9194 \t Acc 4.87 \t AccHead 5.49 \t AccTail 0.34\n",
      "Epoch: [063] \t Loss 3.9240 \t Acc 6.66 \t AccHead 7.58 \t AccTail 0.00\n",
      "Epoch: [064] \t Loss 3.9245 \t Acc 5.76 \t AccHead 5.84 \t AccTail 5.21\n",
      "Epoch: [065] \t Loss 3.9363 \t Acc 6.35 \t AccHead 7.12 \t AccTail 0.69\n",
      "Epoch: [066] \t Loss 3.9496 \t Acc 5.71 \t AccHead 6.43 \t AccTail 0.50\n",
      "Epoch: [067] \t Loss 3.9409 \t Acc 4.46 \t AccHead 5.08 \t AccTail 0.00\n",
      "Epoch: [068] \t Loss 3.9441 \t Acc 6.83 \t AccHead 7.65 \t AccTail 0.84\n",
      "Epoch: [069] \t Loss 3.9518 \t Acc 5.21 \t AccHead 5.91 \t AccTail 0.11\n",
      "Epoch: [070] \t Loss 3.9545 \t Acc 5.75 \t AccHead 6.29 \t AccTail 1.79\n",
      "Epoch: [071] \t Loss 3.9502 \t Acc 5.65 \t AccHead 6.42 \t AccTail 0.00\n",
      "Epoch: [072] \t Loss 3.9610 \t Acc 7.21 \t AccHead 8.04 \t AccTail 1.10\n",
      "Epoch: [073] \t Loss 3.9561 \t Acc 5.79 \t AccHead 6.09 \t AccTail 3.58\n",
      "Epoch: [074] \t Loss 3.9468 \t Acc 5.51 \t AccHead 6.22 \t AccTail 0.31\n",
      "Epoch: [075] \t Loss 3.9516 \t Acc 5.71 \t AccHead 5.87 \t AccTail 4.53\n",
      "Epoch: [076] \t Loss 3.9584 \t Acc 5.77 \t AccHead 5.95 \t AccTail 4.46\n",
      "Epoch: [077] \t Loss 3.9450 \t Acc 5.25 \t AccHead 5.52 \t AccTail 3.27\n",
      "Epoch: [078] \t Loss 3.9562 \t Acc 5.80 \t AccHead 6.24 \t AccTail 2.63\n",
      "Epoch: [079] \t Loss 3.9721 \t Acc 3.55 \t AccHead 4.01 \t AccTail 0.15\n",
      "Epoch: [080] \t Loss 3.9486 \t Acc 6.41 \t AccHead 6.86 \t AccTail 3.12\n",
      "Epoch: [081] \t Loss 3.9592 \t Acc 6.69 \t AccHead 7.54 \t AccTail 0.46\n",
      "Epoch: [082] \t Loss 3.9564 \t Acc 4.50 \t AccHead 5.12 \t AccTail 0.00\n",
      "Epoch: [083] \t Loss 3.9567 \t Acc 4.75 \t AccHead 5.09 \t AccTail 2.25\n",
      "Epoch: [084] \t Loss 3.9494 \t Acc 5.79 \t AccHead 5.93 \t AccTail 4.73\n",
      "Epoch: [085] \t Loss 3.9612 \t Acc 6.70 \t AccHead 7.63 \t AccTail 0.00\n",
      "Epoch: [086] \t Loss 3.9603 \t Acc 4.87 \t AccHead 5.46 \t AccTail 0.57\n",
      "Epoch: [087] \t Loss 3.9602 \t Acc 3.27 \t AccHead 3.72 \t AccTail 0.00\n",
      "Epoch: [088] \t Loss 3.9584 \t Acc 5.96 \t AccHead 6.77 \t AccTail 0.04\n",
      "Epoch: [089] \t Loss 3.9500 \t Acc 4.69 \t AccHead 5.34 \t AccTail 0.00\n",
      "Epoch: [090] \t Loss 3.9711 \t Acc 5.07 \t AccHead 5.26 \t AccTail 3.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 22:44:53,503]\u001b[0m Trial 6 finished with value: 1.8864012956619263 and parameters: {'n_epoch': 90, 'weight_decay': 0.013638058894254228}. Best is trial 5 with value: 10.157546043395996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 1.89 \t AccHead 3.79 \t AccTail 0.00\n",
      "Epoch: [001] \t Loss 4.2345 \t Acc 5.20 \t AccHead 5.58 \t AccTail 2.40\n",
      "Epoch: [002] \t Loss 4.0082 \t Acc 6.29 \t AccHead 7.15 \t AccTail 0.00\n",
      "Epoch: [003] \t Loss 4.0002 \t Acc 3.47 \t AccHead 3.94 \t AccTail 0.00\n",
      "Epoch: [004] \t Loss 4.0038 \t Acc 4.88 \t AccHead 5.51 \t AccTail 0.23\n",
      "Epoch: [005] \t Loss 3.9997 \t Acc 3.37 \t AccHead 3.84 \t AccTail 0.00\n",
      "Epoch: [006] \t Loss 3.9973 \t Acc 4.34 \t AccHead 4.63 \t AccTail 2.28\n",
      "Epoch: [007] \t Loss 4.0071 \t Acc 4.64 \t AccHead 5.13 \t AccTail 1.07\n",
      "Epoch: [008] \t Loss 4.0054 \t Acc 4.21 \t AccHead 3.70 \t AccTail 7.99\n",
      "Epoch: [009] \t Loss 4.0093 \t Acc 6.26 \t AccHead 7.03 \t AccTail 0.65\n",
      "Epoch: [010] \t Loss 4.0159 \t Acc 4.47 \t AccHead 5.07 \t AccTail 0.08\n",
      "Epoch: [011] \t Loss 4.0020 \t Acc 4.67 \t AccHead 5.14 \t AccTail 1.22\n",
      "Epoch: [012] \t Loss 4.0122 \t Acc 4.44 \t AccHead 5.04 \t AccTail 0.11\n",
      "Epoch: [013] \t Loss 4.0090 \t Acc 3.31 \t AccHead 3.77 \t AccTail 0.00\n",
      "Epoch: [014] \t Loss 4.0129 \t Acc 3.36 \t AccHead 3.71 \t AccTail 0.84\n",
      "Epoch: [015] \t Loss 4.0116 \t Acc 5.05 \t AccHead 5.73 \t AccTail 0.04\n",
      "Epoch: [016] \t Loss 4.0165 \t Acc 6.41 \t AccHead 7.29 \t AccTail 0.00\n",
      "Epoch: [017] \t Loss 4.0217 \t Acc 4.45 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [018] \t Loss 4.0336 \t Acc 4.88 \t AccHead 5.07 \t AccTail 3.50\n",
      "Epoch: [019] \t Loss 4.0281 \t Acc 4.60 \t AccHead 5.23 \t AccTail 0.00\n",
      "Epoch: [020] \t Loss 4.0350 \t Acc 4.15 \t AccHead 4.72 \t AccTail 0.00\n",
      "Epoch: [021] \t Loss 4.0274 \t Acc 5.05 \t AccHead 5.31 \t AccTail 3.12\n",
      "Epoch: [022] \t Loss 4.0293 \t Acc 4.08 \t AccHead 4.15 \t AccTail 3.54\n",
      "Epoch: [023] \t Loss 4.0374 \t Acc 4.62 \t AccHead 5.25 \t AccTail 0.00\n",
      "Epoch: [024] \t Loss 4.0326 \t Acc 4.62 \t AccHead 5.10 \t AccTail 1.14\n",
      "Epoch: [025] \t Loss 4.0380 \t Acc 4.98 \t AccHead 4.86 \t AccTail 5.90\n",
      "Epoch: [026] \t Loss 4.0342 \t Acc 4.94 \t AccHead 5.20 \t AccTail 3.05\n",
      "Epoch: [027] \t Loss 4.0324 \t Acc 4.72 \t AccHead 5.33 \t AccTail 0.23\n",
      "Epoch: [028] \t Loss 4.0377 \t Acc 5.15 \t AccHead 4.73 \t AccTail 8.23\n",
      "Epoch: [029] \t Loss 4.0392 \t Acc 5.09 \t AccHead 5.60 \t AccTail 1.37\n",
      "Epoch: [030] \t Loss 4.0383 \t Acc 4.54 \t AccHead 5.10 \t AccTail 0.46\n",
      "Epoch: [031] \t Loss 4.0430 \t Acc 3.51 \t AccHead 3.92 \t AccTail 0.49\n",
      "Epoch: [032] \t Loss 4.0453 \t Acc 2.73 \t AccHead 3.11 \t AccTail 0.00\n",
      "Epoch: [033] \t Loss 4.0395 \t Acc 4.45 \t AccHead 5.06 \t AccTail 0.00\n",
      "Epoch: [034] \t Loss 4.0430 \t Acc 4.20 \t AccHead 4.77 \t AccTail 0.04\n",
      "Epoch: [035] \t Loss 4.0399 \t Acc 4.21 \t AccHead 4.79 \t AccTail 0.00\n",
      "Epoch: [036] \t Loss 4.0445 \t Acc 5.37 \t AccHead 5.73 \t AccTail 2.78\n",
      "Epoch: [037] \t Loss 4.0392 \t Acc 5.24 \t AccHead 5.96 \t AccTail 0.00\n",
      "Epoch: [038] \t Loss 4.0452 \t Acc 5.15 \t AccHead 5.23 \t AccTail 4.53\n",
      "Epoch: [039] \t Loss 4.0424 \t Acc 3.57 \t AccHead 3.02 \t AccTail 7.56\n",
      "Epoch: [040] \t Loss 4.0355 \t Acc 5.31 \t AccHead 5.18 \t AccTail 6.25\n",
      "Epoch: [041] \t Loss 4.0367 \t Acc 4.93 \t AccHead 5.59 \t AccTail 0.08\n",
      "Epoch: [042] \t Loss 4.0370 \t Acc 3.35 \t AccHead 3.39 \t AccTail 3.01\n",
      "Epoch: [043] \t Loss 4.0429 \t Acc 4.47 \t AccHead 5.05 \t AccTail 0.23\n",
      "Epoch: [044] \t Loss 4.0472 \t Acc 1.93 \t AccHead 2.19 \t AccTail 0.00\n",
      "Epoch: [045] \t Loss 4.0558 \t Acc 5.42 \t AccHead 6.01 \t AccTail 1.14\n",
      "Epoch: [046] \t Loss 4.0510 \t Acc 5.21 \t AccHead 5.22 \t AccTail 5.18\n",
      "Epoch: [047] \t Loss 4.0442 \t Acc 4.45 \t AccHead 4.97 \t AccTail 0.65\n",
      "Epoch: [048] \t Loss 4.0380 \t Acc 4.81 \t AccHead 5.27 \t AccTail 1.45\n",
      "Epoch: [049] \t Loss 4.0456 \t Acc 4.60 \t AccHead 5.08 \t AccTail 1.07\n",
      "Epoch: [050] \t Loss 4.0527 \t Acc 4.22 \t AccHead 4.65 \t AccTail 1.10\n",
      "Epoch: [051] \t Loss 4.0496 \t Acc 4.08 \t AccHead 4.34 \t AccTail 2.21\n",
      "Epoch: [052] \t Loss 4.0481 \t Acc 4.52 \t AccHead 5.14 \t AccTail 0.00\n",
      "Epoch: [053] \t Loss 4.0526 \t Acc 3.30 \t AccHead 3.75 \t AccTail 0.00\n",
      "Epoch: [054] \t Loss 4.0512 \t Acc 2.44 \t AccHead 1.43 \t AccTail 9.82\n",
      "Epoch: [055] \t Loss 4.0664 \t Acc 3.91 \t AccHead 4.44 \t AccTail 0.00\n",
      "Epoch: [056] \t Loss 4.1205 \t Acc 2.24 \t AccHead 2.55 \t AccTail 0.00\n",
      "Epoch: [057] \t Loss 4.1243 \t Acc 2.87 \t AccHead 2.42 \t AccTail 6.18\n",
      "Epoch: [058] \t Loss 4.1236 \t Acc 3.47 \t AccHead 3.62 \t AccTail 2.33\n",
      "Epoch: [059] \t Loss 4.1206 \t Acc 1.82 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [060] \t Loss 4.1213 \t Acc 2.30 \t AccHead 2.30 \t AccTail 2.25\n",
      "Epoch: [061] \t Loss 4.1277 \t Acc 3.06 \t AccHead 3.48 \t AccTail 0.00\n",
      "Epoch: [062] \t Loss 4.1192 \t Acc 2.61 \t AccHead 2.69 \t AccTail 2.02\n",
      "Epoch: [063] \t Loss 4.1416 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [064] \t Loss 4.2007 \t Acc 1.80 \t AccHead 2.04 \t AccTail 0.00\n",
      "Epoch: [065] \t Loss 4.2311 \t Acc 2.73 \t AccHead 3.06 \t AccTail 0.27\n",
      "Epoch: [066] \t Loss 4.1806 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [067] \t Loss 4.2040 \t Acc 1.98 \t AccHead 2.19 \t AccTail 0.46\n",
      "Epoch: [068] \t Loss 4.1675 \t Acc 3.13 \t AccHead 3.56 \t AccTail 0.00\n",
      "Epoch: [069] \t Loss 4.1751 \t Acc 2.56 \t AccHead 2.92 \t AccTail 0.00\n",
      "Epoch: [070] \t Loss 4.2296 \t Acc 2.69 \t AccHead 3.06 \t AccTail 0.00\n",
      "Epoch: [071] \t Loss 4.2213 \t Acc 2.43 \t AccHead 2.76 \t AccTail 0.00\n",
      "Epoch: [072] \t Loss 4.1752 \t Acc 2.95 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [073] \t Loss 4.2010 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [074] \t Loss 4.2387 \t Acc 2.39 \t AccHead 2.71 \t AccTail 0.00\n",
      "Epoch: [075] \t Loss 4.1991 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [076] \t Loss 4.2473 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [077] \t Loss 4.2482 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [078] \t Loss 4.2481 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [079] \t Loss 4.2481 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [080] \t Loss 4.2512 \t Acc 1.84 \t AccHead 0.00 \t AccTail 15.22\n",
      "Epoch: [081] \t Loss 4.2473 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [082] \t Loss 4.2466 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [083] \t Loss 4.2466 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [084] \t Loss 4.2471 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [085] \t Loss 4.2478 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [086] \t Loss 4.2475 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [087] \t Loss 4.2460 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [088] \t Loss 4.2475 \t Acc 1.82 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [089] \t Loss 4.2478 \t Acc 1.82 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [090] \t Loss 4.2474 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [091] \t Loss 4.2485 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [092] \t Loss 4.2487 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [093] \t Loss 4.2443 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [094] \t Loss 4.2470 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [095] \t Loss 4.2487 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [096] \t Loss 4.2480 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [097] \t Loss 4.2470 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [098] \t Loss 4.2492 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [099] \t Loss 4.2454 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [100] \t Loss 4.2461 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [101] \t Loss 4.2488 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [102] \t Loss 4.2473 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [103] \t Loss 4.2471 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [104] \t Loss 4.2490 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [105] \t Loss 4.2498 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [106] \t Loss 4.2461 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [107] \t Loss 4.2501 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [108] \t Loss 4.2459 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [109] \t Loss 4.2493 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [110] \t Loss 4.2470 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [111] \t Loss 4.2488 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [112] \t Loss 4.2470 \t Acc 1.83 \t AccHead 0.00 \t AccTail 15.14\n",
      "Epoch: [113] \t Loss 4.2472 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [114] \t Loss 4.2478 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [115] \t Loss 4.2484 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [116] \t Loss 4.2485 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [117] \t Loss 4.2479 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [118] \t Loss 4.2470 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [119] \t Loss 4.2487 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [120] \t Loss 4.2470 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [121] \t Loss 4.2452 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [122] \t Loss 4.2476 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [123] \t Loss 4.2491 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [124] \t Loss 4.2454 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [125] \t Loss 4.2487 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [126] \t Loss 4.2466 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [127] \t Loss 4.2491 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [128] \t Loss 4.2489 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [129] \t Loss 4.2483 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [130] \t Loss 4.2458 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [131] \t Loss 4.2460 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [132] \t Loss 4.2479 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [133] \t Loss 4.2475 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [134] \t Loss 4.2471 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [135] \t Loss 4.2459 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [136] \t Loss 4.2477 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [137] \t Loss 4.2510 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [138] \t Loss 4.2449 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [139] \t Loss 4.2470 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [140] \t Loss 4.2469 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [141] \t Loss 4.2477 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [142] \t Loss 4.2457 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [143] \t Loss 4.2458 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [144] \t Loss 4.2486 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [145] \t Loss 4.2470 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [146] \t Loss 4.2491 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [147] \t Loss 4.2474 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [148] \t Loss 4.2473 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [149] \t Loss 4.2477 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [150] \t Loss 4.2459 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [151] \t Loss 4.2284 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [152] \t Loss 4.2213 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [153] \t Loss 4.2218 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [154] \t Loss 4.2205 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [155] \t Loss 4.2216 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [156] \t Loss 4.2212 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [157] \t Loss 4.2219 \t Acc 1.82 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [158] \t Loss 4.2215 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [159] \t Loss 4.2215 \t Acc 1.84 \t AccHead 0.00 \t AccTail 15.21\n",
      "Epoch: [160] \t Loss 4.2221 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [161] \t Loss 4.2217 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [162] \t Loss 4.2216 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [163] \t Loss 4.2225 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [164] \t Loss 4.2208 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [165] \t Loss 4.2219 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [166] \t Loss 4.2219 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [167] \t Loss 4.2212 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [168] \t Loss 4.2224 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [169] \t Loss 4.2214 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [170] \t Loss 4.2223 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [171] \t Loss 4.2215 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [172] \t Loss 4.2220 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [173] \t Loss 4.2219 \t Acc 1.82 \t AccHead 2.06 \t AccTail 0.00\n",
      "Epoch: [174] \t Loss 4.2212 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [175] \t Loss 4.2220 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [176] \t Loss 4.2216 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [177] \t Loss 4.2227 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [178] \t Loss 4.2212 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [179] \t Loss 4.2222 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [180] \t Loss 4.2213 \t Acc 1.82 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [181] \t Loss 4.2209 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [182] \t Loss 4.2217 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [183] \t Loss 4.2219 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [184] \t Loss 4.2208 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [185] \t Loss 4.2228 \t Acc 1.82 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [186] \t Loss 4.2206 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [187] \t Loss 4.2218 \t Acc 1.82 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [188] \t Loss 4.2221 \t Acc 1.82 \t AccHead 2.07 \t AccTail 0.00\n",
      "Epoch: [189] \t Loss 4.2218 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [190] \t Loss 4.2220 \t Acc 1.82 \t AccHead 2.06 \t AccTail 0.00\n",
      "Epoch: [191] \t Loss 4.2217 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [192] \t Loss 4.2223 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [193] \t Loss 4.2207 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [194] \t Loss 4.2220 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [195] \t Loss 4.2220 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [196] \t Loss 4.2212 \t Acc 1.82 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [197] \t Loss 4.2209 \t Acc 1.83 \t AccHead 2.09 \t AccTail 0.00\n",
      "Epoch: [198] \t Loss 4.2223 \t Acc 1.83 \t AccHead 0.00 \t AccTail 15.14\n",
      "Epoch: [199] \t Loss 4.2219 \t Acc 1.83 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [200] \t Loss 4.2214 \t Acc 1.84 \t AccHead 2.09 \t AccTail 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 23:21:33,100]\u001b[0m Trial 7 finished with value: 1.0364842414855957 and parameters: {'n_epoch': 200, 'weight_decay': 0.022442621990024312}. Best is trial 5 with value: 10.157546043395996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 1.04 \t AccHead 2.08 \t AccTail 0.00\n",
      "Epoch: [001] \t Loss 4.2979 \t Acc 9.44 \t AccHead 10.66 \t AccTail 0.53\n",
      "Epoch: [002] \t Loss 3.7670 \t Acc 13.44 \t AccHead 14.79 \t AccTail 3.62\n",
      "Epoch: [003] \t Loss 3.5585 \t Acc 15.79 \t AccHead 16.78 \t AccTail 8.60\n",
      "Epoch: [004] \t Loss 3.3909 \t Acc 20.12 \t AccHead 21.91 \t AccTail 7.13\n",
      "Epoch: [005] \t Loss 3.2677 \t Acc 22.12 \t AccHead 24.08 \t AccTail 7.87\n",
      "Epoch: [006] \t Loss 3.1408 \t Acc 23.75 \t AccHead 26.15 \t AccTail 6.24\n",
      "Epoch: [007] \t Loss 3.0224 \t Acc 23.87 \t AccHead 25.76 \t AccTail 10.12\n",
      "Epoch: [008] \t Loss 2.9237 \t Acc 28.47 \t AccHead 31.19 \t AccTail 8.69\n",
      "Epoch: [009] \t Loss 2.8276 \t Acc 30.08 \t AccHead 32.67 \t AccTail 11.22\n",
      "Epoch: [010] \t Loss 2.7391 \t Acc 32.48 \t AccHead 35.41 \t AccTail 11.18\n",
      "Epoch: [011] \t Loss 2.6405 \t Acc 32.90 \t AccHead 35.11 \t AccTail 16.78\n",
      "Epoch: [012] \t Loss 2.5646 \t Acc 33.54 \t AccHead 35.75 \t AccTail 17.43\n",
      "Epoch: [013] \t Loss 2.4865 \t Acc 37.12 \t AccHead 39.83 \t AccTail 17.36\n",
      "Epoch: [014] \t Loss 2.4058 \t Acc 38.15 \t AccHead 40.82 \t AccTail 18.76\n",
      "Epoch: [015] \t Loss 2.3399 \t Acc 39.48 \t AccHead 42.55 \t AccTail 17.10\n",
      "Epoch: [016] \t Loss 2.2535 \t Acc 41.61 \t AccHead 44.42 \t AccTail 21.11\n",
      "Epoch: [017] \t Loss 2.2005 \t Acc 43.07 \t AccHead 46.47 \t AccTail 18.29\n",
      "Epoch: [018] \t Loss 2.1353 \t Acc 45.40 \t AccHead 48.43 \t AccTail 23.26\n",
      "Epoch: [019] \t Loss 2.0487 \t Acc 46.62 \t AccHead 49.46 \t AccTail 25.87\n",
      "Epoch: [020] \t Loss 1.9916 \t Acc 47.28 \t AccHead 50.20 \t AccTail 26.07\n",
      "Epoch: [021] \t Loss 1.9294 \t Acc 50.14 \t AccHead 52.84 \t AccTail 30.48\n",
      "Epoch: [022] \t Loss 1.8733 \t Acc 50.80 \t AccHead 53.18 \t AccTail 33.42\n",
      "Epoch: [023] \t Loss 1.7944 \t Acc 51.62 \t AccHead 54.51 \t AccTail 30.58\n",
      "Epoch: [024] \t Loss 1.7449 \t Acc 55.12 \t AccHead 57.70 \t AccTail 36.30\n",
      "Epoch: [025] \t Loss 1.6947 \t Acc 57.97 \t AccHead 60.63 \t AccTail 38.53\n",
      "Epoch: [026] \t Loss 1.6056 \t Acc 59.14 \t AccHead 61.42 \t AccTail 42.58\n",
      "Epoch: [027] \t Loss 1.5656 \t Acc 59.13 \t AccHead 61.87 \t AccTail 39.17\n",
      "Epoch: [028] \t Loss 1.4976 \t Acc 62.23 \t AccHead 64.21 \t AccTail 47.79\n",
      "Epoch: [029] \t Loss 1.4460 \t Acc 62.74 \t AccHead 65.00 \t AccTail 46.27\n",
      "Epoch: [030] \t Loss 1.3706 \t Acc 63.55 \t AccHead 65.54 \t AccTail 49.09\n",
      "Epoch: [031] \t Loss 1.3183 \t Acc 66.84 \t AccHead 68.43 \t AccTail 55.22\n",
      "Epoch: [032] \t Loss 1.2457 \t Acc 66.29 \t AccHead 68.28 \t AccTail 51.79\n",
      "Epoch: [033] \t Loss 1.1973 \t Acc 68.92 \t AccHead 70.90 \t AccTail 54.51\n",
      "Epoch: [034] \t Loss 1.1435 \t Acc 68.10 \t AccHead 69.41 \t AccTail 58.52\n",
      "Epoch: [035] \t Loss 1.0862 \t Acc 72.09 \t AccHead 73.62 \t AccTail 60.99\n",
      "Epoch: [036] \t Loss 1.0184 \t Acc 73.69 \t AccHead 74.93 \t AccTail 64.65\n",
      "Epoch: [037] \t Loss 0.9792 \t Acc 75.30 \t AccHead 76.46 \t AccTail 66.84\n",
      "Epoch: [038] \t Loss 0.9299 \t Acc 77.55 \t AccHead 78.62 \t AccTail 69.71\n",
      "Epoch: [039] \t Loss 0.8902 \t Acc 79.49 \t AccHead 80.45 \t AccTail 72.43\n",
      "Epoch: [040] \t Loss 0.8112 \t Acc 77.98 \t AccHead 79.11 \t AccTail 69.72\n",
      "Epoch: [041] \t Loss 0.7808 \t Acc 81.88 \t AccHead 82.50 \t AccTail 77.37\n",
      "Epoch: [042] \t Loss 0.7505 \t Acc 81.81 \t AccHead 81.81 \t AccTail 81.82\n",
      "Epoch: [043] \t Loss 0.7247 \t Acc 82.76 \t AccHead 83.22 \t AccTail 79.41\n",
      "Epoch: [044] \t Loss 0.6607 \t Acc 83.95 \t AccHead 84.64 \t AccTail 78.91\n",
      "Epoch: [045] \t Loss 0.6427 \t Acc 84.02 \t AccHead 84.56 \t AccTail 80.12\n",
      "Epoch: [046] \t Loss 0.5860 \t Acc 86.45 \t AccHead 86.66 \t AccTail 84.97\n",
      "Epoch: [047] \t Loss 0.5615 \t Acc 84.71 \t AccHead 85.16 \t AccTail 81.42\n",
      "Epoch: [048] \t Loss 0.5416 \t Acc 88.42 \t AccHead 88.55 \t AccTail 87.50\n",
      "Epoch: [049] \t Loss 0.4915 \t Acc 87.37 \t AccHead 87.36 \t AccTail 87.43\n",
      "Epoch: [050] \t Loss 0.4566 \t Acc 88.53 \t AccHead 88.77 \t AccTail 86.80\n",
      "Epoch: [051] \t Loss 0.4425 \t Acc 88.61 \t AccHead 89.19 \t AccTail 84.37\n",
      "Epoch: [052] \t Loss 0.4479 \t Acc 88.78 \t AccHead 88.93 \t AccTail 87.68\n",
      "Epoch: [053] \t Loss 0.3996 \t Acc 90.72 \t AccHead 91.03 \t AccTail 88.44\n",
      "Epoch: [054] \t Loss 0.3841 \t Acc 91.22 \t AccHead 91.30 \t AccTail 90.66\n",
      "Epoch: [055] \t Loss 0.3600 \t Acc 91.54 \t AccHead 91.54 \t AccTail 91.58\n",
      "Epoch: [056] \t Loss 0.3708 \t Acc 91.36 \t AccHead 91.48 \t AccTail 90.49\n",
      "Epoch: [057] \t Loss 0.3477 \t Acc 93.07 \t AccHead 93.24 \t AccTail 91.79\n",
      "Epoch: [058] \t Loss 0.3066 \t Acc 92.76 \t AccHead 92.60 \t AccTail 93.95\n",
      "Epoch: [059] \t Loss 0.2961 \t Acc 93.52 \t AccHead 93.67 \t AccTail 92.47\n",
      "Epoch: [060] \t Loss 0.3127 \t Acc 93.24 \t AccHead 93.60 \t AccTail 90.68\n",
      "Epoch: [061] \t Loss 0.3074 \t Acc 92.22 \t AccHead 92.41 \t AccTail 90.83\n",
      "Epoch: [062] \t Loss 0.2793 \t Acc 94.07 \t AccHead 94.01 \t AccTail 94.48\n",
      "Epoch: [063] \t Loss 0.2612 \t Acc 93.50 \t AccHead 93.55 \t AccTail 93.15\n",
      "Epoch: [064] \t Loss 0.2573 \t Acc 94.19 \t AccHead 94.13 \t AccTail 94.59\n",
      "Epoch: [065] \t Loss 0.2476 \t Acc 94.70 \t AccHead 94.70 \t AccTail 94.67\n",
      "Epoch: [066] \t Loss 0.2427 \t Acc 94.60 \t AccHead 94.71 \t AccTail 93.86\n",
      "Epoch: [067] \t Loss 0.2406 \t Acc 94.70 \t AccHead 94.67 \t AccTail 94.90\n",
      "Epoch: [068] \t Loss 0.2323 \t Acc 93.81 \t AccHead 93.98 \t AccTail 92.57\n",
      "Epoch: [069] \t Loss 0.2196 \t Acc 94.20 \t AccHead 94.33 \t AccTail 93.22\n",
      "Epoch: [070] \t Loss 0.2169 \t Acc 95.71 \t AccHead 95.69 \t AccTail 95.89\n",
      "Epoch: [071] \t Loss 0.1929 \t Acc 96.11 \t AccHead 96.24 \t AccTail 95.17\n",
      "Epoch: [072] \t Loss 0.2002 \t Acc 94.95 \t AccHead 94.96 \t AccTail 94.90\n",
      "Epoch: [073] \t Loss 0.2022 \t Acc 96.46 \t AccHead 96.42 \t AccTail 96.73\n",
      "Epoch: [074] \t Loss 0.1801 \t Acc 95.82 \t AccHead 96.00 \t AccTail 94.57\n",
      "Epoch: [075] \t Loss 0.1733 \t Acc 96.53 \t AccHead 96.52 \t AccTail 96.65\n",
      "Epoch: [076] \t Loss 0.1709 \t Acc 96.34 \t AccHead 96.30 \t AccTail 96.68\n",
      "Epoch: [077] \t Loss 0.1717 \t Acc 96.15 \t AccHead 96.11 \t AccTail 96.44\n",
      "Epoch: [078] \t Loss 0.1649 \t Acc 96.53 \t AccHead 96.57 \t AccTail 96.27\n",
      "Epoch: [079] \t Loss 0.1663 \t Acc 95.81 \t AccHead 95.67 \t AccTail 96.80\n",
      "Epoch: [080] \t Loss 0.1566 \t Acc 97.17 \t AccHead 97.19 \t AccTail 97.03\n",
      "Epoch: [081] \t Loss 0.1489 \t Acc 96.54 \t AccHead 96.52 \t AccTail 96.73\n",
      "Epoch: [082] \t Loss 0.1494 \t Acc 96.66 \t AccHead 96.68 \t AccTail 96.54\n",
      "Epoch: [083] \t Loss 0.1447 \t Acc 96.77 \t AccHead 96.75 \t AccTail 96.92\n",
      "Epoch: [084] \t Loss 0.1386 \t Acc 97.19 \t AccHead 97.17 \t AccTail 97.30\n",
      "Epoch: [085] \t Loss 0.1347 \t Acc 96.74 \t AccHead 96.68 \t AccTail 97.22\n",
      "Epoch: [086] \t Loss 0.1412 \t Acc 97.00 \t AccHead 96.97 \t AccTail 97.22\n",
      "Epoch: [087] \t Loss 0.1355 \t Acc 97.22 \t AccHead 97.15 \t AccTail 97.76\n",
      "Epoch: [088] \t Loss 0.1405 \t Acc 96.49 \t AccHead 96.44 \t AccTail 96.85\n",
      "Epoch: [089] \t Loss 0.1307 \t Acc 97.53 \t AccHead 97.52 \t AccTail 97.56\n",
      "Epoch: [090] \t Loss 0.1240 \t Acc 96.55 \t AccHead 96.57 \t AccTail 96.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 23:38:04,390]\u001b[0m Trial 8 finished with value: 8.665008544921875 and parameters: {'n_epoch': 90, 'weight_decay': 1.88134577869223e-05}. Best is trial 5 with value: 10.157546043395996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 8.67 \t AccHead 14.94 \t AccTail 2.45\n",
      "Epoch: [001] \t Loss 4.2943 \t Acc 7.10 \t AccHead 7.86 \t AccTail 1.56\n",
      "Epoch: [002] \t Loss 3.8019 \t Acc 11.79 \t AccHead 12.94 \t AccTail 3.36\n",
      "Epoch: [003] \t Loss 3.5952 \t Acc 15.79 \t AccHead 17.37 \t AccTail 4.20\n",
      "Epoch: [004] \t Loss 3.4563 \t Acc 17.90 \t AccHead 19.40 \t AccTail 7.04\n",
      "Epoch: [005] \t Loss 3.3137 \t Acc 20.41 \t AccHead 22.30 \t AccTail 6.60\n",
      "Epoch: [006] \t Loss 3.1751 \t Acc 24.02 \t AccHead 25.98 \t AccTail 9.77\n",
      "Epoch: [007] \t Loss 3.0705 \t Acc 24.40 \t AccHead 26.54 \t AccTail 8.80\n",
      "Epoch: [008] \t Loss 2.9741 \t Acc 28.01 \t AccHead 30.76 \t AccTail 7.99\n",
      "Epoch: [009] \t Loss 2.8739 \t Acc 29.28 \t AccHead 32.04 \t AccTail 9.22\n",
      "Epoch: [010] \t Loss 2.7852 \t Acc 28.81 \t AccHead 30.95 \t AccTail 13.22\n",
      "Epoch: [011] \t Loss 2.7044 \t Acc 32.64 \t AccHead 35.07 \t AccTail 14.94\n",
      "Epoch: [012] \t Loss 2.6132 \t Acc 33.94 \t AccHead 36.48 \t AccTail 15.40\n",
      "Epoch: [013] \t Loss 2.5222 \t Acc 35.30 \t AccHead 38.50 \t AccTail 12.09\n",
      "Epoch: [014] \t Loss 2.4495 \t Acc 38.36 \t AccHead 41.48 \t AccTail 15.58\n",
      "Epoch: [015] \t Loss 2.3762 \t Acc 39.47 \t AccHead 42.11 \t AccTail 20.20\n",
      "Epoch: [016] \t Loss 2.3250 \t Acc 39.94 \t AccHead 43.07 \t AccTail 17.13\n",
      "Epoch: [017] \t Loss 2.2457 \t Acc 42.15 \t AccHead 44.83 \t AccTail 22.61\n",
      "Epoch: [018] \t Loss 2.1859 \t Acc 42.57 \t AccHead 45.26 \t AccTail 23.05\n",
      "Epoch: [019] \t Loss 2.1227 \t Acc 44.35 \t AccHead 46.55 \t AccTail 28.35\n",
      "Epoch: [020] \t Loss 2.0892 \t Acc 45.90 \t AccHead 48.23 \t AccTail 28.89\n",
      "Epoch: [021] \t Loss 2.0063 \t Acc 47.91 \t AccHead 50.43 \t AccTail 29.52\n",
      "Epoch: [022] \t Loss 1.9437 \t Acc 42.89 \t AccHead 44.77 \t AccTail 29.19\n",
      "Epoch: [023] \t Loss 1.8908 \t Acc 50.36 \t AccHead 52.63 \t AccTail 33.84\n",
      "Epoch: [024] \t Loss 1.8183 \t Acc 53.29 \t AccHead 55.92 \t AccTail 34.12\n",
      "Epoch: [025] \t Loss 1.7580 \t Acc 54.67 \t AccHead 57.13 \t AccTail 36.74\n",
      "Epoch: [026] \t Loss 1.7033 \t Acc 41.19 \t AccHead 43.36 \t AccTail 25.36\n",
      "Epoch: [027] \t Loss 1.6867 \t Acc 54.49 \t AccHead 56.99 \t AccTail 36.25\n",
      "Epoch: [028] \t Loss 1.5762 \t Acc 60.20 \t AccHead 62.27 \t AccTail 45.10\n",
      "Epoch: [029] \t Loss 1.5130 \t Acc 59.28 \t AccHead 60.90 \t AccTail 47.43\n",
      "Epoch: [030] \t Loss 1.4430 \t Acc 62.43 \t AccHead 64.38 \t AccTail 48.21\n",
      "Epoch: [031] \t Loss 1.4020 \t Acc 64.02 \t AccHead 65.83 \t AccTail 50.82\n",
      "Epoch: [032] \t Loss 1.3236 \t Acc 64.97 \t AccHead 66.66 \t AccTail 52.68\n",
      "Epoch: [033] \t Loss 1.2944 \t Acc 67.81 \t AccHead 69.62 \t AccTail 54.60\n",
      "Epoch: [034] \t Loss 1.2089 \t Acc 67.39 \t AccHead 69.02 \t AccTail 55.50\n",
      "Epoch: [035] \t Loss 1.1464 \t Acc 71.03 \t AccHead 72.71 \t AccTail 58.81\n",
      "Epoch: [036] \t Loss 1.0812 \t Acc 68.92 \t AccHead 69.88 \t AccTail 61.94\n",
      "Epoch: [037] \t Loss 1.0340 \t Acc 72.73 \t AccHead 74.06 \t AccTail 63.06\n",
      "Epoch: [038] \t Loss 0.9972 \t Acc 76.25 \t AccHead 77.67 \t AccTail 65.97\n",
      "Epoch: [039] \t Loss 0.9302 \t Acc 79.31 \t AccHead 80.24 \t AccTail 72.58\n",
      "Epoch: [040] \t Loss 0.8641 \t Acc 77.50 \t AccHead 78.22 \t AccTail 72.30\n",
      "Epoch: [041] \t Loss 0.8327 \t Acc 80.01 \t AccHead 80.66 \t AccTail 75.25\n",
      "Epoch: [042] \t Loss 0.7883 \t Acc 81.05 \t AccHead 81.71 \t AccTail 76.27\n",
      "Epoch: [043] \t Loss 0.7348 \t Acc 80.86 \t AccHead 81.70 \t AccTail 74.74\n",
      "Epoch: [044] \t Loss 0.6980 \t Acc 82.03 \t AccHead 82.56 \t AccTail 78.15\n",
      "Epoch: [045] \t Loss 0.6645 \t Acc 85.06 \t AccHead 85.50 \t AccTail 81.83\n",
      "Epoch: [046] \t Loss 0.5992 \t Acc 84.37 \t AccHead 84.89 \t AccTail 80.55\n",
      "Epoch: [047] \t Loss 0.5980 \t Acc 83.64 \t AccHead 84.26 \t AccTail 79.05\n",
      "Epoch: [048] \t Loss 0.5357 \t Acc 87.30 \t AccHead 87.46 \t AccTail 86.15\n",
      "Epoch: [049] \t Loss 0.5060 \t Acc 87.47 \t AccHead 87.59 \t AccTail 86.61\n",
      "Epoch: [050] \t Loss 0.5012 \t Acc 87.37 \t AccHead 87.51 \t AccTail 86.34\n",
      "Epoch: [051] \t Loss 0.4656 \t Acc 87.86 \t AccHead 88.01 \t AccTail 86.79\n",
      "Epoch: [052] \t Loss 0.4343 \t Acc 90.07 \t AccHead 90.27 \t AccTail 88.65\n",
      "Epoch: [053] \t Loss 0.4087 \t Acc 90.49 \t AccHead 90.43 \t AccTail 90.88\n",
      "Epoch: [054] \t Loss 0.3971 \t Acc 89.82 \t AccHead 90.14 \t AccTail 87.51\n",
      "Epoch: [055] \t Loss 0.3681 \t Acc 90.83 \t AccHead 90.95 \t AccTail 89.95\n",
      "Epoch: [056] \t Loss 0.3625 \t Acc 91.14 \t AccHead 91.20 \t AccTail 90.65\n",
      "Epoch: [057] \t Loss 0.3385 \t Acc 91.98 \t AccHead 92.08 \t AccTail 91.25\n",
      "Epoch: [058] \t Loss 0.3451 \t Acc 92.42 \t AccHead 92.55 \t AccTail 91.42\n",
      "Epoch: [059] \t Loss 0.3134 \t Acc 93.40 \t AccHead 93.66 \t AccTail 91.48\n",
      "Epoch: [060] \t Loss 0.3035 \t Acc 92.17 \t AccHead 92.16 \t AccTail 92.24\n",
      "Epoch: [061] \t Loss 0.3019 \t Acc 92.48 \t AccHead 92.58 \t AccTail 91.75\n",
      "Epoch: [062] \t Loss 0.2924 \t Acc 93.44 \t AccHead 93.62 \t AccTail 92.11\n",
      "Epoch: [063] \t Loss 0.2792 \t Acc 93.08 \t AccHead 93.21 \t AccTail 92.09\n",
      "Epoch: [064] \t Loss 0.2524 \t Acc 94.51 \t AccHead 94.58 \t AccTail 94.02\n",
      "Epoch: [065] \t Loss 0.2353 \t Acc 95.02 \t AccHead 95.10 \t AccTail 94.41\n",
      "Epoch: [066] \t Loss 0.2225 \t Acc 95.07 \t AccHead 95.00 \t AccTail 95.55\n",
      "Epoch: [067] \t Loss 0.2311 \t Acc 95.03 \t AccHead 95.11 \t AccTail 94.48\n",
      "Epoch: [068] \t Loss 0.2173 \t Acc 94.40 \t AccHead 94.33 \t AccTail 94.90\n",
      "Epoch: [069] \t Loss 0.2111 \t Acc 96.10 \t AccHead 96.06 \t AccTail 96.38\n",
      "Epoch: [070] \t Loss 0.2037 \t Acc 95.80 \t AccHead 95.98 \t AccTail 94.55\n",
      "Epoch: [071] \t Loss 0.1961 \t Acc 95.75 \t AccHead 95.74 \t AccTail 95.85\n",
      "Epoch: [072] \t Loss 0.1877 \t Acc 95.45 \t AccHead 95.38 \t AccTail 95.96\n",
      "Epoch: [073] \t Loss 0.1958 \t Acc 96.26 \t AccHead 96.32 \t AccTail 95.85\n",
      "Epoch: [074] \t Loss 0.1753 \t Acc 96.46 \t AccHead 96.40 \t AccTail 96.84\n",
      "Epoch: [075] \t Loss 0.1856 \t Acc 95.61 \t AccHead 95.61 \t AccTail 95.59\n",
      "Epoch: [076] \t Loss 0.1791 \t Acc 96.65 \t AccHead 96.61 \t AccTail 96.95\n",
      "Epoch: [077] \t Loss 0.1679 \t Acc 96.48 \t AccHead 96.34 \t AccTail 97.53\n",
      "Epoch: [078] \t Loss 0.1589 \t Acc 95.57 \t AccHead 95.62 \t AccTail 95.24\n",
      "Epoch: [079] \t Loss 0.1602 \t Acc 95.92 \t AccHead 95.93 \t AccTail 95.85\n",
      "Epoch: [080] \t Loss 0.1484 \t Acc 97.62 \t AccHead 97.55 \t AccTail 98.13\n",
      "Epoch: [081] \t Loss 0.1384 \t Acc 97.17 \t AccHead 97.18 \t AccTail 97.15\n",
      "Epoch: [082] \t Loss 0.1475 \t Acc 97.02 \t AccHead 96.94 \t AccTail 97.60\n",
      "Epoch: [083] \t Loss 0.1437 \t Acc 96.81 \t AccHead 96.80 \t AccTail 96.88\n",
      "Epoch: [084] \t Loss 0.1298 \t Acc 97.27 \t AccHead 97.20 \t AccTail 97.79\n",
      "Epoch: [085] \t Loss 0.1256 \t Acc 97.72 \t AccHead 97.67 \t AccTail 98.02\n",
      "Epoch: [086] \t Loss 0.1330 \t Acc 96.88 \t AccHead 96.98 \t AccTail 96.19\n",
      "Epoch: [087] \t Loss 0.1313 \t Acc 97.35 \t AccHead 97.29 \t AccTail 97.79\n",
      "Epoch: [088] \t Loss 0.1236 \t Acc 97.73 \t AccHead 97.72 \t AccTail 97.79\n",
      "Epoch: [089] \t Loss 0.1177 \t Acc 97.68 \t AccHead 97.66 \t AccTail 97.83\n",
      "Epoch: [090] \t Loss 0.1129 \t Acc 97.57 \t AccHead 97.55 \t AccTail 97.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 23:54:32,210]\u001b[0m Trial 9 finished with value: 8.665008544921875 and parameters: {'n_epoch': 90, 'weight_decay': 1.4579492292689441e-05}. Best is trial 5 with value: 10.157546043395996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 8.67 \t AccHead 15.15 \t AccTail 2.25\n",
      "Epoch: [001] \t Loss 4.2464 \t Acc 10.14 \t AccHead 10.97 \t AccTail 4.07\n",
      "Epoch: [002] \t Loss 3.7374 \t Acc 13.20 \t AccHead 14.97 \t AccTail 0.30\n",
      "Epoch: [003] \t Loss 3.5416 \t Acc 15.48 \t AccHead 16.84 \t AccTail 5.60\n",
      "Epoch: [004] \t Loss 3.4074 \t Acc 18.43 \t AccHead 20.20 \t AccTail 5.55\n",
      "Epoch: [005] \t Loss 3.2564 \t Acc 22.84 \t AccHead 24.89 \t AccTail 7.92\n",
      "Epoch: [006] \t Loss 3.1027 \t Acc 23.18 \t AccHead 25.22 \t AccTail 8.34\n",
      "Epoch: [007] \t Loss 2.9744 \t Acc 25.88 \t AccHead 28.00 \t AccTail 10.45\n",
      "Epoch: [008] \t Loss 2.8717 \t Acc 28.42 \t AccHead 30.70 \t AccTail 11.76\n",
      "Epoch: [009] \t Loss 2.7757 \t Acc 28.67 \t AccHead 30.87 \t AccTail 12.64\n",
      "Epoch: [010] \t Loss 2.6887 \t Acc 32.86 \t AccHead 35.58 \t AccTail 13.07\n",
      "Epoch: [011] \t Loss 2.6121 \t Acc 32.20 \t AccHead 35.18 \t AccTail 10.50\n",
      "Epoch: [012] \t Loss 2.5455 \t Acc 34.94 \t AccHead 37.60 \t AccTail 15.58\n",
      "Epoch: [013] \t Loss 2.4736 \t Acc 35.50 \t AccHead 38.23 \t AccTail 15.66\n",
      "Epoch: [014] \t Loss 2.4098 \t Acc 37.01 \t AccHead 39.08 \t AccTail 21.91\n",
      "Epoch: [015] \t Loss 2.3296 \t Acc 38.01 \t AccHead 40.13 \t AccTail 22.55\n",
      "Epoch: [016] \t Loss 2.2720 \t Acc 40.57 \t AccHead 42.85 \t AccTail 24.00\n",
      "Epoch: [017] \t Loss 2.2207 \t Acc 42.85 \t AccHead 45.85 \t AccTail 21.06\n",
      "Epoch: [018] \t Loss 2.1595 \t Acc 43.29 \t AccHead 46.04 \t AccTail 23.29\n",
      "Epoch: [019] \t Loss 2.1153 \t Acc 41.08 \t AccHead 43.69 \t AccTail 22.05\n",
      "Epoch: [020] \t Loss 2.0606 \t Acc 45.56 \t AccHead 48.59 \t AccTail 23.46\n",
      "Epoch: [021] \t Loss 2.0106 \t Acc 46.61 \t AccHead 49.44 \t AccTail 25.98\n",
      "Epoch: [022] \t Loss 1.9665 \t Acc 47.78 \t AccHead 50.82 \t AccTail 25.67\n",
      "Epoch: [023] \t Loss 1.9156 \t Acc 48.43 \t AccHead 50.62 \t AccTail 32.51\n",
      "Epoch: [024] \t Loss 1.8767 \t Acc 49.84 \t AccHead 52.79 \t AccTail 28.35\n",
      "Epoch: [025] \t Loss 1.8291 \t Acc 50.36 \t AccHead 52.54 \t AccTail 34.46\n",
      "Epoch: [026] \t Loss 1.7823 \t Acc 51.02 \t AccHead 53.67 \t AccTail 31.77\n",
      "Epoch: [027] \t Loss 1.7423 \t Acc 52.58 \t AccHead 54.97 \t AccTail 35.18\n",
      "Epoch: [028] \t Loss 1.7054 \t Acc 52.59 \t AccHead 55.04 \t AccTail 34.74\n",
      "Epoch: [029] \t Loss 1.6605 \t Acc 55.78 \t AccHead 57.79 \t AccTail 41.16\n",
      "Epoch: [030] \t Loss 1.6353 \t Acc 54.46 \t AccHead 56.84 \t AccTail 37.19\n",
      "Epoch: [031] \t Loss 1.5809 \t Acc 53.13 \t AccHead 55.05 \t AccTail 39.17\n",
      "Epoch: [032] \t Loss 1.5415 \t Acc 57.58 \t AccHead 59.77 \t AccTail 41.58\n",
      "Epoch: [033] \t Loss 1.4975 \t Acc 59.45 \t AccHead 61.54 \t AccTail 44.21\n",
      "Epoch: [034] \t Loss 1.4782 \t Acc 59.64 \t AccHead 61.72 \t AccTail 44.47\n",
      "Epoch: [035] \t Loss 1.4074 \t Acc 59.06 \t AccHead 61.06 \t AccTail 44.51\n",
      "Epoch: [036] \t Loss 1.4011 \t Acc 63.75 \t AccHead 65.74 \t AccTail 49.30\n",
      "Epoch: [037] \t Loss 1.3377 \t Acc 61.68 \t AccHead 63.83 \t AccTail 46.05\n",
      "Epoch: [038] \t Loss 1.3090 \t Acc 63.03 \t AccHead 64.39 \t AccTail 53.08\n",
      "Epoch: [039] \t Loss 1.2816 \t Acc 64.36 \t AccHead 66.26 \t AccTail 50.53\n",
      "Epoch: [040] \t Loss 1.2639 \t Acc 65.45 \t AccHead 67.31 \t AccTail 51.90\n",
      "Epoch: [041] \t Loss 1.2277 \t Acc 63.59 \t AccHead 65.32 \t AccTail 50.99\n",
      "Epoch: [042] \t Loss 1.1827 \t Acc 69.28 \t AccHead 70.88 \t AccTail 57.57\n",
      "Epoch: [043] \t Loss 1.1503 \t Acc 67.53 \t AccHead 68.99 \t AccTail 56.85\n",
      "Epoch: [044] \t Loss 1.1419 \t Acc 70.45 \t AccHead 72.09 \t AccTail 58.42\n",
      "Epoch: [045] \t Loss 1.0833 \t Acc 70.15 \t AccHead 71.39 \t AccTail 61.10\n",
      "Epoch: [046] \t Loss 1.0747 \t Acc 69.67 \t AccHead 71.41 \t AccTail 56.99\n",
      "Epoch: [047] \t Loss 1.0304 \t Acc 73.90 \t AccHead 75.24 \t AccTail 64.07\n",
      "Epoch: [048] \t Loss 1.0109 \t Acc 69.92 \t AccHead 71.26 \t AccTail 60.12\n",
      "Epoch: [049] \t Loss 0.9828 \t Acc 73.78 \t AccHead 74.72 \t AccTail 66.90\n",
      "Epoch: [050] \t Loss 0.9491 \t Acc 73.90 \t AccHead 75.01 \t AccTail 65.80\n",
      "Epoch: [051] \t Loss 0.9469 \t Acc 75.86 \t AccHead 77.03 \t AccTail 67.35\n",
      "Epoch: [052] \t Loss 0.8862 \t Acc 75.79 \t AccHead 77.22 \t AccTail 65.35\n",
      "Epoch: [053] \t Loss 0.8703 \t Acc 74.35 \t AccHead 75.53 \t AccTail 65.70\n",
      "Epoch: [054] \t Loss 0.8693 \t Acc 74.18 \t AccHead 75.07 \t AccTail 67.71\n",
      "Epoch: [055] \t Loss 0.8526 \t Acc 75.75 \t AccHead 76.89 \t AccTail 67.50\n",
      "Epoch: [056] \t Loss 0.8327 \t Acc 76.48 \t AccHead 77.55 \t AccTail 68.63\n",
      "Epoch: [057] \t Loss 0.8222 \t Acc 77.60 \t AccHead 78.57 \t AccTail 70.52\n",
      "Epoch: [058] \t Loss 0.7808 \t Acc 79.07 \t AccHead 80.31 \t AccTail 70.03\n",
      "Epoch: [059] \t Loss 0.7496 \t Acc 72.35 \t AccHead 73.16 \t AccTail 66.48\n",
      "Epoch: [060] \t Loss 0.7479 \t Acc 78.41 \t AccHead 78.76 \t AccTail 75.85\n",
      "Epoch: [061] \t Loss 0.7493 \t Acc 80.02 \t AccHead 80.70 \t AccTail 75.10\n",
      "Epoch: [062] \t Loss 0.7421 \t Acc 79.37 \t AccHead 80.03 \t AccTail 74.56\n",
      "Epoch: [063] \t Loss 0.7272 \t Acc 79.56 \t AccHead 79.99 \t AccTail 76.42\n",
      "Epoch: [064] \t Loss 0.7078 \t Acc 78.97 \t AccHead 79.60 \t AccTail 74.35\n",
      "Epoch: [065] \t Loss 0.6959 \t Acc 78.42 \t AccHead 78.85 \t AccTail 75.26\n",
      "Epoch: [066] \t Loss 0.6832 \t Acc 80.33 \t AccHead 81.05 \t AccTail 75.12\n",
      "Epoch: [067] \t Loss 0.6717 \t Acc 80.99 \t AccHead 81.02 \t AccTail 80.79\n",
      "Epoch: [068] \t Loss 0.6640 \t Acc 83.43 \t AccHead 84.06 \t AccTail 78.88\n",
      "Epoch: [069] \t Loss 0.6502 \t Acc 81.34 \t AccHead 81.67 \t AccTail 78.91\n",
      "Epoch: [070] \t Loss 0.6278 \t Acc 79.60 \t AccHead 80.39 \t AccTail 73.83\n",
      "Epoch: [071] \t Loss 0.6348 \t Acc 82.25 \t AccHead 82.51 \t AccTail 80.30\n",
      "Epoch: [072] \t Loss 0.6296 \t Acc 80.85 \t AccHead 81.29 \t AccTail 77.63\n",
      "Epoch: [073] \t Loss 0.6157 \t Acc 80.34 \t AccHead 80.56 \t AccTail 78.80\n",
      "Epoch: [074] \t Loss 0.6063 \t Acc 83.25 \t AccHead 83.48 \t AccTail 81.63\n",
      "Epoch: [075] \t Loss 0.6016 \t Acc 82.39 \t AccHead 82.71 \t AccTail 80.11\n",
      "Epoch: [076] \t Loss 0.5919 \t Acc 83.57 \t AccHead 83.91 \t AccTail 81.05\n",
      "Epoch: [077] \t Loss 0.5869 \t Acc 83.56 \t AccHead 84.34 \t AccTail 77.87\n",
      "Epoch: [078] \t Loss 0.5708 \t Acc 85.72 \t AccHead 85.89 \t AccTail 84.47\n",
      "Epoch: [079] \t Loss 0.5868 \t Acc 86.21 \t AccHead 86.46 \t AccTail 84.45\n",
      "Epoch: [080] \t Loss 0.5560 \t Acc 84.32 \t AccHead 84.53 \t AccTail 82.86\n",
      "Epoch: [081] \t Loss 0.5924 \t Acc 80.23 \t AccHead 80.63 \t AccTail 77.38\n",
      "Epoch: [082] \t Loss 0.5816 \t Acc 82.30 \t AccHead 82.58 \t AccTail 80.27\n",
      "Epoch: [083] \t Loss 0.5332 \t Acc 84.14 \t AccHead 84.03 \t AccTail 84.96\n",
      "Epoch: [084] \t Loss 0.5617 \t Acc 84.18 \t AccHead 84.82 \t AccTail 79.47\n",
      "Epoch: [085] \t Loss 0.5444 \t Acc 82.63 \t AccHead 82.89 \t AccTail 80.72\n",
      "Epoch: [086] \t Loss 0.5540 \t Acc 84.31 \t AccHead 84.51 \t AccTail 82.84\n",
      "Epoch: [087] \t Loss 0.5484 \t Acc 83.61 \t AccHead 83.78 \t AccTail 82.40\n",
      "Epoch: [088] \t Loss 0.5372 \t Acc 86.46 \t AccHead 86.60 \t AccTail 85.40\n",
      "Epoch: [089] \t Loss 0.5140 \t Acc 83.75 \t AccHead 84.11 \t AccTail 81.13\n",
      "Epoch: [090] \t Loss 0.5648 \t Acc 84.03 \t AccHead 84.44 \t AccTail 81.01\n",
      "Epoch: [091] \t Loss 0.5462 \t Acc 84.66 \t AccHead 84.95 \t AccTail 82.49\n",
      "Epoch: [092] \t Loss 0.5208 \t Acc 85.00 \t AccHead 85.44 \t AccTail 81.80\n",
      "Epoch: [093] \t Loss 0.5227 \t Acc 85.72 \t AccHead 86.23 \t AccTail 81.98\n",
      "Epoch: [094] \t Loss 0.5223 \t Acc 86.17 \t AccHead 86.72 \t AccTail 82.14\n",
      "Epoch: [095] \t Loss 0.4964 \t Acc 87.23 \t AccHead 87.61 \t AccTail 84.46\n",
      "Epoch: [096] \t Loss 0.4962 \t Acc 83.53 \t AccHead 83.76 \t AccTail 81.87\n",
      "Epoch: [097] \t Loss 0.5034 \t Acc 84.20 \t AccHead 84.59 \t AccTail 81.36\n",
      "Epoch: [098] \t Loss 0.5026 \t Acc 84.60 \t AccHead 85.08 \t AccTail 81.11\n",
      "Epoch: [099] \t Loss 0.5139 \t Acc 86.71 \t AccHead 86.79 \t AccTail 86.13\n",
      "Epoch: [100] \t Loss 0.4842 \t Acc 83.97 \t AccHead 84.34 \t AccTail 81.23\n",
      "Epoch: [101] \t Loss 0.5107 \t Acc 84.52 \t AccHead 84.57 \t AccTail 84.12\n",
      "Epoch: [102] \t Loss 0.4911 \t Acc 85.87 \t AccHead 85.99 \t AccTail 85.01\n",
      "Epoch: [103] \t Loss 0.4901 \t Acc 82.85 \t AccHead 83.48 \t AccTail 78.27\n",
      "Epoch: [104] \t Loss 0.4973 \t Acc 85.09 \t AccHead 85.31 \t AccTail 83.44\n",
      "Epoch: [105] \t Loss 0.4966 \t Acc 84.99 \t AccHead 85.45 \t AccTail 81.69\n",
      "Epoch: [106] \t Loss 0.5142 \t Acc 84.93 \t AccHead 85.42 \t AccTail 81.33\n",
      "Epoch: [107] \t Loss 0.5056 \t Acc 85.39 \t AccHead 85.88 \t AccTail 81.80\n",
      "Epoch: [108] \t Loss 0.4583 \t Acc 88.21 \t AccHead 88.37 \t AccTail 87.08\n",
      "Epoch: [109] \t Loss 0.4976 \t Acc 84.70 \t AccHead 85.19 \t AccTail 81.09\n",
      "Epoch: [110] \t Loss 0.4693 \t Acc 87.03 \t AccHead 87.47 \t AccTail 83.80\n",
      "Epoch: [111] \t Loss 0.4703 \t Acc 87.52 \t AccHead 87.60 \t AccTail 86.99\n",
      "Epoch: [112] \t Loss 0.4666 \t Acc 87.18 \t AccHead 87.33 \t AccTail 86.10\n",
      "Epoch: [113] \t Loss 0.4593 \t Acc 87.19 \t AccHead 87.34 \t AccTail 86.14\n",
      "Epoch: [114] \t Loss 0.4908 \t Acc 85.53 \t AccHead 86.06 \t AccTail 81.66\n",
      "Epoch: [115] \t Loss 0.4741 \t Acc 84.80 \t AccHead 84.86 \t AccTail 84.36\n",
      "Epoch: [116] \t Loss 0.5011 \t Acc 87.67 \t AccHead 88.02 \t AccTail 85.11\n",
      "Epoch: [117] \t Loss 0.4530 \t Acc 86.58 \t AccHead 86.54 \t AccTail 86.85\n",
      "Epoch: [118] \t Loss 0.4754 \t Acc 85.76 \t AccHead 85.83 \t AccTail 85.27\n",
      "Epoch: [119] \t Loss 0.4776 \t Acc 88.35 \t AccHead 88.61 \t AccTail 86.49\n",
      "Epoch: [120] \t Loss 0.4560 \t Acc 86.34 \t AccHead 86.47 \t AccTail 85.39\n",
      "Epoch: [121] \t Loss 0.4885 \t Acc 83.78 \t AccHead 84.07 \t AccTail 81.68\n",
      "Epoch: [122] \t Loss 0.4493 \t Acc 86.99 \t AccHead 87.19 \t AccTail 85.53\n",
      "Epoch: [123] \t Loss 0.4409 \t Acc 86.81 \t AccHead 86.97 \t AccTail 85.62\n",
      "Epoch: [124] \t Loss 0.4500 \t Acc 84.60 \t AccHead 85.33 \t AccTail 79.31\n",
      "Epoch: [125] \t Loss 0.4542 \t Acc 84.60 \t AccHead 85.17 \t AccTail 80.43\n",
      "Epoch: [126] \t Loss 0.4761 \t Acc 85.39 \t AccHead 85.57 \t AccTail 84.06\n",
      "Epoch: [127] \t Loss 0.4812 \t Acc 88.45 \t AccHead 88.72 \t AccTail 86.44\n",
      "Epoch: [128] \t Loss 0.4673 \t Acc 87.85 \t AccHead 88.37 \t AccTail 84.04\n",
      "Epoch: [129] \t Loss 0.4430 \t Acc 86.11 \t AccHead 86.18 \t AccTail 85.57\n",
      "Epoch: [130] \t Loss 0.4627 \t Acc 87.43 \t AccHead 87.38 \t AccTail 87.81\n",
      "Epoch: [131] \t Loss 0.4128 \t Acc 86.59 \t AccHead 86.38 \t AccTail 88.09\n",
      "Epoch: [132] \t Loss 0.4554 \t Acc 86.59 \t AccHead 87.00 \t AccTail 83.63\n",
      "Epoch: [133] \t Loss 0.4499 \t Acc 86.01 \t AccHead 86.10 \t AccTail 85.33\n",
      "Epoch: [134] \t Loss 0.4591 \t Acc 89.22 \t AccHead 89.27 \t AccTail 88.82\n",
      "Epoch: [135] \t Loss 0.4441 \t Acc 86.46 \t AccHead 86.66 \t AccTail 84.95\n",
      "Epoch: [136] \t Loss 0.4027 \t Acc 88.44 \t AccHead 88.43 \t AccTail 88.47\n",
      "Epoch: [137] \t Loss 0.4485 \t Acc 86.42 \t AccHead 86.54 \t AccTail 85.60\n",
      "Epoch: [138] \t Loss 0.4544 \t Acc 88.39 \t AccHead 88.60 \t AccTail 86.91\n",
      "Epoch: [139] \t Loss 0.4239 \t Acc 87.36 \t AccHead 87.51 \t AccTail 86.30\n",
      "Epoch: [140] \t Loss 0.4430 \t Acc 88.50 \t AccHead 88.60 \t AccTail 87.76\n",
      "Epoch: [141] \t Loss 0.4543 \t Acc 87.61 \t AccHead 87.78 \t AccTail 86.34\n",
      "Epoch: [142] \t Loss 0.4408 \t Acc 88.77 \t AccHead 89.23 \t AccTail 85.44\n",
      "Epoch: [143] \t Loss 0.4312 \t Acc 87.89 \t AccHead 88.41 \t AccTail 84.10\n",
      "Epoch: [144] \t Loss 0.4372 \t Acc 87.72 \t AccHead 87.82 \t AccTail 86.93\n",
      "Epoch: [145] \t Loss 0.4195 \t Acc 88.25 \t AccHead 88.45 \t AccTail 86.83\n",
      "Epoch: [146] \t Loss 0.4406 \t Acc 85.31 \t AccHead 85.11 \t AccTail 86.78\n",
      "Epoch: [147] \t Loss 0.4178 \t Acc 88.44 \t AccHead 88.74 \t AccTail 86.20\n",
      "Epoch: [148] \t Loss 0.4147 \t Acc 82.69 \t AccHead 82.97 \t AccTail 80.68\n",
      "Epoch: [149] \t Loss 0.4656 \t Acc 83.06 \t AccHead 83.38 \t AccTail 80.67\n",
      "Epoch: [150] \t Loss 0.4383 \t Acc 87.80 \t AccHead 87.71 \t AccTail 88.45\n",
      "Epoch: [151] \t Loss 0.1925 \t Acc 98.23 \t AccHead 98.18 \t AccTail 98.55\n",
      "Epoch: [152] \t Loss 0.0921 \t Acc 99.00 \t AccHead 98.93 \t AccTail 99.47\n",
      "Epoch: [153] \t Loss 0.0694 \t Acc 99.29 \t AccHead 99.25 \t AccTail 99.54\n",
      "Epoch: [154] \t Loss 0.0555 \t Acc 99.45 \t AccHead 99.41 \t AccTail 99.73\n",
      "Epoch: [155] \t Loss 0.0496 \t Acc 99.60 \t AccHead 99.57 \t AccTail 99.81\n",
      "Epoch: [156] \t Loss 0.0446 \t Acc 99.60 \t AccHead 99.57 \t AccTail 99.85\n",
      "Epoch: [157] \t Loss 0.0382 \t Acc 99.63 \t AccHead 99.60 \t AccTail 99.85\n",
      "Epoch: [158] \t Loss 0.0350 \t Acc 99.70 \t AccHead 99.67 \t AccTail 99.89\n",
      "Epoch: [159] \t Loss 0.0315 \t Acc 99.69 \t AccHead 99.65 \t AccTail 99.96\n",
      "Epoch: [160] \t Loss 0.0298 \t Acc 99.77 \t AccHead 99.74 \t AccTail 99.96\n",
      "Epoch: [161] \t Loss 0.0285 \t Acc 99.79 \t AccHead 99.78 \t AccTail 99.85\n",
      "Epoch: [162] \t Loss 0.0268 \t Acc 99.77 \t AccHead 99.74 \t AccTail 99.92\n",
      "Epoch: [163] \t Loss 0.0260 \t Acc 99.80 \t AccHead 99.78 \t AccTail 99.96\n",
      "Epoch: [164] \t Loss 0.0250 \t Acc 99.76 \t AccHead 99.75 \t AccTail 99.85\n",
      "Epoch: [165] \t Loss 0.0240 \t Acc 99.82 \t AccHead 99.80 \t AccTail 99.96\n",
      "Epoch: [166] \t Loss 0.0230 \t Acc 99.84 \t AccHead 99.83 \t AccTail 99.92\n",
      "Epoch: [167] \t Loss 0.0224 \t Acc 99.85 \t AccHead 99.83 \t AccTail 99.96\n",
      "Epoch: [168] \t Loss 0.0213 \t Acc 99.83 \t AccHead 99.81 \t AccTail 99.96\n",
      "Epoch: [169] \t Loss 0.0199 \t Acc 99.83 \t AccHead 99.82 \t AccTail 99.92\n",
      "Epoch: [170] \t Loss 0.0195 \t Acc 99.83 \t AccHead 99.82 \t AccTail 99.92\n",
      "Epoch: [171] \t Loss 0.0182 \t Acc 99.86 \t AccHead 99.84 \t AccTail 99.96\n",
      "Epoch: [172] \t Loss 0.0180 \t Acc 99.91 \t AccHead 99.90 \t AccTail 99.96\n",
      "Epoch: [173] \t Loss 0.0178 \t Acc 99.87 \t AccHead 99.86 \t AccTail 99.92\n",
      "Epoch: [174] \t Loss 0.0182 \t Acc 99.84 \t AccHead 99.83 \t AccTail 99.96\n",
      "Epoch: [175] \t Loss 0.0173 \t Acc 99.89 \t AccHead 99.89 \t AccTail 99.92\n",
      "Epoch: [176] \t Loss 0.0161 \t Acc 99.86 \t AccHead 99.85 \t AccTail 99.92\n",
      "Epoch: [177] \t Loss 0.0155 \t Acc 99.92 \t AccHead 99.91 \t AccTail 99.96\n",
      "Epoch: [178] \t Loss 0.0169 \t Acc 99.88 \t AccHead 99.87 \t AccTail 99.96\n",
      "Epoch: [179] \t Loss 0.0156 \t Acc 99.88 \t AccHead 99.87 \t AccTail 99.96\n",
      "Epoch: [180] \t Loss 0.0157 \t Acc 99.86 \t AccHead 99.85 \t AccTail 99.96\n",
      "Epoch: [181] \t Loss 0.0153 \t Acc 99.88 \t AccHead 99.86 \t AccTail 99.96\n",
      "Epoch: [182] \t Loss 0.0152 \t Acc 99.93 \t AccHead 99.93 \t AccTail 99.92\n",
      "Epoch: [183] \t Loss 0.0143 \t Acc 99.91 \t AccHead 99.90 \t AccTail 99.96\n",
      "Epoch: [184] \t Loss 0.0150 \t Acc 99.89 \t AccHead 99.88 \t AccTail 99.92\n",
      "Epoch: [185] \t Loss 0.0147 \t Acc 99.94 \t AccHead 99.93 \t AccTail 100.00\n",
      "Epoch: [186] \t Loss 0.0143 \t Acc 99.92 \t AccHead 99.92 \t AccTail 99.92\n",
      "Epoch: [187] \t Loss 0.0136 \t Acc 99.94 \t AccHead 99.93 \t AccTail 99.96\n",
      "Epoch: [188] \t Loss 0.0138 \t Acc 99.91 \t AccHead 99.90 \t AccTail 99.96\n",
      "Epoch: [189] \t Loss 0.0135 \t Acc 99.93 \t AccHead 99.92 \t AccTail 100.00\n",
      "Epoch: [190] \t Loss 0.0134 \t Acc 99.92 \t AccHead 99.91 \t AccTail 100.00\n",
      "Epoch: [191] \t Loss 0.0131 \t Acc 99.90 \t AccHead 99.90 \t AccTail 99.96\n",
      "Epoch: [192] \t Loss 0.0129 \t Acc 99.89 \t AccHead 99.88 \t AccTail 99.96\n",
      "Epoch: [193] \t Loss 0.0128 \t Acc 99.93 \t AccHead 99.92 \t AccTail 100.00\n",
      "Epoch: [194] \t Loss 0.0127 \t Acc 99.92 \t AccHead 99.91 \t AccTail 100.00\n",
      "Epoch: [195] \t Loss 0.0132 \t Acc 99.89 \t AccHead 99.89 \t AccTail 99.96\n",
      "Epoch: [196] \t Loss 0.0121 \t Acc 99.93 \t AccHead 99.92 \t AccTail 99.96\n",
      "Epoch: [197] \t Loss 0.0122 \t Acc 99.94 \t AccHead 99.94 \t AccTail 99.96\n",
      "Epoch: [198] \t Loss 0.0123 \t Acc 99.93 \t AccHead 99.92 \t AccTail 100.00\n",
      "Epoch: [199] \t Loss 0.0121 \t Acc 99.94 \t AccHead 99.94 \t AccTail 99.96\n",
      "Epoch: [200] \t Loss 0.0124 \t Acc 99.92 \t AccHead 99.91 \t AccTail 100.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 00:31:05,343]\u001b[0m Trial 10 finished with value: 9.670397758483887 and parameters: {'n_epoch': 200, 'weight_decay': 0.00021123599820854373}. Best is trial 5 with value: 10.157546043395996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 9.67 \t AccHead 16.81 \t AccTail 2.60\n",
      "Epoch: [001] \t Loss 4.2221 \t Acc 10.03 \t AccHead 11.06 \t AccTail 2.56\n",
      "Epoch: [002] \t Loss 3.7014 \t Acc 13.75 \t AccHead 15.03 \t AccTail 4.41\n",
      "Epoch: [003] \t Loss 3.5060 \t Acc 15.57 \t AccHead 17.07 \t AccTail 4.68\n",
      "Epoch: [004] \t Loss 3.3602 \t Acc 17.91 \t AccHead 19.11 \t AccTail 9.20\n",
      "Epoch: [005] \t Loss 3.2443 \t Acc 21.97 \t AccHead 23.89 \t AccTail 8.00\n",
      "Epoch: [006] \t Loss 3.1303 \t Acc 24.72 \t AccHead 27.12 \t AccTail 7.22\n",
      "Epoch: [007] \t Loss 3.0099 \t Acc 25.32 \t AccHead 28.19 \t AccTail 4.42\n",
      "Epoch: [008] \t Loss 2.9230 \t Acc 26.57 \t AccHead 28.68 \t AccTail 11.18\n",
      "Epoch: [009] \t Loss 2.8203 \t Acc 28.13 \t AccHead 30.80 \t AccTail 8.72\n",
      "Epoch: [010] \t Loss 2.7436 \t Acc 31.14 \t AccHead 34.02 \t AccTail 10.20\n",
      "Epoch: [011] \t Loss 2.6732 \t Acc 31.85 \t AccHead 34.59 \t AccTail 11.91\n",
      "Epoch: [012] \t Loss 2.6036 \t Acc 32.48 \t AccHead 35.26 \t AccTail 12.22\n",
      "Epoch: [013] \t Loss 2.5405 \t Acc 34.31 \t AccHead 37.57 \t AccTail 10.55\n",
      "Epoch: [014] \t Loss 2.5006 \t Acc 34.42 \t AccHead 37.17 \t AccTail 14.37\n",
      "Epoch: [015] \t Loss 2.4505 \t Acc 36.01 \t AccHead 39.09 \t AccTail 13.58\n",
      "Epoch: [016] \t Loss 2.3863 \t Acc 38.04 \t AccHead 40.72 \t AccTail 18.53\n",
      "Epoch: [017] \t Loss 2.3622 \t Acc 37.99 \t AccHead 40.89 \t AccTail 16.88\n",
      "Epoch: [018] \t Loss 2.3228 \t Acc 37.16 \t AccHead 40.10 \t AccTail 15.77\n",
      "Epoch: [019] \t Loss 2.2785 \t Acc 37.22 \t AccHead 39.86 \t AccTail 17.93\n",
      "Epoch: [020] \t Loss 2.2376 \t Acc 37.69 \t AccHead 40.77 \t AccTail 15.26\n",
      "Epoch: [021] \t Loss 2.2364 \t Acc 38.07 \t AccHead 40.89 \t AccTail 17.53\n",
      "Epoch: [022] \t Loss 2.1837 \t Acc 43.06 \t AccHead 45.95 \t AccTail 22.00\n",
      "Epoch: [023] \t Loss 2.1488 \t Acc 40.19 \t AccHead 43.39 \t AccTail 16.88\n",
      "Epoch: [024] \t Loss 2.1185 \t Acc 43.97 \t AccHead 46.82 \t AccTail 23.29\n",
      "Epoch: [025] \t Loss 2.1031 \t Acc 40.94 \t AccHead 43.91 \t AccTail 19.27\n",
      "Epoch: [026] \t Loss 2.0753 \t Acc 44.53 \t AccHead 47.53 \t AccTail 22.68\n",
      "Epoch: [027] \t Loss 2.0450 \t Acc 41.66 \t AccHead 44.63 \t AccTail 20.03\n",
      "Epoch: [028] \t Loss 2.0315 \t Acc 45.15 \t AccHead 47.96 \t AccTail 24.65\n",
      "Epoch: [029] \t Loss 2.0125 \t Acc 46.35 \t AccHead 48.79 \t AccTail 28.61\n",
      "Epoch: [030] \t Loss 1.9779 \t Acc 45.01 \t AccHead 47.84 \t AccTail 24.41\n",
      "Epoch: [031] \t Loss 1.9484 \t Acc 44.40 \t AccHead 46.89 \t AccTail 26.23\n",
      "Epoch: [032] \t Loss 1.9255 \t Acc 47.35 \t AccHead 50.02 \t AccTail 27.93\n",
      "Epoch: [033] \t Loss 1.9170 \t Acc 46.33 \t AccHead 49.30 \t AccTail 24.66\n",
      "Epoch: [034] \t Loss 1.9029 \t Acc 50.50 \t AccHead 53.02 \t AccTail 32.17\n",
      "Epoch: [035] \t Loss 1.8611 \t Acc 50.35 \t AccHead 52.97 \t AccTail 31.32\n",
      "Epoch: [036] \t Loss 1.8431 \t Acc 47.47 \t AccHead 50.17 \t AccTail 27.75\n",
      "Epoch: [037] \t Loss 1.8315 \t Acc 48.82 \t AccHead 51.77 \t AccTail 27.31\n",
      "Epoch: [038] \t Loss 1.8103 \t Acc 47.24 \t AccHead 50.70 \t AccTail 22.04\n",
      "Epoch: [039] \t Loss 1.8146 \t Acc 50.81 \t AccHead 53.80 \t AccTail 28.96\n",
      "Epoch: [040] \t Loss 1.7711 \t Acc 51.10 \t AccHead 54.02 \t AccTail 29.87\n",
      "Epoch: [041] \t Loss 1.7533 \t Acc 51.25 \t AccHead 53.78 \t AccTail 32.88\n",
      "Epoch: [042] \t Loss 1.7498 \t Acc 51.32 \t AccHead 53.63 \t AccTail 34.46\n",
      "Epoch: [043] \t Loss 1.7162 \t Acc 51.07 \t AccHead 53.45 \t AccTail 33.69\n",
      "Epoch: [044] \t Loss 1.7070 \t Acc 50.47 \t AccHead 52.30 \t AccTail 37.20\n",
      "Epoch: [045] \t Loss 1.7082 \t Acc 53.04 \t AccHead 55.48 \t AccTail 35.25\n",
      "Epoch: [046] \t Loss 1.6760 \t Acc 53.81 \t AccHead 56.63 \t AccTail 33.19\n",
      "Epoch: [047] \t Loss 1.6564 \t Acc 55.36 \t AccHead 57.85 \t AccTail 37.29\n",
      "Epoch: [048] \t Loss 1.6425 \t Acc 54.82 \t AccHead 57.11 \t AccTail 38.15\n",
      "Epoch: [049] \t Loss 1.6417 \t Acc 54.31 \t AccHead 56.46 \t AccTail 38.60\n",
      "Epoch: [050] \t Loss 1.6195 \t Acc 54.49 \t AccHead 56.75 \t AccTail 38.04\n",
      "Epoch: [051] \t Loss 1.5864 \t Acc 55.76 \t AccHead 58.00 \t AccTail 39.49\n",
      "Epoch: [052] \t Loss 1.5706 \t Acc 56.15 \t AccHead 58.41 \t AccTail 39.70\n",
      "Epoch: [053] \t Loss 1.5623 \t Acc 55.85 \t AccHead 58.34 \t AccTail 37.73\n",
      "Epoch: [054] \t Loss 1.5579 \t Acc 55.66 \t AccHead 58.17 \t AccTail 37.32\n",
      "Epoch: [055] \t Loss 1.5456 \t Acc 57.56 \t AccHead 60.01 \t AccTail 39.73\n",
      "Epoch: [056] \t Loss 1.5051 \t Acc 57.00 \t AccHead 59.34 \t AccTail 39.98\n",
      "Epoch: [057] \t Loss 1.5013 \t Acc 58.75 \t AccHead 61.20 \t AccTail 40.91\n",
      "Epoch: [058] \t Loss 1.4863 \t Acc 60.80 \t AccHead 62.82 \t AccTail 46.10\n",
      "Epoch: [059] \t Loss 1.4730 \t Acc 58.44 \t AccHead 59.89 \t AccTail 47.83\n",
      "Epoch: [060] \t Loss 1.4765 \t Acc 55.68 \t AccHead 57.78 \t AccTail 40.37\n",
      "Epoch: [061] \t Loss 1.4644 \t Acc 60.97 \t AccHead 63.08 \t AccTail 45.57\n",
      "Epoch: [062] \t Loss 1.4658 \t Acc 58.55 \t AccHead 60.96 \t AccTail 41.00\n",
      "Epoch: [063] \t Loss 1.4299 \t Acc 58.98 \t AccHead 61.64 \t AccTail 39.63\n",
      "Epoch: [064] \t Loss 1.4225 \t Acc 56.25 \t AccHead 57.93 \t AccTail 44.03\n",
      "Epoch: [065] \t Loss 1.4115 \t Acc 58.72 \t AccHead 60.53 \t AccTail 45.51\n",
      "Epoch: [066] \t Loss 1.4017 \t Acc 61.46 \t AccHead 63.95 \t AccTail 43.36\n",
      "Epoch: [067] \t Loss 1.3898 \t Acc 60.99 \t AccHead 63.53 \t AccTail 42.53\n",
      "Epoch: [068] \t Loss 1.3607 \t Acc 60.42 \t AccHead 62.52 \t AccTail 45.18\n",
      "Epoch: [069] \t Loss 1.3645 \t Acc 64.04 \t AccHead 65.96 \t AccTail 50.08\n",
      "Epoch: [070] \t Loss 1.3520 \t Acc 63.57 \t AccHead 64.91 \t AccTail 53.82\n",
      "Epoch: [071] \t Loss 1.3450 \t Acc 60.63 \t AccHead 61.77 \t AccTail 52.34\n",
      "Epoch: [072] \t Loss 1.3098 \t Acc 63.07 \t AccHead 64.56 \t AccTail 52.23\n",
      "Epoch: [073] \t Loss 1.3154 \t Acc 59.39 \t AccHead 61.25 \t AccTail 45.85\n",
      "Epoch: [074] \t Loss 1.3057 \t Acc 61.18 \t AccHead 62.41 \t AccTail 52.21\n",
      "Epoch: [075] \t Loss 1.2981 \t Acc 63.84 \t AccHead 65.68 \t AccTail 50.46\n",
      "Epoch: [076] \t Loss 1.2941 \t Acc 62.23 \t AccHead 64.08 \t AccTail 48.74\n",
      "Epoch: [077] \t Loss 1.2981 \t Acc 64.66 \t AccHead 66.01 \t AccTail 54.83\n",
      "Epoch: [078] \t Loss 1.2680 \t Acc 63.36 \t AccHead 65.31 \t AccTail 49.24\n",
      "Epoch: [079] \t Loss 1.2717 \t Acc 63.53 \t AccHead 65.52 \t AccTail 49.05\n",
      "Epoch: [080] \t Loss 1.2557 \t Acc 61.67 \t AccHead 62.83 \t AccTail 53.18\n",
      "Epoch: [081] \t Loss 1.2450 \t Acc 63.52 \t AccHead 65.41 \t AccTail 49.71\n",
      "Epoch: [082] \t Loss 1.2451 \t Acc 63.41 \t AccHead 65.10 \t AccTail 51.16\n",
      "Epoch: [083] \t Loss 1.2373 \t Acc 64.65 \t AccHead 66.28 \t AccTail 52.78\n",
      "Epoch: [084] \t Loss 1.2211 \t Acc 63.02 \t AccHead 64.45 \t AccTail 52.61\n",
      "Epoch: [085] \t Loss 1.2273 \t Acc 64.24 \t AccHead 65.55 \t AccTail 54.68\n",
      "Epoch: [086] \t Loss 1.2219 \t Acc 62.47 \t AccHead 64.44 \t AccTail 48.12\n",
      "Epoch: [087] \t Loss 1.2067 \t Acc 61.89 \t AccHead 63.14 \t AccTail 52.80\n",
      "Epoch: [088] \t Loss 1.2064 \t Acc 65.31 \t AccHead 67.05 \t AccTail 52.66\n",
      "Epoch: [089] \t Loss 1.2064 \t Acc 66.06 \t AccHead 67.44 \t AccTail 56.03\n",
      "Epoch: [090] \t Loss 1.1588 \t Acc 64.57 \t AccHead 65.97 \t AccTail 54.33\n",
      "Epoch: [091] \t Loss 1.1909 \t Acc 65.82 \t AccHead 67.01 \t AccTail 57.12\n",
      "Epoch: [092] \t Loss 1.1700 \t Acc 65.38 \t AccHead 66.72 \t AccTail 55.66\n",
      "Epoch: [093] \t Loss 1.1444 \t Acc 68.94 \t AccHead 70.27 \t AccTail 59.29\n",
      "Epoch: [094] \t Loss 1.1992 \t Acc 64.85 \t AccHead 66.31 \t AccTail 54.22\n",
      "Epoch: [095] \t Loss 1.1557 \t Acc 65.58 \t AccHead 67.18 \t AccTail 53.94\n",
      "Epoch: [096] \t Loss 1.1553 \t Acc 65.71 \t AccHead 66.56 \t AccTail 59.51\n",
      "Epoch: [097] \t Loss 1.1473 \t Acc 67.94 \t AccHead 69.74 \t AccTail 54.84\n",
      "Epoch: [098] \t Loss 1.1514 \t Acc 68.00 \t AccHead 69.48 \t AccTail 57.15\n",
      "Epoch: [099] \t Loss 1.1430 \t Acc 67.00 \t AccHead 67.95 \t AccTail 60.09\n",
      "Epoch: [100] \t Loss 1.1333 \t Acc 70.73 \t AccHead 71.57 \t AccTail 64.57\n",
      "Epoch: [101] \t Loss 1.1044 \t Acc 71.59 \t AccHead 72.84 \t AccTail 62.44\n",
      "Epoch: [102] \t Loss 1.1214 \t Acc 65.17 \t AccHead 66.35 \t AccTail 56.57\n",
      "Epoch: [103] \t Loss 1.1110 \t Acc 67.05 \t AccHead 68.21 \t AccTail 58.57\n",
      "Epoch: [104] \t Loss 1.1139 \t Acc 60.76 \t AccHead 61.52 \t AccTail 55.28\n",
      "Epoch: [105] \t Loss 1.1227 \t Acc 67.45 \t AccHead 68.58 \t AccTail 59.22\n",
      "Epoch: [106] \t Loss 1.1144 \t Acc 69.87 \t AccHead 70.92 \t AccTail 62.19\n",
      "Epoch: [107] \t Loss 1.0960 \t Acc 68.10 \t AccHead 68.96 \t AccTail 61.81\n",
      "Epoch: [108] \t Loss 1.1095 \t Acc 64.92 \t AccHead 66.91 \t AccTail 50.40\n",
      "Epoch: [109] \t Loss 1.0905 \t Acc 65.98 \t AccHead 66.81 \t AccTail 59.94\n",
      "Epoch: [110] \t Loss 1.0943 \t Acc 63.35 \t AccHead 64.45 \t AccTail 55.30\n",
      "Epoch: [111] \t Loss 1.0868 \t Acc 67.04 \t AccHead 68.24 \t AccTail 58.31\n",
      "Epoch: [112] \t Loss 1.0613 \t Acc 68.07 \t AccHead 68.99 \t AccTail 61.35\n",
      "Epoch: [113] \t Loss 1.0822 \t Acc 70.47 \t AccHead 71.43 \t AccTail 63.46\n",
      "Epoch: [114] \t Loss 1.0478 \t Acc 66.82 \t AccHead 67.82 \t AccTail 59.52\n",
      "Epoch: [115] \t Loss 1.0693 \t Acc 69.74 \t AccHead 70.82 \t AccTail 61.88\n",
      "Epoch: [116] \t Loss 1.0665 \t Acc 68.18 \t AccHead 69.60 \t AccTail 57.82\n",
      "Epoch: [117] \t Loss 1.0782 \t Acc 65.67 \t AccHead 66.72 \t AccTail 58.03\n",
      "Epoch: [118] \t Loss 1.0840 \t Acc 64.78 \t AccHead 65.07 \t AccTail 62.66\n",
      "Epoch: [119] \t Loss 1.0557 \t Acc 68.86 \t AccHead 69.96 \t AccTail 60.89\n",
      "Epoch: [120] \t Loss 1.0432 \t Acc 68.16 \t AccHead 69.67 \t AccTail 57.09\n",
      "Epoch: [121] \t Loss 1.0188 \t Acc 70.60 \t AccHead 71.81 \t AccTail 61.79\n",
      "Epoch: [122] \t Loss 1.0454 \t Acc 69.36 \t AccHead 70.34 \t AccTail 62.22\n",
      "Epoch: [123] \t Loss 1.0502 \t Acc 64.03 \t AccHead 64.66 \t AccTail 59.39\n",
      "Epoch: [124] \t Loss 1.0324 \t Acc 70.41 \t AccHead 71.07 \t AccTail 65.60\n",
      "Epoch: [125] \t Loss 1.0405 \t Acc 69.72 \t AccHead 71.03 \t AccTail 60.12\n",
      "Epoch: [126] \t Loss 1.0282 \t Acc 64.45 \t AccHead 65.47 \t AccTail 57.04\n",
      "Epoch: [127] \t Loss 1.0384 \t Acc 69.97 \t AccHead 71.22 \t AccTail 60.85\n",
      "Epoch: [128] \t Loss 1.0488 \t Acc 67.13 \t AccHead 67.52 \t AccTail 64.24\n",
      "Epoch: [129] \t Loss 1.0538 \t Acc 67.94 \t AccHead 68.60 \t AccTail 63.08\n",
      "Epoch: [130] \t Loss 1.0086 \t Acc 71.08 \t AccHead 72.21 \t AccTail 62.93\n",
      "Epoch: [131] \t Loss 1.0293 \t Acc 67.03 \t AccHead 67.22 \t AccTail 65.63\n",
      "Epoch: [132] \t Loss 1.0216 \t Acc 71.15 \t AccHead 72.19 \t AccTail 63.57\n",
      "Epoch: [133] \t Loss 1.0261 \t Acc 70.07 \t AccHead 71.23 \t AccTail 61.64\n",
      "Epoch: [134] \t Loss 1.0385 \t Acc 65.71 \t AccHead 66.74 \t AccTail 58.19\n",
      "Epoch: [135] \t Loss 1.0163 \t Acc 70.02 \t AccHead 71.12 \t AccTail 62.05\n",
      "Epoch: [136] \t Loss 1.0081 \t Acc 71.26 \t AccHead 71.83 \t AccTail 67.12\n",
      "Epoch: [137] \t Loss 1.0080 \t Acc 70.38 \t AccHead 71.35 \t AccTail 63.34\n",
      "Epoch: [138] \t Loss 1.0073 \t Acc 69.77 \t AccHead 70.24 \t AccTail 66.40\n",
      "Epoch: [139] \t Loss 1.0056 \t Acc 66.80 \t AccHead 68.15 \t AccTail 56.97\n",
      "Epoch: [140] \t Loss 1.0171 \t Acc 69.59 \t AccHead 70.19 \t AccTail 65.21\n",
      "Epoch: [141] \t Loss 0.9879 \t Acc 68.55 \t AccHead 69.61 \t AccTail 60.84\n",
      "Epoch: [142] \t Loss 1.0030 \t Acc 68.73 \t AccHead 69.84 \t AccTail 60.62\n",
      "Epoch: [143] \t Loss 1.0125 \t Acc 73.35 \t AccHead 74.28 \t AccTail 66.50\n",
      "Epoch: [144] \t Loss 0.9730 \t Acc 67.68 \t AccHead 68.85 \t AccTail 59.18\n",
      "Epoch: [145] \t Loss 1.0023 \t Acc 66.29 \t AccHead 67.32 \t AccTail 58.75\n",
      "Epoch: [146] \t Loss 0.9993 \t Acc 69.40 \t AccHead 70.42 \t AccTail 62.01\n",
      "Epoch: [147] \t Loss 0.9896 \t Acc 72.00 \t AccHead 72.88 \t AccTail 65.59\n",
      "Epoch: [148] \t Loss 0.9791 \t Acc 66.41 \t AccHead 67.82 \t AccTail 56.14\n",
      "Epoch: [149] \t Loss 0.9807 \t Acc 65.33 \t AccHead 66.15 \t AccTail 59.32\n",
      "Epoch: [150] \t Loss 1.0022 \t Acc 72.07 \t AccHead 73.08 \t AccTail 64.68\n",
      "Epoch: [151] \t Loss 0.5199 \t Acc 93.23 \t AccHead 93.44 \t AccTail 91.70\n",
      "Epoch: [152] \t Loss 0.2902 \t Acc 95.72 \t AccHead 95.93 \t AccTail 94.18\n",
      "Epoch: [153] \t Loss 0.2168 \t Acc 96.81 \t AccHead 96.92 \t AccTail 96.00\n",
      "Epoch: [154] \t Loss 0.1798 \t Acc 97.65 \t AccHead 97.72 \t AccTail 97.11\n",
      "Epoch: [155] \t Loss 0.1498 \t Acc 97.98 \t AccHead 98.02 \t AccTail 97.68\n",
      "Epoch: [156] \t Loss 0.1367 \t Acc 98.39 \t AccHead 98.48 \t AccTail 97.75\n",
      "Epoch: [157] \t Loss 0.1178 \t Acc 98.67 \t AccHead 98.67 \t AccTail 98.67\n",
      "Epoch: [158] \t Loss 0.1061 \t Acc 98.76 \t AccHead 98.77 \t AccTail 98.67\n",
      "Epoch: [159] \t Loss 0.0975 \t Acc 98.90 \t AccHead 98.92 \t AccTail 98.74\n",
      "Epoch: [160] \t Loss 0.0873 \t Acc 98.92 \t AccHead 98.90 \t AccTail 99.09\n",
      "Epoch: [161] \t Loss 0.0800 \t Acc 99.14 \t AccHead 99.16 \t AccTail 99.01\n",
      "Epoch: [162] \t Loss 0.0735 \t Acc 99.23 \t AccHead 99.24 \t AccTail 99.20\n",
      "Epoch: [163] \t Loss 0.0698 \t Acc 99.36 \t AccHead 99.34 \t AccTail 99.51\n",
      "Epoch: [164] \t Loss 0.0644 \t Acc 99.33 \t AccHead 99.33 \t AccTail 99.35\n",
      "Epoch: [165] \t Loss 0.0607 \t Acc 99.41 \t AccHead 99.39 \t AccTail 99.58\n",
      "Epoch: [166] \t Loss 0.0592 \t Acc 99.38 \t AccHead 99.36 \t AccTail 99.54\n",
      "Epoch: [167] \t Loss 0.0546 \t Acc 99.48 \t AccHead 99.44 \t AccTail 99.77\n",
      "Epoch: [168] \t Loss 0.0553 \t Acc 99.63 \t AccHead 99.60 \t AccTail 99.85\n",
      "Epoch: [169] \t Loss 0.0513 \t Acc 99.61 \t AccHead 99.57 \t AccTail 99.92\n",
      "Epoch: [170] \t Loss 0.0476 \t Acc 99.57 \t AccHead 99.53 \t AccTail 99.81\n",
      "Epoch: [171] \t Loss 0.0463 \t Acc 99.59 \t AccHead 99.57 \t AccTail 99.70\n",
      "Epoch: [172] \t Loss 0.0439 \t Acc 99.64 \t AccHead 99.61 \t AccTail 99.85\n",
      "Epoch: [173] \t Loss 0.0403 \t Acc 99.68 \t AccHead 99.65 \t AccTail 99.92\n",
      "Epoch: [174] \t Loss 0.0386 \t Acc 99.67 \t AccHead 99.66 \t AccTail 99.77\n",
      "Epoch: [175] \t Loss 0.0358 \t Acc 99.64 \t AccHead 99.64 \t AccTail 99.62\n",
      "Epoch: [176] \t Loss 0.0377 \t Acc 99.69 \t AccHead 99.66 \t AccTail 99.92\n",
      "Epoch: [177] \t Loss 0.0354 \t Acc 99.77 \t AccHead 99.75 \t AccTail 99.85\n",
      "Epoch: [178] \t Loss 0.0335 \t Acc 99.71 \t AccHead 99.70 \t AccTail 99.77\n",
      "Epoch: [179] \t Loss 0.0342 \t Acc 99.76 \t AccHead 99.74 \t AccTail 99.89\n",
      "Epoch: [180] \t Loss 0.0332 \t Acc 99.71 \t AccHead 99.68 \t AccTail 99.89\n",
      "Epoch: [181] \t Loss 0.0319 \t Acc 99.72 \t AccHead 99.71 \t AccTail 99.77\n",
      "Epoch: [182] \t Loss 0.0319 \t Acc 99.72 \t AccHead 99.72 \t AccTail 99.77\n",
      "Epoch: [183] \t Loss 0.0307 \t Acc 99.71 \t AccHead 99.69 \t AccTail 99.85\n",
      "Epoch: [184] \t Loss 0.0281 \t Acc 99.72 \t AccHead 99.70 \t AccTail 99.92\n",
      "Epoch: [185] \t Loss 0.0289 \t Acc 99.78 \t AccHead 99.77 \t AccTail 99.89\n",
      "Epoch: [186] \t Loss 0.0281 \t Acc 99.80 \t AccHead 99.78 \t AccTail 99.96\n",
      "Epoch: [187] \t Loss 0.0278 \t Acc 99.75 \t AccHead 99.75 \t AccTail 99.73\n",
      "Epoch: [188] \t Loss 0.0290 \t Acc 99.76 \t AccHead 99.73 \t AccTail 99.96\n",
      "Epoch: [189] \t Loss 0.0275 \t Acc 99.72 \t AccHead 99.71 \t AccTail 99.81\n",
      "Epoch: [190] \t Loss 0.0269 \t Acc 99.72 \t AccHead 99.69 \t AccTail 99.92\n",
      "Epoch: [191] \t Loss 0.0259 \t Acc 99.82 \t AccHead 99.80 \t AccTail 99.96\n",
      "Epoch: [192] \t Loss 0.0252 \t Acc 99.83 \t AccHead 99.81 \t AccTail 99.92\n",
      "Epoch: [193] \t Loss 0.0254 \t Acc 99.80 \t AccHead 99.78 \t AccTail 99.92\n",
      "Epoch: [194] \t Loss 0.0268 \t Acc 99.75 \t AccHead 99.73 \t AccTail 99.89\n",
      "Epoch: [195] \t Loss 0.0253 \t Acc 99.77 \t AccHead 99.75 \t AccTail 99.89\n",
      "Epoch: [196] \t Loss 0.0262 \t Acc 99.78 \t AccHead 99.78 \t AccTail 99.81\n",
      "Epoch: [197] \t Loss 0.0246 \t Acc 99.79 \t AccHead 99.78 \t AccTail 99.92\n",
      "Epoch: [198] \t Loss 0.0251 \t Acc 99.80 \t AccHead 99.78 \t AccTail 99.92\n",
      "Epoch: [199] \t Loss 0.0246 \t Acc 99.78 \t AccHead 99.77 \t AccTail 99.89\n",
      "Epoch: [200] \t Loss 0.0271 \t Acc 99.79 \t AccHead 99.79 \t AccTail 99.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 01:07:59,681]\u001b[0m Trial 11 finished with value: 10.199005126953125 and parameters: {'n_epoch': 200, 'weight_decay': 0.00047918568755358793}. Best is trial 11 with value: 10.199005126953125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 10.20 \t AccHead 17.92 \t AccTail 2.56\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'CIFAR100' #['CIFAR10', 'CIFAR100']\n",
    "IMB_TYPE = 'step' #['exp', 'step']\n",
    "IMB_FACTOR = 0.1 #[0.1, 0.01]\n",
    "train_loader, test_loader, num_classes = get_loaders()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sampler = optuna.samplers.TPESampler()\n",
    "    study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "    study.optimize(func=train_model, n_trials=12)\n",
    "    joblib.dump(study, 'set_100_step_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e00b9a0-0a34-403a-98d4-a8508b0a8ac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T01:07:59.705688Z",
     "iopub.status.busy": "2022-06-18T01:07:59.705273Z",
     "iopub.status.idle": "2022-06-18T01:07:59.734657Z",
     "shell.execute_reply": "2022-06-18T01:07:59.734094Z",
     "shell.execute_reply.started": "2022-06-18T01:07:59.705641Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_n_epoch</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9.794776</td>\n",
       "      <td>0 days 00:36:25.838325</td>\n",
       "      <td>200</td>\n",
       "      <td>0.002314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.358624</td>\n",
       "      <td>0 days 00:36:40.001090</td>\n",
       "      <td>200</td>\n",
       "      <td>0.005399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.430763</td>\n",
       "      <td>0 days 00:16:31.675795</td>\n",
       "      <td>90</td>\n",
       "      <td>0.003465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.036484</td>\n",
       "      <td>0 days 00:16:42.299458</td>\n",
       "      <td>90</td>\n",
       "      <td>0.037093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.036484</td>\n",
       "      <td>0 days 00:36:49.319264</td>\n",
       "      <td>200</td>\n",
       "      <td>0.019981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>10.157546</td>\n",
       "      <td>0 days 00:36:59.615525</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.886401</td>\n",
       "      <td>0 days 00:16:33.863514</td>\n",
       "      <td>90</td>\n",
       "      <td>0.013638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.036484</td>\n",
       "      <td>0 days 00:36:39.593646</td>\n",
       "      <td>200</td>\n",
       "      <td>0.022443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8.665009</td>\n",
       "      <td>0 days 00:16:31.285765</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>8.665009</td>\n",
       "      <td>0 days 00:16:27.817277</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number      value               duration  params_n_epoch  \\\n",
       "0       0   9.794776 0 days 00:36:25.838325             200   \n",
       "1       1   5.358624 0 days 00:36:40.001090             200   \n",
       "2       2   3.430763 0 days 00:16:31.675795              90   \n",
       "3       3   1.036484 0 days 00:16:42.299458              90   \n",
       "4       4   1.036484 0 days 00:36:49.319264             200   \n",
       "5       5  10.157546 0 days 00:36:59.615525             200   \n",
       "6       6   1.886401 0 days 00:16:33.863514              90   \n",
       "7       7   1.036484 0 days 00:36:39.593646             200   \n",
       "8       8   8.665009 0 days 00:16:31.285765              90   \n",
       "9       9   8.665009 0 days 00:16:27.817277              90   \n",
       "\n",
       "   params_weight_decay  \n",
       "0             0.002314  \n",
       "1             0.005399  \n",
       "2             0.003465  \n",
       "3             0.037093  \n",
       "4             0.019981  \n",
       "5             0.001366  \n",
       "6             0.013638  \n",
       "7             0.022443  \n",
       "8             0.000019  \n",
       "9             0.000015  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = joblib.load('set_100_step_1.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "382ba92d-3210-40f8-923f-088cb0f60103",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T01:07:59.735686Z",
     "iopub.status.busy": "2022-06-18T01:07:59.735441Z",
     "iopub.status.idle": "2022-06-18T05:55:48.730054Z",
     "shell.execute_reply": "2022-06-18T05:55:48.728766Z",
     "shell.execute_reply.started": "2022-06-18T01:07:59.735670Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 01:08:37,432]\u001b[0m A new study created in memory with name: no-name-c9c92fae-1063-47cd-be12-32bf021b1a31\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls num list(train_dataset):\n",
      "[400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "cls num list(val_dataset):\n",
      "[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
      "Epoch: [001] \t Loss 3.9843 \t Acc 4.24 \t AccHead 4.38 \t AccTail 4.02\n",
      "Epoch: [002] \t Loss 3.5913 \t Acc 8.91 \t AccHead 9.75 \t AccTail 7.65\n",
      "Epoch: [003] \t Loss 3.5359 \t Acc 11.03 \t AccHead 12.42 \t AccTail 8.96\n",
      "Epoch: [004] \t Loss 3.5048 \t Acc 11.34 \t AccHead 13.76 \t AccTail 7.72\n",
      "Epoch: [005] \t Loss 3.4909 \t Acc 11.74 \t AccHead 15.50 \t AccTail 6.14\n",
      "Epoch: [006] \t Loss 3.4768 \t Acc 9.39 \t AccHead 13.20 \t AccTail 3.72\n",
      "Epoch: [007] \t Loss 3.4650 \t Acc 11.67 \t AccHead 14.91 \t AccTail 6.83\n",
      "Epoch: [008] \t Loss 3.4514 \t Acc 10.88 \t AccHead 10.76 \t AccTail 11.06\n",
      "Epoch: [009] \t Loss 3.4445 \t Acc 10.13 \t AccHead 11.66 \t AccTail 7.84\n",
      "Epoch: [010] \t Loss 3.4438 \t Acc 10.72 \t AccHead 14.68 \t AccTail 4.81\n",
      "Epoch: [011] \t Loss 3.4451 \t Acc 12.73 \t AccHead 14.46 \t AccTail 10.15\n",
      "Epoch: [012] \t Loss 3.4218 \t Acc 8.23 \t AccHead 10.29 \t AccTail 5.16\n",
      "Epoch: [013] \t Loss 3.4394 \t Acc 8.01 \t AccHead 9.72 \t AccTail 5.45\n",
      "Epoch: [014] \t Loss 3.4257 \t Acc 11.70 \t AccHead 14.03 \t AccTail 8.24\n",
      "Epoch: [015] \t Loss 3.4352 \t Acc 9.99 \t AccHead 10.70 \t AccTail 8.92\n",
      "Epoch: [016] \t Loss 3.4530 \t Acc 9.43 \t AccHead 12.12 \t AccTail 5.40\n",
      "Epoch: [017] \t Loss 3.4451 \t Acc 12.14 \t AccHead 14.27 \t AccTail 8.97\n",
      "Epoch: [018] \t Loss 3.4440 \t Acc 10.42 \t AccHead 9.45 \t AccTail 11.85\n",
      "Epoch: [019] \t Loss 3.4404 \t Acc 9.64 \t AccHead 12.87 \t AccTail 4.81\n",
      "Epoch: [020] \t Loss 3.4447 \t Acc 8.90 \t AccHead 9.65 \t AccTail 7.78\n",
      "Epoch: [021] \t Loss 3.4468 \t Acc 6.25 \t AccHead 7.89 \t AccTail 3.81\n",
      "Epoch: [022] \t Loss 3.4477 \t Acc 11.64 \t AccHead 12.13 \t AccTail 10.91\n",
      "Epoch: [023] \t Loss 3.4441 \t Acc 11.43 \t AccHead 13.19 \t AccTail 8.81\n",
      "Epoch: [024] \t Loss 3.4310 \t Acc 10.24 \t AccHead 13.63 \t AccTail 5.18\n",
      "Epoch: [025] \t Loss 3.4329 \t Acc 12.48 \t AccHead 13.72 \t AccTail 10.64\n",
      "Epoch: [026] \t Loss 3.4427 \t Acc 10.46 \t AccHead 11.00 \t AccTail 9.66\n",
      "Epoch: [027] \t Loss 3.4472 \t Acc 9.26 \t AccHead 10.15 \t AccTail 7.94\n",
      "Epoch: [028] \t Loss 3.4490 \t Acc 10.35 \t AccHead 9.55 \t AccTail 11.53\n",
      "Epoch: [029] \t Loss 3.4396 \t Acc 8.95 \t AccHead 13.13 \t AccTail 2.71\n",
      "Epoch: [030] \t Loss 3.4449 \t Acc 12.19 \t AccHead 13.31 \t AccTail 10.52\n",
      "Epoch: [031] \t Loss 3.4530 \t Acc 10.01 \t AccHead 11.10 \t AccTail 8.37\n",
      "Epoch: [032] \t Loss 3.4363 \t Acc 11.14 \t AccHead 13.01 \t AccTail 8.36\n",
      "Epoch: [033] \t Loss 3.4508 \t Acc 9.90 \t AccHead 13.95 \t AccTail 3.86\n",
      "Epoch: [034] \t Loss 3.4485 \t Acc 11.21 \t AccHead 13.91 \t AccTail 7.17\n",
      "Epoch: [035] \t Loss 3.4657 \t Acc 10.46 \t AccHead 12.22 \t AccTail 7.84\n",
      "Epoch: [036] \t Loss 3.4594 \t Acc 11.16 \t AccHead 13.69 \t AccTail 7.38\n",
      "Epoch: [037] \t Loss 3.4718 \t Acc 9.83 \t AccHead 13.30 \t AccTail 4.66\n",
      "Epoch: [038] \t Loss 3.4501 \t Acc 9.57 \t AccHead 11.43 \t AccTail 6.79\n",
      "Epoch: [039] \t Loss 3.4619 \t Acc 8.91 \t AccHead 11.46 \t AccTail 5.11\n",
      "Epoch: [040] \t Loss 3.4524 \t Acc 10.68 \t AccHead 11.88 \t AccTail 8.89\n",
      "Epoch: [041] \t Loss 3.4411 \t Acc 9.99 \t AccHead 9.87 \t AccTail 10.15\n",
      "Epoch: [042] \t Loss 3.4371 \t Acc 11.65 \t AccHead 12.82 \t AccTail 9.91\n",
      "Epoch: [043] \t Loss 3.4439 \t Acc 11.43 \t AccHead 14.03 \t AccTail 7.56\n",
      "Epoch: [044] \t Loss 3.4525 \t Acc 10.76 \t AccHead 13.20 \t AccTail 7.12\n",
      "Epoch: [045] \t Loss 3.4490 \t Acc 12.09 \t AccHead 14.42 \t AccTail 8.62\n",
      "Epoch: [046] \t Loss 3.4485 \t Acc 10.10 \t AccHead 9.37 \t AccTail 11.17\n",
      "Epoch: [047] \t Loss 3.4454 \t Acc 12.64 \t AccHead 14.59 \t AccTail 9.72\n",
      "Epoch: [048] \t Loss 3.4471 \t Acc 10.26 \t AccHead 12.32 \t AccTail 7.18\n",
      "Epoch: [049] \t Loss 3.4544 \t Acc 11.28 \t AccHead 11.72 \t AccTail 10.64\n",
      "Epoch: [050] \t Loss 3.4546 \t Acc 11.54 \t AccHead 13.08 \t AccTail 9.24\n",
      "Epoch: [051] \t Loss 3.4614 \t Acc 10.98 \t AccHead 14.06 \t AccTail 6.39\n",
      "Epoch: [052] \t Loss 3.4594 \t Acc 13.31 \t AccHead 14.99 \t AccTail 10.80\n",
      "Epoch: [053] \t Loss 3.4423 \t Acc 10.95 \t AccHead 14.24 \t AccTail 6.04\n",
      "Epoch: [054] \t Loss 3.4591 \t Acc 9.38 \t AccHead 10.89 \t AccTail 7.11\n",
      "Epoch: [055] \t Loss 3.4662 \t Acc 8.73 \t AccHead 11.10 \t AccTail 5.20\n",
      "Epoch: [056] \t Loss 3.4629 \t Acc 10.31 \t AccHead 12.53 \t AccTail 7.00\n",
      "Epoch: [057] \t Loss 3.4583 \t Acc 10.59 \t AccHead 10.21 \t AccTail 11.14\n",
      "Epoch: [058] \t Loss 3.4619 \t Acc 11.84 \t AccHead 14.94 \t AccTail 7.22\n",
      "Epoch: [059] \t Loss 3.4683 \t Acc 12.92 \t AccHead 13.60 \t AccTail 11.89\n",
      "Epoch: [060] \t Loss 3.4633 \t Acc 10.41 \t AccHead 12.12 \t AccTail 7.85\n",
      "Epoch: [061] \t Loss 3.4615 \t Acc 11.44 \t AccHead 13.53 \t AccTail 8.33\n",
      "Epoch: [062] \t Loss 3.4583 \t Acc 10.67 \t AccHead 13.09 \t AccTail 7.07\n",
      "Epoch: [063] \t Loss 3.4681 \t Acc 8.82 \t AccHead 11.78 \t AccTail 4.40\n",
      "Epoch: [064] \t Loss 3.4932 \t Acc 10.61 \t AccHead 11.81 \t AccTail 8.83\n",
      "Epoch: [065] \t Loss 3.4816 \t Acc 10.08 \t AccHead 11.31 \t AccTail 8.26\n",
      "Epoch: [066] \t Loss 3.4801 \t Acc 10.97 \t AccHead 11.55 \t AccTail 10.12\n",
      "Epoch: [067] \t Loss 3.4746 \t Acc 9.49 \t AccHead 10.67 \t AccTail 7.72\n",
      "Epoch: [068] \t Loss 3.4817 \t Acc 11.42 \t AccHead 14.47 \t AccTail 6.89\n",
      "Epoch: [069] \t Loss 3.4707 \t Acc 10.35 \t AccHead 12.07 \t AccTail 7.77\n",
      "Epoch: [070] \t Loss 3.4762 \t Acc 9.50 \t AccHead 12.17 \t AccTail 5.52\n",
      "Epoch: [071] \t Loss 3.4881 \t Acc 11.06 \t AccHead 13.42 \t AccTail 7.55\n",
      "Epoch: [072] \t Loss 3.4838 \t Acc 10.34 \t AccHead 11.12 \t AccTail 9.18\n",
      "Epoch: [073] \t Loss 3.4800 \t Acc 12.55 \t AccHead 11.71 \t AccTail 13.80\n",
      "Epoch: [074] \t Loss 3.4778 \t Acc 10.21 \t AccHead 14.10 \t AccTail 4.40\n",
      "Epoch: [075] \t Loss 3.4865 \t Acc 9.83 \t AccHead 9.81 \t AccTail 9.87\n",
      "Epoch: [076] \t Loss 3.4949 \t Acc 9.29 \t AccHead 10.67 \t AccTail 7.25\n",
      "Epoch: [077] \t Loss 3.4829 \t Acc 11.40 \t AccHead 11.28 \t AccTail 11.58\n",
      "Epoch: [078] \t Loss 3.4989 \t Acc 9.22 \t AccHead 10.81 \t AccTail 6.86\n",
      "Epoch: [079] \t Loss 3.4987 \t Acc 10.08 \t AccHead 10.40 \t AccTail 9.59\n",
      "Epoch: [080] \t Loss 3.4917 \t Acc 9.42 \t AccHead 11.96 \t AccTail 5.63\n",
      "Epoch: [081] \t Loss 3.4960 \t Acc 11.81 \t AccHead 12.74 \t AccTail 10.44\n",
      "Epoch: [082] \t Loss 3.4978 \t Acc 9.85 \t AccHead 10.64 \t AccTail 8.66\n",
      "Epoch: [083] \t Loss 3.4949 \t Acc 11.19 \t AccHead 13.79 \t AccTail 7.32\n",
      "Epoch: [084] \t Loss 3.4786 \t Acc 9.34 \t AccHead 10.44 \t AccTail 7.70\n",
      "Epoch: [085] \t Loss 3.4990 \t Acc 9.99 \t AccHead 13.04 \t AccTail 5.43\n",
      "Epoch: [086] \t Loss 3.4900 \t Acc 10.70 \t AccHead 14.13 \t AccTail 5.57\n",
      "Epoch: [087] \t Loss 3.5025 \t Acc 9.44 \t AccHead 11.24 \t AccTail 6.75\n",
      "Epoch: [088] \t Loss 3.5004 \t Acc 9.97 \t AccHead 10.33 \t AccTail 9.43\n",
      "Epoch: [089] \t Loss 3.4903 \t Acc 10.80 \t AccHead 11.84 \t AccTail 9.24\n",
      "Epoch: [090] \t Loss 3.4859 \t Acc 8.69 \t AccHead 9.53 \t AccTail 7.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 01:24:24,896]\u001b[0m Trial 0 finished with value: 2.0469346046447754 and parameters: {'n_epoch': 90, 'weight_decay': 0.008360827951486292}. Best is trial 0 with value: 2.0469346046447754.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 2.05 \t AccHead 4.10 \t AccTail 0.02\n",
      "Epoch: [001] \t Loss 4.0345 \t Acc 8.72 \t AccHead 6.47 \t AccTail 12.09\n",
      "Epoch: [002] \t Loss 3.5585 \t Acc 13.19 \t AccHead 15.51 \t AccTail 9.73\n",
      "Epoch: [003] \t Loss 3.3800 \t Acc 16.03 \t AccHead 18.80 \t AccTail 11.89\n",
      "Epoch: [004] \t Loss 3.2287 \t Acc 19.02 \t AccHead 20.65 \t AccTail 16.57\n",
      "Epoch: [005] \t Loss 3.0985 \t Acc 21.53 \t AccHead 22.71 \t AccTail 19.78\n",
      "Epoch: [006] \t Loss 2.9836 \t Acc 22.76 \t AccHead 23.70 \t AccTail 21.37\n",
      "Epoch: [007] \t Loss 2.8839 \t Acc 26.91 \t AccHead 29.45 \t AccTail 23.12\n",
      "Epoch: [008] \t Loss 2.7733 \t Acc 26.89 \t AccHead 29.99 \t AccTail 22.26\n",
      "Epoch: [009] \t Loss 2.6716 \t Acc 30.17 \t AccHead 34.32 \t AccTail 23.99\n",
      "Epoch: [010] \t Loss 2.5874 \t Acc 30.47 \t AccHead 32.65 \t AccTail 27.21\n",
      "Epoch: [011] \t Loss 2.5114 \t Acc 34.49 \t AccHead 38.71 \t AccTail 28.17\n",
      "Epoch: [012] \t Loss 2.4245 \t Acc 36.48 \t AccHead 40.64 \t AccTail 30.29\n",
      "Epoch: [013] \t Loss 2.3666 \t Acc 36.79 \t AccHead 41.79 \t AccTail 29.33\n",
      "Epoch: [014] \t Loss 2.2695 \t Acc 38.04 \t AccHead 41.11 \t AccTail 33.44\n",
      "Epoch: [015] \t Loss 2.2257 \t Acc 40.00 \t AccHead 44.02 \t AccTail 34.01\n",
      "Epoch: [016] \t Loss 2.1495 \t Acc 41.42 \t AccHead 46.22 \t AccTail 34.24\n",
      "Epoch: [017] \t Loss 2.0827 \t Acc 42.97 \t AccHead 45.65 \t AccTail 38.99\n",
      "Epoch: [018] \t Loss 2.0363 \t Acc 45.38 \t AccHead 49.57 \t AccTail 39.13\n",
      "Epoch: [019] \t Loss 1.9779 \t Acc 45.07 \t AccHead 49.97 \t AccTail 37.74\n",
      "Epoch: [020] \t Loss 1.9191 \t Acc 47.37 \t AccHead 52.47 \t AccTail 39.75\n",
      "Epoch: [021] \t Loss 1.8594 \t Acc 48.86 \t AccHead 53.92 \t AccTail 41.30\n",
      "Epoch: [022] \t Loss 1.8219 \t Acc 51.24 \t AccHead 55.09 \t AccTail 45.49\n",
      "Epoch: [023] \t Loss 1.7567 \t Acc 53.49 \t AccHead 57.98 \t AccTail 46.77\n",
      "Epoch: [024] \t Loss 1.6817 \t Acc 54.30 \t AccHead 58.85 \t AccTail 47.50\n",
      "Epoch: [025] \t Loss 1.6322 \t Acc 55.90 \t AccHead 59.68 \t AccTail 50.26\n",
      "Epoch: [026] \t Loss 1.5847 \t Acc 56.78 \t AccHead 60.48 \t AccTail 51.26\n",
      "Epoch: [027] \t Loss 1.5281 \t Acc 57.80 \t AccHead 61.81 \t AccTail 51.81\n",
      "Epoch: [028] \t Loss 1.4716 \t Acc 58.22 \t AccHead 62.27 \t AccTail 52.18\n",
      "Epoch: [029] \t Loss 1.4071 \t Acc 61.33 \t AccHead 63.52 \t AccTail 58.06\n",
      "Epoch: [030] \t Loss 1.3500 \t Acc 63.26 \t AccHead 66.78 \t AccTail 58.00\n",
      "Epoch: [031] \t Loss 1.2910 \t Acc 64.97 \t AccHead 69.60 \t AccTail 58.07\n",
      "Epoch: [032] \t Loss 1.2524 \t Acc 65.55 \t AccHead 68.23 \t AccTail 61.55\n",
      "Epoch: [033] \t Loss 1.2021 \t Acc 68.05 \t AccHead 71.33 \t AccTail 63.16\n",
      "Epoch: [034] \t Loss 1.1402 \t Acc 70.37 \t AccHead 73.69 \t AccTail 65.41\n",
      "Epoch: [035] \t Loss 1.1013 \t Acc 70.79 \t AccHead 73.57 \t AccTail 66.64\n",
      "Epoch: [036] \t Loss 1.0280 \t Acc 72.27 \t AccHead 75.41 \t AccTail 67.58\n",
      "Epoch: [037] \t Loss 0.9834 \t Acc 73.87 \t AccHead 76.63 \t AccTail 69.76\n",
      "Epoch: [038] \t Loss 0.9250 \t Acc 73.48 \t AccHead 76.45 \t AccTail 69.05\n",
      "Epoch: [039] \t Loss 0.8900 \t Acc 74.12 \t AccHead 76.27 \t AccTail 70.92\n",
      "Epoch: [040] \t Loss 0.8488 \t Acc 77.58 \t AccHead 78.85 \t AccTail 75.69\n",
      "Epoch: [041] \t Loss 0.8128 \t Acc 77.56 \t AccHead 78.81 \t AccTail 75.71\n",
      "Epoch: [042] \t Loss 0.7836 \t Acc 78.37 \t AccHead 81.35 \t AccTail 73.91\n",
      "Epoch: [043] \t Loss 0.7185 \t Acc 81.81 \t AccHead 82.97 \t AccTail 80.07\n",
      "Epoch: [044] \t Loss 0.6835 \t Acc 80.14 \t AccHead 81.18 \t AccTail 78.58\n",
      "Epoch: [045] \t Loss 0.6647 \t Acc 81.40 \t AccHead 84.01 \t AccTail 77.50\n",
      "Epoch: [046] \t Loss 0.6295 \t Acc 84.42 \t AccHead 86.02 \t AccTail 82.03\n",
      "Epoch: [047] \t Loss 0.5933 \t Acc 82.96 \t AccHead 85.70 \t AccTail 78.88\n",
      "Epoch: [048] \t Loss 0.5598 \t Acc 86.83 \t AccHead 88.29 \t AccTail 84.64\n",
      "Epoch: [049] \t Loss 0.5493 \t Acc 86.05 \t AccHead 88.03 \t AccTail 83.09\n",
      "Epoch: [050] \t Loss 0.5175 \t Acc 86.37 \t AccHead 87.98 \t AccTail 83.97\n",
      "Epoch: [051] \t Loss 0.4781 \t Acc 86.36 \t AccHead 87.79 \t AccTail 84.24\n",
      "Epoch: [052] \t Loss 0.4726 \t Acc 88.97 \t AccHead 90.94 \t AccTail 86.02\n",
      "Epoch: [053] \t Loss 0.4302 \t Acc 88.30 \t AccHead 89.73 \t AccTail 86.16\n",
      "Epoch: [054] \t Loss 0.4208 \t Acc 88.15 \t AccHead 88.97 \t AccTail 86.91\n",
      "Epoch: [055] \t Loss 0.4107 \t Acc 89.79 \t AccHead 90.98 \t AccTail 88.02\n",
      "Epoch: [056] \t Loss 0.3755 \t Acc 88.32 \t AccHead 89.82 \t AccTail 86.07\n",
      "Epoch: [057] \t Loss 0.3806 \t Acc 89.82 \t AccHead 90.00 \t AccTail 89.56\n",
      "Epoch: [058] \t Loss 0.3614 \t Acc 90.06 \t AccHead 91.49 \t AccTail 87.93\n",
      "Epoch: [059] \t Loss 0.3397 \t Acc 90.48 \t AccHead 91.60 \t AccTail 88.82\n",
      "Epoch: [060] \t Loss 0.3335 \t Acc 90.54 \t AccHead 91.24 \t AccTail 89.49\n",
      "Epoch: [061] \t Loss 0.3460 \t Acc 92.07 \t AccHead 92.74 \t AccTail 91.07\n",
      "Epoch: [062] \t Loss 0.3146 \t Acc 92.00 \t AccHead 92.69 \t AccTail 90.97\n",
      "Epoch: [063] \t Loss 0.2874 \t Acc 92.93 \t AccHead 93.03 \t AccTail 92.79\n",
      "Epoch: [064] \t Loss 0.2724 \t Acc 94.09 \t AccHead 94.67 \t AccTail 93.21\n",
      "Epoch: [065] \t Loss 0.2468 \t Acc 94.24 \t AccHead 95.07 \t AccTail 93.01\n",
      "Epoch: [066] \t Loss 0.2542 \t Acc 93.10 \t AccHead 93.65 \t AccTail 92.28\n",
      "Epoch: [067] \t Loss 0.2478 \t Acc 93.86 \t AccHead 94.43 \t AccTail 93.01\n",
      "Epoch: [068] \t Loss 0.2334 \t Acc 94.41 \t AccHead 94.92 \t AccTail 93.66\n",
      "Epoch: [069] \t Loss 0.2300 \t Acc 94.47 \t AccHead 94.95 \t AccTail 93.74\n",
      "Epoch: [070] \t Loss 0.2184 \t Acc 94.27 \t AccHead 94.93 \t AccTail 93.28\n",
      "Epoch: [071] \t Loss 0.2279 \t Acc 94.60 \t AccHead 95.19 \t AccTail 93.71\n",
      "Epoch: [072] \t Loss 0.2113 \t Acc 95.72 \t AccHead 95.67 \t AccTail 95.81\n",
      "Epoch: [073] \t Loss 0.1876 \t Acc 94.72 \t AccHead 95.27 \t AccTail 93.90\n",
      "Epoch: [074] \t Loss 0.1956 \t Acc 95.52 \t AccHead 96.00 \t AccTail 94.82\n",
      "Epoch: [075] \t Loss 0.1914 \t Acc 94.70 \t AccHead 94.99 \t AccTail 94.26\n",
      "Epoch: [076] \t Loss 0.1846 \t Acc 96.00 \t AccHead 96.30 \t AccTail 95.57\n",
      "Epoch: [077] \t Loss 0.1771 \t Acc 96.10 \t AccHead 96.34 \t AccTail 95.74\n",
      "Epoch: [078] \t Loss 0.1752 \t Acc 96.12 \t AccHead 96.52 \t AccTail 95.53\n",
      "Epoch: [079] \t Loss 0.1899 \t Acc 95.65 \t AccHead 95.99 \t AccTail 95.15\n",
      "Epoch: [080] \t Loss 0.1650 \t Acc 95.73 \t AccHead 96.29 \t AccTail 94.91\n",
      "Epoch: [081] \t Loss 0.1608 \t Acc 96.83 \t AccHead 97.12 \t AccTail 96.39\n",
      "Epoch: [082] \t Loss 0.1554 \t Acc 96.47 \t AccHead 97.16 \t AccTail 95.44\n",
      "Epoch: [083] \t Loss 0.1500 \t Acc 96.85 \t AccHead 97.28 \t AccTail 96.20\n",
      "Epoch: [084] \t Loss 0.1463 \t Acc 96.90 \t AccHead 97.34 \t AccTail 96.24\n",
      "Epoch: [085] \t Loss 0.1566 \t Acc 96.91 \t AccHead 97.25 \t AccTail 96.39\n",
      "Epoch: [086] \t Loss 0.1474 \t Acc 97.14 \t AccHead 97.72 \t AccTail 96.27\n",
      "Epoch: [087] \t Loss 0.1482 \t Acc 96.05 \t AccHead 96.36 \t AccTail 95.58\n",
      "Epoch: [088] \t Loss 0.1485 \t Acc 96.90 \t AccHead 96.99 \t AccTail 96.76\n",
      "Epoch: [089] \t Loss 0.1367 \t Acc 97.62 \t AccHead 98.02 \t AccTail 97.03\n",
      "Epoch: [090] \t Loss 0.1254 \t Acc 97.43 \t AccHead 97.68 \t AccTail 97.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 01:40:18,115]\u001b[0m Trial 1 finished with value: 8.818360328674316 and parameters: {'n_epoch': 90, 'weight_decay': 1.5116623437537305e-05}. Best is trial 1 with value: 8.818360328674316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 8.82 \t AccHead 17.67 \t AccTail 0.10\n",
      "Epoch: [001] \t Loss 4.0156 \t Acc 11.00 \t AccHead 13.59 \t AccTail 7.13\n",
      "Epoch: [002] \t Loss 3.5281 \t Acc 13.73 \t AccHead 17.53 \t AccTail 8.07\n",
      "Epoch: [003] \t Loss 3.3417 \t Acc 16.39 \t AccHead 19.24 \t AccTail 12.14\n",
      "Epoch: [004] \t Loss 3.2026 \t Acc 20.22 \t AccHead 20.72 \t AccTail 19.48\n",
      "Epoch: [005] \t Loss 3.0711 \t Acc 23.23 \t AccHead 25.93 \t AccTail 19.18\n",
      "Epoch: [006] \t Loss 2.9441 \t Acc 17.12 \t AccHead 19.27 \t AccTail 13.91\n",
      "Epoch: [007] \t Loss 2.8768 \t Acc 26.65 \t AccHead 31.45 \t AccTail 19.47\n",
      "Epoch: [008] \t Loss 2.7597 \t Acc 29.42 \t AccHead 32.25 \t AccTail 25.21\n",
      "Epoch: [009] \t Loss 2.6847 \t Acc 29.08 \t AccHead 31.88 \t AccTail 24.89\n",
      "Epoch: [010] \t Loss 2.5949 \t Acc 32.19 \t AccHead 35.74 \t AccTail 26.90\n",
      "Epoch: [011] \t Loss 2.5109 \t Acc 34.00 \t AccHead 39.04 \t AccTail 26.47\n",
      "Epoch: [012] \t Loss 2.4521 \t Acc 35.16 \t AccHead 38.89 \t AccTail 29.60\n",
      "Epoch: [013] \t Loss 2.3710 \t Acc 34.94 \t AccHead 38.63 \t AccTail 29.43\n",
      "Epoch: [014] \t Loss 2.3077 \t Acc 36.86 \t AccHead 41.60 \t AccTail 29.79\n",
      "Epoch: [015] \t Loss 2.2312 \t Acc 38.94 \t AccHead 43.52 \t AccTail 32.12\n",
      "Epoch: [016] \t Loss 2.1861 \t Acc 41.31 \t AccHead 46.56 \t AccTail 33.45\n",
      "Epoch: [017] \t Loss 2.1256 \t Acc 43.54 \t AccHead 47.52 \t AccTail 37.61\n",
      "Epoch: [018] \t Loss 2.0719 \t Acc 43.50 \t AccHead 47.96 \t AccTail 36.85\n",
      "Epoch: [019] \t Loss 2.0417 \t Acc 43.41 \t AccHead 47.39 \t AccTail 37.47\n",
      "Epoch: [020] \t Loss 1.9736 \t Acc 45.99 \t AccHead 50.31 \t AccTail 39.55\n",
      "Epoch: [021] \t Loss 1.9282 \t Acc 46.14 \t AccHead 50.03 \t AccTail 40.35\n",
      "Epoch: [022] \t Loss 1.8972 \t Acc 48.94 \t AccHead 54.94 \t AccTail 39.99\n",
      "Epoch: [023] \t Loss 1.8355 \t Acc 49.84 \t AccHead 56.39 \t AccTail 40.08\n",
      "Epoch: [024] \t Loss 1.7935 \t Acc 49.97 \t AccHead 53.83 \t AccTail 44.23\n",
      "Epoch: [025] \t Loss 1.7609 \t Acc 50.55 \t AccHead 56.20 \t AccTail 42.11\n",
      "Epoch: [026] \t Loss 1.7305 \t Acc 52.33 \t AccHead 56.58 \t AccTail 45.99\n",
      "Epoch: [027] \t Loss 1.6810 \t Acc 52.02 \t AccHead 56.67 \t AccTail 45.09\n",
      "Epoch: [028] \t Loss 1.6472 \t Acc 52.16 \t AccHead 57.87 \t AccTail 43.64\n",
      "Epoch: [029] \t Loss 1.6053 \t Acc 53.56 \t AccHead 58.85 \t AccTail 45.66\n",
      "Epoch: [030] \t Loss 1.5674 \t Acc 55.38 \t AccHead 58.26 \t AccTail 51.07\n",
      "Epoch: [031] \t Loss 1.5307 \t Acc 53.24 \t AccHead 57.86 \t AccTail 46.34\n",
      "Epoch: [032] \t Loss 1.4945 \t Acc 56.32 \t AccHead 60.08 \t AccTail 50.71\n",
      "Epoch: [033] \t Loss 1.4669 \t Acc 57.06 \t AccHead 62.19 \t AccTail 49.41\n",
      "Epoch: [034] \t Loss 1.4345 \t Acc 59.39 \t AccHead 62.22 \t AccTail 55.17\n",
      "Epoch: [035] \t Loss 1.3988 \t Acc 60.21 \t AccHead 64.60 \t AccTail 53.65\n",
      "Epoch: [036] \t Loss 1.3623 \t Acc 60.78 \t AccHead 65.48 \t AccTail 53.76\n",
      "Epoch: [037] \t Loss 1.3261 \t Acc 62.42 \t AccHead 66.22 \t AccTail 56.76\n",
      "Epoch: [038] \t Loss 1.3066 \t Acc 63.25 \t AccHead 67.39 \t AccTail 57.06\n",
      "Epoch: [039] \t Loss 1.2772 \t Acc 60.28 \t AccHead 64.04 \t AccTail 54.66\n",
      "Epoch: [040] \t Loss 1.2393 \t Acc 60.95 \t AccHead 63.64 \t AccTail 56.94\n",
      "Epoch: [041] \t Loss 1.2222 \t Acc 65.08 \t AccHead 66.84 \t AccTail 62.45\n",
      "Epoch: [042] \t Loss 1.1866 \t Acc 64.81 \t AccHead 69.37 \t AccTail 58.00\n",
      "Epoch: [043] \t Loss 1.1451 \t Acc 67.32 \t AccHead 70.71 \t AccTail 62.26\n",
      "Epoch: [044] \t Loss 1.1267 \t Acc 68.45 \t AccHead 71.84 \t AccTail 63.40\n",
      "Epoch: [045] \t Loss 1.1014 \t Acc 69.87 \t AccHead 72.69 \t AccTail 65.66\n",
      "Epoch: [046] \t Loss 1.0885 \t Acc 70.41 \t AccHead 73.27 \t AccTail 66.14\n",
      "Epoch: [047] \t Loss 1.0411 \t Acc 71.13 \t AccHead 73.99 \t AccTail 66.86\n",
      "Epoch: [048] \t Loss 1.0267 \t Acc 72.11 \t AccHead 74.54 \t AccTail 68.47\n",
      "Epoch: [049] \t Loss 1.0064 \t Acc 73.85 \t AccHead 77.84 \t AccTail 67.90\n",
      "Epoch: [050] \t Loss 0.9671 \t Acc 71.93 \t AccHead 74.50 \t AccTail 68.09\n",
      "Epoch: [051] \t Loss 0.9566 \t Acc 72.16 \t AccHead 73.81 \t AccTail 69.69\n",
      "Epoch: [052] \t Loss 0.9297 \t Acc 72.99 \t AccHead 76.98 \t AccTail 67.05\n",
      "Epoch: [053] \t Loss 0.8922 \t Acc 73.50 \t AccHead 76.10 \t AccTail 69.62\n",
      "Epoch: [054] \t Loss 0.8976 \t Acc 73.72 \t AccHead 76.26 \t AccTail 69.93\n",
      "Epoch: [055] \t Loss 0.8950 \t Acc 72.57 \t AccHead 74.13 \t AccTail 70.24\n",
      "Epoch: [056] \t Loss 0.8479 \t Acc 75.79 \t AccHead 78.08 \t AccTail 72.37\n",
      "Epoch: [057] \t Loss 0.8204 \t Acc 76.81 \t AccHead 78.28 \t AccTail 74.63\n",
      "Epoch: [058] \t Loss 0.8072 \t Acc 75.88 \t AccHead 77.44 \t AccTail 73.56\n",
      "Epoch: [059] \t Loss 0.7879 \t Acc 79.01 \t AccHead 81.01 \t AccTail 76.02\n",
      "Epoch: [060] \t Loss 0.7696 \t Acc 77.43 \t AccHead 80.31 \t AccTail 73.13\n",
      "Epoch: [061] \t Loss 0.7656 \t Acc 76.86 \t AccHead 79.85 \t AccTail 72.40\n",
      "Epoch: [062] \t Loss 0.7457 \t Acc 79.69 \t AccHead 82.93 \t AccTail 74.87\n",
      "Epoch: [063] \t Loss 0.7401 \t Acc 78.42 \t AccHead 80.21 \t AccTail 75.76\n",
      "Epoch: [064] \t Loss 0.7462 \t Acc 78.72 \t AccHead 80.93 \t AccTail 75.42\n",
      "Epoch: [065] \t Loss 0.7021 \t Acc 81.29 \t AccHead 83.20 \t AccTail 78.44\n",
      "Epoch: [066] \t Loss 0.6918 \t Acc 75.65 \t AccHead 76.79 \t AccTail 73.94\n",
      "Epoch: [067] \t Loss 0.6960 \t Acc 82.08 \t AccHead 84.15 \t AccTail 78.99\n",
      "Epoch: [068] \t Loss 0.6812 \t Acc 80.10 \t AccHead 80.52 \t AccTail 79.47\n",
      "Epoch: [069] \t Loss 0.6438 \t Acc 82.70 \t AccHead 84.21 \t AccTail 80.44\n",
      "Epoch: [070] \t Loss 0.6429 \t Acc 77.45 \t AccHead 80.19 \t AccTail 73.37\n",
      "Epoch: [071] \t Loss 0.6362 \t Acc 80.47 \t AccHead 81.89 \t AccTail 78.35\n",
      "Epoch: [072] \t Loss 0.6521 \t Acc 81.59 \t AccHead 82.68 \t AccTail 79.97\n",
      "Epoch: [073] \t Loss 0.6486 \t Acc 80.98 \t AccHead 81.67 \t AccTail 79.97\n",
      "Epoch: [074] \t Loss 0.6443 \t Acc 82.45 \t AccHead 84.04 \t AccTail 80.08\n",
      "Epoch: [075] \t Loss 0.6007 \t Acc 85.28 \t AccHead 86.68 \t AccTail 83.19\n",
      "Epoch: [076] \t Loss 0.5739 \t Acc 84.29 \t AccHead 85.31 \t AccTail 82.77\n",
      "Epoch: [077] \t Loss 0.5807 \t Acc 83.84 \t AccHead 85.73 \t AccTail 81.02\n",
      "Epoch: [078] \t Loss 0.6192 \t Acc 83.92 \t AccHead 84.87 \t AccTail 82.50\n",
      "Epoch: [079] \t Loss 0.5835 \t Acc 84.62 \t AccHead 85.58 \t AccTail 83.19\n",
      "Epoch: [080] \t Loss 0.5707 \t Acc 82.50 \t AccHead 83.95 \t AccTail 80.34\n",
      "Epoch: [081] \t Loss 0.5792 \t Acc 84.02 \t AccHead 85.77 \t AccTail 81.42\n",
      "Epoch: [082] \t Loss 0.5651 \t Acc 85.45 \t AccHead 87.35 \t AccTail 82.61\n",
      "Epoch: [083] \t Loss 0.5527 \t Acc 83.81 \t AccHead 84.93 \t AccTail 82.13\n",
      "Epoch: [084] \t Loss 0.5516 \t Acc 84.99 \t AccHead 86.77 \t AccTail 82.33\n",
      "Epoch: [085] \t Loss 0.5431 \t Acc 84.10 \t AccHead 85.90 \t AccTail 81.40\n",
      "Epoch: [086] \t Loss 0.5600 \t Acc 82.67 \t AccHead 84.50 \t AccTail 79.94\n",
      "Epoch: [087] \t Loss 0.5380 \t Acc 83.03 \t AccHead 84.24 \t AccTail 81.23\n",
      "Epoch: [088] \t Loss 0.5510 \t Acc 85.33 \t AccHead 86.33 \t AccTail 83.83\n",
      "Epoch: [089] \t Loss 0.5460 \t Acc 84.20 \t AccHead 86.01 \t AccTail 81.52\n",
      "Epoch: [090] \t Loss 0.5470 \t Acc 86.21 \t AccHead 86.81 \t AccTail 85.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 01:56:10,608]\u001b[0m Trial 2 finished with value: 9.00444507598877 and parameters: {'n_epoch': 90, 'weight_decay': 0.00023234602808261257}. Best is trial 2 with value: 9.00444507598877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 9.00 \t AccHead 18.00 \t AccTail 0.14\n",
      "Epoch: [001] \t Loss 3.9296 \t Acc 3.89 \t AccHead 5.88 \t AccTail 0.94\n",
      "Epoch: [002] \t Loss 3.7379 \t Acc 7.07 \t AccHead 7.46 \t AccTail 6.50\n",
      "Epoch: [003] \t Loss 3.7425 \t Acc 7.12 \t AccHead 6.20 \t AccTail 8.49\n",
      "Epoch: [004] \t Loss 3.7390 \t Acc 7.29 \t AccHead 8.43 \t AccTail 5.60\n",
      "Epoch: [005] \t Loss 3.7448 \t Acc 6.02 \t AccHead 5.05 \t AccTail 7.47\n",
      "Epoch: [006] \t Loss 3.7479 \t Acc 5.36 \t AccHead 5.79 \t AccTail 4.71\n",
      "Epoch: [007] \t Loss 3.7508 \t Acc 4.35 \t AccHead 6.62 \t AccTail 0.96\n",
      "Epoch: [008] \t Loss 3.7640 \t Acc 5.17 \t AccHead 5.40 \t AccTail 4.83\n",
      "Epoch: [009] \t Loss 3.7619 \t Acc 4.02 \t AccHead 4.92 \t AccTail 2.67\n",
      "Epoch: [010] \t Loss 3.7608 \t Acc 7.24 \t AccHead 9.12 \t AccTail 4.42\n",
      "Epoch: [011] \t Loss 3.7555 \t Acc 7.10 \t AccHead 8.61 \t AccTail 4.86\n",
      "Epoch: [012] \t Loss 3.7612 \t Acc 6.79 \t AccHead 9.61 \t AccTail 2.58\n",
      "Epoch: [013] \t Loss 3.7541 \t Acc 6.76 \t AccHead 8.11 \t AccTail 4.73\n",
      "Epoch: [014] \t Loss 3.7538 \t Acc 7.24 \t AccHead 7.70 \t AccTail 6.55\n",
      "Epoch: [015] \t Loss 3.7575 \t Acc 4.89 \t AccHead 5.00 \t AccTail 4.72\n",
      "Epoch: [016] \t Loss 3.7621 \t Acc 5.89 \t AccHead 5.58 \t AccTail 6.37\n",
      "Epoch: [017] \t Loss 3.7665 \t Acc 4.08 \t AccHead 3.53 \t AccTail 4.90\n",
      "Epoch: [018] \t Loss 3.7676 \t Acc 4.89 \t AccHead 4.54 \t AccTail 5.42\n",
      "Epoch: [019] \t Loss 3.7576 \t Acc 7.15 \t AccHead 7.66 \t AccTail 6.40\n",
      "Epoch: [020] \t Loss 3.7629 \t Acc 5.88 \t AccHead 7.10 \t AccTail 4.07\n",
      "Epoch: [021] \t Loss 3.7691 \t Acc 6.72 \t AccHead 8.18 \t AccTail 4.55\n",
      "Epoch: [022] \t Loss 3.7788 \t Acc 4.06 \t AccHead 3.49 \t AccTail 4.91\n",
      "Epoch: [023] \t Loss 3.7807 \t Acc 6.55 \t AccHead 7.64 \t AccTail 4.92\n",
      "Epoch: [024] \t Loss 3.7753 \t Acc 4.64 \t AccHead 3.49 \t AccTail 6.37\n",
      "Epoch: [025] \t Loss 3.7875 \t Acc 4.90 \t AccHead 6.32 \t AccTail 2.80\n",
      "Epoch: [026] \t Loss 3.7741 \t Acc 5.24 \t AccHead 7.66 \t AccTail 1.64\n",
      "Epoch: [027] \t Loss 3.7781 \t Acc 4.19 \t AccHead 5.44 \t AccTail 2.32\n",
      "Epoch: [028] \t Loss 3.7872 \t Acc 5.44 \t AccHead 4.95 \t AccTail 6.17\n",
      "Epoch: [029] \t Loss 3.7684 \t Acc 4.03 \t AccHead 4.94 \t AccTail 2.67\n",
      "Epoch: [030] \t Loss 3.7720 \t Acc 4.94 \t AccHead 5.69 \t AccTail 3.82\n",
      "Epoch: [031] \t Loss 3.7898 \t Acc 4.52 \t AccHead 6.25 \t AccTail 1.94\n",
      "Epoch: [032] \t Loss 3.7780 \t Acc 4.51 \t AccHead 4.06 \t AccTail 5.18\n",
      "Epoch: [033] \t Loss 3.7818 \t Acc 5.04 \t AccHead 6.51 \t AccTail 2.86\n",
      "Epoch: [034] \t Loss 3.7716 \t Acc 4.46 \t AccHead 4.09 \t AccTail 5.01\n",
      "Epoch: [035] \t Loss 3.8811 \t Acc 4.10 \t AccHead 2.63 \t AccTail 6.30\n",
      "Epoch: [036] \t Loss 3.8627 \t Acc 4.62 \t AccHead 2.35 \t AccTail 8.02\n",
      "Epoch: [037] \t Loss 3.8327 \t Acc 5.80 \t AccHead 7.89 \t AccTail 2.69\n",
      "Epoch: [038] \t Loss 3.8303 \t Acc 4.75 \t AccHead 4.23 \t AccTail 5.53\n",
      "Epoch: [039] \t Loss 3.8115 \t Acc 2.79 \t AccHead 3.68 \t AccTail 1.46\n",
      "Epoch: [040] \t Loss 3.8125 \t Acc 3.94 \t AccHead 6.30 \t AccTail 0.41\n",
      "Epoch: [041] \t Loss 3.8087 \t Acc 4.46 \t AccHead 4.28 \t AccTail 4.72\n",
      "Epoch: [042] \t Loss 3.8047 \t Acc 5.05 \t AccHead 6.53 \t AccTail 2.85\n",
      "Epoch: [043] \t Loss 3.8088 \t Acc 4.81 \t AccHead 7.38 \t AccTail 0.97\n",
      "Epoch: [044] \t Loss 3.7945 \t Acc 4.62 \t AccHead 4.24 \t AccTail 5.19\n",
      "Epoch: [045] \t Loss 3.8119 \t Acc 4.98 \t AccHead 6.51 \t AccTail 2.71\n",
      "Epoch: [046] \t Loss 3.8086 \t Acc 5.74 \t AccHead 6.09 \t AccTail 5.22\n",
      "Epoch: [047] \t Loss 3.7974 \t Acc 4.57 \t AccHead 5.15 \t AccTail 3.69\n",
      "Epoch: [048] \t Loss 3.8019 \t Acc 5.96 \t AccHead 4.99 \t AccTail 7.40\n",
      "Epoch: [049] \t Loss 3.7989 \t Acc 5.32 \t AccHead 7.33 \t AccTail 2.31\n",
      "Epoch: [050] \t Loss 3.8950 \t Acc 3.29 \t AccHead 2.76 \t AccTail 4.09\n",
      "Epoch: [051] \t Loss 3.9002 \t Acc 3.92 \t AccHead 6.42 \t AccTail 0.20\n",
      "Epoch: [052] \t Loss 3.8876 \t Acc 1.98 \t AccHead 1.20 \t AccTail 3.15\n",
      "Epoch: [053] \t Loss 3.8963 \t Acc 2.12 \t AccHead 3.24 \t AccTail 0.45\n",
      "Epoch: [054] \t Loss 3.9016 \t Acc 4.33 \t AccHead 4.36 \t AccTail 4.28\n",
      "Epoch: [055] \t Loss 3.8966 \t Acc 3.91 \t AccHead 2.89 \t AccTail 5.42\n",
      "Epoch: [056] \t Loss 3.9194 \t Acc 2.54 \t AccHead 2.74 \t AccTail 2.26\n",
      "Epoch: [057] \t Loss 3.9175 \t Acc 3.81 \t AccHead 2.93 \t AccTail 5.12\n",
      "Epoch: [058] \t Loss 3.8930 \t Acc 2.08 \t AccHead 0.19 \t AccTail 4.90\n",
      "Epoch: [059] \t Loss 3.8955 \t Acc 2.08 \t AccHead 0.00 \t AccTail 5.18\n",
      "Epoch: [060] \t Loss 3.9025 \t Acc 3.54 \t AccHead 3.63 \t AccTail 3.40\n",
      "Epoch: [061] \t Loss 3.9253 \t Acc 2.85 \t AccHead 4.75 \t AccTail 0.02\n",
      "Epoch: [062] \t Loss 3.9075 \t Acc 2.84 \t AccHead 3.62 \t AccTail 1.68\n",
      "Epoch: [063] \t Loss 3.9101 \t Acc 3.72 \t AccHead 0.18 \t AccTail 9.00\n",
      "Epoch: [064] \t Loss 3.9063 \t Acc 2.01 \t AccHead 3.36 \t AccTail 0.00\n",
      "Epoch: [065] \t Loss 3.9083 \t Acc 3.23 \t AccHead 0.00 \t AccTail 8.04\n",
      "Epoch: [066] \t Loss 3.9543 \t Acc 2.00 \t AccHead 0.00 \t AccTail 4.99\n",
      "Epoch: [067] \t Loss 3.9541 \t Acc 2.94 \t AccHead 2.59 \t AccTail 3.47\n",
      "Epoch: [068] \t Loss 4.0055 \t Acc 2.00 \t AccHead 0.00 \t AccTail 4.99\n",
      "Epoch: [069] \t Loss 3.9803 \t Acc 1.99 \t AccHead 3.33 \t AccTail 0.00\n",
      "Epoch: [070] \t Loss 3.9586 \t Acc 3.95 \t AccHead 5.96 \t AccTail 0.95\n",
      "Epoch: [071] \t Loss 3.9360 \t Acc 2.21 \t AccHead 0.09 \t AccTail 5.37\n",
      "Epoch: [072] \t Loss 3.9337 \t Acc 1.96 \t AccHead 0.01 \t AccTail 4.88\n",
      "Epoch: [073] \t Loss 3.9293 \t Acc 3.76 \t AccHead 4.12 \t AccTail 3.23\n",
      "Epoch: [074] \t Loss 3.9266 \t Acc 2.08 \t AccHead 3.33 \t AccTail 0.21\n",
      "Epoch: [075] \t Loss 3.9456 \t Acc 4.16 \t AccHead 4.81 \t AccTail 3.18\n",
      "Epoch: [076] \t Loss 3.9707 \t Acc 2.00 \t AccHead 0.00 \t AccTail 4.98\n",
      "Epoch: [077] \t Loss 3.9864 \t Acc 2.99 \t AccHead 1.24 \t AccTail 5.62\n",
      "Epoch: [078] \t Loss 3.9574 \t Acc 1.99 \t AccHead 0.00 \t AccTail 4.97\n",
      "Epoch: [079] \t Loss 3.9899 \t Acc 2.78 \t AccHead 4.65 \t AccTail 0.00\n",
      "Epoch: [080] \t Loss 3.9463 \t Acc 3.06 \t AccHead 4.93 \t AccTail 0.27\n",
      "Epoch: [081] \t Loss 3.9512 \t Acc 3.01 \t AccHead 1.08 \t AccTail 5.90\n",
      "Epoch: [082] \t Loss 3.9591 \t Acc 2.90 \t AccHead 4.63 \t AccTail 0.32\n",
      "Epoch: [083] \t Loss 3.9510 \t Acc 2.00 \t AccHead 3.35 \t AccTail 0.00\n",
      "Epoch: [084] \t Loss 3.9522 \t Acc 2.78 \t AccHead 0.00 \t AccTail 6.92\n",
      "Epoch: [085] \t Loss 3.9674 \t Acc 2.02 \t AccHead 0.00 \t AccTail 5.03\n",
      "Epoch: [086] \t Loss 3.9465 \t Acc 2.01 \t AccHead 0.01 \t AccTail 5.00\n",
      "Epoch: [087] \t Loss 3.9456 \t Acc 2.00 \t AccHead 0.00 \t AccTail 4.98\n",
      "Epoch: [088] \t Loss 3.9801 \t Acc 2.00 \t AccHead 0.00 \t AccTail 4.98\n",
      "Epoch: [089] \t Loss 3.9475 \t Acc 2.22 \t AccHead 3.71 \t AccTail 0.00\n",
      "Epoch: [090] \t Loss 3.9458 \t Acc 3.20 \t AccHead 3.65 \t AccTail 2.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 02:12:05,220]\u001b[0m Trial 3 finished with value: 0.9200868010520935 and parameters: {'n_epoch': 90, 'weight_decay': 0.020429814549251836}. Best is trial 2 with value: 9.00444507598877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 0.92 \t AccHead 1.85 \t AccTail 0.00\n",
      "Epoch: [001] \t Loss 4.0318 \t Acc 10.02 \t AccHead 12.63 \t AccTail 6.12\n",
      "Epoch: [002] \t Loss 3.5492 \t Acc 12.27 \t AccHead 12.36 \t AccTail 12.15\n",
      "Epoch: [003] \t Loss 3.3867 \t Acc 14.95 \t AccHead 18.13 \t AccTail 10.19\n",
      "Epoch: [004] \t Loss 3.2347 \t Acc 18.74 \t AccHead 22.52 \t AccTail 13.11\n",
      "Epoch: [005] \t Loss 3.1060 \t Acc 19.64 \t AccHead 21.76 \t AccTail 16.48\n",
      "Epoch: [006] \t Loss 2.9827 \t Acc 24.16 \t AccHead 26.94 \t AccTail 20.01\n",
      "Epoch: [007] \t Loss 2.8828 \t Acc 25.80 \t AccHead 31.28 \t AccTail 17.62\n",
      "Epoch: [008] \t Loss 2.7986 \t Acc 25.38 \t AccHead 27.90 \t AccTail 21.61\n",
      "Epoch: [009] \t Loss 2.6833 \t Acc 28.74 \t AccHead 32.19 \t AccTail 23.58\n",
      "Epoch: [010] \t Loss 2.6152 \t Acc 27.30 \t AccHead 31.31 \t AccTail 21.33\n",
      "Epoch: [011] \t Loss 2.5613 \t Acc 30.06 \t AccHead 34.96 \t AccTail 22.76\n",
      "Epoch: [012] \t Loss 2.5247 \t Acc 30.83 \t AccHead 35.43 \t AccTail 23.98\n",
      "Epoch: [013] \t Loss 2.4606 \t Acc 33.30 \t AccHead 40.32 \t AccTail 22.84\n",
      "Epoch: [014] \t Loss 2.4170 \t Acc 29.31 \t AccHead 33.97 \t AccTail 22.35\n",
      "Epoch: [015] \t Loss 2.3941 \t Acc 34.18 \t AccHead 38.04 \t AccTail 28.42\n",
      "Epoch: [016] \t Loss 2.3537 \t Acc 34.50 \t AccHead 41.81 \t AccTail 23.61\n",
      "Epoch: [017] \t Loss 2.3378 \t Acc 33.81 \t AccHead 37.35 \t AccTail 28.53\n",
      "Epoch: [018] \t Loss 2.2919 \t Acc 37.27 \t AccHead 42.79 \t AccTail 29.03\n",
      "Epoch: [019] \t Loss 2.2689 \t Acc 33.28 \t AccHead 37.35 \t AccTail 27.21\n",
      "Epoch: [020] \t Loss 2.2387 \t Acc 37.02 \t AccHead 41.40 \t AccTail 30.47\n",
      "Epoch: [021] \t Loss 2.2131 \t Acc 34.24 \t AccHead 38.22 \t AccTail 28.30\n",
      "Epoch: [022] \t Loss 2.2087 \t Acc 38.33 \t AccHead 43.08 \t AccTail 31.25\n",
      "Epoch: [023] \t Loss 2.1878 \t Acc 34.80 \t AccHead 39.14 \t AccTail 28.32\n",
      "Epoch: [024] \t Loss 2.1623 \t Acc 39.72 \t AccHead 44.49 \t AccTail 32.60\n",
      "Epoch: [025] \t Loss 2.1310 \t Acc 37.21 \t AccHead 41.68 \t AccTail 30.54\n",
      "Epoch: [026] \t Loss 2.1113 \t Acc 39.60 \t AccHead 44.26 \t AccTail 32.63\n",
      "Epoch: [027] \t Loss 2.1182 \t Acc 40.42 \t AccHead 45.73 \t AccTail 32.49\n",
      "Epoch: [028] \t Loss 2.1058 \t Acc 41.12 \t AccHead 43.94 \t AccTail 36.92\n",
      "Epoch: [029] \t Loss 2.0668 \t Acc 40.82 \t AccHead 45.40 \t AccTail 33.97\n",
      "Epoch: [030] \t Loss 2.0797 \t Acc 40.51 \t AccHead 45.93 \t AccTail 32.43\n",
      "Epoch: [031] \t Loss 2.0600 \t Acc 37.57 \t AccHead 40.24 \t AccTail 33.57\n",
      "Epoch: [032] \t Loss 2.0617 \t Acc 42.01 \t AccHead 46.94 \t AccTail 34.65\n",
      "Epoch: [033] \t Loss 2.0124 \t Acc 41.67 \t AccHead 46.44 \t AccTail 34.56\n",
      "Epoch: [034] \t Loss 2.0129 \t Acc 43.40 \t AccHead 48.04 \t AccTail 36.48\n",
      "Epoch: [035] \t Loss 2.0026 \t Acc 40.13 \t AccHead 44.64 \t AccTail 33.40\n",
      "Epoch: [036] \t Loss 2.0130 \t Acc 43.45 \t AccHead 49.46 \t AccTail 34.49\n",
      "Epoch: [037] \t Loss 1.9823 \t Acc 43.16 \t AccHead 48.63 \t AccTail 34.99\n",
      "Epoch: [038] \t Loss 1.9797 \t Acc 41.12 \t AccHead 44.87 \t AccTail 35.53\n",
      "Epoch: [039] \t Loss 1.9638 \t Acc 41.96 \t AccHead 47.78 \t AccTail 33.28\n",
      "Epoch: [040] \t Loss 1.9698 \t Acc 43.08 \t AccHead 48.91 \t AccTail 34.39\n",
      "Epoch: [041] \t Loss 1.9404 \t Acc 43.98 \t AccHead 48.41 \t AccTail 37.38\n",
      "Epoch: [042] \t Loss 1.9451 \t Acc 45.13 \t AccHead 50.40 \t AccTail 37.26\n",
      "Epoch: [043] \t Loss 1.9534 \t Acc 41.75 \t AccHead 48.19 \t AccTail 32.14\n",
      "Epoch: [044] \t Loss 1.9343 \t Acc 42.07 \t AccHead 48.31 \t AccTail 32.76\n",
      "Epoch: [045] \t Loss 1.9464 \t Acc 44.37 \t AccHead 49.82 \t AccTail 36.23\n",
      "Epoch: [046] \t Loss 1.9307 \t Acc 45.22 \t AccHead 49.80 \t AccTail 38.39\n",
      "Epoch: [047] \t Loss 1.9004 \t Acc 44.23 \t AccHead 48.83 \t AccTail 37.36\n",
      "Epoch: [048] \t Loss 1.9266 \t Acc 41.66 \t AccHead 47.11 \t AccTail 33.54\n",
      "Epoch: [049] \t Loss 1.8963 \t Acc 45.43 \t AccHead 50.12 \t AccTail 38.43\n",
      "Epoch: [050] \t Loss 1.8884 \t Acc 44.95 \t AccHead 48.89 \t AccTail 39.06\n",
      "Epoch: [051] \t Loss 1.8884 \t Acc 41.98 \t AccHead 45.22 \t AccTail 37.13\n",
      "Epoch: [052] \t Loss 1.8855 \t Acc 43.89 \t AccHead 47.53 \t AccTail 38.45\n",
      "Epoch: [053] \t Loss 1.8742 \t Acc 46.24 \t AccHead 49.37 \t AccTail 41.56\n",
      "Epoch: [054] \t Loss 1.8730 \t Acc 47.68 \t AccHead 53.01 \t AccTail 39.71\n",
      "Epoch: [055] \t Loss 1.8708 \t Acc 43.71 \t AccHead 48.92 \t AccTail 35.93\n",
      "Epoch: [056] \t Loss 1.8687 \t Acc 45.86 \t AccHead 50.52 \t AccTail 38.90\n",
      "Epoch: [057] \t Loss 1.8417 \t Acc 44.08 \t AccHead 50.57 \t AccTail 34.38\n",
      "Epoch: [058] \t Loss 1.8630 \t Acc 42.48 \t AccHead 47.52 \t AccTail 34.96\n",
      "Epoch: [059] \t Loss 1.8496 \t Acc 45.27 \t AccHead 49.74 \t AccTail 38.61\n",
      "Epoch: [060] \t Loss 1.8423 \t Acc 39.33 \t AccHead 42.72 \t AccTail 34.26\n",
      "Epoch: [061] \t Loss 1.8465 \t Acc 44.24 \t AccHead 51.30 \t AccTail 33.70\n",
      "Epoch: [062] \t Loss 1.8374 \t Acc 46.07 \t AccHead 50.28 \t AccTail 39.78\n",
      "Epoch: [063] \t Loss 1.8283 \t Acc 47.07 \t AccHead 53.62 \t AccTail 37.30\n",
      "Epoch: [064] \t Loss 1.8321 \t Acc 47.31 \t AccHead 51.19 \t AccTail 41.52\n",
      "Epoch: [065] \t Loss 1.8209 \t Acc 47.55 \t AccHead 52.98 \t AccTail 39.44\n",
      "Epoch: [066] \t Loss 1.8210 \t Acc 43.39 \t AccHead 48.68 \t AccTail 35.49\n",
      "Epoch: [067] \t Loss 1.8183 \t Acc 41.67 \t AccHead 47.68 \t AccTail 32.69\n",
      "Epoch: [068] \t Loss 1.8096 \t Acc 43.50 \t AccHead 48.67 \t AccTail 35.80\n",
      "Epoch: [069] \t Loss 1.8154 \t Acc 45.48 \t AccHead 49.36 \t AccTail 39.69\n",
      "Epoch: [070] \t Loss 1.8000 \t Acc 49.20 \t AccHead 54.82 \t AccTail 40.81\n",
      "Epoch: [071] \t Loss 1.8034 \t Acc 47.99 \t AccHead 51.90 \t AccTail 42.15\n",
      "Epoch: [072] \t Loss 1.8224 \t Acc 47.20 \t AccHead 50.24 \t AccTail 42.66\n",
      "Epoch: [073] \t Loss 1.8141 \t Acc 49.12 \t AccHead 56.40 \t AccTail 38.25\n",
      "Epoch: [074] \t Loss 1.7952 \t Acc 45.41 \t AccHead 50.32 \t AccTail 38.08\n",
      "Epoch: [075] \t Loss 1.7930 \t Acc 45.97 \t AccHead 51.36 \t AccTail 37.92\n",
      "Epoch: [076] \t Loss 1.7789 \t Acc 46.99 \t AccHead 52.29 \t AccTail 39.08\n",
      "Epoch: [077] \t Loss 1.7929 \t Acc 48.45 \t AccHead 53.92 \t AccTail 40.29\n",
      "Epoch: [078] \t Loss 1.7933 \t Acc 49.03 \t AccHead 54.67 \t AccTail 40.61\n",
      "Epoch: [079] \t Loss 1.7703 \t Acc 47.06 \t AccHead 54.61 \t AccTail 35.79\n",
      "Epoch: [080] \t Loss 1.7822 \t Acc 49.00 \t AccHead 55.17 \t AccTail 39.80\n",
      "Epoch: [081] \t Loss 1.7837 \t Acc 49.74 \t AccHead 55.33 \t AccTail 41.40\n",
      "Epoch: [082] \t Loss 1.7692 \t Acc 49.64 \t AccHead 55.66 \t AccTail 40.67\n",
      "Epoch: [083] \t Loss 1.7609 \t Acc 45.67 \t AccHead 51.09 \t AccTail 37.58\n",
      "Epoch: [084] \t Loss 1.7781 \t Acc 46.10 \t AccHead 51.74 \t AccTail 37.71\n",
      "Epoch: [085] \t Loss 1.7645 \t Acc 47.49 \t AccHead 52.62 \t AccTail 39.84\n",
      "Epoch: [086] \t Loss 1.7679 \t Acc 44.57 \t AccHead 50.10 \t AccTail 36.30\n",
      "Epoch: [087] \t Loss 1.7452 \t Acc 48.30 \t AccHead 51.36 \t AccTail 43.74\n",
      "Epoch: [088] \t Loss 1.7532 \t Acc 47.49 \t AccHead 52.20 \t AccTail 40.45\n",
      "Epoch: [089] \t Loss 1.7498 \t Acc 46.42 \t AccHead 50.72 \t AccTail 39.99\n",
      "Epoch: [090] \t Loss 1.7704 \t Acc 46.45 \t AccHead 51.58 \t AccTail 38.80\n",
      "Epoch: [091] \t Loss 1.7472 \t Acc 48.04 \t AccHead 56.00 \t AccTail 36.13\n",
      "Epoch: [092] \t Loss 1.7329 \t Acc 47.69 \t AccHead 53.94 \t AccTail 38.37\n",
      "Epoch: [093] \t Loss 1.7543 \t Acc 48.49 \t AccHead 53.95 \t AccTail 40.33\n",
      "Epoch: [094] \t Loss 1.7474 \t Acc 48.71 \t AccHead 53.37 \t AccTail 41.76\n",
      "Epoch: [095] \t Loss 1.7434 \t Acc 48.80 \t AccHead 53.73 \t AccTail 41.45\n",
      "Epoch: [096] \t Loss 1.7236 \t Acc 43.00 \t AccHead 50.41 \t AccTail 31.96\n",
      "Epoch: [097] \t Loss 1.7204 \t Acc 46.06 \t AccHead 50.45 \t AccTail 39.52\n",
      "Epoch: [098] \t Loss 1.7430 \t Acc 46.36 \t AccHead 49.14 \t AccTail 42.22\n",
      "Epoch: [099] \t Loss 1.7335 \t Acc 46.02 \t AccHead 51.87 \t AccTail 37.29\n",
      "Epoch: [100] \t Loss 1.7381 \t Acc 47.31 \t AccHead 50.36 \t AccTail 42.76\n",
      "Epoch: [101] \t Loss 1.7478 \t Acc 51.33 \t AccHead 56.47 \t AccTail 43.66\n",
      "Epoch: [102] \t Loss 1.7351 \t Acc 46.66 \t AccHead 54.75 \t AccTail 34.59\n",
      "Epoch: [103] \t Loss 1.7354 \t Acc 43.52 \t AccHead 46.60 \t AccTail 38.93\n",
      "Epoch: [104] \t Loss 1.7312 \t Acc 49.08 \t AccHead 54.44 \t AccTail 41.08\n",
      "Epoch: [105] \t Loss 1.7219 \t Acc 45.91 \t AccHead 49.82 \t AccTail 40.06\n",
      "Epoch: [106] \t Loss 1.7197 \t Acc 48.26 \t AccHead 52.66 \t AccTail 41.69\n",
      "Epoch: [107] \t Loss 1.7070 \t Acc 48.56 \t AccHead 52.48 \t AccTail 42.70\n",
      "Epoch: [108] \t Loss 1.7237 \t Acc 52.66 \t AccHead 57.67 \t AccTail 45.19\n",
      "Epoch: [109] \t Loss 1.7263 \t Acc 49.94 \t AccHead 53.78 \t AccTail 44.21\n",
      "Epoch: [110] \t Loss 1.7209 \t Acc 46.99 \t AccHead 52.31 \t AccTail 39.05\n",
      "Epoch: [111] \t Loss 1.7198 \t Acc 47.22 \t AccHead 53.07 \t AccTail 38.49\n",
      "Epoch: [112] \t Loss 1.7161 \t Acc 49.34 \t AccHead 53.72 \t AccTail 42.81\n",
      "Epoch: [113] \t Loss 1.6928 \t Acc 47.87 \t AccHead 54.60 \t AccTail 37.83\n",
      "Epoch: [114] \t Loss 1.7141 \t Acc 48.53 \t AccHead 52.60 \t AccTail 42.45\n",
      "Epoch: [115] \t Loss 1.6975 \t Acc 48.81 \t AccHead 55.50 \t AccTail 38.83\n",
      "Epoch: [116] \t Loss 1.7122 \t Acc 46.25 \t AccHead 51.13 \t AccTail 38.97\n",
      "Epoch: [117] \t Loss 1.7063 \t Acc 49.59 \t AccHead 55.65 \t AccTail 40.55\n",
      "Epoch: [118] \t Loss 1.7183 \t Acc 49.14 \t AccHead 55.09 \t AccTail 40.27\n",
      "Epoch: [119] \t Loss 1.6859 \t Acc 48.48 \t AccHead 53.77 \t AccTail 40.57\n",
      "Epoch: [120] \t Loss 1.7181 \t Acc 49.45 \t AccHead 54.94 \t AccTail 41.26\n",
      "Epoch: [121] \t Loss 1.6913 \t Acc 48.49 \t AccHead 53.28 \t AccTail 41.36\n",
      "Epoch: [122] \t Loss 1.7032 \t Acc 45.69 \t AccHead 49.51 \t AccTail 39.99\n",
      "Epoch: [123] \t Loss 1.7078 \t Acc 44.61 \t AccHead 48.63 \t AccTail 38.61\n",
      "Epoch: [124] \t Loss 1.7063 \t Acc 48.53 \t AccHead 52.94 \t AccTail 41.95\n",
      "Epoch: [125] \t Loss 1.6950 \t Acc 49.92 \t AccHead 55.25 \t AccTail 41.96\n",
      "Epoch: [126] \t Loss 1.6763 \t Acc 51.34 \t AccHead 55.37 \t AccTail 45.33\n",
      "Epoch: [127] \t Loss 1.6891 \t Acc 51.28 \t AccHead 57.11 \t AccTail 42.57\n",
      "Epoch: [128] \t Loss 1.6957 \t Acc 44.82 \t AccHead 50.12 \t AccTail 36.89\n",
      "Epoch: [129] \t Loss 1.6953 \t Acc 50.13 \t AccHead 55.61 \t AccTail 41.93\n",
      "Epoch: [130] \t Loss 1.7038 \t Acc 51.57 \t AccHead 55.79 \t AccTail 45.28\n",
      "Epoch: [131] \t Loss 1.6915 \t Acc 45.18 \t AccHead 49.20 \t AccTail 39.18\n",
      "Epoch: [132] \t Loss 1.6847 \t Acc 47.69 \t AccHead 51.66 \t AccTail 41.76\n",
      "Epoch: [133] \t Loss 1.7097 \t Acc 48.49 \t AccHead 55.50 \t AccTail 38.03\n",
      "Epoch: [134] \t Loss 1.6886 \t Acc 47.96 \t AccHead 51.00 \t AccTail 43.41\n",
      "Epoch: [135] \t Loss 1.6901 \t Acc 51.16 \t AccHead 56.20 \t AccTail 43.62\n",
      "Epoch: [136] \t Loss 1.6871 \t Acc 47.50 \t AccHead 49.95 \t AccTail 43.84\n",
      "Epoch: [137] \t Loss 1.6849 \t Acc 49.51 \t AccHead 53.84 \t AccTail 43.03\n",
      "Epoch: [138] \t Loss 1.6784 \t Acc 51.28 \t AccHead 54.50 \t AccTail 46.47\n",
      "Epoch: [139] \t Loss 1.6805 \t Acc 49.45 \t AccHead 53.45 \t AccTail 43.50\n",
      "Epoch: [140] \t Loss 1.6729 \t Acc 47.11 \t AccHead 51.51 \t AccTail 40.54\n",
      "Epoch: [141] \t Loss 1.6780 \t Acc 47.98 \t AccHead 53.74 \t AccTail 39.39\n",
      "Epoch: [142] \t Loss 1.6733 \t Acc 47.32 \t AccHead 53.05 \t AccTail 38.76\n",
      "Epoch: [143] \t Loss 1.6803 \t Acc 50.56 \t AccHead 56.63 \t AccTail 41.50\n",
      "Epoch: [144] \t Loss 1.6592 \t Acc 51.23 \t AccHead 56.01 \t AccTail 44.08\n",
      "Epoch: [145] \t Loss 1.6735 \t Acc 49.05 \t AccHead 55.38 \t AccTail 39.61\n",
      "Epoch: [146] \t Loss 1.6781 \t Acc 47.09 \t AccHead 50.65 \t AccTail 41.75\n",
      "Epoch: [147] \t Loss 1.6725 \t Acc 49.71 \t AccHead 52.38 \t AccTail 45.73\n",
      "Epoch: [148] \t Loss 1.6830 \t Acc 48.83 \t AccHead 53.66 \t AccTail 41.64\n",
      "Epoch: [149] \t Loss 1.6740 \t Acc 49.71 \t AccHead 53.98 \t AccTail 43.34\n",
      "Epoch: [150] \t Loss 1.6624 \t Acc 43.65 \t AccHead 48.05 \t AccTail 37.08\n",
      "Epoch: [151] \t Loss 1.2120 \t Acc 70.15 \t AccHead 74.41 \t AccTail 63.78\n",
      "Epoch: [152] \t Loss 0.9766 \t Acc 74.19 \t AccHead 78.09 \t AccTail 68.37\n",
      "Epoch: [153] \t Loss 0.8727 \t Acc 76.82 \t AccHead 80.64 \t AccTail 71.13\n",
      "Epoch: [154] \t Loss 0.7922 \t Acc 78.80 \t AccHead 82.06 \t AccTail 73.93\n",
      "Epoch: [155] \t Loss 0.7311 \t Acc 80.98 \t AccHead 84.08 \t AccTail 76.36\n",
      "Epoch: [156] \t Loss 0.6745 \t Acc 82.33 \t AccHead 84.82 \t AccTail 78.60\n",
      "Epoch: [157] \t Loss 0.6299 \t Acc 84.00 \t AccHead 86.60 \t AccTail 80.13\n",
      "Epoch: [158] \t Loss 0.5827 \t Acc 85.38 \t AccHead 87.81 \t AccTail 81.76\n",
      "Epoch: [159] \t Loss 0.5325 \t Acc 86.95 \t AccHead 88.85 \t AccTail 84.12\n",
      "Epoch: [160] \t Loss 0.4946 \t Acc 88.13 \t AccHead 90.27 \t AccTail 84.93\n",
      "Epoch: [161] \t Loss 0.4714 \t Acc 89.19 \t AccHead 91.40 \t AccTail 85.89\n",
      "Epoch: [162] \t Loss 0.4308 \t Acc 90.56 \t AccHead 92.06 \t AccTail 88.32\n",
      "Epoch: [163] \t Loss 0.3987 \t Acc 90.81 \t AccHead 92.46 \t AccTail 88.35\n",
      "Epoch: [164] \t Loss 0.3774 \t Acc 91.71 \t AccHead 93.40 \t AccTail 89.20\n",
      "Epoch: [165] \t Loss 0.3548 \t Acc 92.32 \t AccHead 93.80 \t AccTail 90.12\n",
      "Epoch: [166] \t Loss 0.3397 \t Acc 93.22 \t AccHead 94.66 \t AccTail 91.08\n",
      "Epoch: [167] \t Loss 0.3148 \t Acc 93.92 \t AccHead 95.27 \t AccTail 91.89\n",
      "Epoch: [168] \t Loss 0.2941 \t Acc 93.77 \t AccHead 94.78 \t AccTail 92.25\n",
      "Epoch: [169] \t Loss 0.2886 \t Acc 93.68 \t AccHead 95.22 \t AccTail 91.39\n",
      "Epoch: [170] \t Loss 0.2692 \t Acc 94.65 \t AccHead 95.82 \t AccTail 92.91\n",
      "Epoch: [171] \t Loss 0.2570 \t Acc 94.18 \t AccHead 95.37 \t AccTail 92.40\n",
      "Epoch: [172] \t Loss 0.2379 \t Acc 95.46 \t AccHead 96.18 \t AccTail 94.39\n",
      "Epoch: [173] \t Loss 0.2310 \t Acc 95.56 \t AccHead 96.65 \t AccTail 93.94\n",
      "Epoch: [174] \t Loss 0.2279 \t Acc 95.64 \t AccHead 96.56 \t AccTail 94.28\n",
      "Epoch: [175] \t Loss 0.2194 \t Acc 95.66 \t AccHead 96.52 \t AccTail 94.37\n",
      "Epoch: [176] \t Loss 0.2100 \t Acc 95.65 \t AccHead 96.56 \t AccTail 94.30\n",
      "Epoch: [177] \t Loss 0.2153 \t Acc 95.81 \t AccHead 96.55 \t AccTail 94.71\n",
      "Epoch: [178] \t Loss 0.2140 \t Acc 95.60 \t AccHead 96.39 \t AccTail 94.43\n",
      "Epoch: [179] \t Loss 0.2120 \t Acc 95.47 \t AccHead 96.35 \t AccTail 94.14\n",
      "Epoch: [180] \t Loss 0.2003 \t Acc 95.93 \t AccHead 96.81 \t AccTail 94.62\n",
      "Epoch: [181] \t Loss 0.2035 \t Acc 96.18 \t AccHead 97.12 \t AccTail 94.77\n",
      "Epoch: [182] \t Loss 0.1988 \t Acc 95.66 \t AccHead 96.56 \t AccTail 94.31\n",
      "Epoch: [183] \t Loss 0.2025 \t Acc 95.73 \t AccHead 96.51 \t AccTail 94.56\n",
      "Epoch: [184] \t Loss 0.2020 \t Acc 95.48 \t AccHead 96.24 \t AccTail 94.35\n",
      "Epoch: [185] \t Loss 0.2091 \t Acc 95.61 \t AccHead 96.66 \t AccTail 94.05\n",
      "Epoch: [186] \t Loss 0.2054 \t Acc 96.15 \t AccHead 96.95 \t AccTail 94.96\n",
      "Epoch: [187] \t Loss 0.1917 \t Acc 95.76 \t AccHead 96.50 \t AccTail 94.67\n",
      "Epoch: [188] \t Loss 0.1907 \t Acc 96.28 \t AccHead 96.53 \t AccTail 95.91\n",
      "Epoch: [189] \t Loss 0.1943 \t Acc 96.01 \t AccHead 96.76 \t AccTail 94.88\n",
      "Epoch: [190] \t Loss 0.1854 \t Acc 95.48 \t AccHead 96.08 \t AccTail 94.58\n",
      "Epoch: [191] \t Loss 0.1932 \t Acc 96.03 \t AccHead 96.90 \t AccTail 94.74\n",
      "Epoch: [192] \t Loss 0.1946 \t Acc 94.35 \t AccHead 95.54 \t AccTail 92.56\n",
      "Epoch: [193] \t Loss 0.2096 \t Acc 95.39 \t AccHead 96.01 \t AccTail 94.47\n",
      "Epoch: [194] \t Loss 0.2016 \t Acc 95.37 \t AccHead 95.84 \t AccTail 94.66\n",
      "Epoch: [195] \t Loss 0.2010 \t Acc 94.68 \t AccHead 95.46 \t AccTail 93.52\n",
      "Epoch: [196] \t Loss 0.2074 \t Acc 95.81 \t AccHead 96.38 \t AccTail 94.96\n",
      "Epoch: [197] \t Loss 0.2007 \t Acc 95.54 \t AccHead 96.35 \t AccTail 94.34\n",
      "Epoch: [198] \t Loss 0.2021 \t Acc 95.55 \t AccHead 96.14 \t AccTail 94.68\n",
      "Epoch: [199] \t Loss 0.1909 \t Acc 95.28 \t AccHead 96.05 \t AccTail 94.13\n",
      "Epoch: [200] \t Loss 0.2012 \t Acc 94.90 \t AccHead 95.82 \t AccTail 93.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 02:47:15,363]\u001b[0m Trial 4 finished with value: 10.658534049987793 and parameters: {'n_epoch': 200, 'weight_decay': 0.0008279786638875599}. Best is trial 4 with value: 10.658534049987793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 10.66 \t AccHead 21.44 \t AccTail 0.04\n",
      "Epoch: [001] \t Loss 3.9854 \t Acc 5.09 \t AccHead 4.98 \t AccTail 5.26\n",
      "Epoch: [002] \t Loss 3.5990 \t Acc 9.27 \t AccHead 10.05 \t AccTail 8.10\n",
      "Epoch: [003] \t Loss 3.5722 \t Acc 9.13 \t AccHead 12.91 \t AccTail 3.49\n",
      "Epoch: [004] \t Loss 3.5368 \t Acc 7.51 \t AccHead 7.32 \t AccTail 7.80\n",
      "Epoch: [005] \t Loss 3.5259 \t Acc 10.06 \t AccHead 12.31 \t AccTail 6.70\n",
      "Epoch: [006] \t Loss 3.5208 \t Acc 9.73 \t AccHead 10.17 \t AccTail 9.08\n",
      "Epoch: [007] \t Loss 3.5093 \t Acc 10.62 \t AccHead 11.84 \t AccTail 8.81\n",
      "Epoch: [008] \t Loss 3.5004 \t Acc 10.11 \t AccHead 11.15 \t AccTail 8.56\n",
      "Epoch: [009] \t Loss 3.4963 \t Acc 11.01 \t AccHead 13.29 \t AccTail 7.62\n",
      "Epoch: [010] \t Loss 3.4758 \t Acc 11.02 \t AccHead 11.21 \t AccTail 10.74\n",
      "Epoch: [011] \t Loss 3.4829 \t Acc 11.19 \t AccHead 12.72 \t AccTail 8.91\n",
      "Epoch: [012] \t Loss 3.4737 \t Acc 11.21 \t AccHead 14.00 \t AccTail 7.04\n",
      "Epoch: [013] \t Loss 3.4713 \t Acc 11.26 \t AccHead 10.19 \t AccTail 12.87\n",
      "Epoch: [014] \t Loss 3.4574 \t Acc 8.73 \t AccHead 12.30 \t AccTail 3.39\n",
      "Epoch: [015] \t Loss 3.4609 \t Acc 9.62 \t AccHead 8.85 \t AccTail 10.76\n",
      "Epoch: [016] \t Loss 3.4542 \t Acc 10.38 \t AccHead 9.90 \t AccTail 11.09\n",
      "Epoch: [017] \t Loss 3.4655 \t Acc 11.13 \t AccHead 13.54 \t AccTail 7.54\n",
      "Epoch: [018] \t Loss 3.4634 \t Acc 9.24 \t AccHead 7.83 \t AccTail 11.36\n",
      "Epoch: [019] \t Loss 3.4599 \t Acc 12.10 \t AccHead 15.16 \t AccTail 7.54\n",
      "Epoch: [020] \t Loss 3.4559 \t Acc 11.15 \t AccHead 12.91 \t AccTail 8.52\n",
      "Epoch: [021] \t Loss 3.4601 \t Acc 12.42 \t AccHead 14.30 \t AccTail 9.62\n",
      "Epoch: [022] \t Loss 3.4488 \t Acc 12.73 \t AccHead 17.87 \t AccTail 5.05\n",
      "Epoch: [023] \t Loss 3.4566 \t Acc 12.01 \t AccHead 12.66 \t AccTail 11.04\n",
      "Epoch: [024] \t Loss 3.4541 \t Acc 12.30 \t AccHead 13.62 \t AccTail 10.33\n",
      "Epoch: [025] \t Loss 3.4582 \t Acc 9.38 \t AccHead 11.68 \t AccTail 5.93\n",
      "Epoch: [026] \t Loss 3.4869 \t Acc 11.93 \t AccHead 14.78 \t AccTail 7.70\n",
      "Epoch: [027] \t Loss 3.4612 \t Acc 11.71 \t AccHead 11.70 \t AccTail 11.73\n",
      "Epoch: [028] \t Loss 3.4638 \t Acc 9.80 \t AccHead 13.16 \t AccTail 4.78\n",
      "Epoch: [029] \t Loss 3.4628 \t Acc 10.02 \t AccHead 10.54 \t AccTail 9.23\n",
      "Epoch: [030] \t Loss 3.4675 \t Acc 10.62 \t AccHead 11.83 \t AccTail 8.81\n",
      "Epoch: [031] \t Loss 3.4636 \t Acc 11.15 \t AccHead 12.66 \t AccTail 8.89\n",
      "Epoch: [032] \t Loss 3.4681 \t Acc 12.00 \t AccHead 12.71 \t AccTail 10.94\n",
      "Epoch: [033] \t Loss 3.4826 \t Acc 6.06 \t AccHead 8.91 \t AccTail 1.82\n",
      "Epoch: [034] \t Loss 3.4879 \t Acc 9.68 \t AccHead 10.99 \t AccTail 7.73\n",
      "Epoch: [035] \t Loss 3.4819 \t Acc 10.57 \t AccHead 10.95 \t AccTail 10.00\n",
      "Epoch: [036] \t Loss 3.4701 \t Acc 10.68 \t AccHead 12.42 \t AccTail 8.10\n",
      "Epoch: [037] \t Loss 3.4676 \t Acc 9.58 \t AccHead 11.32 \t AccTail 6.97\n",
      "Epoch: [038] \t Loss 3.4788 \t Acc 8.56 \t AccHead 8.10 \t AccTail 9.25\n",
      "Epoch: [039] \t Loss 3.4807 \t Acc 11.65 \t AccHead 15.07 \t AccTail 6.54\n",
      "Epoch: [040] \t Loss 3.4814 \t Acc 10.01 \t AccHead 11.81 \t AccTail 7.33\n",
      "Epoch: [041] \t Loss 3.4845 \t Acc 7.19 \t AccHead 9.60 \t AccTail 3.57\n",
      "Epoch: [042] \t Loss 3.4870 \t Acc 9.19 \t AccHead 13.41 \t AccTail 2.89\n",
      "Epoch: [043] \t Loss 3.4771 \t Acc 9.88 \t AccHead 10.16 \t AccTail 9.45\n",
      "Epoch: [044] \t Loss 3.4844 \t Acc 10.85 \t AccHead 11.13 \t AccTail 10.43\n",
      "Epoch: [045] \t Loss 3.4819 \t Acc 9.64 \t AccHead 8.13 \t AccTail 11.87\n",
      "Epoch: [046] \t Loss 3.5035 \t Acc 11.08 \t AccHead 13.95 \t AccTail 6.79\n",
      "Epoch: [047] \t Loss 3.5003 \t Acc 10.30 \t AccHead 11.45 \t AccTail 8.57\n",
      "Epoch: [048] \t Loss 3.5037 \t Acc 9.60 \t AccHead 11.13 \t AccTail 7.31\n",
      "Epoch: [049] \t Loss 3.4935 \t Acc 10.04 \t AccHead 9.72 \t AccTail 10.52\n",
      "Epoch: [050] \t Loss 3.4820 \t Acc 11.70 \t AccHead 11.22 \t AccTail 12.42\n",
      "Epoch: [051] \t Loss 3.5072 \t Acc 9.65 \t AccHead 9.70 \t AccTail 9.56\n",
      "Epoch: [052] \t Loss 3.5007 \t Acc 11.93 \t AccHead 12.84 \t AccTail 10.57\n",
      "Epoch: [053] \t Loss 3.5004 \t Acc 9.67 \t AccHead 11.39 \t AccTail 7.11\n",
      "Epoch: [054] \t Loss 3.5081 \t Acc 9.99 \t AccHead 11.62 \t AccTail 7.56\n",
      "Epoch: [055] \t Loss 3.5084 \t Acc 9.92 \t AccHead 10.28 \t AccTail 9.38\n",
      "Epoch: [056] \t Loss 3.4990 \t Acc 10.32 \t AccHead 10.79 \t AccTail 9.63\n",
      "Epoch: [057] \t Loss 3.5154 \t Acc 9.04 \t AccHead 7.95 \t AccTail 10.68\n",
      "Epoch: [058] \t Loss 3.5155 \t Acc 9.75 \t AccHead 10.55 \t AccTail 8.55\n",
      "Epoch: [059] \t Loss 3.5295 \t Acc 8.42 \t AccHead 11.99 \t AccTail 3.12\n",
      "Epoch: [060] \t Loss 3.5185 \t Acc 10.72 \t AccHead 11.12 \t AccTail 10.13\n",
      "Epoch: [061] \t Loss 3.5138 \t Acc 10.99 \t AccHead 12.35 \t AccTail 8.95\n",
      "Epoch: [062] \t Loss 3.5274 \t Acc 6.71 \t AccHead 8.02 \t AccTail 4.76\n",
      "Epoch: [063] \t Loss 3.5268 \t Acc 9.92 \t AccHead 8.63 \t AccTail 11.84\n",
      "Epoch: [064] \t Loss 3.5255 \t Acc 8.26 \t AccHead 10.69 \t AccTail 4.63\n",
      "Epoch: [065] \t Loss 3.5295 \t Acc 9.18 \t AccHead 7.39 \t AccTail 11.87\n",
      "Epoch: [066] \t Loss 3.5228 \t Acc 8.67 \t AccHead 10.35 \t AccTail 6.15\n",
      "Epoch: [067] \t Loss 3.5272 \t Acc 8.31 \t AccHead 9.32 \t AccTail 6.81\n",
      "Epoch: [068] \t Loss 3.5163 \t Acc 9.12 \t AccHead 13.26 \t AccTail 2.96\n",
      "Epoch: [069] \t Loss 3.5312 \t Acc 9.92 \t AccHead 9.67 \t AccTail 10.29\n",
      "Epoch: [070] \t Loss 3.5266 \t Acc 10.03 \t AccHead 10.15 \t AccTail 9.86\n",
      "Epoch: [071] \t Loss 3.5236 \t Acc 8.66 \t AccHead 9.66 \t AccTail 7.18\n",
      "Epoch: [072] \t Loss 3.5299 \t Acc 8.38 \t AccHead 6.76 \t AccTail 10.80\n",
      "Epoch: [073] \t Loss 3.5341 \t Acc 9.81 \t AccHead 10.09 \t AccTail 9.39\n",
      "Epoch: [074] \t Loss 3.5270 \t Acc 8.67 \t AccHead 10.72 \t AccTail 5.61\n",
      "Epoch: [075] \t Loss 3.5370 \t Acc 9.19 \t AccHead 11.83 \t AccTail 5.27\n",
      "Epoch: [076] \t Loss 3.5348 \t Acc 8.64 \t AccHead 8.31 \t AccTail 9.14\n",
      "Epoch: [077] \t Loss 3.5352 \t Acc 9.62 \t AccHead 11.09 \t AccTail 7.41\n",
      "Epoch: [078] \t Loss 3.5347 \t Acc 6.79 \t AccHead 8.81 \t AccTail 3.77\n",
      "Epoch: [079] \t Loss 3.5546 \t Acc 7.80 \t AccHead 10.64 \t AccTail 3.55\n",
      "Epoch: [080] \t Loss 3.5399 \t Acc 11.09 \t AccHead 13.93 \t AccTail 6.85\n",
      "Epoch: [081] \t Loss 3.5373 \t Acc 8.83 \t AccHead 12.39 \t AccTail 3.52\n",
      "Epoch: [082] \t Loss 3.5244 \t Acc 8.82 \t AccHead 9.65 \t AccTail 7.59\n",
      "Epoch: [083] \t Loss 3.5364 \t Acc 8.21 \t AccHead 8.13 \t AccTail 8.34\n",
      "Epoch: [084] \t Loss 3.5417 \t Acc 8.18 \t AccHead 8.65 \t AccTail 7.47\n",
      "Epoch: [085] \t Loss 3.5397 \t Acc 9.59 \t AccHead 10.71 \t AccTail 7.90\n",
      "Epoch: [086] \t Loss 3.5325 \t Acc 7.59 \t AccHead 7.19 \t AccTail 8.17\n",
      "Epoch: [087] \t Loss 3.5401 \t Acc 7.90 \t AccHead 10.86 \t AccTail 3.49\n",
      "Epoch: [088] \t Loss 3.5425 \t Acc 9.81 \t AccHead 12.34 \t AccTail 6.04\n",
      "Epoch: [089] \t Loss 3.5397 \t Acc 10.60 \t AccHead 12.29 \t AccTail 8.07\n",
      "Epoch: [090] \t Loss 3.5474 \t Acc 8.16 \t AccHead 10.03 \t AccTail 5.37\n",
      "Epoch: [091] \t Loss 3.5383 \t Acc 8.95 \t AccHead 11.45 \t AccTail 5.23\n",
      "Epoch: [092] \t Loss 3.5410 \t Acc 8.89 \t AccHead 11.95 \t AccTail 4.34\n",
      "Epoch: [093] \t Loss 3.5402 \t Acc 7.43 \t AccHead 8.61 \t AccTail 5.67\n",
      "Epoch: [094] \t Loss 3.5382 \t Acc 7.77 \t AccHead 7.07 \t AccTail 8.82\n",
      "Epoch: [095] \t Loss 3.5328 \t Acc 9.96 \t AccHead 10.49 \t AccTail 9.16\n",
      "Epoch: [096] \t Loss 3.5375 \t Acc 10.39 \t AccHead 13.52 \t AccTail 5.73\n",
      "Epoch: [097] \t Loss 3.5351 \t Acc 8.80 \t AccHead 11.58 \t AccTail 4.64\n",
      "Epoch: [098] \t Loss 3.5321 \t Acc 8.05 \t AccHead 11.55 \t AccTail 2.83\n",
      "Epoch: [099] \t Loss 3.5475 \t Acc 6.68 \t AccHead 10.09 \t AccTail 1.60\n",
      "Epoch: [100] \t Loss 3.5444 \t Acc 9.33 \t AccHead 8.61 \t AccTail 10.42\n",
      "Epoch: [101] \t Loss 3.5489 \t Acc 10.38 \t AccHead 10.94 \t AccTail 9.55\n",
      "Epoch: [102] \t Loss 3.5472 \t Acc 7.73 \t AccHead 7.99 \t AccTail 7.33\n",
      "Epoch: [103] \t Loss 3.5532 \t Acc 9.72 \t AccHead 11.53 \t AccTail 7.01\n",
      "Epoch: [104] \t Loss 3.5354 \t Acc 7.88 \t AccHead 10.03 \t AccTail 4.67\n",
      "Epoch: [105] \t Loss 3.5427 \t Acc 8.18 \t AccHead 9.98 \t AccTail 5.49\n",
      "Epoch: [106] \t Loss 3.5495 \t Acc 11.06 \t AccHead 11.79 \t AccTail 9.98\n",
      "Epoch: [107] \t Loss 3.5423 \t Acc 8.65 \t AccHead 11.03 \t AccTail 5.11\n",
      "Epoch: [108] \t Loss 3.5502 \t Acc 8.79 \t AccHead 9.86 \t AccTail 7.20\n",
      "Epoch: [109] \t Loss 3.5533 \t Acc 10.31 \t AccHead 9.51 \t AccTail 11.50\n",
      "Epoch: [110] \t Loss 3.5457 \t Acc 7.42 \t AccHead 9.45 \t AccTail 4.39\n",
      "Epoch: [111] \t Loss 3.5513 \t Acc 8.83 \t AccHead 10.15 \t AccTail 6.87\n",
      "Epoch: [112] \t Loss 3.5549 \t Acc 9.09 \t AccHead 10.29 \t AccTail 7.31\n",
      "Epoch: [113] \t Loss 3.5563 \t Acc 10.59 \t AccHead 11.21 \t AccTail 9.67\n",
      "Epoch: [114] \t Loss 3.5500 \t Acc 8.66 \t AccHead 7.43 \t AccTail 10.51\n",
      "Epoch: [115] \t Loss 3.5445 \t Acc 9.41 \t AccHead 12.32 \t AccTail 5.05\n",
      "Epoch: [116] \t Loss 3.5525 \t Acc 9.43 \t AccHead 9.34 \t AccTail 9.56\n",
      "Epoch: [117] \t Loss 3.5477 \t Acc 10.65 \t AccHead 14.70 \t AccTail 4.61\n",
      "Epoch: [118] \t Loss 3.5569 \t Acc 9.32 \t AccHead 11.00 \t AccTail 6.82\n",
      "Epoch: [119] \t Loss 3.5593 \t Acc 9.00 \t AccHead 10.73 \t AccTail 6.43\n",
      "Epoch: [120] \t Loss 3.5562 \t Acc 8.87 \t AccHead 10.72 \t AccTail 6.12\n",
      "Epoch: [121] \t Loss 3.5564 \t Acc 7.96 \t AccHead 7.47 \t AccTail 8.69\n",
      "Epoch: [122] \t Loss 3.5575 \t Acc 9.28 \t AccHead 10.82 \t AccTail 7.00\n",
      "Epoch: [123] \t Loss 3.5550 \t Acc 10.38 \t AccHead 11.82 \t AccTail 8.22\n",
      "Epoch: [124] \t Loss 3.5612 \t Acc 7.46 \t AccHead 7.68 \t AccTail 7.13\n",
      "Epoch: [125] \t Loss 3.5576 \t Acc 9.63 \t AccHead 11.26 \t AccTail 7.19\n",
      "Epoch: [126] \t Loss 3.5549 \t Acc 8.84 \t AccHead 10.41 \t AccTail 6.50\n",
      "Epoch: [127] \t Loss 3.5619 \t Acc 8.50 \t AccHead 10.31 \t AccTail 5.81\n",
      "Epoch: [128] \t Loss 3.5508 \t Acc 9.84 \t AccHead 12.17 \t AccTail 6.37\n",
      "Epoch: [129] \t Loss 3.5631 \t Acc 8.91 \t AccHead 8.89 \t AccTail 8.94\n",
      "Epoch: [130] \t Loss 3.5605 \t Acc 7.31 \t AccHead 7.64 \t AccTail 6.81\n",
      "Epoch: [131] \t Loss 3.5607 \t Acc 7.68 \t AccHead 9.07 \t AccTail 5.62\n",
      "Epoch: [132] \t Loss 3.5677 \t Acc 7.60 \t AccHead 9.75 \t AccTail 4.40\n",
      "Epoch: [133] \t Loss 3.5580 \t Acc 9.06 \t AccHead 10.44 \t AccTail 7.01\n",
      "Epoch: [134] \t Loss 3.5700 \t Acc 9.67 \t AccHead 12.61 \t AccTail 5.28\n",
      "Epoch: [135] \t Loss 3.5572 \t Acc 9.24 \t AccHead 10.31 \t AccTail 7.65\n",
      "Epoch: [136] \t Loss 3.5620 \t Acc 9.38 \t AccHead 10.90 \t AccTail 7.10\n",
      "Epoch: [137] \t Loss 3.5616 \t Acc 8.93 \t AccHead 9.40 \t AccTail 8.22\n",
      "Epoch: [138] \t Loss 3.5582 \t Acc 9.71 \t AccHead 10.40 \t AccTail 8.66\n",
      "Epoch: [139] \t Loss 3.5579 \t Acc 9.01 \t AccHead 10.63 \t AccTail 6.60\n",
      "Epoch: [140] \t Loss 3.5687 \t Acc 9.51 \t AccHead 11.76 \t AccTail 6.14\n",
      "Epoch: [141] \t Loss 3.5651 \t Acc 7.36 \t AccHead 7.56 \t AccTail 7.07\n",
      "Epoch: [142] \t Loss 3.5706 \t Acc 11.16 \t AccHead 12.99 \t AccTail 8.43\n",
      "Epoch: [143] \t Loss 3.5735 \t Acc 8.41 \t AccHead 9.57 \t AccTail 6.68\n",
      "Epoch: [144] \t Loss 3.5773 \t Acc 8.83 \t AccHead 8.05 \t AccTail 9.99\n",
      "Epoch: [145] \t Loss 3.5693 \t Acc 7.36 \t AccHead 6.77 \t AccTail 8.25\n",
      "Epoch: [146] \t Loss 3.5550 \t Acc 6.96 \t AccHead 6.38 \t AccTail 7.81\n",
      "Epoch: [147] \t Loss 3.5675 \t Acc 9.96 \t AccHead 9.98 \t AccTail 9.93\n",
      "Epoch: [148] \t Loss 3.5723 \t Acc 9.12 \t AccHead 9.65 \t AccTail 8.32\n",
      "Epoch: [149] \t Loss 3.5693 \t Acc 9.89 \t AccHead 11.13 \t AccTail 8.04\n",
      "Epoch: [150] \t Loss 3.5621 \t Acc 10.56 \t AccHead 13.47 \t AccTail 6.22\n",
      "Epoch: [151] \t Loss 3.3925 \t Acc 15.34 \t AccHead 15.39 \t AccTail 15.26\n",
      "Epoch: [152] \t Loss 3.3259 \t Acc 14.97 \t AccHead 17.04 \t AccTail 11.88\n",
      "Epoch: [153] \t Loss 3.3022 \t Acc 15.76 \t AccHead 18.16 \t AccTail 12.17\n",
      "Epoch: [154] \t Loss 3.2873 \t Acc 15.90 \t AccHead 17.78 \t AccTail 13.09\n",
      "Epoch: [155] \t Loss 3.2862 \t Acc 16.83 \t AccHead 19.40 \t AccTail 12.99\n",
      "Epoch: [156] \t Loss 3.2681 \t Acc 15.78 \t AccHead 18.95 \t AccTail 11.04\n",
      "Epoch: [157] \t Loss 3.2638 \t Acc 17.43 \t AccHead 20.08 \t AccTail 13.47\n",
      "Epoch: [158] \t Loss 3.2476 \t Acc 16.96 \t AccHead 19.02 \t AccTail 13.89\n",
      "Epoch: [159] \t Loss 3.2485 \t Acc 16.98 \t AccHead 17.69 \t AccTail 15.91\n",
      "Epoch: [160] \t Loss 3.2268 \t Acc 17.24 \t AccHead 18.75 \t AccTail 14.99\n",
      "Epoch: [161] \t Loss 3.2155 \t Acc 17.50 \t AccHead 20.60 \t AccTail 12.88\n",
      "Epoch: [162] \t Loss 3.2206 \t Acc 16.94 \t AccHead 19.34 \t AccTail 13.36\n",
      "Epoch: [163] \t Loss 3.1982 \t Acc 16.54 \t AccHead 16.68 \t AccTail 16.32\n",
      "Epoch: [164] \t Loss 3.1976 \t Acc 17.26 \t AccHead 18.77 \t AccTail 15.01\n",
      "Epoch: [165] \t Loss 3.1897 \t Acc 18.99 \t AccHead 22.40 \t AccTail 13.88\n",
      "Epoch: [166] \t Loss 3.1634 \t Acc 19.21 \t AccHead 21.82 \t AccTail 15.32\n",
      "Epoch: [167] \t Loss 3.1623 \t Acc 18.21 \t AccHead 19.08 \t AccTail 16.91\n",
      "Epoch: [168] \t Loss 3.1552 \t Acc 18.99 \t AccHead 21.56 \t AccTail 15.14\n",
      "Epoch: [169] \t Loss 3.1433 \t Acc 18.89 \t AccHead 20.09 \t AccTail 17.10\n",
      "Epoch: [170] \t Loss 3.1438 \t Acc 19.94 \t AccHead 22.65 \t AccTail 15.90\n",
      "Epoch: [171] \t Loss 3.1382 \t Acc 18.77 \t AccHead 22.99 \t AccTail 12.46\n",
      "Epoch: [172] \t Loss 3.1352 \t Acc 19.02 \t AccHead 22.19 \t AccTail 14.29\n",
      "Epoch: [173] \t Loss 3.1297 \t Acc 18.49 \t AccHead 21.32 \t AccTail 14.27\n",
      "Epoch: [174] \t Loss 3.1282 \t Acc 20.28 \t AccHead 22.68 \t AccTail 16.71\n",
      "Epoch: [175] \t Loss 3.1090 \t Acc 20.39 \t AccHead 23.91 \t AccTail 15.14\n",
      "Epoch: [176] \t Loss 3.1112 \t Acc 19.71 \t AccHead 23.13 \t AccTail 14.60\n",
      "Epoch: [177] \t Loss 3.0975 \t Acc 18.94 \t AccHead 20.97 \t AccTail 15.92\n",
      "Epoch: [178] \t Loss 3.1055 \t Acc 20.70 \t AccHead 24.55 \t AccTail 14.95\n",
      "Epoch: [179] \t Loss 3.1036 \t Acc 19.84 \t AccHead 24.05 \t AccTail 13.56\n",
      "Epoch: [180] \t Loss 3.1021 \t Acc 19.54 \t AccHead 21.47 \t AccTail 16.66\n",
      "Epoch: [181] \t Loss 3.0910 \t Acc 19.71 \t AccHead 23.23 \t AccTail 14.45\n",
      "Epoch: [182] \t Loss 3.0863 \t Acc 20.92 \t AccHead 23.73 \t AccTail 16.74\n",
      "Epoch: [183] \t Loss 3.0951 \t Acc 18.25 \t AccHead 22.50 \t AccTail 11.92\n",
      "Epoch: [184] \t Loss 3.0884 \t Acc 19.42 \t AccHead 21.36 \t AccTail 16.54\n",
      "Epoch: [185] \t Loss 3.0921 \t Acc 19.98 \t AccHead 22.30 \t AccTail 16.51\n",
      "Epoch: [186] \t Loss 3.0765 \t Acc 18.83 \t AccHead 21.90 \t AccTail 14.24\n",
      "Epoch: [187] \t Loss 3.0758 \t Acc 20.44 \t AccHead 24.44 \t AccTail 14.47\n",
      "Epoch: [188] \t Loss 3.0650 \t Acc 19.56 \t AccHead 22.37 \t AccTail 15.36\n",
      "Epoch: [189] \t Loss 3.0671 \t Acc 18.78 \t AccHead 19.83 \t AccTail 17.20\n",
      "Epoch: [190] \t Loss 3.0697 \t Acc 20.71 \t AccHead 22.99 \t AccTail 17.31\n",
      "Epoch: [191] \t Loss 3.0751 \t Acc 17.84 \t AccHead 22.64 \t AccTail 10.69\n",
      "Epoch: [192] \t Loss 3.0588 \t Acc 18.96 \t AccHead 21.57 \t AccTail 15.05\n",
      "Epoch: [193] \t Loss 3.0720 \t Acc 21.58 \t AccHead 25.74 \t AccTail 15.39\n",
      "Epoch: [194] \t Loss 3.0591 \t Acc 19.72 \t AccHead 21.90 \t AccTail 16.47\n",
      "Epoch: [195] \t Loss 3.0775 \t Acc 20.56 \t AccHead 22.07 \t AccTail 18.30\n",
      "Epoch: [196] \t Loss 3.0590 \t Acc 19.43 \t AccHead 21.00 \t AccTail 17.08\n",
      "Epoch: [197] \t Loss 3.0458 \t Acc 20.76 \t AccHead 23.44 \t AccTail 16.76\n",
      "Epoch: [198] \t Loss 3.0593 \t Acc 20.60 \t AccHead 25.08 \t AccTail 13.92\n",
      "Epoch: [199] \t Loss 3.0583 \t Acc 20.88 \t AccHead 22.52 \t AccTail 18.42\n",
      "Epoch: [200] \t Loss 3.0497 \t Acc 20.89 \t AccHead 24.43 \t AccTail 15.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 03:22:25,169]\u001b[0m Trial 5 finished with value: 5.086322784423828 and parameters: {'n_epoch': 200, 'weight_decay': 0.008873178050324965}. Best is trial 4 with value: 10.658534049987793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 5.09 \t AccHead 10.17 \t AccTail 0.08\n",
      "Epoch: [001] \t Loss 3.9386 \t Acc 5.09 \t AccHead 6.06 \t AccTail 3.64\n",
      "Epoch: [002] \t Loss 3.7206 \t Acc 6.32 \t AccHead 8.52 \t AccTail 3.04\n",
      "Epoch: [003] \t Loss 3.7100 \t Acc 6.56 \t AccHead 5.39 \t AccTail 8.29\n",
      "Epoch: [004] \t Loss 3.7087 \t Acc 6.75 \t AccHead 6.92 \t AccTail 6.49\n",
      "Epoch: [005] \t Loss 3.7160 \t Acc 4.68 \t AccHead 5.63 \t AccTail 3.27\n",
      "Epoch: [006] \t Loss 3.7230 \t Acc 5.87 \t AccHead 6.94 \t AccTail 4.28\n",
      "Epoch: [007] \t Loss 3.7216 \t Acc 5.03 \t AccHead 7.46 \t AccTail 1.41\n",
      "Epoch: [008] \t Loss 3.7174 \t Acc 7.49 \t AccHead 9.23 \t AccTail 4.89\n",
      "Epoch: [009] \t Loss 3.7231 \t Acc 5.98 \t AccHead 7.46 \t AccTail 3.78\n",
      "Epoch: [010] \t Loss 3.7277 \t Acc 5.50 \t AccHead 2.22 \t AccTail 10.40\n",
      "Epoch: [011] \t Loss 3.7280 \t Acc 6.58 \t AccHead 4.93 \t AccTail 9.05\n",
      "Epoch: [012] \t Loss 3.7237 \t Acc 7.26 \t AccHead 7.90 \t AccTail 6.31\n",
      "Epoch: [013] \t Loss 3.7273 \t Acc 6.49 \t AccHead 6.51 \t AccTail 6.46\n",
      "Epoch: [014] \t Loss 3.7207 \t Acc 6.32 \t AccHead 6.57 \t AccTail 5.93\n",
      "Epoch: [015] \t Loss 3.7247 \t Acc 7.42 \t AccHead 7.52 \t AccTail 7.27\n",
      "Epoch: [016] \t Loss 3.7174 \t Acc 7.11 \t AccHead 9.57 \t AccTail 3.44\n",
      "Epoch: [017] \t Loss 3.7329 \t Acc 6.03 \t AccHead 8.92 \t AccTail 1.72\n",
      "Epoch: [018] \t Loss 3.7247 \t Acc 6.29 \t AccHead 9.68 \t AccTail 1.21\n",
      "Epoch: [019] \t Loss 3.7244 \t Acc 7.09 \t AccHead 5.76 \t AccTail 9.07\n",
      "Epoch: [020] \t Loss 3.7323 \t Acc 7.91 \t AccHead 8.48 \t AccTail 7.05\n",
      "Epoch: [021] \t Loss 3.7440 \t Acc 5.91 \t AccHead 7.15 \t AccTail 4.07\n",
      "Epoch: [022] \t Loss 3.7440 \t Acc 6.22 \t AccHead 8.42 \t AccTail 2.95\n",
      "Epoch: [023] \t Loss 3.7512 \t Acc 7.02 \t AccHead 9.50 \t AccTail 3.31\n",
      "Epoch: [024] \t Loss 3.7434 \t Acc 7.94 \t AccHead 9.58 \t AccTail 5.50\n",
      "Epoch: [025] \t Loss 3.7310 \t Acc 5.91 \t AccHead 6.23 \t AccTail 5.44\n",
      "Epoch: [026] \t Loss 3.7326 \t Acc 4.74 \t AccHead 4.61 \t AccTail 4.93\n",
      "Epoch: [027] \t Loss 3.7417 \t Acc 6.19 \t AccHead 8.07 \t AccTail 3.38\n",
      "Epoch: [028] \t Loss 3.7403 \t Acc 5.76 \t AccHead 8.03 \t AccTail 2.38\n",
      "Epoch: [029] \t Loss 3.7470 \t Acc 5.86 \t AccHead 4.57 \t AccTail 7.80\n",
      "Epoch: [030] \t Loss 3.7540 \t Acc 6.01 \t AccHead 8.90 \t AccTail 1.69\n",
      "Epoch: [031] \t Loss 3.7508 \t Acc 3.51 \t AccHead 5.44 \t AccTail 0.62\n",
      "Epoch: [032] \t Loss 3.7553 \t Acc 5.56 \t AccHead 6.80 \t AccTail 3.71\n",
      "Epoch: [033] \t Loss 3.7596 \t Acc 5.21 \t AccHead 6.32 \t AccTail 3.56\n",
      "Epoch: [034] \t Loss 3.7587 \t Acc 4.20 \t AccHead 2.21 \t AccTail 7.18\n",
      "Epoch: [035] \t Loss 3.7660 \t Acc 5.09 \t AccHead 4.43 \t AccTail 6.08\n",
      "Epoch: [036] \t Loss 3.7591 \t Acc 5.95 \t AccHead 5.77 \t AccTail 6.24\n",
      "Epoch: [037] \t Loss 3.7560 \t Acc 6.52 \t AccHead 6.56 \t AccTail 6.45\n",
      "Epoch: [038] \t Loss 3.7678 \t Acc 6.69 \t AccHead 9.59 \t AccTail 2.36\n",
      "Epoch: [039] \t Loss 3.7643 \t Acc 5.04 \t AccHead 6.99 \t AccTail 2.12\n",
      "Epoch: [040] \t Loss 3.7545 \t Acc 6.29 \t AccHead 7.61 \t AccTail 4.31\n",
      "Epoch: [041] \t Loss 3.7646 \t Acc 5.82 \t AccHead 3.21 \t AccTail 9.72\n",
      "Epoch: [042] \t Loss 3.7592 \t Acc 5.25 \t AccHead 2.45 \t AccTail 9.43\n",
      "Epoch: [043] \t Loss 3.7549 \t Acc 6.41 \t AccHead 6.41 \t AccTail 6.41\n",
      "Epoch: [044] \t Loss 3.7703 \t Acc 4.13 \t AccHead 5.34 \t AccTail 2.32\n",
      "Epoch: [045] \t Loss 3.7727 \t Acc 6.08 \t AccHead 3.03 \t AccTail 10.65\n",
      "Epoch: [046] \t Loss 3.7576 \t Acc 3.34 \t AccHead 4.09 \t AccTail 2.21\n",
      "Epoch: [047] \t Loss 3.7721 \t Acc 4.47 \t AccHead 6.44 \t AccTail 1.52\n",
      "Epoch: [048] \t Loss 3.7699 \t Acc 2.46 \t AccHead 0.62 \t AccTail 5.22\n",
      "Epoch: [049] \t Loss 3.7627 \t Acc 4.80 \t AccHead 6.94 \t AccTail 1.61\n",
      "Epoch: [050] \t Loss 3.7648 \t Acc 4.08 \t AccHead 5.33 \t AccTail 2.21\n",
      "Epoch: [051] \t Loss 3.7600 \t Acc 5.46 \t AccHead 5.38 \t AccTail 5.57\n",
      "Epoch: [052] \t Loss 3.7677 \t Acc 4.59 \t AccHead 1.89 \t AccTail 8.61\n",
      "Epoch: [053] \t Loss 3.7537 \t Acc 4.79 \t AccHead 2.27 \t AccTail 8.57\n",
      "Epoch: [054] \t Loss 3.7765 \t Acc 4.94 \t AccHead 2.95 \t AccTail 7.91\n",
      "Epoch: [055] \t Loss 3.7650 \t Acc 6.11 \t AccHead 8.62 \t AccTail 2.37\n",
      "Epoch: [056] \t Loss 3.7649 \t Acc 4.34 \t AccHead 1.96 \t AccTail 7.88\n",
      "Epoch: [057] \t Loss 3.7677 \t Acc 4.45 \t AccHead 3.71 \t AccTail 5.55\n",
      "Epoch: [058] \t Loss 3.7685 \t Acc 5.51 \t AccHead 7.19 \t AccTail 3.00\n",
      "Epoch: [059] \t Loss 3.7680 \t Acc 6.45 \t AccHead 6.57 \t AccTail 6.26\n",
      "Epoch: [060] \t Loss 3.7822 \t Acc 5.38 \t AccHead 3.33 \t AccTail 8.44\n",
      "Epoch: [061] \t Loss 3.7783 \t Acc 5.57 \t AccHead 4.09 \t AccTail 7.78\n",
      "Epoch: [062] \t Loss 3.7729 \t Acc 2.43 \t AccHead 0.43 \t AccTail 5.40\n",
      "Epoch: [063] \t Loss 3.7802 \t Acc 5.25 \t AccHead 7.20 \t AccTail 2.35\n",
      "Epoch: [064] \t Loss 3.7998 \t Acc 3.81 \t AccHead 3.76 \t AccTail 3.87\n",
      "Epoch: [065] \t Loss 3.7758 \t Acc 3.01 \t AccHead 3.14 \t AccTail 2.81\n",
      "Epoch: [066] \t Loss 3.7862 \t Acc 5.11 \t AccHead 5.34 \t AccTail 4.76\n",
      "Epoch: [067] \t Loss 3.7836 \t Acc 4.82 \t AccHead 5.15 \t AccTail 4.33\n",
      "Epoch: [068] \t Loss 3.7871 \t Acc 4.93 \t AccHead 5.84 \t AccTail 3.58\n",
      "Epoch: [069] \t Loss 3.7965 \t Acc 4.00 \t AccHead 3.84 \t AccTail 4.24\n",
      "Epoch: [070] \t Loss 3.7919 \t Acc 5.37 \t AccHead 6.78 \t AccTail 3.27\n",
      "Epoch: [071] \t Loss 3.7932 \t Acc 4.41 \t AccHead 3.40 \t AccTail 5.92\n",
      "Epoch: [072] \t Loss 3.7903 \t Acc 4.20 \t AccHead 4.53 \t AccTail 3.70\n",
      "Epoch: [073] \t Loss 3.7820 \t Acc 5.29 \t AccHead 6.69 \t AccTail 3.21\n",
      "Epoch: [074] \t Loss 3.7964 \t Acc 4.23 \t AccHead 4.99 \t AccTail 3.11\n",
      "Epoch: [075] \t Loss 3.7859 \t Acc 3.43 \t AccHead 4.76 \t AccTail 1.45\n",
      "Epoch: [076] \t Loss 3.7809 \t Acc 5.26 \t AccHead 6.95 \t AccTail 2.76\n",
      "Epoch: [077] \t Loss 3.7873 \t Acc 5.50 \t AccHead 4.19 \t AccTail 7.45\n",
      "Epoch: [078] \t Loss 3.7930 \t Acc 5.60 \t AccHead 5.70 \t AccTail 5.46\n",
      "Epoch: [079] \t Loss 3.7857 \t Acc 5.75 \t AccHead 4.23 \t AccTail 8.01\n",
      "Epoch: [080] \t Loss 3.7890 \t Acc 3.45 \t AccHead 5.71 \t AccTail 0.07\n",
      "Epoch: [081] \t Loss 3.7863 \t Acc 4.17 \t AccHead 2.05 \t AccTail 7.33\n",
      "Epoch: [082] \t Loss 3.7821 \t Acc 4.17 \t AccHead 3.02 \t AccTail 5.90\n",
      "Epoch: [083] \t Loss 3.7770 \t Acc 5.45 \t AccHead 5.46 \t AccTail 5.45\n",
      "Epoch: [084] \t Loss 3.7739 \t Acc 5.84 \t AccHead 7.64 \t AccTail 3.17\n",
      "Epoch: [085] \t Loss 3.7801 \t Acc 6.41 \t AccHead 7.52 \t AccTail 4.75\n",
      "Epoch: [086] \t Loss 3.7886 \t Acc 6.11 \t AccHead 5.22 \t AccTail 7.45\n",
      "Epoch: [087] \t Loss 3.7998 \t Acc 4.55 \t AccHead 2.60 \t AccTail 7.45\n",
      "Epoch: [088] \t Loss 3.7883 \t Acc 3.89 \t AccHead 2.62 \t AccTail 5.78\n",
      "Epoch: [089] \t Loss 3.8004 \t Acc 3.77 \t AccHead 2.14 \t AccTail 6.20\n",
      "Epoch: [090] \t Loss 3.7933 \t Acc 5.32 \t AccHead 6.20 \t AccTail 4.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 03:38:23,698]\u001b[0m Trial 6 finished with value: 1.9745683670043945 and parameters: {'n_epoch': 90, 'weight_decay': 0.018706489892097014}. Best is trial 4 with value: 10.658534049987793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 1.97 \t AccHead 3.90 \t AccTail 0.08\n",
      "Epoch: [001] \t Loss 4.0135 \t Acc 10.28 \t AccHead 12.59 \t AccTail 6.83\n",
      "Epoch: [002] \t Loss 3.5277 \t Acc 13.22 \t AccHead 13.99 \t AccTail 12.06\n",
      "Epoch: [003] \t Loss 3.3405 \t Acc 17.02 \t AccHead 17.16 \t AccTail 16.82\n",
      "Epoch: [004] \t Loss 3.2043 \t Acc 20.44 \t AccHead 22.80 \t AccTail 16.93\n",
      "Epoch: [005] \t Loss 3.0644 \t Acc 22.75 \t AccHead 27.13 \t AccTail 16.20\n",
      "Epoch: [006] \t Loss 2.9560 \t Acc 24.84 \t AccHead 29.02 \t AccTail 18.60\n",
      "Epoch: [007] \t Loss 2.8554 \t Acc 22.40 \t AccHead 26.68 \t AccTail 16.00\n",
      "Epoch: [008] \t Loss 2.7692 \t Acc 28.02 \t AccHead 31.10 \t AccTail 23.44\n",
      "Epoch: [009] \t Loss 2.6703 \t Acc 30.21 \t AccHead 34.82 \t AccTail 23.34\n",
      "Epoch: [010] \t Loss 2.5880 \t Acc 31.46 \t AccHead 37.40 \t AccTail 22.60\n",
      "Epoch: [011] \t Loss 2.5079 \t Acc 34.75 \t AccHead 37.52 \t AccTail 30.61\n",
      "Epoch: [012] \t Loss 2.4357 \t Acc 35.54 \t AccHead 39.30 \t AccTail 29.95\n",
      "Epoch: [013] \t Loss 2.3747 \t Acc 36.75 \t AccHead 42.03 \t AccTail 28.87\n",
      "Epoch: [014] \t Loss 2.2941 \t Acc 37.85 \t AccHead 41.65 \t AccTail 32.16\n",
      "Epoch: [015] \t Loss 2.2456 \t Acc 40.81 \t AccHead 45.33 \t AccTail 34.06\n",
      "Epoch: [016] \t Loss 2.1805 \t Acc 41.69 \t AccHead 45.81 \t AccTail 35.52\n",
      "Epoch: [017] \t Loss 2.1118 \t Acc 42.64 \t AccHead 47.93 \t AccTail 34.76\n",
      "Epoch: [018] \t Loss 2.0616 \t Acc 43.63 \t AccHead 47.31 \t AccTail 38.15\n",
      "Epoch: [019] \t Loss 2.0153 \t Acc 44.58 \t AccHead 48.97 \t AccTail 38.03\n",
      "Epoch: [020] \t Loss 1.9555 \t Acc 46.69 \t AccHead 51.45 \t AccTail 39.58\n",
      "Epoch: [021] \t Loss 1.9116 \t Acc 47.13 \t AccHead 52.52 \t AccTail 39.08\n",
      "Epoch: [022] \t Loss 1.8869 \t Acc 49.20 \t AccHead 53.85 \t AccTail 42.27\n",
      "Epoch: [023] \t Loss 1.8294 \t Acc 48.31 \t AccHead 52.21 \t AccTail 42.48\n",
      "Epoch: [024] \t Loss 1.7745 \t Acc 47.31 \t AccHead 52.48 \t AccTail 39.59\n",
      "Epoch: [025] \t Loss 1.7509 \t Acc 50.84 \t AccHead 55.81 \t AccTail 43.42\n",
      "Epoch: [026] \t Loss 1.7140 \t Acc 50.48 \t AccHead 54.55 \t AccTail 44.39\n",
      "Epoch: [027] \t Loss 1.6611 \t Acc 52.84 \t AccHead 58.33 \t AccTail 44.66\n",
      "Epoch: [028] \t Loss 1.6149 \t Acc 54.38 \t AccHead 58.04 \t AccTail 48.91\n",
      "Epoch: [029] \t Loss 1.5906 \t Acc 54.86 \t AccHead 59.11 \t AccTail 48.50\n",
      "Epoch: [030] \t Loss 1.5408 \t Acc 57.17 \t AccHead 61.73 \t AccTail 50.35\n",
      "Epoch: [031] \t Loss 1.5084 \t Acc 59.66 \t AccHead 63.77 \t AccTail 53.52\n",
      "Epoch: [032] \t Loss 1.4792 \t Acc 55.99 \t AccHead 62.38 \t AccTail 46.47\n",
      "Epoch: [033] \t Loss 1.4261 \t Acc 57.51 \t AccHead 63.10 \t AccTail 49.16\n",
      "Epoch: [034] \t Loss 1.3893 \t Acc 58.76 \t AccHead 62.95 \t AccTail 52.50\n",
      "Epoch: [035] \t Loss 1.3600 \t Acc 60.23 \t AccHead 63.25 \t AccTail 55.73\n",
      "Epoch: [036] \t Loss 1.3195 \t Acc 62.07 \t AccHead 65.84 \t AccTail 56.44\n",
      "Epoch: [037] \t Loss 1.3142 \t Acc 62.53 \t AccHead 67.97 \t AccTail 54.40\n",
      "Epoch: [038] \t Loss 1.2521 \t Acc 63.17 \t AccHead 66.60 \t AccTail 58.05\n",
      "Epoch: [039] \t Loss 1.2179 \t Acc 66.87 \t AccHead 68.91 \t AccTail 63.82\n",
      "Epoch: [040] \t Loss 1.1978 \t Acc 65.23 \t AccHead 67.83 \t AccTail 61.36\n",
      "Epoch: [041] \t Loss 1.1528 \t Acc 65.65 \t AccHead 67.04 \t AccTail 63.58\n",
      "Epoch: [042] \t Loss 1.1294 \t Acc 68.25 \t AccHead 71.87 \t AccTail 62.83\n",
      "Epoch: [043] \t Loss 1.1093 \t Acc 68.51 \t AccHead 72.56 \t AccTail 62.47\n",
      "Epoch: [044] \t Loss 1.0542 \t Acc 70.25 \t AccHead 72.89 \t AccTail 66.32\n",
      "Epoch: [045] \t Loss 1.0358 \t Acc 66.50 \t AccHead 69.97 \t AccTail 61.31\n",
      "Epoch: [046] \t Loss 1.0036 \t Acc 72.88 \t AccHead 74.51 \t AccTail 70.44\n",
      "Epoch: [047] \t Loss 0.9882 \t Acc 68.96 \t AccHead 71.28 \t AccTail 65.51\n",
      "Epoch: [048] \t Loss 0.9731 \t Acc 72.74 \t AccHead 75.03 \t AccTail 69.31\n",
      "Epoch: [049] \t Loss 0.9296 \t Acc 71.91 \t AccHead 74.29 \t AccTail 68.34\n",
      "Epoch: [050] \t Loss 0.9132 \t Acc 71.39 \t AccHead 73.85 \t AccTail 67.71\n",
      "Epoch: [051] \t Loss 0.8981 \t Acc 75.21 \t AccHead 77.25 \t AccTail 72.17\n",
      "Epoch: [052] \t Loss 0.8560 \t Acc 73.89 \t AccHead 74.42 \t AccTail 73.09\n",
      "Epoch: [053] \t Loss 0.8238 \t Acc 72.57 \t AccHead 75.65 \t AccTail 67.96\n",
      "Epoch: [054] \t Loss 0.8551 \t Acc 77.29 \t AccHead 78.93 \t AccTail 74.84\n",
      "Epoch: [055] \t Loss 0.7777 \t Acc 75.92 \t AccHead 77.42 \t AccTail 73.67\n",
      "Epoch: [056] \t Loss 0.7817 \t Acc 74.82 \t AccHead 76.40 \t AccTail 72.46\n",
      "Epoch: [057] \t Loss 0.7627 \t Acc 77.49 \t AccHead 79.69 \t AccTail 74.22\n",
      "Epoch: [058] \t Loss 0.7384 \t Acc 79.58 \t AccHead 81.59 \t AccTail 76.58\n",
      "Epoch: [059] \t Loss 0.7277 \t Acc 77.55 \t AccHead 80.06 \t AccTail 73.81\n",
      "Epoch: [060] \t Loss 0.7146 \t Acc 78.53 \t AccHead 80.62 \t AccTail 75.40\n",
      "Epoch: [061] \t Loss 0.6963 \t Acc 78.79 \t AccHead 80.79 \t AccTail 75.80\n",
      "Epoch: [062] \t Loss 0.6824 \t Acc 79.23 \t AccHead 79.97 \t AccTail 78.12\n",
      "Epoch: [063] \t Loss 0.6705 \t Acc 80.78 \t AccHead 82.42 \t AccTail 78.33\n",
      "Epoch: [064] \t Loss 0.6420 \t Acc 81.37 \t AccHead 82.76 \t AccTail 79.28\n",
      "Epoch: [065] \t Loss 0.6602 \t Acc 81.77 \t AccHead 83.17 \t AccTail 79.67\n",
      "Epoch: [066] \t Loss 0.6254 \t Acc 81.03 \t AccHead 83.04 \t AccTail 78.04\n",
      "Epoch: [067] \t Loss 0.6087 \t Acc 81.99 \t AccHead 82.71 \t AccTail 80.91\n",
      "Epoch: [068] \t Loss 0.6207 \t Acc 82.00 \t AccHead 82.93 \t AccTail 80.61\n",
      "Epoch: [069] \t Loss 0.5989 \t Acc 83.22 \t AccHead 84.03 \t AccTail 82.00\n",
      "Epoch: [070] \t Loss 0.6276 \t Acc 79.21 \t AccHead 80.45 \t AccTail 77.37\n",
      "Epoch: [071] \t Loss 0.5790 \t Acc 83.92 \t AccHead 84.94 \t AccTail 82.39\n",
      "Epoch: [072] \t Loss 0.5620 \t Acc 82.44 \t AccHead 84.05 \t AccTail 80.03\n",
      "Epoch: [073] \t Loss 0.5952 \t Acc 83.92 \t AccHead 84.90 \t AccTail 82.45\n",
      "Epoch: [074] \t Loss 0.5471 \t Acc 80.48 \t AccHead 81.34 \t AccTail 79.20\n",
      "Epoch: [075] \t Loss 0.5558 \t Acc 83.35 \t AccHead 85.35 \t AccTail 80.36\n",
      "Epoch: [076] \t Loss 0.5768 \t Acc 82.56 \t AccHead 84.11 \t AccTail 80.26\n",
      "Epoch: [077] \t Loss 0.5595 \t Acc 83.09 \t AccHead 84.11 \t AccTail 81.58\n",
      "Epoch: [078] \t Loss 0.5343 \t Acc 84.40 \t AccHead 86.03 \t AccTail 81.95\n",
      "Epoch: [079] \t Loss 0.5454 \t Acc 85.32 \t AccHead 86.52 \t AccTail 83.52\n",
      "Epoch: [080] \t Loss 0.5297 \t Acc 85.89 \t AccHead 86.44 \t AccTail 85.06\n",
      "Epoch: [081] \t Loss 0.5153 \t Acc 85.70 \t AccHead 86.22 \t AccTail 84.92\n",
      "Epoch: [082] \t Loss 0.5123 \t Acc 82.30 \t AccHead 84.30 \t AccTail 79.31\n",
      "Epoch: [083] \t Loss 0.4974 \t Acc 84.47 \t AccHead 86.45 \t AccTail 81.52\n",
      "Epoch: [084] \t Loss 0.4911 \t Acc 86.34 \t AccHead 87.55 \t AccTail 84.53\n",
      "Epoch: [085] \t Loss 0.5135 \t Acc 84.64 \t AccHead 84.94 \t AccTail 84.19\n",
      "Epoch: [086] \t Loss 0.4937 \t Acc 85.53 \t AccHead 87.14 \t AccTail 83.14\n",
      "Epoch: [087] \t Loss 0.4916 \t Acc 85.30 \t AccHead 87.47 \t AccTail 82.06\n",
      "Epoch: [088] \t Loss 0.4819 \t Acc 83.48 \t AccHead 84.39 \t AccTail 82.12\n",
      "Epoch: [089] \t Loss 0.4885 \t Acc 84.35 \t AccHead 85.60 \t AccTail 82.49\n",
      "Epoch: [090] \t Loss 0.4829 \t Acc 87.58 \t AccHead 88.77 \t AccTail 85.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 03:54:15,107]\u001b[0m Trial 7 finished with value: 8.890726089477539 and parameters: {'n_epoch': 90, 'weight_decay': 0.00020427405395885556}. Best is trial 4 with value: 10.658534049987793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 8.89 \t AccHead 17.83 \t AccTail 0.08\n",
      "Epoch: [001] \t Loss 3.9862 \t Acc 5.31 \t AccHead 5.79 \t AccTail 4.59\n",
      "Epoch: [002] \t Loss 3.5609 \t Acc 9.57 \t AccHead 10.59 \t AccTail 8.05\n",
      "Epoch: [003] \t Loss 3.4893 \t Acc 12.13 \t AccHead 14.62 \t AccTail 8.41\n",
      "Epoch: [004] \t Loss 3.4486 \t Acc 10.49 \t AccHead 10.36 \t AccTail 10.69\n",
      "Epoch: [005] \t Loss 3.4168 \t Acc 11.10 \t AccHead 14.90 \t AccTail 5.43\n",
      "Epoch: [006] \t Loss 3.3870 \t Acc 12.27 \t AccHead 12.56 \t AccTail 11.83\n",
      "Epoch: [007] \t Loss 3.3794 \t Acc 13.60 \t AccHead 17.64 \t AccTail 7.57\n",
      "Epoch: [008] \t Loss 3.3564 \t Acc 13.93 \t AccHead 15.40 \t AccTail 11.73\n",
      "Epoch: [009] \t Loss 3.3337 \t Acc 11.29 \t AccHead 11.70 \t AccTail 10.68\n",
      "Epoch: [010] \t Loss 3.3310 \t Acc 8.55 \t AccHead 8.95 \t AccTail 7.95\n",
      "Epoch: [011] \t Loss 3.3378 \t Acc 15.21 \t AccHead 16.85 \t AccTail 12.77\n",
      "Epoch: [012] \t Loss 3.3321 \t Acc 11.68 \t AccHead 14.78 \t AccTail 7.04\n",
      "Epoch: [013] \t Loss 3.3284 \t Acc 13.59 \t AccHead 17.12 \t AccTail 8.32\n",
      "Epoch: [014] \t Loss 3.3388 \t Acc 8.16 \t AccHead 9.09 \t AccTail 6.76\n",
      "Epoch: [015] \t Loss 3.3182 \t Acc 11.53 \t AccHead 13.88 \t AccTail 8.03\n",
      "Epoch: [016] \t Loss 3.3217 \t Acc 13.94 \t AccHead 15.52 \t AccTail 11.59\n",
      "Epoch: [017] \t Loss 3.3253 \t Acc 13.88 \t AccHead 14.46 \t AccTail 13.02\n",
      "Epoch: [018] \t Loss 3.3196 \t Acc 11.63 \t AccHead 14.83 \t AccTail 6.84\n",
      "Epoch: [019] \t Loss 3.3218 \t Acc 12.20 \t AccHead 15.17 \t AccTail 7.78\n",
      "Epoch: [020] \t Loss 3.3266 \t Acc 14.53 \t AccHead 15.77 \t AccTail 12.69\n",
      "Epoch: [021] \t Loss 3.3312 \t Acc 12.00 \t AccHead 14.42 \t AccTail 8.39\n",
      "Epoch: [022] \t Loss 3.3196 \t Acc 12.07 \t AccHead 12.33 \t AccTail 11.68\n",
      "Epoch: [023] \t Loss 3.3143 \t Acc 10.71 \t AccHead 11.90 \t AccTail 8.94\n",
      "Epoch: [024] \t Loss 3.3089 \t Acc 13.53 \t AccHead 17.88 \t AccTail 7.01\n",
      "Epoch: [025] \t Loss 3.3105 \t Acc 15.64 \t AccHead 18.56 \t AccTail 11.28\n",
      "Epoch: [026] \t Loss 3.3043 \t Acc 12.42 \t AccHead 15.84 \t AccTail 7.32\n",
      "Epoch: [027] \t Loss 3.3128 \t Acc 13.75 \t AccHead 16.61 \t AccTail 9.49\n",
      "Epoch: [028] \t Loss 3.3032 \t Acc 12.04 \t AccHead 13.46 \t AccTail 9.94\n",
      "Epoch: [029] \t Loss 3.3211 \t Acc 11.50 \t AccHead 11.78 \t AccTail 11.08\n",
      "Epoch: [030] \t Loss 3.3060 \t Acc 12.11 \t AccHead 12.47 \t AccTail 11.58\n",
      "Epoch: [031] \t Loss 3.2970 \t Acc 13.21 \t AccHead 14.77 \t AccTail 10.87\n",
      "Epoch: [032] \t Loss 3.3194 \t Acc 14.32 \t AccHead 17.40 \t AccTail 9.72\n",
      "Epoch: [033] \t Loss 3.3001 \t Acc 12.86 \t AccHead 16.48 \t AccTail 7.45\n",
      "Epoch: [034] \t Loss 3.2948 \t Acc 12.72 \t AccHead 14.42 \t AccTail 10.18\n",
      "Epoch: [035] \t Loss 3.2927 \t Acc 14.04 \t AccHead 18.40 \t AccTail 7.53\n",
      "Epoch: [036] \t Loss 3.3013 \t Acc 14.01 \t AccHead 13.58 \t AccTail 14.66\n",
      "Epoch: [037] \t Loss 3.2992 \t Acc 14.48 \t AccHead 16.82 \t AccTail 10.98\n",
      "Epoch: [038] \t Loss 3.2935 \t Acc 12.68 \t AccHead 15.13 \t AccTail 9.02\n",
      "Epoch: [039] \t Loss 3.3027 \t Acc 11.37 \t AccHead 14.81 \t AccTail 6.23\n",
      "Epoch: [040] \t Loss 3.2812 \t Acc 11.71 \t AccHead 12.95 \t AccTail 9.88\n",
      "Epoch: [041] \t Loss 3.2868 \t Acc 12.66 \t AccHead 15.82 \t AccTail 7.92\n",
      "Epoch: [042] \t Loss 3.2900 \t Acc 14.08 \t AccHead 15.96 \t AccTail 11.27\n",
      "Epoch: [043] \t Loss 3.2832 \t Acc 12.08 \t AccHead 16.91 \t AccTail 4.88\n",
      "Epoch: [044] \t Loss 3.2992 \t Acc 10.86 \t AccHead 13.44 \t AccTail 6.99\n",
      "Epoch: [045] \t Loss 3.2799 \t Acc 14.23 \t AccHead 18.42 \t AccTail 7.99\n",
      "Epoch: [046] \t Loss 3.2729 \t Acc 15.75 \t AccHead 17.22 \t AccTail 13.54\n",
      "Epoch: [047] \t Loss 3.2889 \t Acc 12.26 \t AccHead 13.38 \t AccTail 10.60\n",
      "Epoch: [048] \t Loss 3.2867 \t Acc 11.51 \t AccHead 13.13 \t AccTail 9.09\n",
      "Epoch: [049] \t Loss 3.2944 \t Acc 13.72 \t AccHead 18.02 \t AccTail 7.31\n",
      "Epoch: [050] \t Loss 3.2938 \t Acc 10.27 \t AccHead 13.34 \t AccTail 5.67\n",
      "Epoch: [051] \t Loss 3.3071 \t Acc 13.86 \t AccHead 15.95 \t AccTail 10.74\n",
      "Epoch: [052] \t Loss 3.2925 \t Acc 10.68 \t AccHead 11.06 \t AccTail 10.12\n",
      "Epoch: [053] \t Loss 3.3062 \t Acc 12.77 \t AccHead 13.98 \t AccTail 10.95\n",
      "Epoch: [054] \t Loss 3.3186 \t Acc 13.54 \t AccHead 14.99 \t AccTail 11.36\n",
      "Epoch: [055] \t Loss 3.2853 \t Acc 12.25 \t AccHead 15.29 \t AccTail 7.72\n",
      "Epoch: [056] \t Loss 3.2965 \t Acc 11.48 \t AccHead 12.35 \t AccTail 10.18\n",
      "Epoch: [057] \t Loss 3.3047 \t Acc 13.71 \t AccHead 18.31 \t AccTail 6.86\n",
      "Epoch: [058] \t Loss 3.3226 \t Acc 12.59 \t AccHead 15.50 \t AccTail 8.24\n",
      "Epoch: [059] \t Loss 3.3252 \t Acc 12.56 \t AccHead 13.14 \t AccTail 11.68\n",
      "Epoch: [060] \t Loss 3.3106 \t Acc 13.20 \t AccHead 17.13 \t AccTail 7.33\n",
      "Epoch: [061] \t Loss 3.3388 \t Acc 11.02 \t AccHead 12.21 \t AccTail 9.25\n",
      "Epoch: [062] \t Loss 3.3247 \t Acc 12.01 \t AccHead 16.15 \t AccTail 5.83\n",
      "Epoch: [063] \t Loss 3.3263 \t Acc 9.74 \t AccHead 12.75 \t AccTail 5.25\n",
      "Epoch: [064] \t Loss 3.3271 \t Acc 10.98 \t AccHead 10.70 \t AccTail 11.41\n",
      "Epoch: [065] \t Loss 3.3200 \t Acc 12.21 \t AccHead 16.17 \t AccTail 6.30\n",
      "Epoch: [066] \t Loss 3.3244 \t Acc 13.20 \t AccHead 16.83 \t AccTail 7.79\n",
      "Epoch: [067] \t Loss 3.3136 \t Acc 13.33 \t AccHead 19.23 \t AccTail 4.52\n",
      "Epoch: [068] \t Loss 3.3242 \t Acc 13.82 \t AccHead 15.12 \t AccTail 11.88\n",
      "Epoch: [069] \t Loss 3.3320 \t Acc 14.54 \t AccHead 18.07 \t AccTail 9.28\n",
      "Epoch: [070] \t Loss 3.3257 \t Acc 13.66 \t AccHead 17.21 \t AccTail 8.35\n",
      "Epoch: [071] \t Loss 3.3309 \t Acc 12.23 \t AccHead 15.57 \t AccTail 7.24\n",
      "Epoch: [072] \t Loss 3.3182 \t Acc 12.35 \t AccHead 14.54 \t AccTail 9.09\n",
      "Epoch: [073] \t Loss 3.3290 \t Acc 8.96 \t AccHead 12.16 \t AccTail 4.20\n",
      "Epoch: [074] \t Loss 3.3335 \t Acc 10.78 \t AccHead 14.73 \t AccTail 4.89\n",
      "Epoch: [075] \t Loss 3.3302 \t Acc 14.47 \t AccHead 17.18 \t AccTail 10.42\n",
      "Epoch: [076] \t Loss 3.3359 \t Acc 12.19 \t AccHead 14.78 \t AccTail 8.32\n",
      "Epoch: [077] \t Loss 3.3229 \t Acc 14.86 \t AccHead 18.32 \t AccTail 9.70\n",
      "Epoch: [078] \t Loss 3.3288 \t Acc 11.21 \t AccHead 14.47 \t AccTail 6.34\n",
      "Epoch: [079] \t Loss 3.3167 \t Acc 13.32 \t AccHead 14.72 \t AccTail 11.22\n",
      "Epoch: [080] \t Loss 3.3368 \t Acc 12.12 \t AccHead 14.95 \t AccTail 7.90\n",
      "Epoch: [081] \t Loss 3.3727 \t Acc 14.07 \t AccHead 18.99 \t AccTail 6.73\n",
      "Epoch: [082] \t Loss 3.3577 \t Acc 11.66 \t AccHead 14.14 \t AccTail 7.97\n",
      "Epoch: [083] \t Loss 3.3588 \t Acc 9.59 \t AccHead 10.95 \t AccTail 7.55\n",
      "Epoch: [084] \t Loss 3.3544 \t Acc 11.96 \t AccHead 14.89 \t AccTail 7.60\n",
      "Epoch: [085] \t Loss 3.3453 \t Acc 11.83 \t AccHead 13.37 \t AccTail 9.53\n",
      "Epoch: [086] \t Loss 3.3429 \t Acc 11.42 \t AccHead 12.65 \t AccTail 9.59\n",
      "Epoch: [087] \t Loss 3.3501 \t Acc 12.17 \t AccHead 15.48 \t AccTail 7.24\n",
      "Epoch: [088] \t Loss 3.3478 \t Acc 13.49 \t AccHead 16.88 \t AccTail 8.44\n",
      "Epoch: [089] \t Loss 3.3496 \t Acc 12.48 \t AccHead 13.87 \t AccTail 10.41\n",
      "Epoch: [090] \t Loss 3.3459 \t Acc 11.53 \t AccHead 12.88 \t AccTail 9.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 04:10:12,227]\u001b[0m Trial 8 finished with value: 2.9773595333099365 and parameters: {'n_epoch': 90, 'weight_decay': 0.006574832213350951}. Best is trial 4 with value: 10.658534049987793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 2.98 \t AccHead 5.98 \t AccTail 0.02\n",
      "Epoch: [001] \t Loss 4.0552 \t Acc 9.11 \t AccHead 8.12 \t AccTail 10.58\n",
      "Epoch: [002] \t Loss 3.5423 \t Acc 10.40 \t AccHead 10.15 \t AccTail 10.76\n",
      "Epoch: [003] \t Loss 3.4000 \t Acc 11.88 \t AccHead 14.38 \t AccTail 8.16\n",
      "Epoch: [004] \t Loss 3.2935 \t Acc 15.19 \t AccHead 16.54 \t AccTail 13.17\n",
      "Epoch: [005] \t Loss 3.2281 \t Acc 15.07 \t AccHead 19.68 \t AccTail 8.19\n",
      "Epoch: [006] \t Loss 3.1760 \t Acc 16.80 \t AccHead 19.06 \t AccTail 13.43\n",
      "Epoch: [007] \t Loss 3.1293 \t Acc 18.94 \t AccHead 22.00 \t AccTail 14.36\n",
      "Epoch: [008] \t Loss 3.0925 \t Acc 16.49 \t AccHead 16.78 \t AccTail 16.07\n",
      "Epoch: [009] \t Loss 3.0583 \t Acc 19.20 \t AccHead 21.79 \t AccTail 15.33\n",
      "Epoch: [010] \t Loss 3.0062 \t Acc 19.88 \t AccHead 22.45 \t AccTail 16.05\n",
      "Epoch: [011] \t Loss 2.9829 \t Acc 19.70 \t AccHead 23.59 \t AccTail 13.90\n",
      "Epoch: [012] \t Loss 2.9445 \t Acc 21.66 \t AccHead 27.22 \t AccTail 13.37\n",
      "Epoch: [013] \t Loss 2.9496 \t Acc 20.17 \t AccHead 23.38 \t AccTail 15.39\n",
      "Epoch: [014] \t Loss 2.9179 \t Acc 22.39 \t AccHead 24.71 \t AccTail 18.92\n",
      "Epoch: [015] \t Loss 2.9056 \t Acc 18.60 \t AccHead 22.82 \t AccTail 12.31\n",
      "Epoch: [016] \t Loss 2.8851 \t Acc 22.40 \t AccHead 24.77 \t AccTail 18.84\n",
      "Epoch: [017] \t Loss 2.8630 \t Acc 22.06 \t AccHead 26.12 \t AccTail 15.99\n",
      "Epoch: [018] \t Loss 2.8851 \t Acc 19.78 \t AccHead 23.68 \t AccTail 13.96\n",
      "Epoch: [019] \t Loss 2.8808 \t Acc 21.19 \t AccHead 24.28 \t AccTail 16.59\n",
      "Epoch: [020] \t Loss 2.8606 \t Acc 14.83 \t AccHead 15.39 \t AccTail 13.99\n",
      "Epoch: [021] \t Loss 2.8466 \t Acc 22.04 \t AccHead 24.86 \t AccTail 17.82\n",
      "Epoch: [022] \t Loss 2.8503 \t Acc 20.43 \t AccHead 23.96 \t AccTail 15.15\n",
      "Epoch: [023] \t Loss 2.8485 \t Acc 22.24 \t AccHead 24.62 \t AccTail 18.69\n",
      "Epoch: [024] \t Loss 2.8433 \t Acc 20.88 \t AccHead 25.24 \t AccTail 14.38\n",
      "Epoch: [025] \t Loss 2.8472 \t Acc 21.06 \t AccHead 27.92 \t AccTail 10.83\n",
      "Epoch: [026] \t Loss 2.8418 \t Acc 23.02 \t AccHead 26.85 \t AccTail 17.30\n",
      "Epoch: [027] \t Loss 2.8418 \t Acc 24.48 \t AccHead 28.79 \t AccTail 18.05\n",
      "Epoch: [028] \t Loss 2.8304 \t Acc 24.93 \t AccHead 27.74 \t AccTail 20.74\n",
      "Epoch: [029] \t Loss 2.8365 \t Acc 20.41 \t AccHead 23.43 \t AccTail 15.89\n",
      "Epoch: [030] \t Loss 2.8348 \t Acc 23.15 \t AccHead 25.54 \t AccTail 19.57\n",
      "Epoch: [031] \t Loss 2.8492 \t Acc 22.20 \t AccHead 24.57 \t AccTail 18.67\n",
      "Epoch: [032] \t Loss 2.8281 \t Acc 23.00 \t AccHead 28.39 \t AccTail 14.94\n",
      "Epoch: [033] \t Loss 2.8322 \t Acc 24.39 \t AccHead 27.58 \t AccTail 19.63\n",
      "Epoch: [034] \t Loss 2.8187 \t Acc 22.88 \t AccHead 27.08 \t AccTail 16.61\n",
      "Epoch: [035] \t Loss 2.8321 \t Acc 21.26 \t AccHead 24.24 \t AccTail 16.81\n",
      "Epoch: [036] \t Loss 2.8040 \t Acc 20.46 \t AccHead 20.90 \t AccTail 19.79\n",
      "Epoch: [037] \t Loss 2.8233 \t Acc 21.36 \t AccHead 20.56 \t AccTail 22.56\n",
      "Epoch: [038] \t Loss 2.8303 \t Acc 21.58 \t AccHead 25.27 \t AccTail 16.08\n",
      "Epoch: [039] \t Loss 2.8236 \t Acc 23.37 \t AccHead 25.73 \t AccTail 19.86\n",
      "Epoch: [040] \t Loss 2.8127 \t Acc 23.69 \t AccHead 24.96 \t AccTail 21.79\n",
      "Epoch: [041] \t Loss 2.8094 \t Acc 22.17 \t AccHead 27.20 \t AccTail 14.65\n",
      "Epoch: [042] \t Loss 2.8178 \t Acc 24.75 \t AccHead 27.54 \t AccTail 20.60\n",
      "Epoch: [043] \t Loss 2.8026 \t Acc 23.30 \t AccHead 30.24 \t AccTail 12.95\n",
      "Epoch: [044] \t Loss 2.8035 \t Acc 22.00 \t AccHead 27.54 \t AccTail 13.73\n",
      "Epoch: [045] \t Loss 2.8005 \t Acc 24.25 \t AccHead 30.38 \t AccTail 15.10\n",
      "Epoch: [046] \t Loss 2.7997 \t Acc 21.50 \t AccHead 25.09 \t AccTail 16.15\n",
      "Epoch: [047] \t Loss 2.8101 \t Acc 22.52 \t AccHead 27.28 \t AccTail 15.42\n",
      "Epoch: [048] \t Loss 2.8155 \t Acc 22.22 \t AccHead 24.27 \t AccTail 19.15\n",
      "Epoch: [049] \t Loss 2.8180 \t Acc 23.16 \t AccHead 27.59 \t AccTail 16.53\n",
      "Epoch: [050] \t Loss 2.8101 \t Acc 24.15 \t AccHead 30.50 \t AccTail 14.66\n",
      "Epoch: [051] \t Loss 2.8322 \t Acc 22.42 \t AccHead 27.84 \t AccTail 14.32\n",
      "Epoch: [052] \t Loss 2.8175 \t Acc 22.39 \t AccHead 26.69 \t AccTail 15.96\n",
      "Epoch: [053] \t Loss 2.8172 \t Acc 20.26 \t AccHead 20.46 \t AccTail 19.95\n",
      "Epoch: [054] \t Loss 2.8206 \t Acc 25.34 \t AccHead 28.77 \t AccTail 20.20\n",
      "Epoch: [055] \t Loss 2.8128 \t Acc 23.71 \t AccHead 26.82 \t AccTail 19.08\n",
      "Epoch: [056] \t Loss 2.8177 \t Acc 20.37 \t AccHead 20.02 \t AccTail 20.89\n",
      "Epoch: [057] \t Loss 2.8169 \t Acc 20.50 \t AccHead 22.70 \t AccTail 17.22\n",
      "Epoch: [058] \t Loss 2.8038 \t Acc 24.52 \t AccHead 27.43 \t AccTail 20.17\n",
      "Epoch: [059] \t Loss 2.8156 \t Acc 23.14 \t AccHead 27.55 \t AccTail 16.55\n",
      "Epoch: [060] \t Loss 2.8156 \t Acc 22.78 \t AccHead 26.07 \t AccTail 17.86\n",
      "Epoch: [061] \t Loss 2.8350 \t Acc 23.84 \t AccHead 29.53 \t AccTail 15.37\n",
      "Epoch: [062] \t Loss 2.8085 \t Acc 23.52 \t AccHead 27.89 \t AccTail 17.00\n",
      "Epoch: [063] \t Loss 2.8216 \t Acc 22.00 \t AccHead 27.78 \t AccTail 13.37\n",
      "Epoch: [064] \t Loss 2.8190 \t Acc 25.37 \t AccHead 31.10 \t AccTail 16.82\n",
      "Epoch: [065] \t Loss 2.8155 \t Acc 22.63 \t AccHead 25.89 \t AccTail 17.75\n",
      "Epoch: [066] \t Loss 2.8192 \t Acc 21.96 \t AccHead 26.15 \t AccTail 15.71\n",
      "Epoch: [067] \t Loss 2.8187 \t Acc 19.47 \t AccHead 20.84 \t AccTail 17.41\n",
      "Epoch: [068] \t Loss 2.8128 \t Acc 20.55 \t AccHead 26.06 \t AccTail 12.33\n",
      "Epoch: [069] \t Loss 2.8327 \t Acc 22.48 \t AccHead 24.41 \t AccTail 19.60\n",
      "Epoch: [070] \t Loss 2.8044 \t Acc 25.29 \t AccHead 29.55 \t AccTail 18.92\n",
      "Epoch: [071] \t Loss 2.8168 \t Acc 24.23 \t AccHead 29.09 \t AccTail 16.98\n",
      "Epoch: [072] \t Loss 2.8062 \t Acc 20.64 \t AccHead 23.10 \t AccTail 16.98\n",
      "Epoch: [073] \t Loss 2.8084 \t Acc 21.76 \t AccHead 26.48 \t AccTail 14.71\n",
      "Epoch: [074] \t Loss 2.8236 \t Acc 23.20 \t AccHead 26.92 \t AccTail 17.64\n",
      "Epoch: [075] \t Loss 2.8110 \t Acc 20.93 \t AccHead 25.29 \t AccTail 14.43\n",
      "Epoch: [076] \t Loss 2.8141 \t Acc 24.33 \t AccHead 26.77 \t AccTail 20.70\n",
      "Epoch: [077] \t Loss 2.7968 \t Acc 26.66 \t AccHead 30.66 \t AccTail 20.69\n",
      "Epoch: [078] \t Loss 2.8103 \t Acc 21.32 \t AccHead 24.95 \t AccTail 15.90\n",
      "Epoch: [079] \t Loss 2.8085 \t Acc 24.08 \t AccHead 27.21 \t AccTail 19.40\n",
      "Epoch: [080] \t Loss 2.8056 \t Acc 24.50 \t AccHead 28.28 \t AccTail 18.87\n",
      "Epoch: [081] \t Loss 2.8293 \t Acc 24.46 \t AccHead 28.84 \t AccTail 17.93\n",
      "Epoch: [082] \t Loss 2.8292 \t Acc 23.23 \t AccHead 26.04 \t AccTail 19.05\n",
      "Epoch: [083] \t Loss 2.8252 \t Acc 22.17 \t AccHead 25.18 \t AccTail 17.67\n",
      "Epoch: [084] \t Loss 2.8140 \t Acc 22.06 \t AccHead 26.65 \t AccTail 15.20\n",
      "Epoch: [085] \t Loss 2.8308 \t Acc 24.10 \t AccHead 30.18 \t AccTail 15.01\n",
      "Epoch: [086] \t Loss 2.8142 \t Acc 24.66 \t AccHead 28.69 \t AccTail 18.66\n",
      "Epoch: [087] \t Loss 2.8225 \t Acc 23.60 \t AccHead 26.98 \t AccTail 18.54\n",
      "Epoch: [088] \t Loss 2.8107 \t Acc 21.11 \t AccHead 25.44 \t AccTail 14.65\n",
      "Epoch: [089] \t Loss 2.8261 \t Acc 19.92 \t AccHead 24.01 \t AccTail 13.83\n",
      "Epoch: [090] \t Loss 2.8045 \t Acc 23.39 \t AccHead 26.44 \t AccTail 18.85\n",
      "Epoch: [091] \t Loss 2.8136 \t Acc 24.75 \t AccHead 30.10 \t AccTail 16.77\n",
      "Epoch: [092] \t Loss 2.8213 \t Acc 20.19 \t AccHead 22.79 \t AccTail 16.30\n",
      "Epoch: [093] \t Loss 2.8256 \t Acc 19.50 \t AccHead 23.35 \t AccTail 13.76\n",
      "Epoch: [094] \t Loss 2.8278 \t Acc 22.03 \t AccHead 26.33 \t AccTail 15.60\n",
      "Epoch: [095] \t Loss 2.8289 \t Acc 25.01 \t AccHead 30.34 \t AccTail 17.04\n",
      "Epoch: [096] \t Loss 2.8227 \t Acc 21.96 \t AccHead 25.97 \t AccTail 15.98\n",
      "Epoch: [097] \t Loss 2.8198 \t Acc 21.02 \t AccHead 25.91 \t AccTail 13.72\n",
      "Epoch: [098] \t Loss 2.8307 \t Acc 24.96 \t AccHead 27.12 \t AccTail 21.74\n",
      "Epoch: [099] \t Loss 2.8164 \t Acc 25.50 \t AccHead 31.30 \t AccTail 16.85\n",
      "Epoch: [100] \t Loss 2.8172 \t Acc 24.09 \t AccHead 27.59 \t AccTail 18.86\n",
      "Epoch: [101] \t Loss 2.8129 \t Acc 21.73 \t AccHead 25.54 \t AccTail 16.04\n",
      "Epoch: [102] \t Loss 2.8220 \t Acc 18.98 \t AccHead 21.37 \t AccTail 15.41\n",
      "Epoch: [103] \t Loss 2.8411 \t Acc 24.22 \t AccHead 26.82 \t AccTail 20.35\n",
      "Epoch: [104] \t Loss 2.8254 \t Acc 20.52 \t AccHead 21.28 \t AccTail 19.39\n",
      "Epoch: [105] \t Loss 2.8195 \t Acc 21.10 \t AccHead 23.81 \t AccTail 17.06\n",
      "Epoch: [106] \t Loss 2.8218 \t Acc 20.89 \t AccHead 24.94 \t AccTail 14.85\n",
      "Epoch: [107] \t Loss 2.8227 \t Acc 18.89 \t AccHead 21.73 \t AccTail 14.65\n",
      "Epoch: [108] \t Loss 2.8149 \t Acc 20.38 \t AccHead 19.54 \t AccTail 21.64\n",
      "Epoch: [109] \t Loss 2.8195 \t Acc 21.07 \t AccHead 23.54 \t AccTail 17.37\n",
      "Epoch: [110] \t Loss 2.8131 \t Acc 23.27 \t AccHead 27.67 \t AccTail 16.69\n",
      "Epoch: [111] \t Loss 2.8443 \t Acc 19.26 \t AccHead 23.93 \t AccTail 12.28\n",
      "Epoch: [112] \t Loss 2.8307 \t Acc 23.23 \t AccHead 26.28 \t AccTail 18.69\n",
      "Epoch: [113] \t Loss 2.8244 \t Acc 26.17 \t AccHead 31.06 \t AccTail 18.87\n",
      "Epoch: [114] \t Loss 2.8222 \t Acc 23.73 \t AccHead 27.69 \t AccTail 17.81\n",
      "Epoch: [115] \t Loss 2.8251 \t Acc 20.35 \t AccHead 21.47 \t AccTail 18.68\n",
      "Epoch: [116] \t Loss 2.8479 \t Acc 23.23 \t AccHead 24.86 \t AccTail 20.80\n",
      "Epoch: [117] \t Loss 2.8281 \t Acc 24.07 \t AccHead 25.47 \t AccTail 21.97\n",
      "Epoch: [118] \t Loss 2.8337 \t Acc 17.30 \t AccHead 20.54 \t AccTail 12.48\n",
      "Epoch: [119] \t Loss 2.8226 \t Acc 22.16 \t AccHead 27.49 \t AccTail 14.21\n",
      "Epoch: [120] \t Loss 2.8237 \t Acc 19.84 \t AccHead 26.60 \t AccTail 9.71\n",
      "Epoch: [121] \t Loss 2.8235 \t Acc 24.74 \t AccHead 28.89 \t AccTail 18.56\n",
      "Epoch: [122] \t Loss 2.8266 \t Acc 16.52 \t AccHead 21.65 \t AccTail 8.85\n",
      "Epoch: [123] \t Loss 2.8113 \t Acc 23.81 \t AccHead 28.00 \t AccTail 17.57\n",
      "Epoch: [124] \t Loss 2.8120 \t Acc 20.07 \t AccHead 21.93 \t AccTail 17.30\n",
      "Epoch: [125] \t Loss 2.8337 \t Acc 22.75 \t AccHead 25.12 \t AccTail 19.21\n",
      "Epoch: [126] \t Loss 2.8212 \t Acc 21.00 \t AccHead 25.84 \t AccTail 13.77\n",
      "Epoch: [127] \t Loss 2.8287 \t Acc 17.48 \t AccHead 17.24 \t AccTail 17.84\n",
      "Epoch: [128] \t Loss 2.8235 \t Acc 24.56 \t AccHead 28.59 \t AccTail 18.55\n",
      "Epoch: [129] \t Loss 2.8363 \t Acc 21.47 \t AccHead 24.49 \t AccTail 16.98\n",
      "Epoch: [130] \t Loss 2.8293 \t Acc 15.41 \t AccHead 18.88 \t AccTail 10.24\n",
      "Epoch: [131] \t Loss 2.8160 \t Acc 23.41 \t AccHead 24.72 \t AccTail 21.44\n",
      "Epoch: [132] \t Loss 2.8433 \t Acc 23.10 \t AccHead 28.30 \t AccTail 15.35\n",
      "Epoch: [133] \t Loss 2.8202 \t Acc 20.83 \t AccHead 23.44 \t AccTail 16.94\n",
      "Epoch: [134] \t Loss 2.8520 \t Acc 19.32 \t AccHead 20.60 \t AccTail 17.40\n",
      "Epoch: [135] \t Loss 2.8173 \t Acc 20.41 \t AccHead 25.43 \t AccTail 12.91\n",
      "Epoch: [136] \t Loss 2.8183 \t Acc 19.55 \t AccHead 21.45 \t AccTail 16.71\n",
      "Epoch: [137] \t Loss 2.8394 \t Acc 21.17 \t AccHead 26.69 \t AccTail 12.92\n",
      "Epoch: [138] \t Loss 2.8296 \t Acc 22.05 \t AccHead 23.67 \t AccTail 19.63\n",
      "Epoch: [139] \t Loss 2.8287 \t Acc 21.95 \t AccHead 27.18 \t AccTail 14.13\n",
      "Epoch: [140] \t Loss 2.8362 \t Acc 21.94 \t AccHead 27.40 \t AccTail 13.78\n",
      "Epoch: [141] \t Loss 2.8527 \t Acc 22.98 \t AccHead 26.99 \t AccTail 17.00\n",
      "Epoch: [142] \t Loss 2.8215 \t Acc 24.70 \t AccHead 27.67 \t AccTail 20.27\n",
      "Epoch: [143] \t Loss 2.8155 \t Acc 20.72 \t AccHead 26.21 \t AccTail 12.53\n",
      "Epoch: [144] \t Loss 2.8322 \t Acc 22.53 \t AccHead 23.33 \t AccTail 21.32\n",
      "Epoch: [145] \t Loss 2.8343 \t Acc 24.06 \t AccHead 26.99 \t AccTail 19.69\n",
      "Epoch: [146] \t Loss 2.8204 \t Acc 19.50 \t AccHead 23.18 \t AccTail 14.02\n",
      "Epoch: [147] \t Loss 2.8265 \t Acc 22.84 \t AccHead 25.42 \t AccTail 18.99\n",
      "Epoch: [148] \t Loss 2.8298 \t Acc 19.65 \t AccHead 23.35 \t AccTail 14.14\n",
      "Epoch: [149] \t Loss 2.8419 \t Acc 23.98 \t AccHead 26.18 \t AccTail 20.69\n",
      "Epoch: [150] \t Loss 2.8234 \t Acc 22.76 \t AccHead 28.28 \t AccTail 14.52\n",
      "Epoch: [151] \t Loss 2.4695 \t Acc 38.45 \t AccHead 43.79 \t AccTail 30.46\n",
      "Epoch: [152] \t Loss 2.2687 \t Acc 39.33 \t AccHead 43.89 \t AccTail 32.53\n",
      "Epoch: [153] \t Loss 2.1917 \t Acc 41.38 \t AccHead 47.08 \t AccTail 32.86\n",
      "Epoch: [154] \t Loss 2.1429 \t Acc 40.92 \t AccHead 47.07 \t AccTail 31.74\n",
      "Epoch: [155] \t Loss 2.1187 \t Acc 42.27 \t AccHead 47.23 \t AccTail 34.86\n",
      "Epoch: [156] \t Loss 2.0758 \t Acc 43.44 \t AccHead 50.08 \t AccTail 33.53\n",
      "Epoch: [157] \t Loss 2.0567 \t Acc 44.58 \t AccHead 49.84 \t AccTail 36.72\n",
      "Epoch: [158] \t Loss 2.0284 \t Acc 43.53 \t AccHead 47.91 \t AccTail 36.99\n",
      "Epoch: [159] \t Loss 2.0045 \t Acc 43.17 \t AccHead 48.76 \t AccTail 34.82\n",
      "Epoch: [160] \t Loss 1.9956 \t Acc 43.93 \t AccHead 49.00 \t AccTail 36.36\n",
      "Epoch: [161] \t Loss 1.9931 \t Acc 46.01 \t AccHead 51.62 \t AccTail 37.63\n",
      "Epoch: [162] \t Loss 1.9697 \t Acc 42.45 \t AccHead 48.08 \t AccTail 34.06\n",
      "Epoch: [163] \t Loss 1.9455 \t Acc 43.77 \t AccHead 49.72 \t AccTail 34.88\n",
      "Epoch: [164] \t Loss 1.9359 \t Acc 45.64 \t AccHead 50.18 \t AccTail 38.87\n",
      "Epoch: [165] \t Loss 1.9180 \t Acc 46.76 \t AccHead 52.71 \t AccTail 37.90\n",
      "Epoch: [166] \t Loss 1.8879 \t Acc 45.54 \t AccHead 49.58 \t AccTail 39.50\n",
      "Epoch: [167] \t Loss 1.9020 \t Acc 46.81 \t AccHead 52.09 \t AccTail 38.93\n",
      "Epoch: [168] \t Loss 1.8659 \t Acc 47.39 \t AccHead 53.41 \t AccTail 38.41\n",
      "Epoch: [169] \t Loss 1.8518 \t Acc 47.70 \t AccHead 53.31 \t AccTail 39.31\n",
      "Epoch: [170] \t Loss 1.8257 \t Acc 44.34 \t AccHead 50.83 \t AccTail 34.66\n",
      "Epoch: [171] \t Loss 1.8430 \t Acc 47.58 \t AccHead 53.02 \t AccTail 39.47\n",
      "Epoch: [172] \t Loss 1.8088 \t Acc 48.48 \t AccHead 54.67 \t AccTail 39.25\n",
      "Epoch: [173] \t Loss 1.7915 \t Acc 49.17 \t AccHead 55.38 \t AccTail 39.91\n",
      "Epoch: [174] \t Loss 1.7771 \t Acc 49.35 \t AccHead 55.72 \t AccTail 39.86\n",
      "Epoch: [175] \t Loss 1.7738 \t Acc 50.97 \t AccHead 56.25 \t AccTail 43.10\n",
      "Epoch: [176] \t Loss 1.7421 \t Acc 49.78 \t AccHead 55.08 \t AccTail 41.88\n",
      "Epoch: [177] \t Loss 1.7618 \t Acc 49.27 \t AccHead 53.52 \t AccTail 42.94\n",
      "Epoch: [178] \t Loss 1.7355 \t Acc 49.45 \t AccHead 54.17 \t AccTail 42.41\n",
      "Epoch: [179] \t Loss 1.7252 \t Acc 51.87 \t AccHead 56.82 \t AccTail 44.49\n",
      "Epoch: [180] \t Loss 1.7122 \t Acc 51.01 \t AccHead 56.43 \t AccTail 42.89\n",
      "Epoch: [181] \t Loss 1.7022 \t Acc 51.15 \t AccHead 56.21 \t AccTail 43.59\n",
      "Epoch: [182] \t Loss 1.7010 \t Acc 53.12 \t AccHead 58.35 \t AccTail 45.32\n",
      "Epoch: [183] \t Loss 1.6707 \t Acc 53.34 \t AccHead 57.57 \t AccTail 47.02\n",
      "Epoch: [184] \t Loss 1.6353 \t Acc 50.89 \t AccHead 55.55 \t AccTail 43.95\n",
      "Epoch: [185] \t Loss 1.6614 \t Acc 53.94 \t AccHead 58.59 \t AccTail 46.99\n",
      "Epoch: [186] \t Loss 1.6305 \t Acc 52.17 \t AccHead 58.51 \t AccTail 42.72\n",
      "Epoch: [187] \t Loss 1.6343 \t Acc 53.98 \t AccHead 60.01 \t AccTail 44.98\n",
      "Epoch: [188] \t Loss 1.6204 \t Acc 52.35 \t AccHead 57.65 \t AccTail 44.42\n",
      "Epoch: [189] \t Loss 1.5826 \t Acc 51.87 \t AccHead 56.62 \t AccTail 44.78\n",
      "Epoch: [190] \t Loss 1.5893 \t Acc 55.45 \t AccHead 61.79 \t AccTail 45.99\n",
      "Epoch: [191] \t Loss 1.5765 \t Acc 51.12 \t AccHead 55.25 \t AccTail 44.95\n",
      "Epoch: [192] \t Loss 1.5884 \t Acc 54.87 \t AccHead 60.99 \t AccTail 45.74\n",
      "Epoch: [193] \t Loss 1.5663 \t Acc 53.34 \t AccHead 59.04 \t AccTail 44.83\n",
      "Epoch: [194] \t Loss 1.5501 \t Acc 54.14 \t AccHead 59.54 \t AccTail 46.07\n",
      "Epoch: [195] \t Loss 1.5434 \t Acc 53.94 \t AccHead 58.58 \t AccTail 47.01\n",
      "Epoch: [196] \t Loss 1.5412 \t Acc 54.62 \t AccHead 59.63 \t AccTail 47.14\n",
      "Epoch: [197] \t Loss 1.5237 \t Acc 54.09 \t AccHead 59.29 \t AccTail 46.33\n",
      "Epoch: [198] \t Loss 1.5330 \t Acc 55.50 \t AccHead 60.88 \t AccTail 47.46\n",
      "Epoch: [199] \t Loss 1.5047 \t Acc 52.60 \t AccHead 57.41 \t AccTail 45.42\n",
      "Epoch: [200] \t Loss 1.5087 \t Acc 55.97 \t AccHead 60.28 \t AccTail 49.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 04:45:30,102]\u001b[0m Trial 9 finished with value: 8.280781745910645 and parameters: {'n_epoch': 200, 'weight_decay': 0.0032371076307295913}. Best is trial 4 with value: 10.658534049987793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 8.28 \t AccHead 16.67 \t AccTail 0.02\n",
      "Epoch: [001] \t Loss 4.0105 \t Acc 10.01 \t AccHead 12.94 \t AccTail 5.63\n",
      "Epoch: [002] \t Loss 3.5326 \t Acc 14.34 \t AccHead 15.21 \t AccTail 13.04\n",
      "Epoch: [003] \t Loss 3.3539 \t Acc 16.33 \t AccHead 16.71 \t AccTail 15.77\n",
      "Epoch: [004] \t Loss 3.2058 \t Acc 19.93 \t AccHead 22.19 \t AccTail 16.56\n",
      "Epoch: [005] \t Loss 3.0587 \t Acc 20.64 \t AccHead 24.95 \t AccTail 14.21\n",
      "Epoch: [006] \t Loss 2.9571 \t Acc 23.87 \t AccHead 25.24 \t AccTail 21.82\n",
      "Epoch: [007] \t Loss 2.8245 \t Acc 26.55 \t AccHead 29.56 \t AccTail 22.05\n",
      "Epoch: [008] \t Loss 2.7308 \t Acc 30.02 \t AccHead 33.72 \t AccTail 24.49\n",
      "Epoch: [009] \t Loss 2.6256 \t Acc 30.49 \t AccHead 33.04 \t AccTail 26.70\n",
      "Epoch: [010] \t Loss 2.5501 \t Acc 30.93 \t AccHead 35.00 \t AccTail 24.87\n",
      "Epoch: [011] \t Loss 2.4782 \t Acc 33.30 \t AccHead 36.11 \t AccTail 29.10\n",
      "Epoch: [012] \t Loss 2.4236 \t Acc 35.70 \t AccHead 39.91 \t AccTail 29.41\n",
      "Epoch: [013] \t Loss 2.3591 \t Acc 34.98 \t AccHead 39.09 \t AccTail 28.84\n",
      "Epoch: [014] \t Loss 2.3087 \t Acc 38.02 \t AccHead 43.93 \t AccTail 29.21\n",
      "Epoch: [015] \t Loss 2.2624 \t Acc 39.58 \t AccHead 42.85 \t AccTail 34.70\n",
      "Epoch: [016] \t Loss 2.2174 \t Acc 39.91 \t AccHead 46.55 \t AccTail 30.02\n",
      "Epoch: [017] \t Loss 2.1727 \t Acc 38.78 \t AccHead 44.38 \t AccTail 30.42\n",
      "Epoch: [018] \t Loss 2.1380 \t Acc 40.31 \t AccHead 46.16 \t AccTail 31.58\n",
      "Epoch: [019] \t Loss 2.0905 \t Acc 39.64 \t AccHead 45.11 \t AccTail 31.47\n",
      "Epoch: [020] \t Loss 2.0745 \t Acc 41.42 \t AccHead 45.03 \t AccTail 36.03\n",
      "Epoch: [021] \t Loss 2.0445 \t Acc 41.01 \t AccHead 45.47 \t AccTail 34.34\n",
      "Epoch: [022] \t Loss 1.9984 \t Acc 41.53 \t AccHead 45.18 \t AccTail 36.07\n",
      "Epoch: [023] \t Loss 1.9829 \t Acc 43.85 \t AccHead 50.54 \t AccTail 33.87\n",
      "Epoch: [024] \t Loss 1.9598 \t Acc 43.25 \t AccHead 48.42 \t AccTail 35.54\n",
      "Epoch: [025] \t Loss 1.9166 \t Acc 44.94 \t AccHead 49.18 \t AccTail 38.61\n",
      "Epoch: [026] \t Loss 1.8970 \t Acc 46.18 \t AccHead 49.14 \t AccTail 41.75\n",
      "Epoch: [027] \t Loss 1.8700 \t Acc 41.94 \t AccHead 46.34 \t AccTail 35.36\n",
      "Epoch: [028] \t Loss 1.8563 \t Acc 47.45 \t AccHead 50.56 \t AccTail 42.80\n",
      "Epoch: [029] \t Loss 1.8403 \t Acc 45.43 \t AccHead 49.90 \t AccTail 38.75\n",
      "Epoch: [030] \t Loss 1.8177 \t Acc 48.38 \t AccHead 52.74 \t AccTail 41.88\n",
      "Epoch: [031] \t Loss 1.7922 \t Acc 45.77 \t AccHead 48.20 \t AccTail 42.14\n",
      "Epoch: [032] \t Loss 1.7719 \t Acc 50.47 \t AccHead 55.47 \t AccTail 42.99\n",
      "Epoch: [033] \t Loss 1.7487 \t Acc 46.87 \t AccHead 51.11 \t AccTail 40.53\n",
      "Epoch: [034] \t Loss 1.7398 \t Acc 49.55 \t AccHead 53.64 \t AccTail 43.45\n",
      "Epoch: [035] \t Loss 1.7145 \t Acc 47.99 \t AccHead 51.19 \t AccTail 43.22\n",
      "Epoch: [036] \t Loss 1.6944 \t Acc 49.13 \t AccHead 52.85 \t AccTail 43.57\n",
      "Epoch: [037] \t Loss 1.6877 \t Acc 48.63 \t AccHead 54.53 \t AccTail 39.82\n",
      "Epoch: [038] \t Loss 1.6693 \t Acc 53.09 \t AccHead 57.01 \t AccTail 47.25\n",
      "Epoch: [039] \t Loss 1.6299 \t Acc 51.80 \t AccHead 56.61 \t AccTail 44.63\n",
      "Epoch: [040] \t Loss 1.6380 \t Acc 52.09 \t AccHead 56.70 \t AccTail 45.21\n",
      "Epoch: [041] \t Loss 1.6118 \t Acc 50.71 \t AccHead 55.46 \t AccTail 43.61\n",
      "Epoch: [042] \t Loss 1.6080 \t Acc 52.62 \t AccHead 56.35 \t AccTail 47.05\n",
      "Epoch: [043] \t Loss 1.5914 \t Acc 54.05 \t AccHead 59.36 \t AccTail 46.12\n",
      "Epoch: [044] \t Loss 1.5607 \t Acc 55.14 \t AccHead 60.00 \t AccTail 47.89\n",
      "Epoch: [045] \t Loss 1.5628 \t Acc 50.60 \t AccHead 55.22 \t AccTail 43.70\n",
      "Epoch: [046] \t Loss 1.5330 \t Acc 56.50 \t AccHead 61.42 \t AccTail 49.14\n",
      "Epoch: [047] \t Loss 1.5240 \t Acc 56.07 \t AccHead 60.70 \t AccTail 49.16\n",
      "Epoch: [048] \t Loss 1.4957 \t Acc 57.30 \t AccHead 60.82 \t AccTail 52.05\n",
      "Epoch: [049] \t Loss 1.4872 \t Acc 55.52 \t AccHead 58.28 \t AccTail 51.41\n",
      "Epoch: [050] \t Loss 1.4690 \t Acc 57.44 \t AccHead 61.87 \t AccTail 50.83\n",
      "Epoch: [051] \t Loss 1.4594 \t Acc 58.26 \t AccHead 62.86 \t AccTail 51.39\n",
      "Epoch: [052] \t Loss 1.4486 \t Acc 59.76 \t AccHead 65.13 \t AccTail 51.73\n",
      "Epoch: [053] \t Loss 1.4267 \t Acc 59.22 \t AccHead 62.95 \t AccTail 53.66\n",
      "Epoch: [054] \t Loss 1.4336 \t Acc 57.46 \t AccHead 60.70 \t AccTail 52.61\n",
      "Epoch: [055] \t Loss 1.3983 \t Acc 56.43 \t AccHead 60.19 \t AccTail 50.82\n",
      "Epoch: [056] \t Loss 1.3891 \t Acc 57.92 \t AccHead 61.87 \t AccTail 52.03\n",
      "Epoch: [057] \t Loss 1.3845 \t Acc 56.55 \t AccHead 61.69 \t AccTail 48.86\n",
      "Epoch: [058] \t Loss 1.3851 \t Acc 58.56 \t AccHead 63.38 \t AccTail 51.37\n",
      "Epoch: [059] \t Loss 1.3705 \t Acc 58.83 \t AccHead 62.99 \t AccTail 52.61\n",
      "Epoch: [060] \t Loss 1.3506 \t Acc 58.87 \t AccHead 62.85 \t AccTail 52.93\n",
      "Epoch: [061] \t Loss 1.3379 \t Acc 60.32 \t AccHead 63.62 \t AccTail 55.39\n",
      "Epoch: [062] \t Loss 1.3274 \t Acc 58.59 \t AccHead 62.67 \t AccTail 52.49\n",
      "Epoch: [063] \t Loss 1.3075 \t Acc 59.48 \t AccHead 62.00 \t AccTail 55.71\n",
      "Epoch: [064] \t Loss 1.3185 \t Acc 60.35 \t AccHead 63.34 \t AccTail 55.89\n",
      "Epoch: [065] \t Loss 1.3089 \t Acc 59.98 \t AccHead 62.27 \t AccTail 56.55\n",
      "Epoch: [066] \t Loss 1.2873 \t Acc 65.51 \t AccHead 69.01 \t AccTail 60.29\n",
      "Epoch: [067] \t Loss 1.2712 \t Acc 58.58 \t AccHead 61.09 \t AccTail 54.82\n",
      "Epoch: [068] \t Loss 1.2622 \t Acc 62.09 \t AccHead 67.39 \t AccTail 54.18\n",
      "Epoch: [069] \t Loss 1.2728 \t Acc 62.70 \t AccHead 66.67 \t AccTail 56.76\n",
      "Epoch: [070] \t Loss 1.2411 \t Acc 62.86 \t AccHead 66.37 \t AccTail 57.61\n",
      "Epoch: [071] \t Loss 1.2353 \t Acc 62.29 \t AccHead 64.84 \t AccTail 58.49\n",
      "Epoch: [072] \t Loss 1.2342 \t Acc 59.28 \t AccHead 62.76 \t AccTail 54.09\n",
      "Epoch: [073] \t Loss 1.2310 \t Acc 62.68 \t AccHead 66.91 \t AccTail 56.38\n",
      "Epoch: [074] \t Loss 1.2056 \t Acc 64.26 \t AccHead 67.93 \t AccTail 58.79\n",
      "Epoch: [075] \t Loss 1.1932 \t Acc 61.18 \t AccHead 65.15 \t AccTail 55.25\n",
      "Epoch: [076] \t Loss 1.1883 \t Acc 64.86 \t AccHead 69.17 \t AccTail 58.43\n",
      "Epoch: [077] \t Loss 1.1974 \t Acc 64.27 \t AccHead 68.99 \t AccTail 57.22\n",
      "Epoch: [078] \t Loss 1.1665 \t Acc 61.75 \t AccHead 63.31 \t AccTail 59.43\n",
      "Epoch: [079] \t Loss 1.1495 \t Acc 65.77 \t AccHead 68.67 \t AccTail 61.44\n",
      "Epoch: [080] \t Loss 1.1540 \t Acc 65.72 \t AccHead 71.23 \t AccTail 57.47\n",
      "Epoch: [081] \t Loss 1.1565 \t Acc 61.62 \t AccHead 64.59 \t AccTail 57.19\n",
      "Epoch: [082] \t Loss 1.1418 \t Acc 64.85 \t AccHead 69.01 \t AccTail 58.63\n",
      "Epoch: [083] \t Loss 1.1339 \t Acc 67.80 \t AccHead 70.76 \t AccTail 63.40\n",
      "Epoch: [084] \t Loss 1.1531 \t Acc 67.56 \t AccHead 70.59 \t AccTail 63.03\n",
      "Epoch: [085] \t Loss 1.1479 \t Acc 67.42 \t AccHead 70.70 \t AccTail 62.51\n",
      "Epoch: [086] \t Loss 1.1107 \t Acc 65.21 \t AccHead 68.23 \t AccTail 60.70\n",
      "Epoch: [087] \t Loss 1.1000 \t Acc 67.71 \t AccHead 70.10 \t AccTail 64.14\n",
      "Epoch: [088] \t Loss 1.0954 \t Acc 62.31 \t AccHead 65.89 \t AccTail 56.98\n",
      "Epoch: [089] \t Loss 1.1053 \t Acc 65.55 \t AccHead 68.57 \t AccTail 61.05\n",
      "Epoch: [090] \t Loss 1.1111 \t Acc 63.02 \t AccHead 67.28 \t AccTail 56.67\n",
      "Epoch: [091] \t Loss 1.1040 \t Acc 61.81 \t AccHead 64.52 \t AccTail 57.76\n",
      "Epoch: [092] \t Loss 1.0689 \t Acc 70.85 \t AccHead 75.30 \t AccTail 64.19\n",
      "Epoch: [093] \t Loss 1.0668 \t Acc 67.52 \t AccHead 70.56 \t AccTail 62.97\n",
      "Epoch: [094] \t Loss 1.0959 \t Acc 67.77 \t AccHead 71.97 \t AccTail 61.50\n",
      "Epoch: [095] \t Loss 1.0562 \t Acc 65.92 \t AccHead 70.04 \t AccTail 59.78\n",
      "Epoch: [096] \t Loss 1.0323 \t Acc 67.74 \t AccHead 71.67 \t AccTail 61.87\n",
      "Epoch: [097] \t Loss 1.0418 \t Acc 69.12 \t AccHead 70.34 \t AccTail 67.30\n",
      "Epoch: [098] \t Loss 1.0697 \t Acc 68.36 \t AccHead 71.03 \t AccTail 64.38\n",
      "Epoch: [099] \t Loss 1.0459 \t Acc 66.41 \t AccHead 68.85 \t AccTail 62.77\n",
      "Epoch: [100] \t Loss 1.0446 \t Acc 65.42 \t AccHead 65.89 \t AccTail 64.72\n",
      "Epoch: [101] \t Loss 1.0418 \t Acc 67.55 \t AccHead 70.50 \t AccTail 63.14\n",
      "Epoch: [102] \t Loss 1.0332 \t Acc 69.50 \t AccHead 70.81 \t AccTail 67.55\n",
      "Epoch: [103] \t Loss 1.0211 \t Acc 66.10 \t AccHead 69.67 \t AccTail 60.76\n",
      "Epoch: [104] \t Loss 1.0040 \t Acc 70.85 \t AccHead 73.95 \t AccTail 66.22\n",
      "Epoch: [105] \t Loss 1.0360 \t Acc 69.02 \t AccHead 72.08 \t AccTail 64.44\n",
      "Epoch: [106] \t Loss 1.0041 \t Acc 65.53 \t AccHead 68.44 \t AccTail 61.20\n",
      "Epoch: [107] \t Loss 1.0207 \t Acc 67.55 \t AccHead 68.80 \t AccTail 65.69\n",
      "Epoch: [108] \t Loss 1.0059 \t Acc 68.32 \t AccHead 71.93 \t AccTail 62.94\n",
      "Epoch: [109] \t Loss 1.0031 \t Acc 69.21 \t AccHead 71.93 \t AccTail 65.14\n",
      "Epoch: [110] \t Loss 0.9797 \t Acc 69.24 \t AccHead 73.07 \t AccTail 63.51\n",
      "Epoch: [111] \t Loss 1.0010 \t Acc 70.47 \t AccHead 72.74 \t AccTail 67.07\n",
      "Epoch: [112] \t Loss 0.9905 \t Acc 68.85 \t AccHead 73.19 \t AccTail 62.38\n",
      "Epoch: [113] \t Loss 0.9852 \t Acc 70.97 \t AccHead 74.61 \t AccTail 65.54\n",
      "Epoch: [114] \t Loss 0.9880 \t Acc 66.43 \t AccHead 71.24 \t AccTail 59.25\n",
      "Epoch: [115] \t Loss 0.9934 \t Acc 69.24 \t AccHead 73.22 \t AccTail 63.29\n",
      "Epoch: [116] \t Loss 0.9392 \t Acc 70.73 \t AccHead 72.69 \t AccTail 67.82\n",
      "Epoch: [117] \t Loss 0.9658 \t Acc 69.67 \t AccHead 71.33 \t AccTail 67.18\n",
      "Epoch: [118] \t Loss 0.9737 \t Acc 67.05 \t AccHead 69.14 \t AccTail 63.92\n",
      "Epoch: [119] \t Loss 0.9777 \t Acc 70.94 \t AccHead 73.78 \t AccTail 66.70\n",
      "Epoch: [120] \t Loss 0.9706 \t Acc 67.75 \t AccHead 70.74 \t AccTail 63.28\n",
      "Epoch: [121] \t Loss 0.9259 \t Acc 70.62 \t AccHead 73.64 \t AccTail 66.11\n",
      "Epoch: [122] \t Loss 0.9523 \t Acc 70.45 \t AccHead 74.10 \t AccTail 65.01\n",
      "Epoch: [123] \t Loss 0.9399 \t Acc 72.88 \t AccHead 75.64 \t AccTail 68.76\n",
      "Epoch: [124] \t Loss 0.9464 \t Acc 72.34 \t AccHead 73.42 \t AccTail 70.71\n",
      "Epoch: [125] \t Loss 0.9652 \t Acc 69.50 \t AccHead 72.04 \t AccTail 65.71\n",
      "Epoch: [126] \t Loss 0.9538 \t Acc 68.59 \t AccHead 69.39 \t AccTail 67.41\n",
      "Epoch: [127] \t Loss 0.9183 \t Acc 71.69 \t AccHead 74.22 \t AccTail 67.92\n",
      "Epoch: [128] \t Loss 0.9307 \t Acc 72.76 \t AccHead 73.00 \t AccTail 72.39\n",
      "Epoch: [129] \t Loss 0.9495 \t Acc 68.95 \t AccHead 70.19 \t AccTail 67.10\n",
      "Epoch: [130] \t Loss 0.9395 \t Acc 70.84 \t AccHead 73.51 \t AccTail 66.87\n",
      "Epoch: [131] \t Loss 0.9635 \t Acc 70.64 \t AccHead 72.91 \t AccTail 67.27\n",
      "Epoch: [132] \t Loss 0.9015 \t Acc 71.48 \t AccHead 73.07 \t AccTail 69.10\n",
      "Epoch: [133] \t Loss 0.9307 \t Acc 68.29 \t AccHead 70.79 \t AccTail 64.57\n",
      "Epoch: [134] \t Loss 0.9325 \t Acc 71.03 \t AccHead 73.41 \t AccTail 67.49\n",
      "Epoch: [135] \t Loss 0.9346 \t Acc 70.79 \t AccHead 73.05 \t AccTail 67.40\n",
      "Epoch: [136] \t Loss 0.9281 \t Acc 69.64 \t AccHead 73.21 \t AccTail 64.30\n",
      "Epoch: [137] \t Loss 0.9257 \t Acc 72.10 \t AccHead 74.80 \t AccTail 68.06\n",
      "Epoch: [138] \t Loss 0.9157 \t Acc 70.86 \t AccHead 71.59 \t AccTail 69.78\n",
      "Epoch: [139] \t Loss 0.9116 \t Acc 71.76 \t AccHead 75.88 \t AccTail 65.61\n",
      "Epoch: [140] \t Loss 0.9008 \t Acc 72.12 \t AccHead 74.13 \t AccTail 69.12\n",
      "Epoch: [141] \t Loss 0.9218 \t Acc 75.45 \t AccHead 79.59 \t AccTail 69.26\n",
      "Epoch: [142] \t Loss 0.9136 \t Acc 69.27 \t AccHead 71.94 \t AccTail 65.28\n",
      "Epoch: [143] \t Loss 0.8888 \t Acc 73.04 \t AccHead 74.10 \t AccTail 71.45\n",
      "Epoch: [144] \t Loss 0.8949 \t Acc 73.42 \t AccHead 76.05 \t AccTail 69.48\n",
      "Epoch: [145] \t Loss 0.8878 \t Acc 71.71 \t AccHead 74.07 \t AccTail 68.19\n",
      "Epoch: [146] \t Loss 0.9146 \t Acc 73.58 \t AccHead 75.70 \t AccTail 70.42\n",
      "Epoch: [147] \t Loss 0.8837 \t Acc 71.12 \t AccHead 74.80 \t AccTail 65.63\n",
      "Epoch: [148] \t Loss 0.8940 \t Acc 71.34 \t AccHead 74.36 \t AccTail 66.84\n",
      "Epoch: [149] \t Loss 0.8990 \t Acc 73.75 \t AccHead 75.15 \t AccTail 71.66\n",
      "Epoch: [150] \t Loss 0.9141 \t Acc 70.51 \t AccHead 72.47 \t AccTail 67.58\n",
      "Epoch: [151] \t Loss 0.4656 \t Acc 93.45 \t AccHead 94.43 \t AccTail 92.00\n",
      "Epoch: [152] \t Loss 0.2648 \t Acc 95.81 \t AccHead 96.63 \t AccTail 94.60\n",
      "Epoch: [153] \t Loss 0.1995 \t Acc 96.60 \t AccHead 97.12 \t AccTail 95.83\n",
      "Epoch: [154] \t Loss 0.1639 \t Acc 97.58 \t AccHead 97.98 \t AccTail 96.97\n",
      "Epoch: [155] \t Loss 0.1367 \t Acc 97.99 \t AccHead 98.37 \t AccTail 97.42\n",
      "Epoch: [156] \t Loss 0.1178 \t Acc 98.37 \t AccHead 98.61 \t AccTail 98.00\n",
      "Epoch: [157] \t Loss 0.1071 \t Acc 98.55 \t AccHead 98.88 \t AccTail 98.06\n",
      "Epoch: [158] \t Loss 0.0947 \t Acc 98.73 \t AccHead 98.98 \t AccTail 98.36\n",
      "Epoch: [159] \t Loss 0.0881 \t Acc 98.77 \t AccHead 99.05 \t AccTail 98.35\n",
      "Epoch: [160] \t Loss 0.0823 \t Acc 98.97 \t AccHead 99.14 \t AccTail 98.73\n",
      "Epoch: [161] \t Loss 0.0736 \t Acc 99.02 \t AccHead 99.25 \t AccTail 98.68\n",
      "Epoch: [162] \t Loss 0.0693 \t Acc 99.15 \t AccHead 99.35 \t AccTail 98.85\n",
      "Epoch: [163] \t Loss 0.0627 \t Acc 99.26 \t AccHead 99.46 \t AccTail 98.98\n",
      "Epoch: [164] \t Loss 0.0591 \t Acc 99.32 \t AccHead 99.43 \t AccTail 99.16\n",
      "Epoch: [165] \t Loss 0.0540 \t Acc 99.43 \t AccHead 99.59 \t AccTail 99.19\n",
      "Epoch: [166] \t Loss 0.0526 \t Acc 99.31 \t AccHead 99.45 \t AccTail 99.10\n",
      "Epoch: [167] \t Loss 0.0500 \t Acc 99.39 \t AccHead 99.51 \t AccTail 99.21\n",
      "Epoch: [168] \t Loss 0.0486 \t Acc 99.46 \t AccHead 99.60 \t AccTail 99.26\n",
      "Epoch: [169] \t Loss 0.0455 \t Acc 99.49 \t AccHead 99.57 \t AccTail 99.38\n",
      "Epoch: [170] \t Loss 0.0428 \t Acc 99.49 \t AccHead 99.58 \t AccTail 99.35\n",
      "Epoch: [171] \t Loss 0.0428 \t Acc 99.48 \t AccHead 99.65 \t AccTail 99.23\n",
      "Epoch: [172] \t Loss 0.0406 \t Acc 99.52 \t AccHead 99.67 \t AccTail 99.30\n",
      "Epoch: [173] \t Loss 0.0404 \t Acc 99.53 \t AccHead 99.67 \t AccTail 99.33\n",
      "Epoch: [174] \t Loss 0.0379 \t Acc 99.61 \t AccHead 99.67 \t AccTail 99.53\n",
      "Epoch: [175] \t Loss 0.0350 \t Acc 99.55 \t AccHead 99.68 \t AccTail 99.35\n",
      "Epoch: [176] \t Loss 0.0340 \t Acc 99.66 \t AccHead 99.75 \t AccTail 99.54\n",
      "Epoch: [177] \t Loss 0.0336 \t Acc 99.68 \t AccHead 99.75 \t AccTail 99.58\n",
      "Epoch: [178] \t Loss 0.0348 \t Acc 99.69 \t AccHead 99.77 \t AccTail 99.56\n",
      "Epoch: [179] \t Loss 0.0323 \t Acc 99.68 \t AccHead 99.77 \t AccTail 99.55\n",
      "Epoch: [180] \t Loss 0.0313 \t Acc 99.68 \t AccHead 99.72 \t AccTail 99.61\n",
      "Epoch: [181] \t Loss 0.0311 \t Acc 99.63 \t AccHead 99.80 \t AccTail 99.39\n",
      "Epoch: [182] \t Loss 0.0288 \t Acc 99.69 \t AccHead 99.78 \t AccTail 99.55\n",
      "Epoch: [183] \t Loss 0.0289 \t Acc 99.67 \t AccHead 99.75 \t AccTail 99.55\n",
      "Epoch: [184] \t Loss 0.0279 \t Acc 99.76 \t AccHead 99.82 \t AccTail 99.68\n",
      "Epoch: [185] \t Loss 0.0276 \t Acc 99.75 \t AccHead 99.84 \t AccTail 99.63\n",
      "Epoch: [186] \t Loss 0.0250 \t Acc 99.76 \t AccHead 99.84 \t AccTail 99.64\n",
      "Epoch: [187] \t Loss 0.0256 \t Acc 99.74 \t AccHead 99.81 \t AccTail 99.64\n",
      "Epoch: [188] \t Loss 0.0249 \t Acc 99.73 \t AccHead 99.74 \t AccTail 99.73\n",
      "Epoch: [189] \t Loss 0.0263 \t Acc 99.65 \t AccHead 99.66 \t AccTail 99.65\n",
      "Epoch: [190] \t Loss 0.0243 \t Acc 99.70 \t AccHead 99.79 \t AccTail 99.56\n",
      "Epoch: [191] \t Loss 0.0268 \t Acc 99.77 \t AccHead 99.85 \t AccTail 99.65\n",
      "Epoch: [192] \t Loss 0.0250 \t Acc 99.76 \t AccHead 99.85 \t AccTail 99.63\n",
      "Epoch: [193] \t Loss 0.0234 \t Acc 99.75 \t AccHead 99.80 \t AccTail 99.69\n",
      "Epoch: [194] \t Loss 0.0224 \t Acc 99.75 \t AccHead 99.77 \t AccTail 99.73\n",
      "Epoch: [195] \t Loss 0.0229 \t Acc 99.77 \t AccHead 99.80 \t AccTail 99.74\n",
      "Epoch: [196] \t Loss 0.0222 \t Acc 99.81 \t AccHead 99.85 \t AccTail 99.76\n",
      "Epoch: [197] \t Loss 0.0226 \t Acc 99.73 \t AccHead 99.77 \t AccTail 99.66\n",
      "Epoch: [198] \t Loss 0.0219 \t Acc 99.80 \t AccHead 99.84 \t AccTail 99.74\n",
      "Epoch: [199] \t Loss 0.0227 \t Acc 99.71 \t AccHead 99.79 \t AccTail 99.59\n",
      "Epoch: [200] \t Loss 0.0220 \t Acc 99.80 \t AccHead 99.87 \t AccTail 99.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 05:20:35,591]\u001b[0m Trial 10 finished with value: 10.255349159240723 and parameters: {'n_epoch': 200, 'weight_decay': 0.00048160603724095184}. Best is trial 4 with value: 10.658534049987793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 10.26 \t AccHead 20.62 \t AccTail 0.04\n",
      "Epoch: [001] \t Loss 4.0498 \t Acc 9.16 \t AccHead 11.54 \t AccTail 5.61\n",
      "Epoch: [002] \t Loss 3.5286 \t Acc 13.29 \t AccHead 14.32 \t AccTail 11.75\n",
      "Epoch: [003] \t Loss 3.3440 \t Acc 16.26 \t AccHead 18.58 \t AccTail 12.79\n",
      "Epoch: [004] \t Loss 3.1828 \t Acc 21.00 \t AccHead 23.09 \t AccTail 17.89\n",
      "Epoch: [005] \t Loss 3.0565 \t Acc 22.56 \t AccHead 27.04 \t AccTail 15.86\n",
      "Epoch: [006] \t Loss 2.9413 \t Acc 25.02 \t AccHead 26.66 \t AccTail 22.56\n",
      "Epoch: [007] \t Loss 2.8459 \t Acc 26.22 \t AccHead 30.79 \t AccTail 19.38\n",
      "Epoch: [008] \t Loss 2.7572 \t Acc 27.70 \t AccHead 30.64 \t AccTail 23.32\n",
      "Epoch: [009] \t Loss 2.6814 \t Acc 28.76 \t AccHead 30.38 \t AccTail 26.35\n",
      "Epoch: [010] \t Loss 2.5913 \t Acc 30.23 \t AccHead 32.68 \t AccTail 26.58\n",
      "Epoch: [011] \t Loss 2.5242 \t Acc 31.89 \t AccHead 36.18 \t AccTail 25.48\n",
      "Epoch: [012] \t Loss 2.4694 \t Acc 35.46 \t AccHead 40.25 \t AccTail 28.31\n",
      "Epoch: [013] \t Loss 2.4010 \t Acc 34.68 \t AccHead 37.83 \t AccTail 29.99\n",
      "Epoch: [014] \t Loss 2.3692 \t Acc 34.59 \t AccHead 39.77 \t AccTail 26.85\n",
      "Epoch: [015] \t Loss 2.3273 \t Acc 37.58 \t AccHead 44.56 \t AccTail 27.17\n",
      "Epoch: [016] \t Loss 2.2738 \t Acc 38.68 \t AccHead 43.50 \t AccTail 31.48\n",
      "Epoch: [017] \t Loss 2.2507 \t Acc 37.20 \t AccHead 42.05 \t AccTail 29.97\n",
      "Epoch: [018] \t Loss 2.2242 \t Acc 36.24 \t AccHead 39.26 \t AccTail 31.74\n",
      "Epoch: [019] \t Loss 2.1723 \t Acc 38.38 \t AccHead 42.64 \t AccTail 32.03\n",
      "Epoch: [020] \t Loss 2.1585 \t Acc 39.98 \t AccHead 46.51 \t AccTail 30.23\n",
      "Epoch: [021] \t Loss 2.1252 \t Acc 38.62 \t AccHead 44.48 \t AccTail 29.88\n",
      "Epoch: [022] \t Loss 2.1155 \t Acc 40.45 \t AccHead 45.64 \t AccTail 32.71\n",
      "Epoch: [023] \t Loss 2.0672 \t Acc 42.30 \t AccHead 46.38 \t AccTail 36.21\n",
      "Epoch: [024] \t Loss 2.0651 \t Acc 40.97 \t AccHead 46.01 \t AccTail 33.44\n",
      "Epoch: [025] \t Loss 2.0423 \t Acc 42.81 \t AccHead 49.33 \t AccTail 33.08\n",
      "Epoch: [026] \t Loss 2.0275 \t Acc 40.64 \t AccHead 44.32 \t AccTail 35.14\n",
      "Epoch: [027] \t Loss 2.0009 \t Acc 43.86 \t AccHead 48.18 \t AccTail 37.41\n",
      "Epoch: [028] \t Loss 1.9894 \t Acc 42.25 \t AccHead 46.80 \t AccTail 35.46\n",
      "Epoch: [029] \t Loss 1.9712 \t Acc 43.33 \t AccHead 48.93 \t AccTail 34.97\n",
      "Epoch: [030] \t Loss 1.9539 \t Acc 45.05 \t AccHead 51.04 \t AccTail 36.11\n",
      "Epoch: [031] \t Loss 1.9516 \t Acc 45.61 \t AccHead 51.71 \t AccTail 36.50\n",
      "Epoch: [032] \t Loss 1.9188 \t Acc 43.33 \t AccHead 48.89 \t AccTail 35.05\n",
      "Epoch: [033] \t Loss 1.9105 \t Acc 44.56 \t AccHead 48.07 \t AccTail 39.33\n",
      "Epoch: [034] \t Loss 1.9048 \t Acc 46.16 \t AccHead 51.13 \t AccTail 38.75\n",
      "Epoch: [035] \t Loss 1.8837 \t Acc 46.45 \t AccHead 51.46 \t AccTail 38.99\n",
      "Epoch: [036] \t Loss 1.8630 \t Acc 45.17 \t AccHead 52.87 \t AccTail 33.68\n",
      "Epoch: [037] \t Loss 1.8558 \t Acc 45.51 \t AccHead 50.45 \t AccTail 38.13\n",
      "Epoch: [038] \t Loss 1.8470 \t Acc 46.30 \t AccHead 50.94 \t AccTail 39.38\n",
      "Epoch: [039] \t Loss 1.8368 \t Acc 49.52 \t AccHead 55.52 \t AccTail 40.58\n",
      "Epoch: [040] \t Loss 1.8333 \t Acc 47.04 \t AccHead 50.93 \t AccTail 41.23\n",
      "Epoch: [041] \t Loss 1.8195 \t Acc 45.79 \t AccHead 49.26 \t AccTail 40.61\n",
      "Epoch: [042] \t Loss 1.8207 \t Acc 46.30 \t AccHead 50.43 \t AccTail 40.13\n",
      "Epoch: [043] \t Loss 1.7951 \t Acc 48.08 \t AccHead 52.00 \t AccTail 42.22\n",
      "Epoch: [044] \t Loss 1.7712 \t Acc 48.68 \t AccHead 52.29 \t AccTail 43.30\n",
      "Epoch: [045] \t Loss 1.7856 \t Acc 46.29 \t AccHead 52.45 \t AccTail 37.09\n",
      "Epoch: [046] \t Loss 1.7650 \t Acc 49.22 \t AccHead 54.59 \t AccTail 41.23\n",
      "Epoch: [047] \t Loss 1.7756 \t Acc 46.85 \t AccHead 50.92 \t AccTail 40.77\n",
      "Epoch: [048] \t Loss 1.7430 \t Acc 49.45 \t AccHead 54.57 \t AccTail 41.80\n",
      "Epoch: [049] \t Loss 1.7300 \t Acc 50.71 \t AccHead 55.39 \t AccTail 43.72\n",
      "Epoch: [050] \t Loss 1.7426 \t Acc 49.41 \t AccHead 54.53 \t AccTail 41.78\n",
      "Epoch: [051] \t Loss 1.7587 \t Acc 48.51 \t AccHead 53.12 \t AccTail 41.64\n",
      "Epoch: [052] \t Loss 1.7099 \t Acc 49.39 \t AccHead 54.79 \t AccTail 41.33\n",
      "Epoch: [053] \t Loss 1.7212 \t Acc 48.45 \t AccHead 53.45 \t AccTail 41.00\n",
      "Epoch: [054] \t Loss 1.7015 \t Acc 48.91 \t AccHead 53.50 \t AccTail 42.06\n",
      "Epoch: [055] \t Loss 1.7180 \t Acc 49.94 \t AccHead 55.40 \t AccTail 41.80\n",
      "Epoch: [056] \t Loss 1.6674 \t Acc 48.03 \t AccHead 54.48 \t AccTail 38.41\n",
      "Epoch: [057] \t Loss 1.6815 \t Acc 51.67 \t AccHead 56.74 \t AccTail 44.09\n",
      "Epoch: [058] \t Loss 1.6930 \t Acc 50.04 \t AccHead 54.60 \t AccTail 43.23\n",
      "Epoch: [059] \t Loss 1.6649 \t Acc 52.59 \t AccHead 58.83 \t AccTail 43.29\n",
      "Epoch: [060] \t Loss 1.6554 \t Acc 50.72 \t AccHead 56.42 \t AccTail 42.21\n",
      "Epoch: [061] \t Loss 1.6705 \t Acc 49.20 \t AccHead 54.90 \t AccTail 40.69\n",
      "Epoch: [062] \t Loss 1.6501 \t Acc 49.93 \t AccHead 53.66 \t AccTail 44.37\n",
      "Epoch: [063] \t Loss 1.6479 \t Acc 49.25 \t AccHead 53.39 \t AccTail 43.08\n",
      "Epoch: [064] \t Loss 1.6481 \t Acc 48.44 \t AccHead 53.62 \t AccTail 40.72\n",
      "Epoch: [065] \t Loss 1.6287 \t Acc 50.50 \t AccHead 54.19 \t AccTail 44.98\n",
      "Epoch: [066] \t Loss 1.6345 \t Acc 51.42 \t AccHead 57.32 \t AccTail 42.62\n",
      "Epoch: [067] \t Loss 1.6149 \t Acc 51.50 \t AccHead 56.34 \t AccTail 44.27\n",
      "Epoch: [068] \t Loss 1.6313 \t Acc 51.95 \t AccHead 55.04 \t AccTail 47.33\n",
      "Epoch: [069] \t Loss 1.6050 \t Acc 50.88 \t AccHead 54.47 \t AccTail 45.53\n",
      "Epoch: [070] \t Loss 1.6059 \t Acc 49.23 \t AccHead 51.74 \t AccTail 45.50\n",
      "Epoch: [071] \t Loss 1.5868 \t Acc 52.17 \t AccHead 55.84 \t AccTail 46.71\n",
      "Epoch: [072] \t Loss 1.6100 \t Acc 50.64 \t AccHead 56.26 \t AccTail 42.26\n",
      "Epoch: [073] \t Loss 1.6001 \t Acc 50.78 \t AccHead 56.98 \t AccTail 41.53\n",
      "Epoch: [074] \t Loss 1.5780 \t Acc 50.04 \t AccHead 54.45 \t AccTail 43.46\n",
      "Epoch: [075] \t Loss 1.5824 \t Acc 53.64 \t AccHead 58.57 \t AccTail 46.28\n",
      "Epoch: [076] \t Loss 1.5716 \t Acc 51.89 \t AccHead 57.06 \t AccTail 44.17\n",
      "Epoch: [077] \t Loss 1.5705 \t Acc 52.97 \t AccHead 57.62 \t AccTail 46.05\n",
      "Epoch: [078] \t Loss 1.5613 \t Acc 52.10 \t AccHead 55.75 \t AccTail 46.66\n",
      "Epoch: [079] \t Loss 1.5784 \t Acc 52.42 \t AccHead 57.53 \t AccTail 44.81\n",
      "Epoch: [080] \t Loss 1.5450 \t Acc 48.91 \t AccHead 51.94 \t AccTail 44.38\n",
      "Epoch: [081] \t Loss 1.5528 \t Acc 52.24 \t AccHead 57.77 \t AccTail 44.00\n",
      "Epoch: [082] \t Loss 1.5669 \t Acc 54.77 \t AccHead 58.19 \t AccTail 49.67\n",
      "Epoch: [083] \t Loss 1.5539 \t Acc 53.87 \t AccHead 58.96 \t AccTail 46.27\n",
      "Epoch: [084] \t Loss 1.5582 \t Acc 52.26 \t AccHead 58.30 \t AccTail 43.25\n",
      "Epoch: [085] \t Loss 1.5454 \t Acc 55.40 \t AccHead 56.78 \t AccTail 53.34\n",
      "Epoch: [086] \t Loss 1.5533 \t Acc 55.20 \t AccHead 60.19 \t AccTail 47.77\n",
      "Epoch: [087] \t Loss 1.5569 \t Acc 54.43 \t AccHead 59.87 \t AccTail 46.31\n",
      "Epoch: [088] \t Loss 1.5314 \t Acc 55.00 \t AccHead 60.05 \t AccTail 47.46\n",
      "Epoch: [089] \t Loss 1.5333 \t Acc 54.73 \t AccHead 58.78 \t AccTail 48.68\n",
      "Epoch: [090] \t Loss 1.5210 \t Acc 54.81 \t AccHead 58.78 \t AccTail 48.88\n",
      "Epoch: [091] \t Loss 1.5048 \t Acc 53.41 \t AccHead 61.28 \t AccTail 41.64\n",
      "Epoch: [092] \t Loss 1.5180 \t Acc 53.61 \t AccHead 57.52 \t AccTail 47.77\n",
      "Epoch: [093] \t Loss 1.5250 \t Acc 54.44 \t AccHead 58.98 \t AccTail 47.67\n",
      "Epoch: [094] \t Loss 1.5115 \t Acc 54.74 \t AccHead 58.42 \t AccTail 49.25\n",
      "Epoch: [095] \t Loss 1.4907 \t Acc 56.84 \t AccHead 61.00 \t AccTail 50.64\n",
      "Epoch: [096] \t Loss 1.5007 \t Acc 54.49 \t AccHead 61.12 \t AccTail 44.58\n",
      "Epoch: [097] \t Loss 1.5142 \t Acc 52.10 \t AccHead 55.80 \t AccTail 46.57\n",
      "Epoch: [098] \t Loss 1.5005 \t Acc 52.57 \t AccHead 55.66 \t AccTail 47.97\n",
      "Epoch: [099] \t Loss 1.4861 \t Acc 57.61 \t AccHead 61.76 \t AccTail 51.41\n",
      "Epoch: [100] \t Loss 1.4893 \t Acc 52.00 \t AccHead 58.61 \t AccTail 42.13\n",
      "Epoch: [101] \t Loss 1.4818 \t Acc 50.28 \t AccHead 54.81 \t AccTail 43.49\n",
      "Epoch: [102] \t Loss 1.4770 \t Acc 53.14 \t AccHead 57.33 \t AccTail 46.87\n",
      "Epoch: [103] \t Loss 1.4874 \t Acc 56.79 \t AccHead 63.40 \t AccTail 46.91\n",
      "Epoch: [104] \t Loss 1.4854 \t Acc 54.02 \t AccHead 57.42 \t AccTail 48.95\n",
      "Epoch: [105] \t Loss 1.4944 \t Acc 53.15 \t AccHead 58.22 \t AccTail 45.58\n",
      "Epoch: [106] \t Loss 1.4643 \t Acc 53.37 \t AccHead 57.18 \t AccTail 47.69\n",
      "Epoch: [107] \t Loss 1.4505 \t Acc 54.72 \t AccHead 58.47 \t AccTail 49.13\n",
      "Epoch: [108] \t Loss 1.4395 \t Acc 51.82 \t AccHead 57.20 \t AccTail 43.79\n",
      "Epoch: [109] \t Loss 1.4678 \t Acc 59.80 \t AccHead 64.91 \t AccTail 52.18\n",
      "Epoch: [110] \t Loss 1.4436 \t Acc 54.57 \t AccHead 60.57 \t AccTail 45.62\n",
      "Epoch: [111] \t Loss 1.4511 \t Acc 56.09 \t AccHead 59.46 \t AccTail 51.07\n",
      "Epoch: [112] \t Loss 1.4709 \t Acc 58.07 \t AccHead 62.98 \t AccTail 50.75\n",
      "Epoch: [113] \t Loss 1.4555 \t Acc 56.22 \t AccHead 60.57 \t AccTail 49.71\n",
      "Epoch: [114] \t Loss 1.4509 \t Acc 57.96 \t AccHead 61.72 \t AccTail 52.35\n",
      "Epoch: [115] \t Loss 1.4486 \t Acc 53.10 \t AccHead 55.14 \t AccTail 50.05\n",
      "Epoch: [116] \t Loss 1.4393 \t Acc 54.06 \t AccHead 57.34 \t AccTail 49.16\n",
      "Epoch: [117] \t Loss 1.4378 \t Acc 56.84 \t AccHead 61.30 \t AccTail 50.19\n",
      "Epoch: [118] \t Loss 1.4266 \t Acc 55.23 \t AccHead 58.63 \t AccTail 50.15\n",
      "Epoch: [119] \t Loss 1.4286 \t Acc 55.71 \t AccHead 60.89 \t AccTail 47.98\n",
      "Epoch: [120] \t Loss 1.4266 \t Acc 56.25 \t AccHead 61.35 \t AccTail 48.65\n",
      "Epoch: [121] \t Loss 1.4299 \t Acc 57.03 \t AccHead 60.72 \t AccTail 51.51\n",
      "Epoch: [122] \t Loss 1.4295 \t Acc 54.30 \t AccHead 60.03 \t AccTail 45.75\n",
      "Epoch: [123] \t Loss 1.4140 \t Acc 56.98 \t AccHead 61.39 \t AccTail 50.38\n",
      "Epoch: [124] \t Loss 1.4262 \t Acc 57.72 \t AccHead 62.29 \t AccTail 50.92\n",
      "Epoch: [125] \t Loss 1.4071 \t Acc 57.47 \t AccHead 61.07 \t AccTail 52.08\n",
      "Epoch: [126] \t Loss 1.3998 \t Acc 56.62 \t AccHead 61.75 \t AccTail 48.96\n",
      "Epoch: [127] \t Loss 1.4163 \t Acc 56.23 \t AccHead 58.99 \t AccTail 52.11\n",
      "Epoch: [128] \t Loss 1.4079 \t Acc 53.57 \t AccHead 59.91 \t AccTail 44.09\n",
      "Epoch: [129] \t Loss 1.4001 \t Acc 56.63 \t AccHead 61.00 \t AccTail 50.11\n",
      "Epoch: [130] \t Loss 1.3791 \t Acc 56.20 \t AccHead 61.77 \t AccTail 47.91\n",
      "Epoch: [131] \t Loss 1.4049 \t Acc 56.93 \t AccHead 60.94 \t AccTail 50.94\n",
      "Epoch: [132] \t Loss 1.3964 \t Acc 57.59 \t AccHead 60.37 \t AccTail 53.44\n",
      "Epoch: [133] \t Loss 1.3748 \t Acc 58.43 \t AccHead 60.24 \t AccTail 55.72\n",
      "Epoch: [134] \t Loss 1.3832 \t Acc 58.52 \t AccHead 63.17 \t AccTail 51.57\n",
      "Epoch: [135] \t Loss 1.3882 \t Acc 61.55 \t AccHead 64.94 \t AccTail 56.49\n",
      "Epoch: [136] \t Loss 1.3979 \t Acc 57.92 \t AccHead 62.24 \t AccTail 51.47\n",
      "Epoch: [137] \t Loss 1.3776 \t Acc 57.87 \t AccHead 61.61 \t AccTail 52.28\n",
      "Epoch: [138] \t Loss 1.3765 \t Acc 55.83 \t AccHead 60.26 \t AccTail 49.23\n",
      "Epoch: [139] \t Loss 1.3814 \t Acc 58.80 \t AccHead 62.03 \t AccTail 53.98\n",
      "Epoch: [140] \t Loss 1.3612 \t Acc 56.75 \t AccHead 62.00 \t AccTail 48.89\n",
      "Epoch: [141] \t Loss 1.3660 \t Acc 55.01 \t AccHead 59.38 \t AccTail 48.50\n",
      "Epoch: [142] \t Loss 1.3699 \t Acc 59.57 \t AccHead 63.50 \t AccTail 53.72\n",
      "Epoch: [143] \t Loss 1.3770 \t Acc 60.48 \t AccHead 63.51 \t AccTail 55.95\n",
      "Epoch: [144] \t Loss 1.3553 \t Acc 56.28 \t AccHead 59.32 \t AccTail 51.74\n",
      "Epoch: [145] \t Loss 1.3769 \t Acc 57.13 \t AccHead 62.09 \t AccTail 49.74\n",
      "Epoch: [146] \t Loss 1.3572 \t Acc 60.49 \t AccHead 64.99 \t AccTail 53.75\n",
      "Epoch: [147] \t Loss 1.3659 \t Acc 55.44 \t AccHead 59.02 \t AccTail 50.10\n",
      "Epoch: [148] \t Loss 1.3660 \t Acc 57.21 \t AccHead 62.13 \t AccTail 49.86\n",
      "Epoch: [149] \t Loss 1.3715 \t Acc 60.39 \t AccHead 63.22 \t AccTail 56.17\n",
      "Epoch: [150] \t Loss 1.3496 \t Acc 58.58 \t AccHead 61.87 \t AccTail 53.69\n",
      "Epoch: [151] \t Loss 0.8475 \t Acc 82.60 \t AccHead 85.14 \t AccTail 78.80\n",
      "Epoch: [152] \t Loss 0.6033 \t Acc 86.01 \t AccHead 88.22 \t AccTail 82.71\n",
      "Epoch: [153] \t Loss 0.4998 \t Acc 88.57 \t AccHead 90.37 \t AccTail 85.88\n",
      "Epoch: [154] \t Loss 0.4331 \t Acc 90.32 \t AccHead 91.93 \t AccTail 87.93\n",
      "Epoch: [155] \t Loss 0.3805 \t Acc 91.62 \t AccHead 93.26 \t AccTail 89.18\n",
      "Epoch: [156] \t Loss 0.3449 \t Acc 92.91 \t AccHead 94.23 \t AccTail 90.95\n",
      "Epoch: [157] \t Loss 0.3074 \t Acc 93.84 \t AccHead 95.07 \t AccTail 91.99\n",
      "Epoch: [158] \t Loss 0.2825 \t Acc 94.71 \t AccHead 95.89 \t AccTail 92.94\n",
      "Epoch: [159] \t Loss 0.2543 \t Acc 95.12 \t AccHead 96.23 \t AccTail 93.46\n",
      "Epoch: [160] \t Loss 0.2282 \t Acc 95.85 \t AccHead 96.64 \t AccTail 94.69\n",
      "Epoch: [161] \t Loss 0.2120 \t Acc 96.20 \t AccHead 96.94 \t AccTail 95.10\n",
      "Epoch: [162] \t Loss 0.1949 \t Acc 96.92 \t AccHead 97.54 \t AccTail 95.98\n",
      "Epoch: [163] \t Loss 0.1778 \t Acc 97.20 \t AccHead 97.72 \t AccTail 96.42\n",
      "Epoch: [164] \t Loss 0.1620 \t Acc 97.63 \t AccHead 98.45 \t AccTail 96.41\n",
      "Epoch: [165] \t Loss 0.1540 \t Acc 97.45 \t AccHead 98.04 \t AccTail 96.57\n",
      "Epoch: [166] \t Loss 0.1404 \t Acc 97.66 \t AccHead 98.36 \t AccTail 96.61\n",
      "Epoch: [167] \t Loss 0.1328 \t Acc 98.15 \t AccHead 98.54 \t AccTail 97.58\n",
      "Epoch: [168] \t Loss 0.1243 \t Acc 98.08 \t AccHead 98.49 \t AccTail 97.45\n",
      "Epoch: [169] \t Loss 0.1154 \t Acc 98.23 \t AccHead 98.50 \t AccTail 97.83\n",
      "Epoch: [170] \t Loss 0.1096 \t Acc 98.50 \t AccHead 98.80 \t AccTail 98.05\n",
      "Epoch: [171] \t Loss 0.1056 \t Acc 98.63 \t AccHead 99.05 \t AccTail 98.00\n",
      "Epoch: [172] \t Loss 0.0969 \t Acc 98.75 \t AccHead 99.16 \t AccTail 98.13\n",
      "Epoch: [173] \t Loss 0.0943 \t Acc 98.80 \t AccHead 99.15 \t AccTail 98.29\n",
      "Epoch: [174] \t Loss 0.0892 \t Acc 98.82 \t AccHead 99.12 \t AccTail 98.38\n",
      "Epoch: [175] \t Loss 0.0907 \t Acc 98.65 \t AccHead 98.99 \t AccTail 98.14\n",
      "Epoch: [176] \t Loss 0.0828 \t Acc 98.91 \t AccHead 99.11 \t AccTail 98.60\n",
      "Epoch: [177] \t Loss 0.0819 \t Acc 98.84 \t AccHead 99.20 \t AccTail 98.32\n",
      "Epoch: [178] \t Loss 0.0789 \t Acc 98.85 \t AccHead 99.03 \t AccTail 98.57\n",
      "Epoch: [179] \t Loss 0.0786 \t Acc 98.89 \t AccHead 99.22 \t AccTail 98.40\n",
      "Epoch: [180] \t Loss 0.0785 \t Acc 99.01 \t AccHead 99.27 \t AccTail 98.63\n",
      "Epoch: [181] \t Loss 0.0732 \t Acc 99.08 \t AccHead 99.25 \t AccTail 98.83\n",
      "Epoch: [182] \t Loss 0.0690 \t Acc 99.04 \t AccHead 99.24 \t AccTail 98.74\n",
      "Epoch: [183] \t Loss 0.0749 \t Acc 99.01 \t AccHead 99.31 \t AccTail 98.56\n",
      "Epoch: [184] \t Loss 0.0716 \t Acc 99.03 \t AccHead 99.21 \t AccTail 98.78\n",
      "Epoch: [185] \t Loss 0.0676 \t Acc 99.18 \t AccHead 99.43 \t AccTail 98.81\n",
      "Epoch: [186] \t Loss 0.0713 \t Acc 99.06 \t AccHead 99.35 \t AccTail 98.64\n",
      "Epoch: [187] \t Loss 0.0722 \t Acc 99.01 \t AccHead 99.20 \t AccTail 98.73\n",
      "Epoch: [188] \t Loss 0.0704 \t Acc 99.12 \t AccHead 99.28 \t AccTail 98.88\n",
      "Epoch: [189] \t Loss 0.0700 \t Acc 99.12 \t AccHead 99.27 \t AccTail 98.89\n",
      "Epoch: [190] \t Loss 0.0705 \t Acc 99.01 \t AccHead 99.28 \t AccTail 98.61\n",
      "Epoch: [191] \t Loss 0.0734 \t Acc 99.06 \t AccHead 99.21 \t AccTail 98.85\n",
      "Epoch: [192] \t Loss 0.0678 \t Acc 98.89 \t AccHead 99.31 \t AccTail 98.26\n",
      "Epoch: [193] \t Loss 0.0683 \t Acc 99.06 \t AccHead 99.25 \t AccTail 98.78\n",
      "Epoch: [194] \t Loss 0.0685 \t Acc 99.15 \t AccHead 99.34 \t AccTail 98.86\n",
      "Epoch: [195] \t Loss 0.0694 \t Acc 99.04 \t AccHead 99.31 \t AccTail 98.63\n",
      "Epoch: [196] \t Loss 0.0681 \t Acc 99.05 \t AccHead 99.29 \t AccTail 98.70\n",
      "Epoch: [197] \t Loss 0.0651 \t Acc 99.07 \t AccHead 99.22 \t AccTail 98.84\n",
      "Epoch: [198] \t Loss 0.0709 \t Acc 99.09 \t AccHead 99.24 \t AccTail 98.86\n",
      "Epoch: [199] \t Loss 0.0660 \t Acc 98.90 \t AccHead 99.07 \t AccTail 98.65\n",
      "Epoch: [200] \t Loss 0.0678 \t Acc 98.94 \t AccHead 99.26 \t AccTail 98.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-18 05:55:48,701]\u001b[0m Trial 11 finished with value: 10.482787132263184 and parameters: {'n_epoch': 200, 'weight_decay': 0.0006700179119568688}. Best is trial 4 with value: 10.658534049987793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 10.48 \t AccHead 21.02 \t AccTail 0.10\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'CIFAR100' #['CIFAR10', 'CIFAR100']\n",
    "IMB_TYPE = 'step' #['exp', 'step']\n",
    "IMB_FACTOR = 0.01 #[0.1, 0.01]\n",
    "train_loader, test_loader, num_classes = get_loaders()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sampler = optuna.samplers.TPESampler()\n",
    "    study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "    study.optimize(func=train_model, n_trials=12)\n",
    "    joblib.dump(study, 'set_100_step_01.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aeab1b5a-364f-47b7-97ed-1f6653e78ff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T05:55:48.732988Z",
     "iopub.status.busy": "2022-06-18T05:55:48.732552Z",
     "iopub.status.idle": "2022-06-18T05:55:48.761961Z",
     "shell.execute_reply": "2022-06-18T05:55:48.761203Z",
     "shell.execute_reply.started": "2022-06-18T05:55:48.732940Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_n_epoch</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.046935</td>\n",
       "      <td>0 days 00:15:47.460978</td>\n",
       "      <td>90</td>\n",
       "      <td>0.008361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.818360</td>\n",
       "      <td>0 days 00:15:53.215305</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9.004445</td>\n",
       "      <td>0 days 00:15:52.490003</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.920087</td>\n",
       "      <td>0 days 00:15:54.608893</td>\n",
       "      <td>90</td>\n",
       "      <td>0.020430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10.658534</td>\n",
       "      <td>0 days 00:35:10.138892</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5.086323</td>\n",
       "      <td>0 days 00:35:09.802480</td>\n",
       "      <td>200</td>\n",
       "      <td>0.008873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.974568</td>\n",
       "      <td>0 days 00:15:58.526158</td>\n",
       "      <td>90</td>\n",
       "      <td>0.018706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>8.890726</td>\n",
       "      <td>0 days 00:15:51.404988</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2.977360</td>\n",
       "      <td>0 days 00:15:57.117649</td>\n",
       "      <td>90</td>\n",
       "      <td>0.006575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>8.280782</td>\n",
       "      <td>0 days 00:35:17.871600</td>\n",
       "      <td>200</td>\n",
       "      <td>0.003237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number      value               duration  params_n_epoch  \\\n",
       "0       0   2.046935 0 days 00:15:47.460978              90   \n",
       "1       1   8.818360 0 days 00:15:53.215305              90   \n",
       "2       2   9.004445 0 days 00:15:52.490003              90   \n",
       "3       3   0.920087 0 days 00:15:54.608893              90   \n",
       "4       4  10.658534 0 days 00:35:10.138892             200   \n",
       "5       5   5.086323 0 days 00:35:09.802480             200   \n",
       "6       6   1.974568 0 days 00:15:58.526158              90   \n",
       "7       7   8.890726 0 days 00:15:51.404988              90   \n",
       "8       8   2.977360 0 days 00:15:57.117649              90   \n",
       "9       9   8.280782 0 days 00:35:17.871600             200   \n",
       "\n",
       "   params_weight_decay  \n",
       "0             0.008361  \n",
       "1             0.000015  \n",
       "2             0.000232  \n",
       "3             0.020430  \n",
       "4             0.000828  \n",
       "5             0.008873  \n",
       "6             0.018706  \n",
       "7             0.000204  \n",
       "8             0.006575  \n",
       "9             0.003237  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = joblib.load('set_100_step_01.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ea30e37-4eaa-4499-9e6b-ba9a863befc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-23T05:43:04.692635Z",
     "iopub.status.busy": "2022-06-23T05:43:04.692131Z",
     "iopub.status.idle": "2022-06-23T05:43:04.742099Z",
     "shell.execute_reply": "2022-06-23T05:43:04.741387Z",
     "shell.execute_reply.started": "2022-06-23T05:43:04.692572Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>63.545456</td>\n",
       "      <td>0 days 00:16:38.094424</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>40.272728</td>\n",
       "      <td>0 days 00:16:49.030045</td>\n",
       "      <td>0.002888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>63.303032</td>\n",
       "      <td>0 days 00:16:46.738419</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>64.989899</td>\n",
       "      <td>0 days 00:16:35.773399</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>52.121212</td>\n",
       "      <td>0 days 00:16:32.594171</td>\n",
       "      <td>0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>63.828281</td>\n",
       "      <td>0 days 00:16:32.708094</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>56.181820</td>\n",
       "      <td>0 days 00:16:37.289671</td>\n",
       "      <td>0.000806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>33.070705</td>\n",
       "      <td>0 days 00:16:40.985060</td>\n",
       "      <td>0.003321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>62.838383</td>\n",
       "      <td>0 days 00:16:23.999368</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>63.272728</td>\n",
       "      <td>0 days 00:16:45.124516</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number      value               duration  params_weight_decay\n",
       "0       0  63.545456 0 days 00:16:38.094424             0.000272\n",
       "1       1  40.272728 0 days 00:16:49.030045             0.002888\n",
       "2       2  63.303032 0 days 00:16:46.738419             0.000025\n",
       "3       3  64.989899 0 days 00:16:35.773399             0.000052\n",
       "4       4  52.121212 0 days 00:16:32.594171             0.000695\n",
       "5       5  63.828281 0 days 00:16:32.708094             0.000014\n",
       "6       6  56.181820 0 days 00:16:37.289671             0.000806\n",
       "7       7  33.070705 0 days 00:16:40.985060             0.003321\n",
       "8       8  62.838383 0 days 00:16:23.999368             0.000022\n",
       "9       9  63.272728 0 days 00:16:45.124516             0.000121"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = joblib.load('set_10_step_1.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b416719-66d3-4ceb-9407-224d5fd5fb20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-23T05:43:11.797276Z",
     "iopub.status.busy": "2022-06-23T05:43:11.796818Z",
     "iopub.status.idle": "2022-06-23T05:43:11.829511Z",
     "shell.execute_reply": "2022-06-23T05:43:11.828622Z",
     "shell.execute_reply.started": "2022-06-23T05:43:11.797225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_n_epoch</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35.335155</td>\n",
       "      <td>0 days 00:35:15.375066</td>\n",
       "      <td>200</td>\n",
       "      <td>0.007382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>44.302902</td>\n",
       "      <td>0 days 00:34:58.414487</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>24.699223</td>\n",
       "      <td>0 days 00:35:06.414250</td>\n",
       "      <td>200</td>\n",
       "      <td>0.015852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>42.867252</td>\n",
       "      <td>0 days 00:34:57.689213</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>41.684361</td>\n",
       "      <td>0 days 00:15:56.394683</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>44.646648</td>\n",
       "      <td>0 days 00:35:09.745846</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>41.492268</td>\n",
       "      <td>0 days 00:15:56.506590</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>41.077747</td>\n",
       "      <td>0 days 00:34:48.574028</td>\n",
       "      <td>200</td>\n",
       "      <td>0.002343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>44.211910</td>\n",
       "      <td>0 days 00:35:02.353758</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>38.236782</td>\n",
       "      <td>0 days 00:15:44.087744</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number      value               duration  params_n_epoch  \\\n",
       "0       0  35.335155 0 days 00:35:15.375066             200   \n",
       "1       1  44.302902 0 days 00:34:58.414487             200   \n",
       "2       2  24.699223 0 days 00:35:06.414250             200   \n",
       "3       3  42.867252 0 days 00:34:57.689213             200   \n",
       "4       4  41.684361 0 days 00:15:56.394683              90   \n",
       "5       5  44.646648 0 days 00:35:09.745846             200   \n",
       "6       6  41.492268 0 days 00:15:56.506590              90   \n",
       "7       7  41.077747 0 days 00:34:48.574028             200   \n",
       "8       8  44.211910 0 days 00:35:02.353758             200   \n",
       "9       9  38.236782 0 days 00:15:44.087744              90   \n",
       "\n",
       "   params_weight_decay  \n",
       "0             0.007382  \n",
       "1             0.000257  \n",
       "2             0.015852  \n",
       "3             0.000022  \n",
       "4             0.000154  \n",
       "5             0.000288  \n",
       "6             0.000235  \n",
       "7             0.002343  \n",
       "8             0.000421  \n",
       "9             0.000979  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = joblib.load('set_10_step_01.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3dd55350-418c-4a68-bc9b-8c999051af85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T09:19:11.128008Z",
     "iopub.status.busy": "2022-06-18T09:19:11.127565Z",
     "iopub.status.idle": "2022-06-18T09:19:11.159550Z",
     "shell.execute_reply": "2022-06-18T09:19:11.158879Z",
     "shell.execute_reply.started": "2022-06-18T09:19:11.127959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31.877022</td>\n",
       "      <td>0 days 00:14:06.456049</td>\n",
       "      <td>0.005602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39.987862</td>\n",
       "      <td>0 days 00:14:11.593239</td>\n",
       "      <td>0.004971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>64.199028</td>\n",
       "      <td>0 days 00:14:16.540441</td>\n",
       "      <td>0.000634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>43.112862</td>\n",
       "      <td>0 days 00:14:14.050488</td>\n",
       "      <td>0.003426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>52.740692</td>\n",
       "      <td>0 days 00:14:17.540152</td>\n",
       "      <td>0.002612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>38.723705</td>\n",
       "      <td>0 days 00:14:16.798418</td>\n",
       "      <td>0.004207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>53.772247</td>\n",
       "      <td>0 days 00:14:07.148492</td>\n",
       "      <td>0.002109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>55.805016</td>\n",
       "      <td>0 days 00:14:13.198820</td>\n",
       "      <td>0.001185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>67.647652</td>\n",
       "      <td>0 days 00:14:08.406153</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>38.612457</td>\n",
       "      <td>0 days 00:14:02.489840</td>\n",
       "      <td>0.004171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number      value               duration  params_weight_decay\n",
       "0       0  31.877022 0 days 00:14:06.456049             0.005602\n",
       "1       1  39.987862 0 days 00:14:11.593239             0.004971\n",
       "2       2  64.199028 0 days 00:14:16.540441             0.000634\n",
       "3       3  43.112862 0 days 00:14:14.050488             0.003426\n",
       "4       4  52.740692 0 days 00:14:17.540152             0.002612\n",
       "5       5  38.723705 0 days 00:14:16.798418             0.004207\n",
       "6       6  53.772247 0 days 00:14:07.148492             0.002109\n",
       "7       7  55.805016 0 days 00:14:13.198820             0.001185\n",
       "8       8  67.647652 0 days 00:14:08.406153             0.000023\n",
       "9       9  38.612457 0 days 00:14:02.489840             0.004171"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = joblib.load('set_10_exp_1.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac4c77ad-bc30-4657-83ee-e47a3db33d05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T09:19:06.161070Z",
     "iopub.status.busy": "2022-06-18T09:19:06.160635Z",
     "iopub.status.idle": "2022-06-18T09:19:06.185739Z",
     "shell.execute_reply": "2022-06-18T09:19:06.185116Z",
     "shell.execute_reply.started": "2022-06-18T09:19:06.161022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>51.199997</td>\n",
       "      <td>0 days 00:12:15.557371</td>\n",
       "      <td>0.000410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>49.459999</td>\n",
       "      <td>0 days 00:12:02.644975</td>\n",
       "      <td>0.000963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>52.820000</td>\n",
       "      <td>0 days 00:12:10.245198</td>\n",
       "      <td>0.000166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>55.209999</td>\n",
       "      <td>0 days 00:12:04.400424</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>38.430000</td>\n",
       "      <td>0 days 00:12:12.288648</td>\n",
       "      <td>0.001987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>45.869999</td>\n",
       "      <td>0 days 00:12:21.222020</td>\n",
       "      <td>0.000987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>54.230000</td>\n",
       "      <td>0 days 00:12:17.140612</td>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>52.559998</td>\n",
       "      <td>0 days 00:12:26.544858</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>28.990000</td>\n",
       "      <td>0 days 00:12:19.172162</td>\n",
       "      <td>0.003362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>55.629997</td>\n",
       "      <td>0 days 00:12:17.106273</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number      value               duration  params_weight_decay\n",
       "0       0  51.199997 0 days 00:12:15.557371             0.000410\n",
       "1       1  49.459999 0 days 00:12:02.644975             0.000963\n",
       "2       2  52.820000 0 days 00:12:10.245198             0.000166\n",
       "3       3  55.209999 0 days 00:12:04.400424             0.000266\n",
       "4       4  38.430000 0 days 00:12:12.288648             0.001987\n",
       "5       5  45.869999 0 days 00:12:21.222020             0.000987\n",
       "6       6  54.230000 0 days 00:12:17.140612             0.000154\n",
       "7       7  52.559998 0 days 00:12:26.544858             0.000058\n",
       "8       8  28.990000 0 days 00:12:19.172162             0.003362\n",
       "9       9  55.629997 0 days 00:12:17.106273             0.000047"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = joblib.load('set_10_exp_01.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c579a432-0e55-43a2-8af5-6c2129310c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T09:18:58.534912Z",
     "iopub.status.busy": "2022-06-18T09:18:58.534451Z",
     "iopub.status.idle": "2022-06-18T09:18:58.563687Z",
     "shell.execute_reply": "2022-06-18T09:18:58.563068Z",
     "shell.execute_reply.started": "2022-06-18T09:18:58.534838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_n_epoch</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.033485</td>\n",
       "      <td>0 days 00:31:00.387800</td>\n",
       "      <td>200</td>\n",
       "      <td>0.037809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.340223</td>\n",
       "      <td>0 days 00:13:55.552840</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9.270360</td>\n",
       "      <td>0 days 00:30:53.134421</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8.691608</td>\n",
       "      <td>0 days 00:14:00.592525</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9.125672</td>\n",
       "      <td>0 days 00:13:54.098197</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>10.272840</td>\n",
       "      <td>0 days 00:30:27.863838</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>10.572551</td>\n",
       "      <td>0 days 00:30:33.004942</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>8.360893</td>\n",
       "      <td>0 days 00:13:42.935642</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.033485</td>\n",
       "      <td>0 days 00:13:18.556360</td>\n",
       "      <td>90</td>\n",
       "      <td>0.068770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.033485</td>\n",
       "      <td>0 days 00:13:26.297676</td>\n",
       "      <td>90</td>\n",
       "      <td>0.047246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>9.394378</td>\n",
       "      <td>0 days 00:29:50.833744</td>\n",
       "      <td>200</td>\n",
       "      <td>0.003729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>9.487391</td>\n",
       "      <td>0 days 00:29:51.319172</td>\n",
       "      <td>200</td>\n",
       "      <td>0.004207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number      value               duration  params_n_epoch  \\\n",
       "0        0   1.033485 0 days 00:31:00.387800             200   \n",
       "1        1   8.340223 0 days 00:13:55.552840              90   \n",
       "2        2   9.270360 0 days 00:30:53.134421             200   \n",
       "3        3   8.691608 0 days 00:14:00.592525              90   \n",
       "4        4   9.125672 0 days 00:13:54.098197              90   \n",
       "5        5  10.272840 0 days 00:30:27.863838             200   \n",
       "6        6  10.572551 0 days 00:30:33.004942             200   \n",
       "7        7   8.360893 0 days 00:13:42.935642              90   \n",
       "8        8   1.033485 0 days 00:13:18.556360              90   \n",
       "9        9   1.033485 0 days 00:13:26.297676              90   \n",
       "10      10   9.394378 0 days 00:29:50.833744             200   \n",
       "11      11   9.487391 0 days 00:29:51.319172             200   \n",
       "\n",
       "    params_weight_decay  \n",
       "0              0.037809  \n",
       "1              0.000682  \n",
       "2              0.000013  \n",
       "3              0.000073  \n",
       "4              0.000073  \n",
       "5              0.000257  \n",
       "6              0.001405  \n",
       "7              0.000526  \n",
       "8              0.068770  \n",
       "9              0.047246  \n",
       "10             0.003729  \n",
       "11             0.004207  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = joblib.load('set_100_exp_1.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b98add41-cf89-49e1-8a1a-8236fa7f5068",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T09:18:55.161861Z",
     "iopub.status.busy": "2022-06-18T09:18:55.161421Z",
     "iopub.status.idle": "2022-06-18T09:18:55.189913Z",
     "shell.execute_reply": "2022-06-18T09:18:55.189266Z",
     "shell.execute_reply.started": "2022-06-18T09:18:55.161812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_n_epoch</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.131880</td>\n",
       "      <td>0 days 00:10:21.297956</td>\n",
       "      <td>90</td>\n",
       "      <td>0.029963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.085151</td>\n",
       "      <td>0 days 00:23:31.749703</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.192108</td>\n",
       "      <td>0 days 00:10:51.839308</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.430945</td>\n",
       "      <td>0 days 00:10:51.158423</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.038422</td>\n",
       "      <td>0 days 00:23:44.966203</td>\n",
       "      <td>200</td>\n",
       "      <td>0.066359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6.085151</td>\n",
       "      <td>0 days 00:23:45.929806</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2.253375</td>\n",
       "      <td>0 days 00:10:17.861273</td>\n",
       "      <td>90</td>\n",
       "      <td>0.022016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2.585670</td>\n",
       "      <td>0 days 00:10:29.631700</td>\n",
       "      <td>90</td>\n",
       "      <td>0.007837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>4.953271</td>\n",
       "      <td>0 days 00:10:33.087734</td>\n",
       "      <td>90</td>\n",
       "      <td>0.001553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5.908619</td>\n",
       "      <td>0 days 00:22:57.850075</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5.233645</td>\n",
       "      <td>0 days 00:23:01.993573</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>5.763240</td>\n",
       "      <td>0 days 00:23:48.775123</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value               duration  params_n_epoch  \\\n",
       "0        0  1.131880 0 days 00:10:21.297956              90   \n",
       "1        1  6.085151 0 days 00:23:31.749703             200   \n",
       "2        2  5.192108 0 days 00:10:51.839308              90   \n",
       "3        3  5.430945 0 days 00:10:51.158423              90   \n",
       "4        4  1.038422 0 days 00:23:44.966203             200   \n",
       "5        5  6.085151 0 days 00:23:45.929806             200   \n",
       "6        6  2.253375 0 days 00:10:17.861273              90   \n",
       "7        7  2.585670 0 days 00:10:29.631700              90   \n",
       "8        8  4.953271 0 days 00:10:33.087734              90   \n",
       "9        9  5.908619 0 days 00:22:57.850075             200   \n",
       "10      10  5.233645 0 days 00:23:01.993573             200   \n",
       "11      11  5.763240 0 days 00:23:48.775123             200   \n",
       "\n",
       "    params_weight_decay  \n",
       "0              0.029963  \n",
       "1              0.001043  \n",
       "2              0.000493  \n",
       "3              0.000039  \n",
       "4              0.066359  \n",
       "5              0.000571  \n",
       "6              0.022016  \n",
       "7              0.007837  \n",
       "8              0.001553  \n",
       "9              0.000697  \n",
       "10             0.000020  \n",
       "11             0.000100  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = joblib.load('set_100_exp_01.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0bd28e76-c3c8-49bd-8a0c-f2e7b88a0fa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T09:18:44.161152Z",
     "iopub.status.busy": "2022-06-18T09:18:44.160706Z",
     "iopub.status.idle": "2022-06-18T09:18:44.187621Z",
     "shell.execute_reply": "2022-06-18T09:18:44.186892Z",
     "shell.execute_reply.started": "2022-06-18T09:18:44.161102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>63.545456</td>\n",
       "      <td>0 days 00:16:38.094424</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>40.272728</td>\n",
       "      <td>0 days 00:16:49.030045</td>\n",
       "      <td>0.002888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>63.303032</td>\n",
       "      <td>0 days 00:16:46.738419</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>64.989899</td>\n",
       "      <td>0 days 00:16:35.773399</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>52.121212</td>\n",
       "      <td>0 days 00:16:32.594171</td>\n",
       "      <td>0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>63.828281</td>\n",
       "      <td>0 days 00:16:32.708094</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>56.181820</td>\n",
       "      <td>0 days 00:16:37.289671</td>\n",
       "      <td>0.000806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>33.070705</td>\n",
       "      <td>0 days 00:16:40.985060</td>\n",
       "      <td>0.003321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>62.838383</td>\n",
       "      <td>0 days 00:16:23.999368</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>63.272728</td>\n",
       "      <td>0 days 00:16:45.124516</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number      value               duration  params_weight_decay\n",
       "0       0  63.545456 0 days 00:16:38.094424             0.000272\n",
       "1       1  40.272728 0 days 00:16:49.030045             0.002888\n",
       "2       2  63.303032 0 days 00:16:46.738419             0.000025\n",
       "3       3  64.989899 0 days 00:16:35.773399             0.000052\n",
       "4       4  52.121212 0 days 00:16:32.594171             0.000695\n",
       "5       5  63.828281 0 days 00:16:32.708094             0.000014\n",
       "6       6  56.181820 0 days 00:16:37.289671             0.000806\n",
       "7       7  33.070705 0 days 00:16:40.985060             0.003321\n",
       "8       8  62.838383 0 days 00:16:23.999368             0.000022\n",
       "9       9  63.272728 0 days 00:16:45.124516             0.000121"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = joblib.load('set_10_step_1.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fd5b8830-dcf4-4d7a-b1d5-fb8e394e17fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T09:18:39.412993Z",
     "iopub.status.busy": "2022-06-18T09:18:39.412547Z",
     "iopub.status.idle": "2022-06-18T09:18:39.441079Z",
     "shell.execute_reply": "2022-06-18T09:18:39.440422Z",
     "shell.execute_reply.started": "2022-06-18T09:18:39.412943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_n_epoch</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35.335155</td>\n",
       "      <td>0 days 00:35:15.375066</td>\n",
       "      <td>200</td>\n",
       "      <td>0.007382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>44.302902</td>\n",
       "      <td>0 days 00:34:58.414487</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>24.699223</td>\n",
       "      <td>0 days 00:35:06.414250</td>\n",
       "      <td>200</td>\n",
       "      <td>0.015852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>42.867252</td>\n",
       "      <td>0 days 00:34:57.689213</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>41.684361</td>\n",
       "      <td>0 days 00:15:56.394683</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>44.646648</td>\n",
       "      <td>0 days 00:35:09.745846</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>41.492268</td>\n",
       "      <td>0 days 00:15:56.506590</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>41.077747</td>\n",
       "      <td>0 days 00:34:48.574028</td>\n",
       "      <td>200</td>\n",
       "      <td>0.002343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>44.211910</td>\n",
       "      <td>0 days 00:35:02.353758</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>38.236782</td>\n",
       "      <td>0 days 00:15:44.087744</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10.110201</td>\n",
       "      <td>0 days 00:35:10.911606</td>\n",
       "      <td>200</td>\n",
       "      <td>0.084512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>43.494087</td>\n",
       "      <td>0 days 00:35:07.986056</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number      value               duration  params_n_epoch  \\\n",
       "0        0  35.335155 0 days 00:35:15.375066             200   \n",
       "1        1  44.302902 0 days 00:34:58.414487             200   \n",
       "2        2  24.699223 0 days 00:35:06.414250             200   \n",
       "3        3  42.867252 0 days 00:34:57.689213             200   \n",
       "4        4  41.684361 0 days 00:15:56.394683              90   \n",
       "5        5  44.646648 0 days 00:35:09.745846             200   \n",
       "6        6  41.492268 0 days 00:15:56.506590              90   \n",
       "7        7  41.077747 0 days 00:34:48.574028             200   \n",
       "8        8  44.211910 0 days 00:35:02.353758             200   \n",
       "9        9  38.236782 0 days 00:15:44.087744              90   \n",
       "10      10  10.110201 0 days 00:35:10.911606             200   \n",
       "11      11  43.494087 0 days 00:35:07.986056             200   \n",
       "\n",
       "    params_weight_decay  \n",
       "0              0.007382  \n",
       "1              0.000257  \n",
       "2              0.015852  \n",
       "3              0.000022  \n",
       "4              0.000154  \n",
       "5              0.000288  \n",
       "6              0.000235  \n",
       "7              0.002343  \n",
       "8              0.000421  \n",
       "9              0.000979  \n",
       "10             0.084512  \n",
       "11             0.000036  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = joblib.load('set_10_step_01.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c7185ea-50f6-41f5-bf6a-5b436f112e8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T09:18:34.161532Z",
     "iopub.status.busy": "2022-06-18T09:18:34.161095Z",
     "iopub.status.idle": "2022-06-18T09:18:34.190118Z",
     "shell.execute_reply": "2022-06-18T09:18:34.189443Z",
     "shell.execute_reply.started": "2022-06-18T09:18:34.161482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_n_epoch</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9.794776</td>\n",
       "      <td>0 days 00:36:25.838325</td>\n",
       "      <td>200</td>\n",
       "      <td>0.002314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.358624</td>\n",
       "      <td>0 days 00:36:40.001090</td>\n",
       "      <td>200</td>\n",
       "      <td>0.005399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.430763</td>\n",
       "      <td>0 days 00:16:31.675795</td>\n",
       "      <td>90</td>\n",
       "      <td>0.003465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.036484</td>\n",
       "      <td>0 days 00:16:42.299458</td>\n",
       "      <td>90</td>\n",
       "      <td>0.037093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.036484</td>\n",
       "      <td>0 days 00:36:49.319264</td>\n",
       "      <td>200</td>\n",
       "      <td>0.019981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>10.157546</td>\n",
       "      <td>0 days 00:36:59.615525</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.886401</td>\n",
       "      <td>0 days 00:16:33.863514</td>\n",
       "      <td>90</td>\n",
       "      <td>0.013638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.036484</td>\n",
       "      <td>0 days 00:36:39.593646</td>\n",
       "      <td>200</td>\n",
       "      <td>0.022443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8.665009</td>\n",
       "      <td>0 days 00:16:31.285765</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>8.665009</td>\n",
       "      <td>0 days 00:16:27.817277</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>9.670398</td>\n",
       "      <td>0 days 00:36:33.130358</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>10.199005</td>\n",
       "      <td>0 days 00:36:54.335330</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number      value               duration  params_n_epoch  \\\n",
       "0        0   9.794776 0 days 00:36:25.838325             200   \n",
       "1        1   5.358624 0 days 00:36:40.001090             200   \n",
       "2        2   3.430763 0 days 00:16:31.675795              90   \n",
       "3        3   1.036484 0 days 00:16:42.299458              90   \n",
       "4        4   1.036484 0 days 00:36:49.319264             200   \n",
       "5        5  10.157546 0 days 00:36:59.615525             200   \n",
       "6        6   1.886401 0 days 00:16:33.863514              90   \n",
       "7        7   1.036484 0 days 00:36:39.593646             200   \n",
       "8        8   8.665009 0 days 00:16:31.285765              90   \n",
       "9        9   8.665009 0 days 00:16:27.817277              90   \n",
       "10      10   9.670398 0 days 00:36:33.130358             200   \n",
       "11      11  10.199005 0 days 00:36:54.335330             200   \n",
       "\n",
       "    params_weight_decay  \n",
       "0              0.002314  \n",
       "1              0.005399  \n",
       "2              0.003465  \n",
       "3              0.037093  \n",
       "4              0.019981  \n",
       "5              0.001366  \n",
       "6              0.013638  \n",
       "7              0.022443  \n",
       "8              0.000019  \n",
       "9              0.000015  \n",
       "10             0.000211  \n",
       "11             0.000479  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = joblib.load('set_100_step_1.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8c739f4f-da0f-472e-aab5-6e59e3929fc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T09:15:41.175065Z",
     "iopub.status.busy": "2022-06-18T09:15:41.174199Z",
     "iopub.status.idle": "2022-06-18T09:15:41.207599Z",
     "shell.execute_reply": "2022-06-18T09:15:41.207006Z",
     "shell.execute_reply.started": "2022-06-18T09:15:41.175000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_n_epoch</th>\n",
       "      <th>params_weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.046935</td>\n",
       "      <td>0 days 00:15:47.460978</td>\n",
       "      <td>90</td>\n",
       "      <td>0.008361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.818360</td>\n",
       "      <td>0 days 00:15:53.215305</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9.004445</td>\n",
       "      <td>0 days 00:15:52.490003</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.920087</td>\n",
       "      <td>0 days 00:15:54.608893</td>\n",
       "      <td>90</td>\n",
       "      <td>0.020430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10.658534</td>\n",
       "      <td>0 days 00:35:10.138892</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5.086323</td>\n",
       "      <td>0 days 00:35:09.802480</td>\n",
       "      <td>200</td>\n",
       "      <td>0.008873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.974568</td>\n",
       "      <td>0 days 00:15:58.526158</td>\n",
       "      <td>90</td>\n",
       "      <td>0.018706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>8.890726</td>\n",
       "      <td>0 days 00:15:51.404988</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2.977360</td>\n",
       "      <td>0 days 00:15:57.117649</td>\n",
       "      <td>90</td>\n",
       "      <td>0.006575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>8.280782</td>\n",
       "      <td>0 days 00:35:17.871600</td>\n",
       "      <td>200</td>\n",
       "      <td>0.003237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10.255349</td>\n",
       "      <td>0 days 00:35:05.484656</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>10.482787</td>\n",
       "      <td>0 days 00:35:13.107166</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number      value               duration  params_n_epoch  \\\n",
       "0        0   2.046935 0 days 00:15:47.460978              90   \n",
       "1        1   8.818360 0 days 00:15:53.215305              90   \n",
       "2        2   9.004445 0 days 00:15:52.490003              90   \n",
       "3        3   0.920087 0 days 00:15:54.608893              90   \n",
       "4        4  10.658534 0 days 00:35:10.138892             200   \n",
       "5        5   5.086323 0 days 00:35:09.802480             200   \n",
       "6        6   1.974568 0 days 00:15:58.526158              90   \n",
       "7        7   8.890726 0 days 00:15:51.404988              90   \n",
       "8        8   2.977360 0 days 00:15:57.117649              90   \n",
       "9        9   8.280782 0 days 00:35:17.871600             200   \n",
       "10      10  10.255349 0 days 00:35:05.484656             200   \n",
       "11      11  10.482787 0 days 00:35:13.107166             200   \n",
       "\n",
       "    params_weight_decay  \n",
       "0              0.008361  \n",
       "1              0.000015  \n",
       "2              0.000232  \n",
       "3              0.020430  \n",
       "4              0.000828  \n",
       "5              0.008873  \n",
       "6              0.018706  \n",
       "7              0.000204  \n",
       "8              0.006575  \n",
       "9              0.003237  \n",
       "10             0.000482  \n",
       "11             0.000670  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = joblib.load('set_100_step_01.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.9.0-py3.8-cuda11.1",
   "language": "python",
   "name": "torch1.9.0-py3.8-cuda11.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
